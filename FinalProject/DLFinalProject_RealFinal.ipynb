{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVAsdBGqBquX",
        "outputId": "415500bd-94d1-4084-cf39-74263922fbdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.40-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.40-py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.40 ultralytics-thop-2.0.12\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting bdd100k\n",
            "  Downloading bdd100k-1.0.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting gmplot (from bdd100k)\n",
            "  Downloading gmplot-1.4.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from bdd100k) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bdd100k) (3.8.0)\n",
            "Collecting motmetrics (from bdd100k)\n",
            "  Downloading motmetrics-1.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bdd100k) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from bdd100k) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from bdd100k) (11.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from bdd100k) (2.0.8)\n",
            "Collecting scalabel (from bdd100k)\n",
            "  Downloading scalabel-0.3.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from bdd100k) (0.24.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from bdd100k) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bdd100k) (4.66.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from bdd100k) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gmplot->bdd100k) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bdd100k) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bdd100k) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bdd100k) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bdd100k) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bdd100k) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bdd100k) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bdd100k) (2.8.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from motmetrics->bdd100k) (1.13.1)\n",
            "Collecting xmltodict>=0.12.0 (from motmetrics->bdd100k)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->bdd100k) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->bdd100k) (2024.2)\n",
            "Collecting boto3 (from scalabel->bdd100k)\n",
            "  Downloading boto3-1.35.72-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting nanoid (from scalabel->bdd100k)\n",
            "  Downloading nanoid-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting plyfile (from scalabel->bdd100k)\n",
            "  Downloading plyfile-1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from scalabel->bdd100k) (5.9.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from scalabel->bdd100k) (2.9.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from scalabel->bdd100k) (6.0.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->bdd100k) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->bdd100k) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->bdd100k) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->bdd100k) (0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->bdd100k) (1.16.0)\n",
            "Collecting botocore<1.36.0,>=1.35.72 (from boto3->scalabel->bdd100k)\n",
            "  Downloading botocore-1.35.72-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->scalabel->bdd100k)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->scalabel->bdd100k)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->scalabel->bdd100k) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->scalabel->bdd100k) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->scalabel->bdd100k) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gmplot->bdd100k) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gmplot->bdd100k) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gmplot->bdd100k) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gmplot->bdd100k) (2024.8.30)\n",
            "Downloading bdd100k-1.0.1-py3-none-any.whl (54 kB)\n",
            "Downloading gmplot-1.4.1-py3-none-any.whl (164 kB)\n",
            "Downloading motmetrics-1.4.0-py3-none-any.whl (161 kB)\n",
            "Downloading scalabel-0.3.1-py3-none-any.whl (133 kB)\n",
            "Downloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading boto3-1.35.72-py3-none-any.whl (139 kB)\n",
            "Downloading nanoid-2.0.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading plyfile-1.1-py3-none-any.whl (23 kB)\n",
            "Downloading botocore-1.35.72-py3-none-any.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: nanoid, xmltodict, plyfile, jmespath, gmplot, botocore, s3transfer, motmetrics, boto3, scalabel, bdd100k\n",
            "Successfully installed bdd100k-1.0.1 boto3-1.35.72 botocore-1.35.72 gmplot-1.4.1 jmespath-1.0.1 motmetrics-1.4.0 nanoid-2.0.0 plyfile-1.1 s3transfer-0.10.4 scalabel-0.3.1 xmltodict-0.14.2\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Collecting jupyter_contrib_nbextensions\n",
            "  Downloading jupyter_contrib_nbextensions-0.7.0.tar.gz (23.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython_genutils in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_nbextensions) (0.2.0)\n",
            "Collecting jupyter_contrib_core>=0.3.3 (from jupyter_contrib_nbextensions)\n",
            "  Downloading jupyter_contrib_core-0.4.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jupyter_core in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_nbextensions) (5.7.2)\n",
            "Collecting jupyter_highlight_selected_word>=0.1.1 (from jupyter_contrib_nbextensions)\n",
            "  Downloading jupyter_highlight_selected_word-0.2.0-py2.py3-none-any.whl.metadata (730 bytes)\n",
            "Collecting jupyter_nbextensions_configurator>=0.4.0 (from jupyter_contrib_nbextensions)\n",
            "  Downloading jupyter_nbextensions_configurator-0.6.4-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nbconvert>=6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_nbextensions) (7.16.4)\n",
            "Requirement already satisfied: notebook>=6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_nbextensions) (6.5.5)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_nbextensions) (6.3.3)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_nbextensions) (5.7.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_nbextensions) (5.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from jupyter_contrib_core>=0.3.3->jupyter_contrib_nbextensions) (75.1.0)\n",
            "Requirement already satisfied: jupyter-server in /usr/local/lib/python3.10/dist-packages (from jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.24.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (6.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.1.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (2.18.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.0->jupyter_contrib_nbextensions) (1.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter_core->jupyter_contrib_nbextensions) (4.3.6)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (5.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.0->jupyter_contrib_nbextensions) (1.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=6.0->jupyter_contrib_nbextensions) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8,>=5.3.4->notebook>=6.0->jupyter_contrib_nbextensions) (2.8.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=6.0->jupyter_contrib_nbextensions) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert>=6.0->jupyter_contrib_nbextensions) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert>=6.0->jupyter_contrib_nbextensions) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook>=6.0->jupyter_contrib_nbextensions) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=6.0->jupyter_contrib_nbextensions) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.0->jupyter_contrib_nbextensions) (2.6)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (7.34.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server->jupyter_nbextensions_configurator>=0.4.0->jupyter_contrib_nbextensions) (1.2.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert>=6.0->jupyter_contrib_nbextensions) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert>=6.0->jupyter_contrib_nbextensions) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert>=6.0->jupyter_contrib_nbextensions) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert>=6.0->jupyter_contrib_nbextensions) (0.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client<8,>=5.3.4->notebook>=6.0->jupyter_contrib_nbextensions) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=6.0->jupyter_contrib_nbextensions) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=6.0->jupyter_contrib_nbextensions) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook>=6.0->jupyter_contrib_nbextensions) (0.2.13)\n",
            "Downloading jupyter_highlight_selected_word-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading jupyter_nbextensions_configurator-0.6.4-py2.py3-none-any.whl (466 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: jupyter_contrib_nbextensions, jupyter_contrib_core\n",
            "  Building wheel for jupyter_contrib_nbextensions (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jupyter_contrib_nbextensions: filename=jupyter_contrib_nbextensions-0.7.0-py2.py3-none-any.whl size=23428768 sha256=025f2e14ffed0d994a664b9e5f72a4724608b3db9f91cc77b6f874fe5abd2356\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/cc/7d/99ef154f984726b1201c0f72cfe9c9d7c5132c1a2ae4d8677f\n",
            "  Building wheel for jupyter_contrib_core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jupyter_contrib_core: filename=jupyter_contrib_core-0.4.2-py2.py3-none-any.whl size=17475 sha256=6ffc32c8fc3596378d448b7237cd2d90c189619019362a9e0eea35d313cfa2f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/52/88/e0643cdfd68f0562087918c37dd583378648dbc3df68b907f7\n",
            "Successfully built jupyter_contrib_nbextensions jupyter_contrib_core\n",
            "Installing collected packages: jupyter_highlight_selected_word, jedi, jupyter_contrib_core, jupyter_nbextensions_configurator, jupyter_contrib_nbextensions\n",
            "Successfully installed jedi-0.19.2 jupyter_contrib_core-0.4.2 jupyter_contrib_nbextensions-0.7.0 jupyter_highlight_selected_word-0.2.0 jupyter_nbextensions_configurator-0.6.4\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "bdd100k                            1.0.1\n",
            "geopandas                          1.0.1\n",
            "matplotlib                         3.8.0\n",
            "matplotlib-inline                  0.1.7\n",
            "matplotlib-venn                    1.1.1\n",
            "numpy                              1.26.4\n",
            "opencv-contrib-python              4.10.0.84\n",
            "opencv-python                      4.10.0.84\n",
            "opencv-python-headless             4.10.0.84\n",
            "pandas                             2.2.2\n",
            "pandas-datareader                  0.10.0\n",
            "pandas-gbq                         0.24.0\n",
            "pandas-stubs                       2.2.2.240909\n",
            "sklearn-pandas                     2.2.0\n",
            "torch                              2.5.1+cu121\n",
            "torchaudio                         2.5.1+cu121\n",
            "torchsummary                       1.5.1\n",
            "torchvision                        0.20.1+cu121\n",
            "ultralytics                        8.3.40\n",
            "ultralytics-thop                   2.0.12\n"
          ]
        }
      ],
      "source": [
        "# Upgrade pip to the latest version\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Install ultralytics for YOLOv8\n",
        "!pip install ultralytics\n",
        "\n",
        "# Install torch and torchvision\n",
        "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install additional libraries for data processing\n",
        "!pip install pandas numpy matplotlib opencv-python scikit-learn tqdm\n",
        "\n",
        "# Install libraries for handling BDD100K dataset and annotations\n",
        "!pip install bdd100k\n",
        "\n",
        "# Install PyYAML for configuration handling\n",
        "!pip install pyyaml\n",
        "\n",
        "# Install Jupyter extensions (optional but helpful in Colab)\n",
        "!pip install jupyter_contrib_nbextensions\n",
        "\n",
        "# Install any visualization tools for better experiment tracking\n",
        "!pip install seaborn plotly\n",
        "\n",
        "# For logging and experiment tracking (optional)\n",
        "!pip install wandb\n",
        "\n",
        "# Verification step to check installed libraries and versions\n",
        "!pip list | grep -E 'torch|ultralytics|numpy|opencv|pandas|bdd100k|matplotlib'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define paths to the datasets in Google Drive\n",
        "train_images_zip = \"/content/drive/My Drive/100k_images_train.zip\"\n",
        "val_images_zip = \"/content/drive/My Drive/100k_images_val.zip\"\n",
        "labels_zip = \"/content/drive/My Drive/bdd100k_det_20_labels_trainval.zip\"\n",
        "\n",
        "# Step 3: Create directories to store the extracted data\n",
        "os.makedirs(\"/content/data/train_images\", exist_ok=True)\n",
        "os.makedirs(\"/content/data/val_images\", exist_ok=True)\n",
        "os.makedirs(\"/content/data/labels\", exist_ok=True)\n",
        "\n",
        "# Step 4: Function to extract zip files\n",
        "def extract_zip(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extracted: {zip_path} to {extract_to}\")\n",
        "\n",
        "# Step 5: Extract datasets\n",
        "extract_zip(train_images_zip, \"/content/data/train_images\")\n",
        "extract_zip(val_images_zip, \"/content/data/val_images\")\n",
        "extract_zip(labels_zip, \"/content/data/labels\")\n",
        "\n",
        "print(\"All files have been successfully extracted!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3D7_qS0GEty",
        "outputId": "8382c95d-15b2-4f78-bc89-14ed480b408b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extracted: /content/drive/My Drive/100k_images_train.zip to /content/data/train_images\n",
            "Extracted: /content/drive/My Drive/100k_images_val.zip to /content/data/val_images\n",
            "Extracted: /content/drive/My Drive/bdd100k_det_20_labels_trainval.zip to /content/data/labels\n",
            "All files have been successfully extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Paths to the example files\n",
        "train_image_path = \"/content/data/train_images/bdd100k/images/100k/train\"\n",
        "val_image_path = \"/content/data/val_images/bdd100k/images/100k/val\"\n",
        "train_json_path = \"/content/data/labels/bdd100k/labels/det_20/det_train.json\"\n",
        "\n",
        "# Step 1: Load and display an example train image\n",
        "train_image_file = os.listdir(train_image_path)[0]  # First image from train folder\n",
        "train_image = cv2.imread(os.path.join(train_image_path, train_image_file))\n",
        "train_image = cv2.cvtColor(train_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(train_image)\n",
        "plt.title(\"Example Train Image\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 2: Load and display an example val image\n",
        "val_image_file = os.listdir(val_image_path)[0]  # First image from val folder\n",
        "val_image = cv2.imread(os.path.join(val_image_path, val_image_file))\n",
        "val_image = cv2.cvtColor(val_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(val_image)\n",
        "plt.title(\"Example Validation Image\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Load and display the first element of det_train.json\n",
        "with open(train_json_path, 'r') as f:\n",
        "    train_annotations = json.load(f)\n",
        "\n",
        "# Display the first element\n",
        "print(\"First element in det_train.json:\")\n",
        "print(json.dumps(train_annotations[0], indent=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UWXoFadwHyOK",
        "outputId": "d840d3a2-6a7f-43e3-80d7-d8cc65e34017"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First element in det_train.json:\n",
            "{\n",
            "    \"name\": \"0000f77c-6257be58.jpg\",\n",
            "    \"attributes\": {\n",
            "        \"weather\": \"clear\",\n",
            "        \"timeofday\": \"daytime\",\n",
            "        \"scene\": \"city street\"\n",
            "    },\n",
            "    \"timestamp\": 10000,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"id\": \"0\",\n",
            "            \"attributes\": {\n",
            "                \"occluded\": false,\n",
            "                \"truncated\": false,\n",
            "                \"trafficLightColor\": \"G\"\n",
            "            },\n",
            "            \"category\": \"traffic light\",\n",
            "            \"box2d\": {\n",
            "                \"x1\": 1125.902264,\n",
            "                \"y1\": 133.184488,\n",
            "                \"x2\": 1156.978645,\n",
            "                \"y2\": 210.875445\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"1\",\n",
            "            \"attributes\": {\n",
            "                \"occluded\": false,\n",
            "                \"truncated\": false,\n",
            "                \"trafficLightColor\": \"G\"\n",
            "            },\n",
            "            \"category\": \"traffic light\",\n",
            "            \"box2d\": {\n",
            "                \"x1\": 1156.978645,\n",
            "                \"y1\": 136.637417,\n",
            "                \"x2\": 1191.50796,\n",
            "                \"y2\": 210.875443\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"2\",\n",
            "            \"attributes\": {\n",
            "                \"occluded\": false,\n",
            "                \"truncated\": false,\n",
            "                \"trafficLightColor\": \"NA\"\n",
            "            },\n",
            "            \"category\": \"traffic sign\",\n",
            "            \"box2d\": {\n",
            "                \"x1\": 1105.66915985699,\n",
            "                \"y1\": 211.122087,\n",
            "                \"x2\": 1170.79037,\n",
            "                \"y2\": 233.566141\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"3\",\n",
            "            \"attributes\": {\n",
            "                \"occluded\": false,\n",
            "                \"truncated\": true,\n",
            "                \"trafficLightColor\": \"NA\"\n",
            "            },\n",
            "            \"category\": \"traffic sign\",\n",
            "            \"box2d\": {\n",
            "                \"x1\": 0.0,\n",
            "                \"y1\": 0.246631,\n",
            "                \"x2\": 100.381647,\n",
            "                \"y2\": 122.825696\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"4\",\n",
            "            \"attributes\": {\n",
            "                \"occluded\": false,\n",
            "                \"truncated\": false,\n",
            "                \"trafficLightColor\": \"NA\"\n",
            "            },\n",
            "            \"category\": \"car\",\n",
            "            \"box2d\": {\n",
            "                \"x1\": 49.44476737704903,\n",
            "                \"y1\": 254.530367,\n",
            "                \"x2\": 357.805838,\n",
            "                \"y2\": 487.906215\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"5\",\n",
            "            \"attributes\": {\n",
            "                \"occluded\": false,\n",
            "                \"truncated\": false,\n",
            "                \"trafficLightColor\": \"NA\"\n",
            "            },\n",
            "            \"category\": \"car\",\n",
            "            \"box2d\": {\n",
            "                \"x1\": 507.82755,\n",
            "                \"y1\": 221.727518,\n",
            "                \"x2\": 908.367588,\n",
            "                \"y2\": 441.0052451528153\n",
            "            }\n",
            "        },\n",
            "        {\n",
            "            \"id\": \"6\",\n",
            "            \"attributes\": {\n",
            "                \"occluded\": false,\n",
            "                \"truncated\": true,\n",
            "                \"trafficLightColor\": \"NA\"\n",
            "            },\n",
            "            \"category\": \"traffic sign\",\n",
            "            \"box2d\": {\n",
            "                \"x1\": 0.156955,\n",
            "                \"y1\": 0.809282,\n",
            "                \"x2\": 102.417429,\n",
            "                \"y2\": 133.411856\n",
            "            }\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the pre-trained YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")  # Replace 'yolov8n.pt' with your desired model if needed\n",
        "\n",
        "# Step 2: Path to validation images and labels\n",
        "val_image_path = \"/content/data/val_images/bdd100k/images/100k/val\"\n",
        "val_label_path = \"/content/data/labels/bdd100k/labels/det_20/det_val.json\"\n",
        "\n",
        "# Step 3: Load validation annotations (ground truth)\n",
        "with open(val_label_path, 'r') as f:\n",
        "    val_annotations = json.load(f)\n",
        "\n",
        "# Step 4: Get all possible ground truth categories\n",
        "ground_truth_categories = set()\n",
        "for annotation in val_annotations:\n",
        "    for label in annotation['labels']:\n",
        "        ground_truth_categories.add(label['category'])\n",
        "\n",
        "# Step 5: Initialize results dictionary\n",
        "results = {\n",
        "    \"class_wise\": {category: {\"TP\": 0, \"FP\": 0, \"FN\": 0} for category in ground_truth_categories},\n",
        "    \"overall\": {\"TP\": 0, \"FP\": 0, \"FN\": 0}\n",
        "}\n",
        "\n",
        "# Step 6: Function to calculate IoU\n",
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, x2, y2 = max(box1[0], box2[0]), max(box1[1], box2[1]), min(box1[2], box2[2]), min(box1[3], box2[3])\n",
        "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    return inter_area / union_area if union_area > 0 else 0\n",
        "\n",
        "# Step 7: Perform evaluation\n",
        "iou_threshold = 0.5  # IoU threshold for matching\n",
        "\n",
        "for annotation in tqdm(val_annotations, desc=\"Evaluating\"):\n",
        "    image_name = annotation['name']\n",
        "    image_path = os.path.join(val_image_path, image_name)\n",
        "\n",
        "    # Ground truth boxes and categories\n",
        "    gt_boxes = [(label['box2d']['x1'], label['box2d']['y1'], label['box2d']['x2'], label['box2d']['y2']) for label in annotation['labels']]\n",
        "    gt_categories = [label['category'] for label in annotation['labels']]\n",
        "\n",
        "    # Perform inference\n",
        "    predictions = model(image_path)\n",
        "    pred_boxes = [result.boxes.xyxy.cpu().numpy() for result in predictions]\n",
        "    pred_classes = [result.boxes.cls.cpu().numpy() for result in predictions]\n",
        "    pred_scores = [result.boxes.conf.cpu().numpy() for result in predictions]\n",
        "\n",
        "    # Flatten results\n",
        "    pred_boxes = np.concatenate(pred_boxes) if len(pred_boxes) > 0 else []\n",
        "    pred_classes = np.concatenate(pred_classes) if len(pred_classes) > 0 else []\n",
        "    pred_scores = np.concatenate(pred_scores) if len(pred_scores) > 0 else []\n",
        "\n",
        "    # Match predictions with ground truth\n",
        "    matched = set()\n",
        "    for i, pred_box in enumerate(pred_boxes):\n",
        "        pred_class = pred_classes[i]\n",
        "        category = model.names[int(pred_class)]  # Map predicted class to category name\n",
        "\n",
        "        # Skip if predicted class is not in ground truth categories\n",
        "        if category not in results[\"class_wise\"]:\n",
        "            continue\n",
        "\n",
        "        best_iou = 0\n",
        "        best_gt_idx = -1\n",
        "        for j, gt_box in enumerate(gt_boxes):\n",
        "            if j in matched:\n",
        "                continue\n",
        "            iou = calculate_iou(pred_box, gt_box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_gt_idx = j\n",
        "\n",
        "        if best_iou >= iou_threshold:\n",
        "            # True Positive\n",
        "            results[\"class_wise\"][category][\"TP\"] += 1\n",
        "            results[\"overall\"][\"TP\"] += 1\n",
        "            matched.add(best_gt_idx)\n",
        "        else:\n",
        "            # False Positive\n",
        "            results[\"class_wise\"][category][\"FP\"] += 1\n",
        "            results[\"overall\"][\"FP\"] += 1\n",
        "\n",
        "    # Count False Negatives\n",
        "    for j, gt_box in enumerate(gt_boxes):\n",
        "        if j not in matched:\n",
        "            category = gt_categories[j]\n",
        "            results[\"class_wise\"][category][\"FN\"] += 1\n",
        "            results[\"overall\"][\"FN\"] += 1\n",
        "\n",
        "# Step 8: Calculate Precision, Recall, and F1-score\n",
        "for category, metrics in results[\"class_wise\"].items():\n",
        "    TP, FP, FN = metrics[\"TP\"], metrics[\"FP\"], metrics[\"FN\"]\n",
        "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "    f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
        "    metrics.update({\"Precision\": precision, \"Recall\": recall, \"F1-score\": f1_score})\n",
        "print(\"Ground Truth Categories:\", ground_truth_categories)\n",
        "# Step 9: Display Results\n",
        "print(\"\\nClass-wise Results:\")\n",
        "for category, metrics in results[\"class_wise\"].items():\n",
        "    print(f\"Category: {category}\")\n",
        "    print(f\"  Precision: {metrics['Precision']:.2f}\")\n",
        "    print(f\"  Recall: {metrics['Recall']:.2f}\")\n",
        "    print(f\"  F1-score: {metrics['F1-score']:.2f}\")\n",
        "    print(f\"  TP: {metrics['TP']}, FP: {metrics['FP']}, FN: {metrics['FN']}\")\n",
        "\n",
        "print(\"\\nOverall Results:\")\n",
        "print(f\"  TP: {results['overall']['TP']}, FP: {results['overall']['FP']}, FN: {results['overall']['FN']}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B_QGIUGI0GL",
        "outputId": "b527fe8e-8cb0-4690-aff5-9dd9383d2b6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/10000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1c66a42-6f7d68ca.jpg: 384x640 12 cars, 1 truck, 32.6ms\n",
            "Speed: 1.9ms preprocess, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 1/10000 [00:00<1:06:32,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1c81faa-3df17267.jpg: 384x640 (no detections), 32.2ms\n",
            "Speed: 5.0ms preprocess, 32.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1c81faa-c80764c5.jpg: 384x640 1 car, 28.4ms\n",
            "Speed: 1.8ms preprocess, 28.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 3/10000 [00:00<24:39,  6.76it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1c9c847-3bda4659.jpg: 384x640 15 cars, 1 bus, 21.7ms\n",
            "Speed: 1.9ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ca2e5d-84cf9134.jpg: 384x640 4 persons, 6 cars, 2 traffic lights, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 5/10000 [00:00<16:56,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ca8418-84a133a0.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1cac6a7-04e33135.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1cd1e94-26dd524f.jpg: 384x640 2 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1cd1e94-549d0bfe.jpg: 384x640 1 person, 2 cars, 1 bus, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 9/10000 [00:00<10:07, 16.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ceb32e-3f481b43.jpg: 384x640 5 cars, 1 truck, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ceb32e-51852abe.jpg: 384x640 9 cars, 19.9ms\n",
            "Speed: 1.9ms preprocess, 19.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ceb32e-813f84b2.jpg: 384x640 1 car, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 12/10000 [00:00<08:49, 18.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ceb32e-a106591d.jpg: 384x640 12 cars, 3 trucks, 21.4ms\n",
            "Speed: 9.0ms preprocess, 21.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1cebfb7-284f5117.jpg: 384x640 5 cars, 34.4ms\n",
            "Speed: 1.9ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0091f-75824d0d.jpg: 384x640 5 cars, 1 truck, 22.4ms\n",
            "Speed: 2.0ms preprocess, 22.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 15/10000 [00:01<09:08, 18.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0091f-f2c2d2ae.jpg: 384x640 4 cars, 3 trucks, 30.2ms\n",
            "Speed: 2.0ms preprocess, 30.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0a191-03dcecc2.jpg: 384x640 3 persons, 4 cars, 1 truck, 14.4ms\n",
            "Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0a191-06deb55d.jpg: 384x640 9 persons, 9 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 18/10000 [00:01<08:31, 19.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0a191-28f0e779.jpg: 384x640 12 cars, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0a191-2ed2269e.jpg: 384x640 6 cars, 20.8ms\n",
            "Speed: 3.5ms preprocess, 20.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0a191-5490450b.jpg: 384x640 2 cars, 1 traffic light, 34.0ms\n",
            "Speed: 3.3ms preprocess, 34.0ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 21/10000 [00:01<08:59, 18.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0a191-65deaeef.jpg: 384x640 8 cars, 2 trucks, 20.7ms\n",
            "Speed: 3.5ms preprocess, 20.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d0a191-de8948f6.jpg: 384x640 10 cars, 1 traffic light, 20.0ms\n",
            "Speed: 4.1ms preprocess, 20.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 23/10000 [00:01<09:01, 18.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d10d08-5b108225.jpg: 384x640 5 cars, 17.9ms\n",
            "Speed: 1.9ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d10d08-743fd86c.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d10d08-c35503b8.jpg: 384x640 11 cars, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 26/10000 [00:01<08:18, 20.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d10d08-da110fcb.jpg: 384x640 9 cars, 1 traffic light, 24.9ms\n",
            "Speed: 3.7ms preprocess, 24.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d10d08-ec660956.jpg: 384x640 3 cars, 29.5ms\n",
            "Speed: 9.2ms preprocess, 29.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d22449-117aa773.jpg: 384x640 2 cars, 17.1ms\n",
            "Speed: 2.0ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 29/10000 [00:01<08:40, 19.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d22449-15fb948f.jpg: 384x640 2 cars, 10.1ms\n",
            "Speed: 4.1ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d22ed6-f1cac061.jpg: 384x640 2 persons, 7 cars, 1 bus, 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d3907b-2278601b.jpg: 384x640 1 car, 1 traffic light, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d4b62c-60aab822.jpg: 384x640 15 cars, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 33/10000 [00:01<07:12, 23.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d4b62c-89eeb5d3.jpg: 384x640 2 cars, 3 traffic lights, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d4b62c-d9805029.jpg: 384x640 10 cars, 1 traffic light, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d59b1f-a38aec79.jpg: 384x640 3 cars, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d7b3ac-0bdb47dc.jpg: 384x640 4 cars, 1 truck, 6.9ms\n",
            "Speed: 1.4ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d7b3ac-2a92e19f.jpg: 384x640 2 cars, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 38/10000 [00:02<05:48, 28.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d7b3ac-36f2d3b7.jpg: 384x640 3 cars, 6.5ms\n",
            "Speed: 1.5ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d7b3ac-5744370e.jpg: 384x640 3 cars, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d7b3ac-5af8623b.jpg: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d7b3ac-995f9d8a.jpg: 384x640 1 person, 3 cars, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d7b3ac-9e14f05f.jpg: 384x640 5 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 43/10000 [00:02<04:54, 33.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d7b3ac-afa57f22.jpg: 384x640 2 cars, 1 bus, 1 truck, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d8735d-eee9f184.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d968b9-563405f4.jpg: 384x640 1 person, 5 cars, 1 bus, 1 truck, 3 traffic lights, 7.0ms\n",
            "Speed: 1.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d968b9-ce42734f.jpg: 384x640 1 person, 13 cars, 3 trucks, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d971b4-ac67ca0d.jpg: 384x640 11 cars, 7.0ms\n",
            "Speed: 1.5ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 48/10000 [00:02<04:32, 36.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d9e136-6c94ea3f.jpg: 384x640 2 persons, 5 cars, 1 motorcycle, 1 bus, 1 traffic light, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1d9e136-9ab25cb3.jpg: 384x640 1 person, 8 cars, 1 truck, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1da9c53-0f3d4c5d.jpg: 384x640 5 cars, 1 truck, 14.5ms\n",
            "Speed: 1.7ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1dac7f7-6b2e0382.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 52/10000 [00:02<04:36, 36.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1db7e22-cfa74dc3.jpg: 384x640 2 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1dce572-c6a8cb5e.jpg: 384x640 5 cars, 1 truck, 9.0ms\n",
            "Speed: 1.6ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1dd58c1-8b546ba7.jpg: 384x640 1 person, 4 cars, 2 trucks, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1df722f-57d21f3f.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 56/10000 [00:02<04:35, 36.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1df722f-5bcc3db7.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e0c01d-dd9e6e2f.jpg: 384x640 1 person, 2 cars, 2 trucks, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e1a7b8-0aec80e8.jpg: 384x640 6 cars, 2 trucks, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e1a7b8-65ec7612.jpg: 384x640 1 person, 4 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 1.6ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 60/10000 [00:02<04:30, 36.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e1a7b8-a7426a97.jpg: 384x640 4 cars, 1 truck, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e1a7b8-b397c445.jpg: 384x640 3 cars, 1 truck, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e2346e-c5f98707.jpg: 384x640 (no detections), 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e3e9f5-92377424.jpg: 384x640 9 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 64/10000 [00:02<04:27, 37.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e62c91-eca210a9.jpg: 384x640 1 person, 7 cars, 9.1ms\n",
            "Speed: 1.6ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e6efc0-2552cc5d.jpg: 384x640 2 cars, 1 truck, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e88fd2-c1e4fd2b.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e8ad72-c3c79240.jpg: 384x640 5 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 68/10000 [00:02<04:23, 37.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1e9ee0e-67e26f2e.jpg: 384x640 17 cars, 8.7ms\n",
            "Speed: 1.5ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ea0ae4-4f770228.jpg: 384x640 2 cars, 1 truck, 9.3ms\n",
            "Speed: 1.7ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1eb9133-5cc75c18.jpg: 384x640 1 car, 9.8ms\n",
            "Speed: 1.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ebfc3c-740ec84a.jpg: 384x640 9 cars, 12.7ms\n",
            "Speed: 1.6ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 72/10000 [00:02<04:32, 36.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ebfc3c-cc9c2bb8.jpg: 384x640 4 persons, 4 cars, 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ee702d-0ae1fc10.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ee702d-4a193906.jpg: 384x640 7 cars, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ee702d-525fcebf.jpg: 384x640 2 cars, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 76/10000 [00:02<04:35, 35.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f022d3-3774de8b.jpg: 384x640 10 cars, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f022d3-45162c67.jpg: 384x640 1 car, 1 bus, 2 traffic lights, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f0efd9-37a14dda.jpg: 384x640 4 cars, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f0efd9-e900c6e5.jpg: 384x640 3 cars, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f20aa0-3401c3bf.jpg: 384x640 1 person, 4 cars, 1 train, 1 traffic light, 6.7ms\n",
            "Speed: 1.4ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 81/10000 [00:03<04:14, 38.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f20aa0-50213047.jpg: 384x640 1 person, 5 cars, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f20aa0-6ef1db42.jpg: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f25ff6-1ddb7e43.jpg: 384x640 3 cars, 1 motorcycle, 1 truck, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-07b32e8c.jpg: 384x640 2 cars, 6.7ms\n",
            "Speed: 1.4ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-09593e90.jpg: 384x640 2 cars, 1 train, 9.5ms\n",
            "Speed: 1.6ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 86/10000 [00:03<03:58, 41.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-16256d7c.jpg: 384x640 1 person, 6 cars, 1 bus, 2 trucks, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-33824f31.jpg: 384x640 10 persons, 8 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-846d8cb2.jpg: 384x640 1 person, 4 cars, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-97465266.jpg: 384x640 1 person, 9 cars, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-9958bd99.jpg: 384x640 6 persons, 4 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 91/10000 [00:03<04:13, 39.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-bf7d513f.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-cf446195.jpg: 384x640 11 cars, 8.5ms\n",
            "Speed: 1.6ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-d8d1459c.jpg: 384x640 1 person, 2 cars, 2 trucks, 1 fire hydrant, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f4491b-dd8dfed5.jpg: 384x640 9 cars, 1 traffic light, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 95/10000 [00:03<04:17, 38.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f62c41-ed0c6521.jpg: 384x640 1 person, 2 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f6c103-5ce1f3c6.jpg: 384x640 2 cars, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f6c103-8b75ea3e.jpg: 384x640 6 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f6c103-b00e8aad.jpg: 384x640 4 cars, 1 truck, 3 traffic lights, 9.2ms\n",
            "Speed: 1.6ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 99/10000 [00:03<04:21, 37.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1f85377-44885085.jpg: 384x640 4 cars, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1fbaab8-68db7df7.jpg: 384x640 2 cars, 2 traffic lights, 9.0ms\n",
            "Speed: 1.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1fbf878-b31a8293.jpg: 384x640 4 persons, 3 cars, 1 bus, 4 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1fc95c9-644e3c3f.jpg: 384x640 1 person, 6 cars, 1 truck, 1 traffic light, 1 fire hydrant, 7.2ms\n",
            "Speed: 1.5ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 103/10000 [00:03<04:18, 38.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1fc95c9-cb2882c7.jpg: 384x640 5 cars, 3 trucks, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ff4656-0435391e.jpg: 384x640 9 cars, 2 traffic lights, 6.5ms\n",
            "Speed: 1.5ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ff4656-94ee8536.jpg: 384x640 5 cars, 1 truck, 6.5ms\n",
            "Speed: 1.5ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b1ff4656-ebcfeb35.jpg: 384x640 1 person, 2 cars, 2 motorcycles, 1 truck, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b200b84e-4a792877.jpg: 384x640 2 cars, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 108/10000 [00:03<04:05, 40.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b200e97a-bf074435.jpg: 384x640 5 cars, 1 truck, 8.4ms\n",
            "Speed: 1.5ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20234fd-822029be.jpg: 384x640 3 persons, 4 cars, 1 truck, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b202cae2-672e61c5.jpg: 384x640 11 cars, 1 bus, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b202cae2-f46c74a6.jpg: 384x640 10 cars, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2036451-aa924fd1.jpg: 384x640 8 cars, 6.7ms\n",
            "Speed: 1.4ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 113/10000 [00:03<04:03, 40.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2046bcf-8bc6a044.jpg: 384x640 1 person, 8 cars, 10.4ms\n",
            "Speed: 2.5ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b204a5c1-05981158.jpg: 384x640 1 person, 4 cars, 2 buss, 1 truck, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b204a5c1-064b0040.jpg: 384x640 12 cars, 13.4ms\n",
            "Speed: 1.6ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b204a5c1-fa3d5b88.jpg: 384x640 6 cars, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b205eb4d-f84aaa1a.jpg: 384x640 11 cars, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 118/10000 [00:04<04:16, 38.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2064e61-2beadd45.jpg: 384x640 7 cars, 3 traffic lights, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b206a78b-99f405ab.jpg: 384x640 1 person, 4 cars, 1 train, 9.5ms\n",
            "Speed: 1.5ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2080dc7-f9b98a5f.jpg: 384x640 (no detections), 6.7ms\n",
            "Speed: 1.6ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20841f9-cef732d5.jpg: 384x640 4 cars, 2 buss, 1 truck, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b1e63-4d8478a4.jpg: 384x640 6 cars, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|          | 123/10000 [00:04<04:05, 40.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b69d2-64b9cdb8.jpg: 384x640 5 cars, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b69d2-650e674d.jpg: 384x640 12 cars, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b69d2-6e2b9e73.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.5ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b69d2-7767e6b6.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.6ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b69d2-bd242bf0.jpg: 384x640 2 persons, 2 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|▏         | 128/10000 [00:04<04:04, 40.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b69d2-ca16c907.jpg: 384x640 3 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b69d2-e31380a7.jpg: 384x640 1 car, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b69d2-ffc1d6af.jpg: 384x640 4 cars, 1 truck, 19.1ms\n",
            "Speed: 4.1ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20b9c19-91e01a50.jpg: 384x640 8 cars, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20d494a-cdebe83e.jpg: 384x640 3 cars, 11.3ms\n",
            "Speed: 2.5ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|▏         | 133/10000 [00:04<04:31, 36.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20e291a-32ac11c1.jpg: 384x640 7 cars, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20e291a-6012d836.jpg: 384x640 14 cars, 1 truck, 17.0ms\n",
            "Speed: 2.0ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20eae11-149766ce.jpg: 384x640 1 person, 6 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20eae11-18cd8ca2.jpg: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|▏         | 137/10000 [00:04<04:53, 33.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20eae11-6817ba7a.jpg: 384x640 5 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b20ff95c-b9444127.jpg: 384x640 2 persons, 1 truck, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2102d00-5eb86b71.jpg: 384x640 6 cars, 15.3ms\n",
            "Speed: 4.7ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2102d00-a8c09be1.jpg: 384x640 1 person, 5 cars, 18.3ms\n",
            "Speed: 2.3ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|▏         | 141/10000 [00:04<05:09, 31.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2131b7b-e58faab7.jpg: 384x640 1 car, 16.4ms\n",
            "Speed: 5.0ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b213e4eb-09c01a17.jpg: 384x640 6 cars, 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b214d1e1-f248c616.jpg: 384x640 4 persons, 4 cars, 1 traffic light, 17.3ms\n",
            "Speed: 4.0ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21547c1-73e457f8.jpg: 384x640 2 cars, 1 truck, 20.1ms\n",
            "Speed: 3.5ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|▏         | 145/10000 [00:04<05:37, 29.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21547c1-796757ac.jpg: 384x640 3 cars, 2 traffic lights, 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2156f8e-72e1547c.jpg: 384x640 (no detections), 22.3ms\n",
            "Speed: 5.0ms preprocess, 22.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b215943a-10e44587.jpg: 384x640 1 person, 4 cars, 1 stop sign, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   1%|▏         | 148/10000 [00:05<05:58, 27.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b216243d-55963da2.jpg: 384x640 6 cars, 1 truck, 18.6ms\n",
            "Speed: 2.9ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b216243d-ad4306b9.jpg: 384x640 3 persons, 5 cars, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2169b74-fa197951.jpg: 384x640 2 cars, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 151/10000 [00:05<06:01, 27.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21742c2-0e7a2b57.jpg: 384x640 3 cars, 2 trucks, 14.8ms\n",
            "Speed: 2.4ms preprocess, 14.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21742c2-18d3463a.jpg: 384x640 10 persons, 5 cars, 1 truck, 1 umbrella, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2194b15-1825056a.jpg: 384x640 4 cars, 1 truck, 4 traffic lights, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 154/10000 [00:05<06:09, 26.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21ac8b3-9b9cb45a.jpg: 384x640 3 cars, 19.1ms\n",
            "Speed: 1.9ms preprocess, 19.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21bfb83-ea32f716.jpg: 384x640 7 cars, 2 traffic lights, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21c68e6-65674a17.jpg: 384x640 1 person, 1 car, 8.7ms\n",
            "Speed: 4.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 157/10000 [00:05<06:21, 25.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21c86ac-0dc77d82.jpg: 384x640 4 cars, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21c86ac-2eb7ba16.jpg: 384x640 10 cars, 2 trucks, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21c86ac-71205084.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b21d5efb-5e2cd743.jpg: 384x640 8 cars, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 161/10000 [00:05<05:45, 28.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2208b0f-2796a692.jpg: 384x640 7 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b222c329-5dc8dbf7.jpg: 384x640 2 persons, 4 cars, 2 trucks, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b229488e-e4714bb7.jpg: 384x640 1 car, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b22a4d9f-48b2e986.jpg: 384x640 5 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 165/10000 [00:05<05:23, 30.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b22a4d9f-73cc8810.jpg: 384x640 6 cars, 1 truck, 1 stop sign, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b22e02cd-6af68e18.jpg: 384x640 5 cars, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b22f174d-a19c875e.jpg: 384x640 1 person, 1 bicycle, 7 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b22f385b-5d7e5202.jpg: 384x640 5 cars, 1 truck, 2 traffic lights, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 169/10000 [00:05<05:22, 30.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b230132b-ff8f2719.jpg: 384x640 5 cars, 4 traffic lights, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b230a7b2-c881c382.jpg: 384x640 (no detections), 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b231a630-c4522992.jpg: 384x640 6 cars, 3 trucks, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b232c7c9-d251d9ee.jpg: 384x640 20 cars, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 173/10000 [00:05<05:20, 30.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2331b83-648e56ca.jpg: 384x640 4 cars, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2331b83-a28e6b57.jpg: 384x640 1 person, 6 cars, 2 buss, 2 trucks, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23493b1-3200de1c.jpg: 384x640 4 persons, 4 cars, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b237db93-fab44bf2.jpg: 384x640 2 cars, 2 trucks, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 177/10000 [00:06<05:15, 31.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23a79d1-43dfeecd.jpg: 384x640 3 cars, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23a79d1-e434acaa.jpg: 384x640 6 cars, 1 boat, 1 traffic light, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23adb0d-72704b27.jpg: 384x640 2 cars, 1 truck, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23adb0d-8a7aaced.jpg: 384x640 1 person, 6 cars, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 181/10000 [00:06<05:09, 31.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23b2649-1a78948d.jpg: 384x640 3 cars, 1 bench, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23b2649-6af03cd5.jpg: 384x640 9 cars, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23b2649-8349d2a1.jpg: 384x640 3 cars, 1 truck, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23bb45f-ddeea1d8.jpg: 384x640 1 person, 3 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 185/10000 [00:06<04:54, 33.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23c9e00-5506ddfb.jpg: 384x640 4 cars, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23c9e00-b425de1b.jpg: 384x640 5 cars, 8.1ms\n",
            "Speed: 5.5ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23d2079-0c019d8e.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23f7012-32d284ce.jpg: 384x640 4 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 189/10000 [00:06<04:58, 32.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23f7012-fab06dac.jpg: 384x640 3 cars, 2 traffic lights, 12.7ms\n",
            "Speed: 6.2ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b23fe89b-c704fe97.jpg: 384x640 6 cars, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24071b8-b3ee1196.jpg: 384x640 2 persons, 4 cars, 1 truck, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2408e45-984ba5aa.jpg: 384x640 8 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 193/10000 [00:06<05:10, 31.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b242929f-3051abca.jpg: 384x640 7 cars, 16.7ms\n",
            "Speed: 3.1ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b242f6b2-0033bdfb.jpg: 384x640 1 person, 5 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b242f6b2-99d2f2c1.jpg: 384x640 5 cars, 2 traffic lights, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b242f6b2-eaa39345.jpg: 384x640 3 persons, 5 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 197/10000 [00:06<05:24, 30.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b242f6b2-f5da110f.jpg: 384x640 9 persons, 3 cars, 1 traffic light, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24380ab-63272e5a.jpg: 384x640 (no detections), 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24380ab-6dbeb908.jpg: 384x640 1 car, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24380ab-855e9c00.jpg: 384x640 1 car, 1 truck, 16.4ms\n",
            "Speed: 2.3ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 201/10000 [00:06<05:23, 30.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24380ab-c07680d1.jpg: 384x640 1 car, 20.8ms\n",
            "Speed: 1.9ms preprocess, 20.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2443c9d-8cc3991f.jpg: 384x640 14 cars, 10.3ms\n",
            "Speed: 5.2ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b245b306-ca3dca4e.jpg: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b245e52e-0a0e4e69.jpg: 384x640 5 cars, 11.6ms\n",
            "Speed: 3.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 205/10000 [00:06<05:35, 29.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b245e52e-aaeeb959.jpg: 384x640 8 cars, 1 truck, 1 traffic light, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b246c8e8-3dd42e6c.jpg: 384x640 2 cars, 1 traffic light, 15.2ms\n",
            "Speed: 3.0ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b246c8e8-4dd36bfc.jpg: 384x640 1 car, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 208/10000 [00:07<05:48, 28.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b246c8e8-ecce1321.jpg: 384x640 1 car, 1 train, 1 traffic light, 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24702e3-0456c83c.jpg: 384x640 7 cars, 3 trucks, 16.1ms\n",
            "Speed: 2.4ms preprocess, 16.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24702e3-900f61ea.jpg: 384x640 6 cars, 1 truck, 14.8ms\n",
            "Speed: 2.0ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 211/10000 [00:07<05:57, 27.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24702e3-e6f33768.jpg: 384x640 8 cars, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24702e3-f56e0731.jpg: 384x640 7 cars, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24702e3-fe617f57.jpg: 384x640 10 cars, 8 traffic lights, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 214/10000 [00:07<05:56, 27.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b248306f-a5089e94.jpg: 384x640 6 cars, 4 traffic lights, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2490dcb-7469cbe8.jpg: 384x640 1 person, 9 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b249e7f2-92d2efad.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b249e7f2-d619bd69.jpg: 384x640 (no detections), 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 218/10000 [00:07<05:22, 30.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24b3585-221ac8ac.jpg: 384x640 8 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24bdca1-e4f0c558.jpg: 384x640 8 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24c9ee6-e43a6e8b.jpg: 384x640 1 car, 8.2ms\n",
            "Speed: 3.6ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24ca67a-594d7d3c.jpg: 384x640 1 truck, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 222/10000 [00:07<05:08, 31.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24d283f-33783d1b.jpg: 384x640 7 cars, 1 bus, 3 trucks, 7.7ms\n",
            "Speed: 2.0ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24f03f7-ff66eaca.jpg: 384x640 4 cars, 4 traffic lights, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b24f7455-e8c55d6a.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2505382-1423f56a.jpg: 384x640 7 cars, 1 traffic light, 1 stop sign, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 226/10000 [00:07<04:53, 33.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2505382-272e7823.jpg: 384x640 2 traffic lights, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2505382-2905b23c.jpg: 384x640 6 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2505382-549785d3.jpg: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2505382-de5238f0.jpg: 384x640 4 cars, 1 traffic light, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 230/10000 [00:07<04:50, 33.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b250fb0c-01a1b8d3.jpg: 384x640 1 person, 7 cars, 1 truck, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b251064f-30002542.jpg: 384x640 6 cars, 2 trucks, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b251064f-4696b75e.jpg: 384x640 5 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b251064f-5f6b663e.jpg: 384x640 4 cars, 1 truck, 1 bird, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 234/10000 [00:07<04:50, 33.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b251064f-8d92db81.jpg: 384x640 5 persons, 10 cars, 3 traffic lights, 8.7ms\n",
            "Speed: 6.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b251064f-e7a165fd.jpg: 384x640 1 person, 15 cars, 3 traffic lights, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b251b746-00138418.jpg: 384x640 6 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-0bdf0ac7.jpg: 384x640 2 cars, 1 traffic light, 11.9ms\n",
            "Speed: 4.2ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 238/10000 [00:07<05:24, 30.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-2f889586.jpg: 384x640 3 cars, 1 bus, 1 truck, 3 traffic lights, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-5ccba454.jpg: 384x640 2 cars, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-6502a28c.jpg: 384x640 3 cars, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-82c804d4.jpg: 384x640 1 person, 2 cars, 11.8ms\n",
            "Speed: 5.7ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 242/10000 [00:08<05:28, 29.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-bc3cbb18.jpg: 384x640 7 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-e5f99451.jpg: 384x640 6 cars, 2 traffic lights, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-f2f28aff.jpg: 384x640 6 persons, 5 cars, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b255cd6c-fb594dcb.jpg: 384x640 4 cars, 3 traffic lights, 12.9ms\n",
            "Speed: 3.9ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 246/10000 [00:08<05:37, 28.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2576c8c-2924c365.jpg: 384x640 3 persons, 8 cars, 1 truck, 1 stop sign, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2576c8c-2de20b8a.jpg: 384x640 16 cars, 15.2ms\n",
            "Speed: 2.6ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b257f482-cf55d35c.jpg: 384x640 4 cars, 15.7ms\n",
            "Speed: 3.2ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|▏         | 249/10000 [00:08<05:52, 27.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b258a38b-0126cc8c.jpg: 384x640 4 persons, 1 car, 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b258d359-49a3ad31.jpg: 384x640 6 cars, 14.5ms\n",
            "Speed: 2.8ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b258d359-db99eff1.jpg: 384x640 5 cars, 17.3ms\n",
            "Speed: 2.0ms preprocess, 17.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 252/10000 [00:08<05:54, 27.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b259c5e1-cda39ef9.jpg: 384x640 2 persons, 2 cars, 1 bus, 1 truck, 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b25aac57-705d50ad.jpg: 384x640 1 car, 10.2ms\n",
            "Speed: 4.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b25ae6c0-311e72c2.jpg: 384x640 2 persons, 7 cars, 1 truck, 21.4ms\n",
            "Speed: 2.5ms preprocess, 21.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 255/10000 [00:08<06:08, 26.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b25ae6c0-fb9fea6a.jpg: 384x640 5 cars, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b25c1103-5da4b435.jpg: 384x640 2 cars, 1 truck, 16.5ms\n",
            "Speed: 1.9ms preprocess, 16.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b25c51f5-e9dba941.jpg: 384x640 1 person, 6 cars, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 258/10000 [00:08<06:12, 26.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b25fb716-78d8d49b.jpg: 384x640 3 cars, 15.0ms\n",
            "Speed: 3.8ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b25fd5d3-fa4bfca0.jpg: 384x640 4 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b25fdb41-4644e3f7.jpg: 384x640 4 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 261/10000 [00:08<06:10, 26.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b262f576-b0373824.jpg: 384x640 3 persons, 2 cars, 1 traffic light, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26309ce-447c0ac7.jpg: 384x640 9 cars, 13.2ms\n",
            "Speed: 3.7ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26309ce-fc963b47.jpg: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 264/10000 [00:08<06:02, 26.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26327fe-3ac19999.jpg: 384x640 11 cars, 1 train, 18.5ms\n",
            "Speed: 3.0ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26331b9-102f5d9a.jpg: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.9ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2638d82-062aa1de.jpg: 384x640 3 cars, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 267/10000 [00:09<06:13, 26.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b263f57d-1ccf6e51.jpg: 384x640 2 cars, 1 traffic light, 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2648a7f-42f72f67.jpg: 384x640 2 cars, 1 truck, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b265b9cf-2d517da6.jpg: 384x640 4 cars, 3 trucks, 3 traffic lights, 19.3ms\n",
            "Speed: 1.9ms preprocess, 19.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 270/10000 [00:09<06:32, 24.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26610ce-083c3bd1.jpg: 384x640 3 cars, 15.1ms\n",
            "Speed: 6.0ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b266429a-83757042.jpg: 384x640 5 cars, 3 traffic lights, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b266429a-ac0c4ed3.jpg: 384x640 3 persons, 2 cars, 1 train, 14.6ms\n",
            "Speed: 5.1ms preprocess, 14.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 273/10000 [00:09<06:35, 24.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b266db29-12bf52fa.jpg: 384x640 7 cars, 1 traffic light, 1 fire hydrant, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b266db29-29fa8335.jpg: 384x640 2 persons, 7 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b266db29-403143cc.jpg: 384x640 3 persons, 3 cars, 1 truck, 1 umbrella, 13.8ms\n",
            "Speed: 4.1ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 276/10000 [00:09<06:27, 25.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b266db29-4d22b355.jpg: 384x640 4 cars, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b266db29-c518f15d.jpg: 384x640 9 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b266db29-da0abce7.jpg: 384x640 14 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 279/10000 [00:09<06:18, 25.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2675b13-d04e4a76.jpg: 384x640 3 cars, 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b268bb58-5ead8a56.jpg: 384x640 10 cars, 4 trucks, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2694461-db4f4470.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 282/10000 [00:09<06:16, 25.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26aafd1-1bc4dccc.jpg: 384x640 1 person, 7 cars, 20.6ms\n",
            "Speed: 2.6ms preprocess, 20.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26aafd1-513824d4.jpg: 384x640 13 cars, 1 truck, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26ba07a-1c7593b1.jpg: 384x640 1 car, 1 traffic light, 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 285/10000 [00:09<06:11, 26.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26ba07a-203e440c.jpg: 384x640 2 cars, 15.9ms\n",
            "Speed: 2.3ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26ba07a-2b68a502.jpg: 384x640 11 cars, 1 traffic light, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26ba07a-38f78442.jpg: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26ba07a-c7bcbe2d.jpg: 384x640 1 tv, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 289/10000 [00:09<05:41, 28.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26ba07a-da78f324.jpg: 384x640 3 cars, 1 traffic light, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26ba07a-e4ca935c.jpg: 384x640 1 train, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26ba07a-f781b661.jpg: 384x640 1 car, 1 bus, 1 train, 1 traffic light, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26cfcdc-10346684.jpg: 384x640 9 cars, 1 bus, 1 truck, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26cfcdc-2e290c42.jpg: 384x640 5 cars, 1 bus, 1 truck, 2 traffic lights, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 294/10000 [00:10<04:58, 32.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26cfcdc-7b00747d.jpg: 384x640 7 cars, 1 truck, 1 traffic light, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26cfcdc-eb092da8.jpg: 384x640 1 car, 1 truck, 2 traffic lights, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26dd913-2888cbfd.jpg: 384x640 2 persons, 10 cars, 1 truck, 1 traffic light, 7.2ms\n",
            "Speed: 1.5ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26dddb5-28e4a05f.jpg: 384x640 3 cars, 1 bus, 1 truck, 2 traffic lights, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26f7271-d906ee87.jpg: 384x640 1 car, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 299/10000 [00:10<04:31, 35.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26f8762-61cfb033.jpg: 384x640 1 person, 6 cars, 1 truck, 15 birds, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26f9b1e-09c56a3c.jpg: 384x640 3 cars, 1 fire hydrant, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b26f9b1e-3e172ced.jpg: 384x640 7 cars, 1 bus, 1 truck, 3 traffic lights, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27098c3-0db780d5.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 1 fire hydrant, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 303/10000 [00:10<04:36, 35.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27098c3-915a9986.jpg: 384x640 1 person, 21 cars, 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27098c3-c443b6e3.jpg: 384x640 9 cars, 1 truck, 1 traffic light, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27098c3-dedf92b2.jpg: 384x640 3 persons, 1 bicycle, 2 cars, 2 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b270d8e4-0f565398.jpg: 384x640 1 person, 5 cars, 2 trucks, 1 umbrella, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 307/10000 [00:10<05:01, 32.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27127df-eac9b95e.jpg: 384x640 3 cars, 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2714f5d-07bf604c.jpg: 384x640 5 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2714f5d-5bc98e55.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2715214-13e3dd85.jpg: 384x640 12 cars, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 311/10000 [00:10<04:58, 32.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2715214-d38332ea.jpg: 384x640 1 person, 12 cars, 1 bus, 1 truck, 3 traffic lights, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27369f3-9b9598f4.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27369f3-dd3c0b46.jpg: 384x640 3 cars, 1 traffic light, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2743b5d-e2d585be.jpg: 384x640 1 person, 15 cars, 1 traffic light, 6.9ms\n",
            "Speed: 2.0ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 315/10000 [00:10<04:56, 32.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2752cd6-12ba5588.jpg: 384x640 4 cars, 7.0ms\n",
            "Speed: 1.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b275c028-6a0665cb.jpg: 384x640 2 cars, 3 traffic lights, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27688b6-1af27060.jpg: 384x640 4 cars, 1 train, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27688b6-cd521517.jpg: 384x640 2 cars, 1 bus, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2778280-4179c4af.jpg: 384x640 5 cars, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 320/10000 [00:10<04:27, 36.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b277a772-08d8d7ad.jpg: 384x640 8 cars, 8.2ms\n",
            "Speed: 4.6ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b277a772-715e949c.jpg: 384x640 5 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b277a772-848f75a9.jpg: 384x640 5 cars, 1 truck, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b277a772-87c10d5c.jpg: 384x640 8 cars, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 324/10000 [00:10<04:20, 37.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2794401-ba7d3c05.jpg: 384x640 3 cars, 1 train, 1 truck, 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b279bc06-3c8aeb90.jpg: 384x640 2 persons, 7 cars, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b279bc06-4fa57251.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b279bc06-b7bc42a9.jpg: 384x640 5 cars, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27b0cd9-f184d9a3.jpg: 384x640 4 cars, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 329/10000 [00:11<04:09, 38.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27cd403-d7616bfa.jpg: 384x640 5 cars, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27cd403-f2d087cc.jpg: 384x640 17 cars, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27cde22-56abd0e1.jpg: 384x640 2 cars, 1 truck, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27d5dcb-5bdec286.jpg: 384x640 1 person, 10 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 333/10000 [00:11<04:07, 39.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27d5dcb-856c0b43.jpg: 384x640 1 person, 6 cars, 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27d5dcb-9230790c.jpg: 384x640 2 persons, 9 cars, 1 traffic light, 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27e8b69-c00092ae.jpg: 384x640 9 cars, 4 traffic lights, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27fdbad-ab895d86.jpg: 384x640 (no detections), 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b27fdbad-ae939e31.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 338/10000 [00:11<03:59, 40.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b280c9c1-4340305f.jpg: 384x640 1 person, 8 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b280c9c1-a75d23e5.jpg: 384x640 7 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2828509-133b042d.jpg: 384x640 2 traffic lights, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2828509-682cd3b2.jpg: 384x640 6 cars, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2828509-8e8fa55f.jpg: 384x640 1 car, 1 truck, 2 traffic lights, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 343/10000 [00:11<04:22, 36.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b284c0e8-85fbc42a.jpg: 384x640 10 persons, 3 cars, 3 trucks, 2 traffic lights, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b284c0e8-b813f3cf.jpg: 384x640 1 person, 4 cars, 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b285698b-ff1293ce.jpg: 384x640 8 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2860d72-0b43e851.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   3%|▎         | 347/10000 [00:11<04:34, 35.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b289f2e8-cec8700d.jpg: 384x640 7 cars, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28aac6c-9f1b99cb.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28cb5d3-2cf728ac.jpg: 384x640 1 car, 1 truck, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28cb5d3-9ff4ab4a.jpg: 384x640 2 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▎         | 351/10000 [00:11<04:39, 34.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28cb5d3-c4758dfd.jpg: 384x640 8 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28cb5d3-f800ecd2.jpg: 384x640 1 person, 3 cars, 1 bus, 1 train, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28cfc9b-224431ab.jpg: 384x640 7 cars, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28ec521-69495052.jpg: 384x640 3 cars, 1 truck, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▎         | 355/10000 [00:11<04:46, 33.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28ec521-8266e1a4.jpg: 384x640 8 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28ec521-834a964c.jpg: 384x640 5 cars, 2 trucks, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28ec521-898e11bd.jpg: 384x640 2 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28f288b-784f7606.jpg: 384x640 3 cars, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▎         | 359/10000 [00:11<04:40, 34.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b28fc734-5add25db.jpg: 384x640 3 cars, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29026f0-d5a5ee8c.jpg: 384x640 1 person, 2 cars, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b291cfd6-a46efbcc.jpg: 384x640 8 persons, 1 backpack, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b291cfd6-a6275049.jpg: 384x640 1 person, 5 cars, 1 bus, 1 truck, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b291cfd6-ff98ba56.jpg: 384x640 4 cars, 4 trucks, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▎         | 364/10000 [00:11<04:26, 36.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29273b2-339a1500.jpg: 384x640 1 person, 6 cars, 1 truck, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2932832-a2c8f6ef.jpg: 384x640 3 persons, 11 cars, 1 truck, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2932832-df9384eb.jpg: 384x640 3 persons, 10 cars, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2933acb-1e0c16cc.jpg: 384x640 5 cars, 1 bus, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▎         | 368/10000 [00:12<04:25, 36.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2933acb-e890758f.jpg: 384x640 4 cars, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29377e0-83e8340a.jpg: 384x640 8 cars, 6.6ms\n",
            "Speed: 2.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2939bf0-221e1dfb.jpg: 384x640 6 cars, 1 traffic light, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b294386c-24ddd0c3.jpg: 384x640 7 persons, 6 cars, 1 motorcycle, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29511e5-0e7c7013.jpg: 384x640 8 cars, 1 traffic light, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▎         | 373/10000 [00:12<04:13, 38.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2965b06-88a1da19.jpg: 384x640 3 cars, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29806ee-7194648d.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29806ee-ac06730f.jpg: 384x640 3 cars, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29806ee-e89a39a6.jpg: 384x640 10 cars, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 377/10000 [00:12<04:22, 36.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29c2372-b53a797c.jpg: 384x640 3 persons, 5 cars, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29c5efd-754ba560.jpg: 384x640 3 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29f09ea-911177ce.jpg: 384x640 2 persons, 6 cars, 1 motorcycle, 15.6ms\n",
            "Speed: 2.7ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29f09ea-ecd5304b.jpg: 384x640 5 cars, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 381/10000 [00:12<04:38, 34.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29f7159-219cf764.jpg: 384x640 5 cars, 2 traffic lights, 9.4ms\n",
            "Speed: 3.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b29f9214-4846c10c.jpg: 384x640 10 cars, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a0648b-d8e126bc.jpg: 384x640 6 cars, 1 truck, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a0dbe8-85f1894e.jpg: 384x640 3 cars, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 385/10000 [00:12<04:40, 34.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a1e013-638d6e4d.jpg: 384x640 8 cars, 2 trucks, 2 traffic lights, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a1e172-a969db88.jpg: 384x640 3 cars, 1 traffic light, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a46c1e-87aac2ec.jpg: 384x640 14 cars, 10.2ms\n",
            "Speed: 4.1ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a4738f-1c4a1373.jpg: 384x640 8 cars, 1 traffic light, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 389/10000 [00:12<04:43, 33.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a4bc4d-6f7c1727.jpg: 384x640 3 cars, 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a4bc4d-b251ccb1.jpg: 384x640 3 cars, 1 truck, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a5baf7-58519386.jpg: 384x640 5 cars, 2 traffic lights, 6.7ms\n",
            "Speed: 1.4ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a60634-0817a6eb.jpg: 384x640 4 cars, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a60634-40847419.jpg: 384x640 3 cars, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 394/10000 [00:12<04:20, 36.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a60634-6e9f96fe.jpg: 384x640 3 traffic lights, 6.5ms\n",
            "Speed: 1.5ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a60634-ad36f179.jpg: 384x640 6 cars, 1 truck, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a8e8b4-50058f09.jpg: 384x640 4 persons, 9 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a8e8b4-a4e93829.jpg: 384x640 1 person, 3 cars, 2 trucks, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 398/10000 [00:12<04:17, 37.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a99ee3-5abca703.jpg: 384x640 1 car, 6.5ms\n",
            "Speed: 1.5ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2a9d547-f7f6fa92.jpg: 384x640 3 cars, 6.6ms\n",
            "Speed: 2.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ae0446-4b0bfda7.jpg: 384x640 11 cars, 1 fire hydrant, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ae0446-f456c162.jpg: 384x640 1 car, 6.5ms\n",
            "Speed: 1.5ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ae4fc5-3abd5802.jpg: 384x640 6 cars, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 403/10000 [00:13<04:06, 38.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ae4fc5-d1082ddf.jpg: 384x640 15 cars, 1 truck, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2aefccb-24d289a9.jpg: 384x640 3 cars, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2afce7f-0cb9967a.jpg: 384x640 5 cars, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2b03a01-a60e895f.jpg: 384x640 9 cars, 2 traffic lights, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2b2f563-ec318c61.jpg: 384x640 3 cars, 1 truck, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 408/10000 [00:13<04:01, 39.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2b32394-e46669cb.jpg: 384x640 3 cars, 1 bus, 3 trucks, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2b70230-bad4ff6e.jpg: 384x640 7 cars, 1 truck, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2b70230-c43553a9.jpg: 384x640 1 person, 5 cars, 5 traffic lights, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2b74321-f6578001.jpg: 384x640 10 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 412/10000 [00:13<04:07, 38.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bc4efb-a184131d.jpg: 384x640 20 cars, 1 traffic light, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bceb54-0b1f3332.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bceb54-4d3cc92c.jpg: 384x640 7 cars, 1 traffic light, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bdb7b6-041bebc9.jpg: 384x640 4 cars, 1 motorcycle, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 416/10000 [00:13<04:23, 36.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bdb7b6-137acb11.jpg: 384x640 6 persons, 4 cars, 1 traffic light, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bdb7b6-3e75222e.jpg: 384x640 6 cars, 15.3ms\n",
            "Speed: 2.0ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bdb7b6-602437cb.jpg: 384x640 5 cars, 1 truck, 2 traffic lights, 14.9ms\n",
            "Speed: 3.6ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bdb7b6-d34fab57.jpg: 384x640 1 person, 10 cars, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 420/10000 [00:13<04:42, 33.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bdc7e5-b4ebc5bd.jpg: 384x640 2 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2be7200-b6f7fe0a.jpg: 384x640 1 person, 7 cars, 1 truck, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bee3e1-80c787bd.jpg: 384x640 5 cars, 1 traffic light, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bee3e1-915eb541.jpg: 384x640 6 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 424/10000 [00:13<04:40, 34.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bf0e03-a07f0a81.jpg: 384x640 9 cars, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2bf0e03-a3921cd6.jpg: 384x640 4 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c0e5c1-9666ba7e.jpg: 384x640 9 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c23864-810e4e1d.jpg: 384x640 8 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 428/10000 [00:13<04:43, 33.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c2f563-02143de0.jpg: 384x640 5 persons, 12 cars, 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c5110e-09e459e9.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c5110e-ef7e4997.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c542e3-02f579a6.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 432/10000 [00:13<04:43, 33.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c7d048-fdd059eb.jpg: 384x640 1 person, 2 cars, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c7ebc4-731ea908.jpg: 384x640 (no detections), 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c88d3b-1c1ad881.jpg: 384x640 1 car, 1 bus, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2c9b221-d447dcc3.jpg: 384x640 1 person, 6 cars, 2 traffic lights, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 436/10000 [00:14<04:34, 34.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2cac490-b27b82da.jpg: 384x640 5 cars, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2cbf6d8-732b47be.jpg: 384x640 4 cars, 1 truck, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2cce432-e17e840e.jpg: 384x640 6 cars, 7.3ms\n",
            "Speed: 1.8ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2cd33bd-a5043d29.jpg: 384x640 1 bicycle, 10 cars, 2 trucks, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 440/10000 [00:14<04:23, 36.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2cda443-f7cb5ccf.jpg: 384x640 (no detections), 8.0ms\n",
            "Speed: 2.7ms preprocess, 8.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2cf78ec-6043f571.jpg: 384x640 1 car, 1 bus, 1 truck, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d22b2f-8302eb61.jpg: 384x640 11 cars, 1 bus, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d22b2f-91d0af18.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 444/10000 [00:14<04:20, 36.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d3510a-659ae4de.jpg: 384x640 1 person, 4 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d49c0c-e888f874.jpg: 384x640 12 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d4c878-2267ca6d.jpg: 384x640 1 person, 4 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d502aa-64d3e228.jpg: 384x640 3 persons, 1 car, 1 bus, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   4%|▍         | 448/10000 [00:14<04:25, 35.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d502aa-ef17ffbd.jpg: 384x640 3 persons, 1 car, 3 traffic lights, 11.4ms\n",
            "Speed: 1.7ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d502aa-f0b28e3e.jpg: 384x640 2 persons, 2 cars, 1 traffic light, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d502aa-f8382905.jpg: 384x640 5 cars, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d502aa-f9141409.jpg: 384x640 11 persons, 6 cars, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 452/10000 [00:14<04:36, 34.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d83b7b-9627ff87.jpg: 384x640 1 person, 5 cars, 1 truck, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d8704e-66d10551.jpg: 384x640 5 persons, 5 cars, 1 traffic light, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d8704e-9e7dddd6.jpg: 384x640 2 persons, 3 cars, 2 traffic lights, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d90c73-32ae0488.jpg: 384x640 3 cars, 1 bus, 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 456/10000 [00:14<04:39, 34.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2d9b817-9a617024.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2da7e9c-6fe28d5e.jpg: 384x640 1 person, 21 cars, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2daf29d-6198754f.jpg: 384x640 10 persons, 7 cars, 5 traffic lights, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2db41a2-721e0f4e.jpg: 384x640 6 cars, 1 bus, 7.6ms\n",
            "Speed: 2.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 460/10000 [00:14<04:39, 34.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2dbb793-305e0fc5.jpg: 384x640 3 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2dbb793-9f0b2bec.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2dc7ea5-4a031fdd.jpg: 384x640 3 cars, 1 motorcycle, 1 traffic light, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ddae9c-9aafceae.jpg: 384x640 3 cars, 1 truck, 2 traffic lights, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2dde0d9-1303a9ef.jpg: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 465/10000 [00:14<04:20, 36.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2de6f59-9f74dea1.jpg: 384x640 6 cars, 1 truck, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2de938e-84eab379.jpg: 384x640 3 persons, 2 cars, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2de938e-a8430554.jpg: 384x640 1 person, 14 cars, 2 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e2126b-0512426c.jpg: 384x640 5 cars, 1 truck, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 469/10000 [00:14<04:24, 36.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e2b2be-4142962b.jpg: 384x640 6 cars, 1 truck, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e2f4ed-6ba045d0.jpg: 384x640 7 cars, 1 tv, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e431b6-332c438d.jpg: 384x640 3 cars, 7.4ms\n",
            "Speed: 1.4ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e54795-0a58624f.jpg: 384x640 10 persons, 8 cars, 1 traffic light, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 473/10000 [00:15<04:27, 35.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e54795-0dc285dd.jpg: 384x640 7 cars, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e54795-349f005b.jpg: 384x640 6 cars, 1 truck, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e54795-601d2d78.jpg: 384x640 1 person, 4 cars, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e54795-698ce97f.jpg: 384x640 2 persons, 6 cars, 3 traffic lights, 7.0ms\n",
            "Speed: 1.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 477/10000 [00:15<04:19, 36.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e54795-6d4ef5f9.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e54795-d8c2ba6d.jpg: 384x640 3 cars, 1 bus, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e54795-db1f3bad.jpg: 384x640 4 persons, 3 bicycles, 13 cars, 3 traffic lights, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e63097-51c16783.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 1.6ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 481/10000 [00:15<04:30, 35.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e73518-547798ef.jpg: 384x640 3 cars, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e96aa8-3624f23d.jpg: 384x640 1 person, 2 cars, 1 train, 1 traffic light, 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2e96aa8-4d92cdf0.jpg: 384x640 6 cars, 1 traffic light, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ea3465-78dea25f.jpg: 384x640 1 surfboard, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 485/10000 [00:15<04:39, 34.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ec68ce-d345784e.jpg: 384x640 2 persons, 1 car, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ed13f9-01b4dd4f.jpg: 384x640 3 cars, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2edfbf5-544c4e6e.jpg: 384x640 5 cars, 1 truck, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2edfbf5-e0fc7810.jpg: 384x640 4 persons, 1 car, 1 truck, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 489/10000 [00:15<04:35, 34.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2eed8fa-2694b15d.jpg: 384x640 5 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2eed8fa-cf59a253.jpg: 384x640 1 car, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2efc911-2ad925b4.jpg: 384x640 1 car, 18.4ms\n",
            "Speed: 1.9ms preprocess, 18.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f3d83a-1effdb49.jpg: 384x640 1 person, 8 cars, 1 truck, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 493/10000 [00:15<04:52, 32.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f48fc3-0b8ff39a.jpg: 384x640 14 persons, 3 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f48fc3-eda0e217.jpg: 384x640 1 person, 7 cars, 1 bus, 1 truck, 2 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f48fc3-f0ddacf0.jpg: 384x640 12 cars, 1 traffic light, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f4a409-36a7d7c9.jpg: 384x640 10 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▍         | 497/10000 [00:15<04:56, 32.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f4a409-5adcc4f0.jpg: 384x640 9 cars, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f4a409-5ddff11a.jpg: 384x640 2 cars, 2 trucks, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f4a409-80dacf25.jpg: 384x640 4 cars, 10.2ms\n",
            "Speed: 5.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f4ebb7-ceaa12dc.jpg: 384x640 7 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 501/10000 [00:15<04:53, 32.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f68bad-aa8f35d1.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f6cc51-462c2887.jpg: 384x640 9 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2f9cc9e-809f5cae.jpg: 384x640 1 car, 1 traffic light, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2fa3e5f-8c4b06d0.jpg: 384x640 2 cars, 1 truck, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 505/10000 [00:16<04:49, 32.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2fbc1aa-b6180041.jpg: 384x640 6 cars, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2fbf86d-d5de82a4.jpg: 384x640 10 cars, 3 trucks, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2fc6d24-0af7cdca.jpg: 384x640 1 person, 6 cars, 1 truck, 1 traffic light, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2fc7cb5-1635d64b.jpg: 384x640 3 cars, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 509/10000 [00:16<04:53, 32.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2fe5d69-f31d4c9b.jpg: 384x640 1 person, 5 cars, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2fed216-2e5c452d.jpg: 384x640 4 cars, 3 traffic lights, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b2ff6aba-fa4ac7d7.jpg: 384x640 4 cars, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3039ada-2ef2a725.jpg: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 513/10000 [00:16<04:48, 32.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3048201-d86d9cd8.jpg: 384x640 3 persons, 3 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b305fc0b-ec8916d5.jpg: 384x640 1 car, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3060c96-d2391b61.jpg: 384x640 7 cars, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3064012-5a01e51a.jpg: 384x640 12 cars, 7.8ms\n",
            "Speed: 1.4ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 517/10000 [00:16<04:45, 33.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b306fb3f-178fca4e.jpg: 384x640 1 airplane, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b306fb3f-3118e8b6.jpg: 384x640 9 cars, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b306fb3f-f02e46cc.jpg: 384x640 6 cars, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3079ec6-df7b2d92.jpg: 384x640 3 cars, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3091a27-aa7841b5.jpg: 384x640 1 person, 7 cars, 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 522/10000 [00:16<04:29, 35.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b30af183-3029b316.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b30af183-e9209104.jpg: 384x640 7 cars, 1 truck, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b30b460d-0e26bd8a.jpg: 384x640 4 cars, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b30b460d-73d12a29.jpg: 384x640 5 cars, 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 526/10000 [00:16<04:20, 36.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b30b460d-7a788684.jpg: 384x640 1 truck, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b30b460d-9829fd26.jpg: 384x640 2 cars, 17.6ms\n",
            "Speed: 1.8ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b30b460d-f081f92b.jpg: 384x640 1 car, 2 traffic lights, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b30ba07c-6692a0e3.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 530/10000 [00:16<04:19, 36.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b310be3f-c5d5e18c.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3110036-a32dc26e.jpg: 384x640 3 cars, 1 bus, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-195ffbf7.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-3dfa9124.jpg: 384x640 2 cars, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-461523a5.jpg: 384x640 7 cars, 1 bus, 1 truck, 1 bench, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 535/10000 [00:16<04:08, 38.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-581b2755.jpg: 384x640 17 cars, 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-6b1e5be7.jpg: 384x640 6 cars, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-afc8cca5.jpg: 384x640 1 car, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-b9d7694a.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-c0fd88c4.jpg: 384x640 9 cars, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 540/10000 [00:16<04:00, 39.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3121071-cac49b3a.jpg: 384x640 4 cars, 1 truck, 10.5ms\n",
            "Speed: 2.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b312dcb5-3c956847.jpg: 384x640 1 person, 3 cars, 1 motorcycle, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b312dcb5-82c0d608.jpg: 384x640 (no detections), 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b312dcb5-ab4b0e08.jpg: 384x640 3 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b312dcb5-fbd7070b.jpg: 384x640 9 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 545/10000 [00:17<03:57, 39.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b313a4dc-217f1233.jpg: 384x640 1 person, 2 cars, 1 bus, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3154d05-86ce5ff2.jpg: 384x640 11 cars, 7.4ms\n",
            "Speed: 1.9ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3154d05-8bc595ba.jpg: 384x640 19 cars, 1 truck, 5 traffic lights, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3158519-23c9c58d.jpg: 384x640 7 cars, 1 bus, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   5%|▌         | 549/10000 [00:17<04:03, 38.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3158519-6afea489.jpg: 384x640 2 cars, 1 traffic light, 6.6ms\n",
            "Speed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3159650-0d7fbee8.jpg: 384x640 2 persons, 5 cars, 2 traffic lights, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3159650-1ba75f9b.jpg: 384x640 10 cars, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b315fa95-4aa651f8.jpg: 384x640 2 cars, 1 traffic light, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 553/10000 [00:17<04:15, 36.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b319b67e-b43ffc33.jpg: 384x640 2 persons, 3 cars, 1 bench, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b31c98f7-a342fff6.jpg: 384x640 5 cars, 2 trucks, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b31cbddb-e2d8873f.jpg: 384x640 8 cars, 1 bus, 2 trucks, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b321c6b6-ab603d42.jpg: 384x640 5 cars, 1 train, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 557/10000 [00:17<04:32, 34.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3223c85-fccaf29d.jpg: 384x640 5 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b322412a-58073611.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b322412a-b47af37f.jpg: 384x640 1 truck, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3248383-f66bbcc1.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 561/10000 [00:17<04:30, 34.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b325fe35-b59e4e91.jpg: 384x640 2 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b32661a1-57c937fe.jpg: 384x640 3 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b329fe7d-f06455d3.jpg: 384x640 1 person, 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b32a9f8b-2b3d9894.jpg: 384x640 1 bus, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 565/10000 [00:17<04:29, 34.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b32f48c8-410503d5.jpg: 384x640 2 cars, 22.2ms\n",
            "Speed: 1.8ms preprocess, 22.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b331b06b-83fd459b.jpg: 384x640 7 cars, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3321962-e23b25e3.jpg: 384x640 12 cars, 2 trucks, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3329255-4a5988f8.jpg: 384x640 8 cars, 1 truck, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 569/10000 [00:17<04:41, 33.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3329255-76b9bb88.jpg: 384x640 16 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b332df78-28a61de0.jpg: 384x640 16 cars, 13.4ms\n",
            "Speed: 1.7ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b332df78-6765dddc.jpg: 384x640 10 cars, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b332df78-76e11eff.jpg: 384x640 6 cars, 2 traffic lights, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 573/10000 [00:17<04:44, 33.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b332df78-970364e2.jpg: 384x640 4 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b332df78-d6228140.jpg: 384x640 7 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b332df78-d6c7dff7.jpg: 384x640 4 cars, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3339cd5-06f84bb3.jpg: 384x640 16 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 577/10000 [00:18<04:43, 33.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3343231-8fe3f2e2.jpg: 384x640 4 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b334b56d-1dd4b8ad.jpg: 384x640 1 car, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b334b56d-2ce33cd7.jpg: 384x640 1 traffic light, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b334b56d-8296ef57.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 581/10000 [00:18<04:34, 34.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b334b56d-b82e26b5.jpg: 384x640 4 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3363496-032f16bf.jpg: 384x640 3 cars, 1 traffic light, 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3363496-9d8e32e7.jpg: 384x640 7 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b336bdb9-99780d3c.jpg: 384x640 1 fire hydrant, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 585/10000 [00:18<04:31, 34.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b336bdb9-ed5d2cc3.jpg: 384x640 4 cars, 2 traffic lights, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3378e5e-9b684546.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3378e5e-b7593301.jpg: 384x640 3 cars, 4 traffic lights, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3378e5e-e0df1ef5.jpg: 384x640 3 cars, 1 truck, 8.7ms\n",
            "Speed: 2.7ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 589/10000 [00:18<04:31, 34.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3386c15-1c922cea.jpg: 384x640 7 cars, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b338efff-595690ba.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b33a7e88-bc0eabcf.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b33ced12-423ec0dc.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 2 stop signs, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 593/10000 [00:18<04:30, 34.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b33ced12-5caa9205.jpg: 384x640 3 cars, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b33ced12-c53391e6.jpg: 384x640 1 car, 6 trucks, 7.6ms\n",
            "Speed: 2.4ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b33ea6cb-3464fb13.jpg: 384x640 3 persons, 8 cars, 2 trucks, 7.9ms\n",
            "Speed: 2.1ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b33ea6cb-8ef8b9c4.jpg: 384x640 10 persons, 2 cars, 2 trucks, 2 traffic lights, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 597/10000 [00:18<04:28, 34.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b33ea6cb-ddf24803.jpg: 384x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b33ec9f6-61139b0d.jpg: 384x640 4 cars, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3422c91-f0c36ed7.jpg: 384x640 3 persons, 2 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3432539-8f9fc466.jpg: 384x640 6 cars, 1 truck, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 601/10000 [00:18<04:24, 35.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3433dec-e7a93351.jpg: 384x640 4 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b344266e-2e034c1e.jpg: 384x640 2 persons, 4 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3450139-9dcaced8.jpg: 384x640 13 cars, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3450498-dbbb787e.jpg: 384x640 1 person, 5 cars, 2 trucks, 1 traffic light, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 605/10000 [00:18<04:23, 35.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3456910-6136f90e.jpg: 384x640 3 cars, 1 truck, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3456910-cf5fb475.jpg: 384x640 (no detections), 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3467777-44b644dd.jpg: 384x640 2 persons, 2 cars, 2 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3479da9-2d5165c5.jpg: 384x640 2 persons, 1 bicycle, 6 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3488ceb-84e6ade1.jpg: 384x640 10 cars, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 610/10000 [00:18<04:12, 37.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3497248-54bbe9be.jpg: 384x640 6 cars, 1 traffic light, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b34b1b88-0f326921.jpg: 384x640 1 car, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b34b1b88-5bfe3b85.jpg: 384x640 (no detections), 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b34e373f-fb594a99.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b350afdd-9c872c22.jpg: 384x640 3 cars, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 615/10000 [00:19<04:02, 38.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b352b7f5-276129f2.jpg: 384x640 9 cars, 3 trucks, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b352b7f5-c17c1c72.jpg: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b355880f-7cb7ed1e.jpg: 384x640 2 cars, 1 bus, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b355880f-9131b077.jpg: 384x640 1 person, 4 cars, 1 truck, 1 stop sign, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3560f77-2bb7f40d.jpg: 384x640 2 persons, 4 cars, 1 bus, 6.5ms\n",
            "Speed: 1.5ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 620/10000 [00:19<03:54, 39.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3563bcf-1962e18d.jpg: 384x640 9 cars, 1 truck, 7.1ms\n",
            "Speed: 1.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3565dc3-9d685e22.jpg: 384x640 4 cars, 18.8ms\n",
            "Speed: 1.8ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3566b0e-f8e7b731.jpg: 384x640 6 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3599e04-174421e4.jpg: 384x640 5 cars, 3 traffic lights, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▌         | 624/10000 [00:19<04:10, 37.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3599e04-2aa7d131.jpg: 384x640 1 car, 1 truck, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3599e04-6f80b3b7.jpg: 384x640 1 person, 2 cars, 1 truck, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35a415a-02526f57.jpg: 384x640 5 cars, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35c1016-4e29ef43.jpg: 384x640 1 person, 6 cars, 2 traffic lights, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▋         | 628/10000 [00:19<04:25, 35.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35c1016-5a7c77ee.jpg: 384x640 3 cars, 1 bus, 1 truck, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35c8e3d-439b1b23.jpg: 384x640 9 cars, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35c8e3d-bc2c104b.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35c8e3d-f985138a.jpg: 384x640 1 car, 1 bus, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▋         | 632/10000 [00:19<04:30, 34.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35cfd7c-2d625033.jpg: 384x640 3 cars, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35cfd7c-33d93645.jpg: 384x640 2 cars, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35dac08-031e3f6f.jpg: 384x640 9 cars, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35dac08-396cde53.jpg: 384x640 7 cars, 2 traffic lights, 11.3ms\n",
            "Speed: 3.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▋         | 636/10000 [00:19<04:35, 33.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35dac08-a80be8c5.jpg: 384x640 1 car, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b35f4a74-bd3dd74f.jpg: 384x640 7 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b362130a-d4f3a32a.jpg: 384x640 1 car, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b364b881-5dd3ec28.jpg: 384x640 3 cars, 4 traffic lights, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▋         | 640/10000 [00:19<04:45, 32.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b366921d-956d220b.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36710b9-7f5e88a3.jpg: 384x640 2 cars, 1 fire hydrant, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3674f80-8070d692.jpg: 384x640 4 persons, 5 cars, 2 trucks, 4 traffic lights, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3683422-cce330a8.jpg: 384x640 5 cars, 2 traffic lights, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▋         | 644/10000 [00:19<04:54, 31.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b368ee71-aba6eeef.jpg: 384x640 7 cars, 1 truck, 2 traffic lights, 21.8ms\n",
            "Speed: 1.9ms preprocess, 21.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b368ee71-c63152ff.jpg: 384x640 16 cars, 15.0ms\n",
            "Speed: 5.9ms preprocess, 15.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b368ee71-cf27b7fa.jpg: 384x640 1 bicycle, 5 cars, 1 traffic light, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b368ee71-e2f04304.jpg: 384x640 7 cars, 2 buss, 17.0ms\n",
            "Speed: 3.4ms preprocess, 17.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   6%|▋         | 648/10000 [00:20<05:28, 28.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36a5c73-437be32a.jpg: 384x640 1 person, 1 car, 13.9ms\n",
            "Speed: 2.1ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36a5c73-64eacfbf.jpg: 384x640 1 person, 3 cars, 1 truck, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36a5c73-7985c3ec.jpg: 384x640 4 cars, 1 truck, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36a5c73-cf70561a.jpg: 384x640 6 cars, 1 bus, 3 traffic lights, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 652/10000 [00:20<05:15, 29.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36d14ea-eed9255b.jpg: 384x640 14 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36de7af-08e5967a.jpg: 384x640 2 traffic lights, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36de7af-887696f9.jpg: 384x640 4 persons, 2 cars, 3 buss, 1 truck, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36de7af-ca137216.jpg: 384x640 8 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 656/10000 [00:20<05:02, 30.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36e0178-0f46bca5.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36e0178-2037ca44.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b36fcdfe-fd6585e0.jpg: 384x640 7 cars, 1 bus, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3709948-6e8ef33d.jpg: 384x640 1 car, 3 traffic lights, 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 660/10000 [00:20<04:56, 31.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b371451e-7caf934b.jpg: 384x640 3 cars, 1 truck, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b371dc0e-a5f4365f.jpg: 384x640 9 cars, 1 bus, 1 truck, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37385bd-9d5b76d4.jpg: 384x640 10 cars, 1 bus, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37693d0-cd9bdf88.jpg: 384x640 8 cars, 1 truck, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 664/10000 [00:20<05:00, 31.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b376c5c2-07a93591.jpg: 384x640 6 cars, 1 truck, 2 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3770858-ea33d0dc.jpg: 384x640 2 cars, 1 traffic light, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3770858-fa8c241b.jpg: 384x640 1 person, 5 cars, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b378e452-3aa3d11d.jpg: 384x640 4 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 668/10000 [00:20<04:51, 32.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b378e452-c639ce0f.jpg: 384x640 10 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37b0528-92d07297.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37b9cf2-9d52b009.jpg: 384x640 5 persons, 1 car, 1 bus, 2 trucks, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37c1ca4-561ffad3.jpg: 384x640 5 cars, 1 truck, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 672/10000 [00:20<04:46, 32.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37c2955-5f0aef70.jpg: 384x640 4 cars, 1 traffic light, 18.2ms\n",
            "Speed: 1.8ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37c2955-66532a77.jpg: 384x640 3 cars, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37c5be2-b9164b91.jpg: 384x640 9 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37c86c4-53f2f54c.jpg: 384x640 3 persons, 6 cars, 1 bus, 2 trucks, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 676/10000 [00:20<04:43, 32.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37cacf7-0d3ce003.jpg: 384x640 10 cars, 3 traffic lights, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37d75bd-e971140f.jpg: 384x640 5 persons, 9 cars, 1 bus, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37dfad0-708bd5bb.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37e9cc3-cf8111d8.jpg: 384x640 5 persons, 4 cars, 1 bus, 1 truck, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 680/10000 [00:21<04:47, 32.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37f2b89-44772e64.jpg: 384x640 2 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b37fcc2f-fa9beaf4.jpg: 384x640 4 cars, 3 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b380ae2f-afd868dc.jpg: 384x640 1 car, 1 bus, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3810b68-42b78db3.jpg: 384x640 2 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 684/10000 [00:21<04:35, 33.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3815e24-b9565680.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3823cab-48611ba2.jpg: 384x640 1 person, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3823cab-b88da702.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3826400-c03b5432.jpg: 384x640 7 cars, 3 traffic lights, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 688/10000 [00:21<04:28, 34.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3826fd8-774c2e0a.jpg: 384x640 6 persons, 9 cars, 1 truck, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3841888-101ea0f3.jpg: 384x640 7 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3853f81-272f6c37.jpg: 384x640 2 persons, 5 cars, 1 truck, 3 traffic lights, 16.9ms\n",
            "Speed: 1.9ms preprocess, 16.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38580a1-f26eb052.jpg: 384x640 1 person, 12 cars, 1 fire hydrant, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 692/10000 [00:21<04:53, 31.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b385ecb1-7f38178b.jpg: 384x640 1 car, 3 traffic lights, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3865788-92f46f80.jpg: 384x640 8 cars, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b386d34e-a6a9ea07.jpg: 384x640 6 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3875c8d-cc4081eb.jpg: 384x640 9 cars, 1 truck, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 696/10000 [00:21<04:46, 32.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b388f9b2-55dbd56a.jpg: 384x640 6 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b388f9b2-a91718d0.jpg: 384x640 2 cars, 1 traffic light, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3899bec-df46f67b.jpg: 384x640 4 cars, 1 train, 1 truck, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38b2b6a-77f9d5e5.jpg: 384x640 1 car, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 700/10000 [00:21<04:39, 33.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38b2b6a-cb374ce8.jpg: 384x640 1 car, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38b4f98-0e8820b0.jpg: 384x640 1 person, 10 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38b8783-9cc1ad04.jpg: 384x640 8 persons, 3 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38e631d-e2d95e18.jpg: 384x640 2 cars, 1 bus, 1 truck, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 704/10000 [00:21<04:33, 34.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38f59d4-58f1cff8.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38f59d4-8dfeca9f.jpg: 384x640 1 person, 3 cars, 1 bus, 1 truck, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38fb69e-5f5f73ae.jpg: 384x640 1 car, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b38fb69e-99642683.jpg: 384x640 4 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 708/10000 [00:21<04:22, 35.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3931c96-5417a573.jpg: 384x640 6 cars, 1 truck, 11.3ms\n",
            "Speed: 4.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3933f83-a32ef4fd.jpg: 384x640 4 cars, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b394dd7a-8901eb36.jpg: 384x640 7 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b394dd7a-db2b62a1.jpg: 384x640 3 cars, 1 bus, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 712/10000 [00:22<04:26, 34.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b394dd7a-fe45748a.jpg: 384x640 12 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39519c6-7f66da0f.jpg: 384x640 2 traffic lights, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39519c6-b3787b96.jpg: 384x640 1 person, 4 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39572b6-aa95db3d.jpg: 384x640 1 person, 3 cars, 1 train, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39572b6-ad240c2b.jpg: 384x640 9 cars, 1 truck, 1 stop sign, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 717/10000 [00:22<04:12, 36.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3967d1b-0088ba4e.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3967d1b-2ff5c0ef.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3967d1b-5dbec492.jpg: 384x640 2 cars, 1 traffic light, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3969458-13fa5e0e.jpg: 384x640 2 cars, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3969458-7c67d658.jpg: 384x640 1 person, 3 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 722/10000 [00:22<04:04, 38.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b396946b-d29f75f9.jpg: 384x640 1 person, 18 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b396e413-6c8191b9.jpg: 384x640 5 cars, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b398327e-08f3a1f2.jpg: 384x640 2 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b398327e-3d2a2683.jpg: 384x640 4 cars, 1 truck, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 726/10000 [00:22<04:15, 36.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b398327e-f873cb8b.jpg: 384x640 5 cars, 1 truck, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b398a52e-5d44ea66.jpg: 384x640 1 car, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b398e0fb-257cf424.jpg: 384x640 8 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3990772-45bf6ad7.jpg: 384x640 6 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 730/10000 [00:22<04:10, 37.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3990aa9-4fb64582.jpg: 384x640 1 person, 7 cars, 2 trucks, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3990aa9-8adaa51a.jpg: 384x640 8 cars, 1 truck, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39dd7ca-a740454f.jpg: 384x640 1 person, 1 car, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39e8c78-f02c29c6.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 734/10000 [00:22<04:13, 36.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-076e7ef7.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-12217985.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-183566f9.jpg: 384x640 2 persons, 1 car, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-1eb875fa.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 738/10000 [00:22<04:07, 37.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-227ff7a8.jpg: 384x640 3 cars, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-29b2a728.jpg: 384x640 9 cars, 1 traffic light, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-2a77c651.jpg: 384x640 6 cars, 1 bus, 1 traffic light, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-2b89090a.jpg: 384x640 7 cars, 2 traffic lights, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 742/10000 [00:22<04:10, 36.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-34b1611e.jpg: 384x640 2 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-398678c5.jpg: 384x640 1 traffic light, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-553d15a3.jpg: 384x640 1 person, 2 cars, 1 traffic light, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-65f6ed9d.jpg: 384x640 5 cars, 1 tv, 12.6ms\n",
            "Speed: 6.4ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   7%|▋         | 746/10000 [00:22<04:11, 36.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-d295442e.jpg: 384x640 1 tv, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-d5fb9508.jpg: 384x640 6 cars, 1 tv, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39fe3cd-f0d534c0.jpg: 384x640 4 cars, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39ffdda-b9a4ad33.jpg: 384x640 11 cars, 3 traffic lights, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 750/10000 [00:23<04:33, 33.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b39ffdda-eec0cc38.jpg: 384x640 7 cars, 1 bus, 1 truck, 2 traffic lights, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a087a4-9d116610.jpg: 384x640 6 cars, 1 truck, 1 traffic light, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a102ed-6ef54f5e.jpg: 384x640 7 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a1e72b-1f4b129d.jpg: 384x640 2 cars, 1 traffic light, 9.7ms\n",
            "Speed: 4.8ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 754/10000 [00:23<04:40, 32.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a1e72b-f46924ca.jpg: 384x640 4 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a1e72b-f9a8ed50.jpg: 384x640 7 cars, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a238e3-de6b8b86.jpg: 384x640 4 cars, 3 traffic lights, 11.5ms\n",
            "Speed: 5.4ms preprocess, 11.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a238e3-ede6d45d.jpg: 384x640 7 cars, 1 train, 1 truck, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 758/10000 [00:23<05:04, 30.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a3d166-3a6a258d.jpg: 384x640 2 cars, 1 truck, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a4cbbb-73f71148.jpg: 384x640 6 cars, 14.7ms\n",
            "Speed: 5.3ms preprocess, 14.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a4cbbb-b67444d7.jpg: 384x640 1 car, 1 stop sign, 17.9ms\n",
            "Speed: 4.7ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a58c04-e89d17a2.jpg: 384x640 4 persons, 4 cars, 2 trucks, 1 traffic light, 14.5ms\n",
            "Speed: 4.8ms preprocess, 14.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 762/10000 [00:23<05:31, 27.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a6f586-21d97cce.jpg: 384x640 15 cars, 1 bus, 2 trucks, 18.5ms\n",
            "Speed: 3.8ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a6f586-23d13c49.jpg: 384x640 2 cars, 16.0ms\n",
            "Speed: 1.9ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a6f586-3ea7e1ad.jpg: 384x640 1 person, 6 cars, 1 bus, 1 truck, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 765/10000 [00:23<05:52, 26.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a72605-98b37492.jpg: 384x640 4 cars, 15.4ms\n",
            "Speed: 6.0ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a76bd5-4e7a1ce2.jpg: 384x640 1 person, 7 cars, 1 potted plant, 14.8ms\n",
            "Speed: 6.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a7b21a-48bcf2b8.jpg: 384x640 4 cars, 1 train, 18.7ms\n",
            "Speed: 2.0ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 768/10000 [00:23<05:58, 25.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a84a0f-0fb529e1.jpg: 384x640 10 cars, 1 bus, 15.0ms\n",
            "Speed: 3.0ms preprocess, 15.0ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a84a0f-61844c69.jpg: 384x640 6 cars, 1 truck, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a87019-ba714074.jpg: 384x640 1 person, 10 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a9281a-74ae5b60.jpg: 384x640 7 cars, 1 truck, 4 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 772/10000 [00:23<05:32, 27.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a9281a-75473a1b.jpg: 384x640 8 cars, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a9281a-8b4f26f1.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a9281a-e8ba5d66.jpg: 384x640 9 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a94ee5-68ed7d65.jpg: 384x640 8 cars, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 776/10000 [00:24<05:04, 30.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3a969fe-5181b89f.jpg: 384x640 6 cars, 18.6ms\n",
            "Speed: 1.9ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3aacff1-967c15c1.jpg: 384x640 7 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3acb0a1-f459ea19.jpg: 384x640 1 truck, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ae380d-76bac333.jpg: 384x640 4 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 780/10000 [00:24<04:53, 31.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ae7668-c78f47c8.jpg: 384x640 7 cars, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b06694-627742e3.jpg: 384x640 7 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b0f7f7-c97288ca.jpg: 384x640 6 cars, 2 traffic lights, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b2ffbe-cd80cda8.jpg: 384x640 15 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 784/10000 [00:24<04:43, 32.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b44b49-3af119e3.jpg: 384x640 3 persons, 6 cars, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b44b49-7336e3ee.jpg: 384x640 5 cars, 1 truck, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b4c0fe-2683b31e.jpg: 384x640 1 person, 4 cars, 1 truck, 14.8ms\n",
            "Speed: 5.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b64b42-403091d9.jpg: 384x640 4 persons, 6 cars, 1 truck, 5 traffic lights, 16.1ms\n",
            "Speed: 4.1ms preprocess, 16.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 788/10000 [00:24<05:06, 30.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b64b42-dab3c506.jpg: 384x640 11 cars, 1 bus, 1 truck, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b8fce6-c67646a7.jpg: 384x640 3 persons, 4 cars, 2 trucks, 1 traffic light, 11.1ms\n",
            "Speed: 5.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b94eea-b06bca81.jpg: 384x640 2 persons, 3 cars, 2 trucks, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3b9ee6e-6d2617d1.jpg: 384x640 5 cars, 16.7ms\n",
            "Speed: 2.1ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 792/10000 [00:24<05:33, 27.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3bbc110-3ef16a61.jpg: 384x640 4 cars, 17.5ms\n",
            "Speed: 2.6ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3bc36c8-03cb07d2.jpg: 384x640 1 person, 8 cars, 3 benchs, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3be4113-1fb56ec4.jpg: 384x640 3 cars, 12.6ms\n",
            "Speed: 5.0ms preprocess, 12.6ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 795/10000 [00:24<05:47, 26.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3be4113-a7c6d89b.jpg: 384x640 3 persons, 2 cars, 2 traffic lights, 19.5ms\n",
            "Speed: 1.9ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c0357a-10fef986.jpg: 384x640 5 persons, 1 car, 2 traffic lights, 18.2ms\n",
            "Speed: 5.1ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c0460d-33d7256d.jpg: 384x640 7 cars, 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 798/10000 [00:24<05:57, 25.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c094d3-75cda540.jpg: 384x640 1 person, 10 cars, 1 truck, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c21bae-260d0b00.jpg: 384x640 1 car, 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c26aff-417063a0.jpg: 384x640 8 cars, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 801/10000 [00:24<05:57, 25.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c26aff-63a0d7d6.jpg: 384x640 (no detections), 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c2f984-a6fb75a4.jpg: 384x640 9 cars, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c39081-34b43a1c.jpg: 384x640 3 cars, 4 traffic lights, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 804/10000 [00:25<05:44, 26.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c3f8ef-8f40dc74.jpg: 384x640 3 cars, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c4e98b-0c191966.jpg: 384x640 2 cars, 1 truck, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c4e98b-2788a3e8.jpg: 384x640 3 cars, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c4e98b-8469f497.jpg: 384x640 4 cars, 10.1ms\n",
            "Speed: 4.0ms preprocess, 10.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 808/10000 [00:25<05:20, 28.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c4e98b-da58e181.jpg: 384x640 1 car, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c672a8-b7b886ae.jpg: 384x640 2 cars, 1 traffic light, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c939e3-370d8f4a.jpg: 384x640 1 person, 4 cars, 1 traffic light, 20.4ms\n",
            "Speed: 1.9ms preprocess, 20.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 811/10000 [00:25<05:21, 28.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c939e3-3fb7622a.jpg: 384x640 1 car, 2 buss, 17.1ms\n",
            "Speed: 3.9ms preprocess, 17.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c939e3-61fb6427.jpg: 384x640 6 cars, 2 trucks, 1 traffic light, 17.4ms\n",
            "Speed: 2.9ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3c9eef1-dcb3d0e7.jpg: 384x640 11 cars, 1 traffic light, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 814/10000 [00:25<05:36, 27.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3cc736f-03134262.jpg: 384x640 (no detections), 17.5ms\n",
            "Speed: 3.8ms preprocess, 17.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3cc736f-7a7794c0.jpg: 384x640 2 cars, 16.6ms\n",
            "Speed: 2.9ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3cc736f-b7a66149.jpg: 384x640 2 cars, 3 trucks, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 817/10000 [00:25<05:37, 27.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3cd4bfe-93377084.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ce9f98-2b3d06d6.jpg: 384x640 1 car, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ce9f98-2dc52573.jpg: 384x640 (no detections), 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ce9f98-97451163.jpg: 384x640 3 cars, 1 truck, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 821/10000 [00:25<05:19, 28.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d0ccae-26380ab5.jpg: 384x640 7 cars, 4 traffic lights, 13.2ms\n",
            "Speed: 3.6ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d0d68d-cc5961d6.jpg: 384x640 7 cars, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d264b3-fbaef5ac.jpg: 384x640 3 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d4554c-86182e6e.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 825/10000 [00:25<05:02, 30.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d46fca-a69e8189.jpg: 384x640 3 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d46fca-a8bd9b5c.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d46fca-dbf2af72.jpg: 384x640 (no detections), 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d54db3-9ac260a3.jpg: 384x640 11 cars, 1 traffic light, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 829/10000 [00:25<04:48, 31.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d67c06-57b140bf.jpg: 384x640 11 cars, 1 traffic light, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d6c39a-07f81865.jpg: 384x640 6 persons, 1 bus, 1 truck, 1 stop sign, 11.6ms\n",
            "Speed: 3.7ms preprocess, 11.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d6c39a-0a14df0d.jpg: 384x640 6 cars, 1 truck, 10.7ms\n",
            "Speed: 3.7ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d6c39a-7bb39a3a.jpg: 384x640 10 cars, 2 trucks, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 833/10000 [00:25<04:54, 31.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d6c39a-a396c692.jpg: 384x640 13 cars, 3 traffic lights, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3d6c39a-ecf305b3.jpg: 384x640 16 cars, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3da33d5-a64e7657.jpg: 384x640 16 cars, 1 truck, 13.9ms\n",
            "Speed: 6.6ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3db60f1-533170c9.jpg: 384x640 6 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 837/10000 [00:26<05:20, 28.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3dc64cd-37f9c22d.jpg: 384x640 3 persons, 4 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3dc64cd-705e7567.jpg: 384x640 1 person, 3 cars, 4 traffic lights, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3dd5345-15bbf8ed.jpg: 384x640 1 car, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3dfa1f5-9f4eded2.jpg: 384x640 5 cars, 1 truck, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 841/10000 [00:26<05:16, 28.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e0345b-20d013f8.jpg: 384x640 9 cars, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e0345b-69069f01.jpg: 384x640 6 persons, 4 cars, 1 truck, 1 traffic light, 16.8ms\n",
            "Speed: 4.0ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e0345b-ae566cbd.jpg: 384x640 3 cars, 18.5ms\n",
            "Speed: 1.9ms preprocess, 18.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 844/10000 [00:26<05:25, 28.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e08585-1fcf0877.jpg: 384x640 1 car, 17.4ms\n",
            "Speed: 3.7ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e08585-3f5e6565.jpg: 384x640 1 person, 4 cars, 18.2ms\n",
            "Speed: 1.8ms preprocess, 18.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e08585-5cf240fb.jpg: 384x640 7 cars, 2 traffic lights, 14.9ms\n",
            "Speed: 3.6ms preprocess, 14.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 847/10000 [00:26<05:26, 28.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e08585-cb03a2fb.jpg: 384x640 3 traffic lights, 17.2ms\n",
            "Speed: 2.0ms preprocess, 17.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e137e5-fe7ef981.jpg: 384x640 9 cars, 6 traffic lights, 16.8ms\n",
            "Speed: 2.1ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e18480-118f9e2f.jpg: 384x640 1 person, 6 cars, 17.7ms\n",
            "Speed: 2.0ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   8%|▊         | 850/10000 [00:26<05:51, 26.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e18480-6c84e030.jpg: 384x640 4 persons, 2 cars, 2 trucks, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e2086f-4db03957.jpg: 384x640 2 persons, 6 cars, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e2086f-d41fbd4d.jpg: 384x640 3 persons, 2 cars, 1 truck, 3 traffic lights, 15.8ms\n",
            "Speed: 4.5ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▊         | 853/10000 [00:26<05:54, 25.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e32b36-0ca66c00.jpg: 384x640 1 person, 3 cars, 1 bus, 1 truck, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e51564-d2ac524c.jpg: 384x640 2 persons, 10 cars, 1 truck, 19.3ms\n",
            "Speed: 1.9ms preprocess, 19.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e65789-dfe0bc9e.jpg: 384x640 8 cars, 1 truck, 1 stop sign, 14.7ms\n",
            "Speed: 6.6ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▊         | 856/10000 [00:26<06:21, 24.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e70fdd-e1df8660.jpg: 384x640 2 cars, 2 traffic lights, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e72283-34ebe4f5.jpg: 384x640 9 cars, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e72283-584093dc.jpg: 384x640 7 cars, 10.9ms\n",
            "Speed: 7.0ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▊         | 859/10000 [00:27<06:01, 25.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e72283-595c3576.jpg: 384x640 2 cars, 1 truck, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e72283-d1f9593d.jpg: 384x640 4 cars, 2 traffic lights, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e72283-d9fc39b0.jpg: 384x640 5 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e74777-122e3878.jpg: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▊         | 863/10000 [00:27<05:21, 28.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e7bfdb-0ce50151.jpg: 384x640 4 cars, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e83de5-c5e9dcca.jpg: 384x640 5 cars, 1 truck, 2 traffic lights, 1 stop sign, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3e921ad-1fc43094.jpg: 384x640 11 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ea5e17-c67b7a7a.jpg: 384x640 1 person, 2 cars, 1 bus, 1 truck, 19.2ms\n",
            "Speed: 2.9ms preprocess, 19.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▊         | 867/10000 [00:27<05:17, 28.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ea802a-8830eb32.jpg: 384x640 8 cars, 1 truck, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ea802a-c689de9a.jpg: 384x640 12 cars, 17.0ms\n",
            "Speed: 5.9ms preprocess, 17.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3eafc22-1064ce9e.jpg: 384x640 2 cars, 1 truck, 16.4ms\n",
            "Speed: 2.1ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▊         | 870/10000 [00:27<05:31, 27.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3eb8895-e5b1e6df.jpg: 384x640 11 cars, 17.0ms\n",
            "Speed: 2.1ms preprocess, 17.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ec8e38-41c64395.jpg: 384x640 2 cars, 1 truck, 14.8ms\n",
            "Speed: 3.5ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ee5ba2-6cc0565d.jpg: 384x640 1 person, 8 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▊         | 873/10000 [00:27<05:27, 27.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3eede0e-f4585509.jpg: 384x640 1 car, 11.3ms\n",
            "Speed: 4.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ef316c-2906f850.jpg: 384x640 2 cars, 1 bus, 2 trucks, 16.0ms\n",
            "Speed: 3.3ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3ef6557-e6709cd9.jpg: 384x640 3 cars, 1 truck, 2 traffic lights, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f0cdab-6712e58f.jpg: 384x640 1 traffic light, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 877/10000 [00:27<05:15, 28.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f0cdab-d5954c9a.jpg: 384x640 6 cars, 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f17367-d730de0b.jpg: 384x640 13 cars, 1 bus, 19.7ms\n",
            "Speed: 1.9ms preprocess, 19.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f2fee7-1482dee6.jpg: 384x640 1 person, 3 cars, 2 traffic lights, 17.3ms\n",
            "Speed: 3.0ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 880/10000 [00:27<05:26, 27.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f3c908-0ab1d376.jpg: 384x640 6 cars, 18.8ms\n",
            "Speed: 1.9ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f3c908-48568eda.jpg: 384x640 5 cars, 3 traffic lights, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f3c908-baffb699.jpg: 384x640 1 person, 3 cars, 14.4ms\n",
            "Speed: 5.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 883/10000 [00:27<05:34, 27.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f479a1-b85845b3.jpg: 384x640 6 cars, 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f59b98-e7f870e2.jpg: 384x640 5 cars, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f603f2-4a80d188.jpg: 384x640 1 car, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3f7c502-d89499e0.jpg: 384x640 4 cars, 4 traffic lights, 11.8ms\n",
            "Speed: 4.1ms preprocess, 11.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 887/10000 [00:27<05:26, 27.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3fbc6ad-4ee78a0d.jpg: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b3fbc6ad-746053d9.jpg: 384x640 13 cars, 1 truck, 3 traffic lights, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b400b7f4-9c93e226.jpg: 384x640 10 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b401b6fa-a9a7f11d.jpg: 384x640 8 cars, 1 fire hydrant, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 891/10000 [00:28<05:13, 29.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b403b27c-37cac4b8.jpg: 384x640 1 person, 5 cars, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b40476bc-1397121a.jpg: 384x640 3 cars, 1 bus, 1 truck, 1 traffic light, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4065fc4-ede06556.jpg: 384x640 14 persons, 8 cars, 1 bus, 1 train, 2 traffic lights, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 894/10000 [00:28<05:15, 28.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b40669bb-19958f9a.jpg: 384x640 1 car, 2 traffic lights, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b406dc5a-44d22755.jpg: 384x640 2 cars, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b406dc5a-7a946e61.jpg: 384x640 1 car, 2 buss, 1 truck, 1 traffic light, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b407aa58-02233e09.jpg: 384x640 1 car, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 898/10000 [00:28<04:55, 30.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4082905-e694720e.jpg: 384x640 5 cars, 1 traffic light, 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b409ed8a-da6926db.jpg: 384x640 8 cars, 1 traffic light, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b409ed8a-e7d46dce.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b40b0ea3-b242efc9.jpg: 384x640 4 cars, 1 truck, 1 fire hydrant, 19.8ms\n",
            "Speed: 1.9ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 902/10000 [00:28<05:06, 29.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b40cd5b3-ebe11d7a.jpg: 384x640 6 persons, 7 cars, 2 traffic lights, 18.4ms\n",
            "Speed: 1.9ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b40ce2eb-ac2ffa01.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b40ce2eb-c53a5e8e.jpg: 384x640 1 person, 11 cars, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 905/10000 [00:28<05:16, 28.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b40e08ea-f2d97c95.jpg: 384x640 8 persons, 3 cars, 2 traffic lights, 1 fire hydrant, 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4110365-9ae12ee1.jpg: 384x640 4 cars, 1 truck, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4115405-2f28f75a.jpg: 384x640 1 bicycle, 8 cars, 2 traffic lights, 15.1ms\n",
            "Speed: 3.1ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 908/10000 [00:28<05:30, 27.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b413b23f-7c897b06.jpg: 384x640 6 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b415973a-b39bd6de.jpg: 384x640 3 persons, 4 cars, 4 trucks, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b415cc29-7371aa85.jpg: 384x640 9 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4174c37-1f3b4b77.jpg: 384x640 4 cars, 3 traffic lights, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 912/10000 [00:28<05:14, 28.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b417ddcd-b1a6dfc8.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41ace08-830c808c.jpg: 384x640 7 cars, 1 train, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41ace08-88fb022d.jpg: 384x640 5 cars, 1 truck, 12.3ms\n",
            "Speed: 3.1ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41ace08-8b937256.jpg: 384x640 1 car, 4 traffic lights, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 916/10000 [00:28<04:56, 30.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41ace08-c8468690.jpg: 384x640 6 cars, 1 truck, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41b3454-e034bb74.jpg: 384x640 2 persons, 15 cars, 16.8ms\n",
            "Speed: 3.9ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41cc383-337e708b.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41d0744-6cabc495.jpg: 384x640 10 cars, 1 truck, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 920/10000 [00:29<05:09, 29.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41d35f8-6cf85033.jpg: 384x640 5 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41d71c1-47e43030.jpg: 384x640 9 cars, 4 trucks, 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b41e6d87-872385f8.jpg: 384x640 2 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 923/10000 [00:29<05:07, 29.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4201bd2-75c1998d.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b421c89a-c7cdebb4.jpg: 384x640 5 cars, 4 traffic lights, 18.6ms\n",
            "Speed: 3.1ms preprocess, 18.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b422ec08-236606a0.jpg: 384x640 1 person, 1 bicycle, 7 cars, 1 truck, 16.7ms\n",
            "Speed: 2.6ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 926/10000 [00:29<05:28, 27.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b422ec08-d42660b6.jpg: 384x640 9 cars, 4 trucks, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4235ab3-6f3f972f.jpg: 384x640 2 traffic lights, 17.1ms\n",
            "Speed: 2.7ms preprocess, 17.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4235ab3-a1c929ae.jpg: 384x640 4 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 929/10000 [00:29<05:30, 27.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4235ab3-b305d3e9.jpg: 384x640 1 car, 1 traffic light, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4253085-22b9e610.jpg: 384x640 4 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4253085-3de357a1.jpg: 384x640 1 person, 1 bicycle, 3 cars, 3 traffic lights, 14.7ms\n",
            "Speed: 1.8ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4253085-85838593.jpg: 384x640 1 person, 1 car, 1 traffic light, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 933/10000 [00:29<05:10, 29.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4253085-9f907156.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 3.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4253085-ce679d21.jpg: 384x640 3 cars, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4253085-d5fcbadc.jpg: 384x640 2 persons, 5 cars, 1 bench, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4253988-26b49c14.jpg: 384x640 4 cars, 3 traffic lights, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 937/10000 [00:29<04:55, 30.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4259d0f-137ad720.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4259d0f-8b672078.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4259d0f-d93d7a19.jpg: 384x640 2 persons, 4 cars, 2 traffic lights, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b426ea12-4e58141a.jpg: 384x640 3 cars, 1 traffic light, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 941/10000 [00:29<04:38, 32.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4278d1f-3a128041.jpg: 384x640 1 car, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4278d1f-dbd0295c.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4284bbe-1905abe0.jpg: 384x640 2 persons, 9 cars, 5 traffic lights, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42913b9-49092dfe.jpg: 384x640 7 cars, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 945/10000 [00:29<04:28, 33.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42acb4c-ac2e0180.jpg: 384x640 1 person, 1 car, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42b0859-0e5601ac.jpg: 384x640 19 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42cd355-1ce051b1.jpg: 384x640 9 cars, 1 truck, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42df626-243bcce8.jpg: 384x640 1 car, 1 bus, 2 traffic lights, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   9%|▉         | 949/10000 [00:30<04:27, 33.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42df626-3c4d9bfd.jpg: 384x640 1 person, 11 cars, 4 traffic lights, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42df626-73f78ba9.jpg: 384x640 1 person, 7 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42df626-bee4420b.jpg: 384x640 3 persons, 2 cars, 1 truck, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42df626-e358ca4a.jpg: 384x640 2 persons, 6 cars, 1 traffic light, 1 bench, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 953/10000 [00:30<04:28, 33.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42e1548-6b544378.jpg: 384x640 8 cars, 3 traffic lights, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42e6271-4bce300c.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b42fdaf1-0925c561.jpg: 384x640 2 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4301c7b-735da0d0.jpg: 384x640 5 persons, 3 cars, 2 trucks, 1 bench, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 957/10000 [00:30<04:32, 33.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4301c7b-da5261f0.jpg: 384x640 5 cars, 1 bus, 2 trucks, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4304e43-89ba0daa.jpg: 384x640 4 persons, 5 cars, 1 bus, 3 trucks, 1 fire hydrant, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4333743-072dae1e.jpg: 384x640 1 person, 5 cars, 1 truck, 2 traffic lights, 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b433534e-ff3646aa.jpg: 384x640 3 persons, 5 cars, 1 truck, 3 traffic lights, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 961/10000 [00:30<04:48, 31.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4340944-5f7048d1.jpg: 384x640 2 cars, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b439c4fe-5064fe59.jpg: 384x640 1 bicycle, 9 cars, 2 trucks, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b439d51b-5d88ba11.jpg: 384x640 6 cars, 1 bus, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b43bcc83-c97d569e.jpg: 384x640 2 persons, 4 cars, 1 truck, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 965/10000 [00:30<04:57, 30.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b43de6e1-f20e4351.jpg: 384x640 3 cars, 19.8ms\n",
            "Speed: 2.2ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b43eb946-92f9152d.jpg: 384x640 8 cars, 2 trucks, 18.2ms\n",
            "Speed: 1.9ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b43eb946-b8bc931c.jpg: 384x640 5 cars, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b43eb946-c0cad251.jpg: 384x640 6 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 969/10000 [00:30<05:15, 28.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b440d54c-2aff7bf8.jpg: 384x640 2 persons, 6 cars, 3 trucks, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b440d54c-5f5ff777.jpg: 384x640 3 cars, 1 truck, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b442c34a-6fe5cbba.jpg: 384x640 2 persons, 3 cars, 1 truck, 3 traffic lights, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4448a1d-e9c03bb5.jpg: 384x640 7 cars, 1 bus, 1 traffic light, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 973/10000 [00:30<05:07, 29.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4466011-05cbc315.jpg: 384x640 10 cars, 1 traffic light, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b446d26a-9717e68c.jpg: 384x640 1 car, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4475526-2f0bca11.jpg: 384x640 4 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4475526-4a48bfe5.jpg: 384x640 7 cars, 1 traffic light, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 977/10000 [00:30<05:00, 29.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4475e22-27ceb162.jpg: 384x640 5 cars, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4478c66-0103c647.jpg: 384x640 1 person, 7 cars, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b447a3cf-10656b18.jpg: 384x640 2 cars, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b449af64-1cfd83f9.jpg: 384x640 3 persons, 5 cars, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 981/10000 [00:31<04:46, 31.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44a71bf-4d366798.jpg: 384x640 5 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44a71bf-712b4538.jpg: 384x640 2 persons, 4 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44a7e5f-1db66cfe.jpg: 384x640 1 person, 5 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44a7e5f-30a49487.jpg: 384x640 7 cars, 1 bus, 1 traffic light, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 985/10000 [00:31<04:35, 32.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44a7e5f-37c27ba5.jpg: 384x640 1 person, 6 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44a7e5f-89b66e95.jpg: 384x640 6 cars, 1 traffic light, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44b6eff-dda9780d.jpg: 384x640 1 person, 7 cars, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44bcbbe-e980e271.jpg: 384x640 3 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 989/10000 [00:31<04:30, 33.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44cb319-fb4c4b4f.jpg: 384x640 1 car, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44d57fb-e85243b2.jpg: 384x640 2 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44ee0ec-a0786e4c.jpg: 384x640 1 person, 3 cars, 14.1ms\n",
            "Speed: 5.9ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44f2475-c80a51b7.jpg: 384x640 1 person, 7 cars, 4 traffic lights, 2 stop signs, 10.1ms\n",
            "Speed: 9.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 993/10000 [00:31<04:43, 31.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44f7365-beb4d3e7.jpg: 384x640 9 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44fd543-87f493ee.jpg: 384x640 6 cars, 1 traffic light, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b44fd543-a15ceadf.jpg: 384x640 10 cars, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b451b495-bb458d47.jpg: 384x640 1 person, 3 cars, 2 traffic lights, 14.7ms\n",
            "Speed: 2.2ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|▉         | 997/10000 [00:31<04:45, 31.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4536117-bc85ba28.jpg: 384x640 3 cars, 2 trucks, 15.3ms\n",
            "Speed: 2.0ms preprocess, 15.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b454034b-d84dae74.jpg: 384x640 7 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4542860-0b880bb4.jpg: 384x640 8 persons, 9 cars, 1 traffic light, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4542860-40cc6d5a.jpg: 384x640 4 cars, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1001/10000 [00:31<04:59, 30.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4542860-e818b412.jpg: 384x640 11 cars, 1 truck, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4543c78-696f5be4.jpg: 384x640 5 cars, 2 trucks, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4543c78-db967acc.jpg: 384x640 2 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4543c78-ee2e75f3.jpg: 384x640 6 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1005/10000 [00:31<04:49, 31.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4561bec-26a99096.jpg: 384x640 2 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4581cf1-8515d725.jpg: 384x640 6 cars, 2 trucks, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4581cf1-fa4a5f32.jpg: 384x640 13 cars, 1 truck, 3 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b45928e6-f07ac4c9.jpg: 384x640 1 person, 5 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1009/10000 [00:31<04:43, 31.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4599849-8379f0de.jpg: 384x640 10 cars, 3 traffic lights, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4599acc-dd9c9177.jpg: 384x640 1 car, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b459e707-2d208c56.jpg: 384x640 3 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b45a63ea-fb379a2d.jpg: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1013/10000 [00:32<04:31, 33.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b45d3222-6a6544e2.jpg: 384x640 4 cars, 3 traffic lights, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b45ddf05-e4775ab6.jpg: 384x640 12 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b45f01c5-85bc12e8.jpg: 384x640 4 persons, 3 cars, 1 bus, 2 traffic lights, 2 umbrellas, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b45f2c17-2cae6d9f.jpg: 384x640 3 cars, 1 train, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1017/10000 [00:32<04:25, 33.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b45f2c17-e27031fb.jpg: 384x640 1 traffic light, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46009c2-72be5f8b.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46009c2-9334336d.jpg: 384x640 2 cars, 1 traffic light, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46009c2-f64f79ff.jpg: 384x640 (no detections), 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1021/10000 [00:32<04:14, 35.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46009c2-f92ccaa1.jpg: 384x640 7 cars, 14.9ms\n",
            "Speed: 3.1ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4607812-225d9a01.jpg: 384x640 2 persons, 2 cars, 1 bus, 1 truck, 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4607812-48ed5dcb.jpg: 384x640 9 persons, 7 cars, 1 truck, 2 traffic lights, 10.0ms\n",
            "Speed: 4.1ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4607812-9259ade8.jpg: 384x640 1 person, 3 cars, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1025/10000 [00:32<04:48, 31.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4607812-d0ab0af7.jpg: 384x640 7 cars, 1 truck, 1 traffic light, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4620633-1c10abdb.jpg: 384x640 2 cars, 21.1ms\n",
            "Speed: 1.8ms preprocess, 21.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4626a3d-9361e0fd.jpg: 384x640 8 persons, 6 cars, 2 handbags, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b462d8a3-a32ccc75.jpg: 384x640 4 persons, 5 cars, 1 truck, 2 traffic lights, 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1029/10000 [00:32<05:22, 27.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4632db3-9724d92c.jpg: 384x640 5 cars, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46478b0-167fe009.jpg: 384x640 1 traffic light, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46478b0-1eb55806.jpg: 384x640 10 persons, 3 cars, 1 traffic light, 15.1ms\n",
            "Speed: 2.0ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1032/10000 [00:32<05:21, 27.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b464d209-9e91f389.jpg: 384x640 4 cars, 18.0ms\n",
            "Speed: 2.0ms preprocess, 18.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4654b11-c935938c.jpg: 384x640 3 cars, 16.7ms\n",
            "Speed: 2.0ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4654b11-fc1af85a.jpg: 384x640 2 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1035/10000 [00:32<05:16, 28.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4672385-6ea18d27.jpg: 384x640 1 car, 1 truck, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4672385-70ffa818.jpg: 384x640 3 cars, 1 bus, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4688d0b-3e2bda23.jpg: 384x640 2 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46a845f-8867c137.jpg: 384x640 1 person, 7 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1039/10000 [00:32<04:57, 30.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46d2f57-0fb71a0d.jpg: 384x640 6 cars, 2 fire hydrants, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46d2f57-82953e7a.jpg: 384x640 1 person, 6 cars, 1 fire hydrant, 10.6ms\n",
            "Speed: 4.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46ee89c-5d054327.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46ee89c-76b16eec.jpg: 384x640 4 cars, 10.6ms\n",
            "Speed: 1.7ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1043/10000 [00:33<04:44, 31.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46efeed-4e09d4a1.jpg: 384x640 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46efeed-a398b08d.jpg: 384x640 2 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b46efeed-d21567e0.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b470a84a-fcde9033.jpg: 384x640 11 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  10%|█         | 1047/10000 [00:33<04:36, 32.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4712ebe-91e430b2.jpg: 384x640 7 cars, 1 truck, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4712ebe-9ecac024.jpg: 384x640 13 cars, 1 truck, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4715825-7c265849.jpg: 384x640 (no detections), 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4715825-e1fbf174.jpg: 384x640 1 traffic light, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1051/10000 [00:33<04:37, 32.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b47262a4-3c664e48.jpg: 384x640 2 persons, 9 cars, 1 truck, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b47262a4-aa7a5ad9.jpg: 384x640 2 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b47262a4-b17e0871.jpg: 384x640 7 cars, 4 traffic lights, 1 fire hydrant, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b472aeb8-f6353af9.jpg: 384x640 5 cars, 1 truck, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1055/10000 [00:33<04:48, 31.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4735a56-3315b8d6.jpg: 384x640 4 cars, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b473c236-79848d60.jpg: 384x640 3 cars, 2 trucks, 1 traffic light, 1 tv, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b473c3c3-f52b760e.jpg: 384x640 3 cars, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b477c2e7-6590a089.jpg: 384x640 5 cars, 1 truck, 1 laptop, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1059/10000 [00:33<04:45, 31.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b478cdd5-9cf96449.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b479f06d-2cc86910.jpg: 384x640 1 bicycle, 3 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b479f06d-83153737.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b47cbe8c-411ffa20.jpg: 384x640 1 person, 1 car, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 4.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1063/10000 [00:33<04:32, 32.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b47cbe8c-f90cd4ec.jpg: 384x640 3 cars, 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b47f85d4-6cc172b6.jpg: 384x640 1 car, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b47f85d4-c6562257.jpg: 384x640 2 persons, 5 cars, 1 train, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48012c1-619fc3eb.jpg: 384x640 1 person, 2 cars, 3 traffic lights, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1067/10000 [00:33<04:28, 33.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48012c1-fbcf8e5c.jpg: 384x640 7 cars, 10.8ms\n",
            "Speed: 4.9ms preprocess, 10.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4823e33-8cabe78b.jpg: 384x640 2 cars, 5 traffic lights, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b483a180-56a9db7c.jpg: 384x640 13 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b484aa24-d70cf6e5.jpg: 384x640 6 cars, 1 bus, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1071/10000 [00:33<04:33, 32.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b484aa6b-23bfffa8.jpg: 384x640 2 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4860efe-0056999a.jpg: 384x640 9 cars, 3 trucks, 1 traffic light, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4860efe-127bd880.jpg: 384x640 1 person, 6 cars, 10.5ms\n",
            "Speed: 3.5ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4860efe-4647e771.jpg: 384x640 4 cars, 1 stop sign, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1075/10000 [00:34<04:25, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4860efe-c0a45030.jpg: 384x640 1 person, 7 cars, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4860efe-c78e84fa.jpg: 384x640 6 cars, 6 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4863201-63b08472.jpg: 384x640 5 cars, 1 truck, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4863201-6521c146.jpg: 384x640 3 persons, 4 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1079/10000 [00:34<04:19, 34.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b486e8ba-a96e55e5.jpg: 384x640 18 cars, 1 bus, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b487a2fa-001bf8be.jpg: 384x640 3 persons, 1 bicycle, 3 cars, 2 buss, 1 traffic light, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b487a2fa-0821d7a6.jpg: 384x640 2 persons, 12 cars, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b487a2fa-53094db8.jpg: 384x640 5 persons, 7 cars, 1 bus, 1 truck, 1 traffic light, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1083/10000 [00:34<04:42, 31.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b487a2fa-b74b81bc.jpg: 384x640 3 persons, 8 cars, 2 trucks, 15.4ms\n",
            "Speed: 2.0ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4888487-83bb5db4.jpg: 384x640 3 cars, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48a6dea-df402aaa.jpg: 384x640 2 cars, 3 traffic lights, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48b4ae2-cd8800d8.jpg: 384x640 1 car, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1087/10000 [00:34<04:52, 30.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48c7b5f-0beee565.jpg: 384x640 8 cars, 1 truck, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48c7b5f-49fec7f1.jpg: 384x640 9 cars, 1 truck, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48c7b5f-76b4418e.jpg: 384x640 1 person, 5 cars, 1 chair, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48c7b5f-800d31b4.jpg: 384x640 4 cars, 2 buss, 1 truck, 18.8ms\n",
            "Speed: 2.5ms preprocess, 18.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1091/10000 [00:34<05:05, 29.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48c7b5f-ae58463a.jpg: 384x640 2 cars, 1 truck, 15.7ms\n",
            "Speed: 3.4ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48c7b5f-cec3fed8.jpg: 384x640 10 cars, 11.9ms\n",
            "Speed: 2.5ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48c7b5f-d1d94eaf.jpg: 384x640 3 cars, 1 truck, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1094/10000 [00:34<05:12, 28.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48ca7aa-40d54a99.jpg: 384x640 3 cars, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48dd7b4-6462b6f7.jpg: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.4ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48dd7b4-950fc1b4.jpg: 384x640 2 cars, 20.8ms\n",
            "Speed: 2.2ms preprocess, 20.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48dd7b4-9cc0d29a.jpg: 384x640 (no detections), 14.6ms\n",
            "Speed: 4.7ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1098/10000 [00:34<05:03, 29.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48eb8a9-6e9beea8.jpg: 384x640 11 cars, 2 trucks, 20.4ms\n",
            "Speed: 1.8ms preprocess, 20.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48ef806-82544a56.jpg: 384x640 13 cars, 1 fire hydrant, 16.2ms\n",
            "Speed: 3.2ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48f3f71-eec18320.jpg: 384x640 2 traffic lights, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1101/10000 [00:34<05:29, 27.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48fabad-9ef198f0.jpg: 384x640 11 cars, 1 truck, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48fc70b-2ca6ed01.jpg: 384x640 2 cars, 2 trucks, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48fc70b-34dc3139.jpg: 384x640 1 person, 7 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48fc70b-72a49533.jpg: 384x640 1 person, 7 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1105/10000 [00:35<05:07, 28.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48fc70b-9d91e215.jpg: 384x640 12 cars, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b48fc70b-b1a801f2.jpg: 384x640 5 cars, 1 bus, 1 truck, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4901f32-1ede5a35.jpg: 384x640 11 cars, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1108/10000 [00:35<05:07, 28.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4901f32-5e356f74.jpg: 384x640 3 cars, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4927f8e-fb16ed87.jpg: 384x640 3 cars, 1 traffic light, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4946e87-165efbb5.jpg: 384x640 9 cars, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4946e87-e2fe2819.jpg: 384x640 1 person, 3 cars, 1 bus, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1112/10000 [00:35<04:57, 29.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4946e87-f31e29b1.jpg: 384x640 1 car, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4946e87-fe31271f.jpg: 384x640 7 cars, 17.0ms\n",
            "Speed: 2.1ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b495e3ab-90180a0e.jpg: 384x640 1 person, 18 cars, 20.9ms\n",
            "Speed: 2.3ms preprocess, 20.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b496906c-86644814.jpg: 384x640 10 cars, 10.7ms\n",
            "Speed: 3.9ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1116/10000 [00:35<05:30, 26.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49698d7-1999d598.jpg: 384x640 11 cars, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4982ab8-780c40a0.jpg: 384x640 2 cars, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49944e9-57ac98be.jpg: 384x640 10 cars, 21.7ms\n",
            "Speed: 4.2ms preprocess, 21.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1119/10000 [00:35<05:33, 26.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4998daa-2074f0c8.jpg: 384x640 9 cars, 1 traffic light, 12.4ms\n",
            "Speed: 4.3ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b499ff48-31afe322.jpg: 384x640 3 persons, 8 cars, 1 truck, 5 traffic lights, 17.7ms\n",
            "Speed: 3.2ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b499ff48-6a0b212e.jpg: 384x640 18 persons, 5 cars, 2 buss, 6 traffic lights, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█         | 1122/10000 [00:35<06:03, 24.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49a1b50-186fb520.jpg: 384x640 (no detections), 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49a1b50-aad00d19.jpg: 384x640 4 persons, 5 cars, 2 traffic lights, 14.3ms\n",
            "Speed: 4.0ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49a272b-c52895c3.jpg: 384x640 1 person, 2 cars, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█▏        | 1125/10000 [00:35<05:55, 24.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49d2384-af5fd985.jpg: 384x640 2 cars, 1 truck, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49d6c0d-457e13b3.jpg: 384x640 1 person, 7 cars, 1 truck, 1 traffic light, 16.1ms\n",
            "Speed: 7.7ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49d6c0d-bb90cc08.jpg: 384x640 14 persons, 3 cars, 1 bus, 1 truck, 1 traffic light, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█▏        | 1128/10000 [00:35<06:07, 24.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b49f5a46-b38ad0c6.jpg: 384x640 14 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a08ee2-5cac9543.jpg: 384x640 14 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a23106-80491109.jpg: 384x640 4 cars, 1 truck, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█▏        | 1131/10000 [00:36<05:50, 25.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a23106-f7270c1c.jpg: 384x640 8 persons, 5 cars, 1 clock, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a240e1-6e3cd8b8.jpg: 384x640 6 cars, 1 motorcycle, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a2565f-3fc0ab61.jpg: 384x640 1 car, 1 bus, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a2cbc5-fc978a94.jpg: 384x640 1 person, 3 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█▏        | 1135/10000 [00:36<05:24, 27.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a4d2a8-450f54f5.jpg: 384x640 7 cars, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a63a7e-429587ed.jpg: 384x640 7 cars, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a63a7e-74155969.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a8e0fd-7ca55075.jpg: 384x640 1 car, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█▏        | 1139/10000 [00:36<05:06, 28.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a8ec73-0c39599d.jpg: 384x640 4 persons, 2 cars, 1 bus, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a8ec73-1c6196a0.jpg: 384x640 8 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a8ec73-22166ba3.jpg: 384x640 1 person, 4 cars, 1 bus, 1 truck, 1 traffic light, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a8ec73-4a6c61c7.jpg: 384x640 7 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█▏        | 1143/10000 [00:36<04:58, 29.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a8ec73-70456cee.jpg: 384x640 4 persons, 1 bicycle, 2 cars, 1 motorcycle, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a8ec73-7e0ae9b4.jpg: 384x640 8 persons, 5 cars, 2 trucks, 1 traffic light, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a8ec73-893c4da4.jpg: 384x640 3 persons, 10 cars, 1 truck, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  11%|█▏        | 1146/10000 [00:36<05:00, 29.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a99fcc-7870a48b.jpg: 384x640 5 cars, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a99fcc-8552240d.jpg: 384x640 10 cars, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a99fcc-a81c5051.jpg: 384x640 2 persons, 10 cars, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a99fcc-cc3d571d.jpg: 384x640 9 cars, 1 truck, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1150/10000 [00:36<04:56, 29.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a99fcc-d849eaf4.jpg: 384x640 6 cars, 1 truck, 3 traffic lights, 9.9ms\n",
            "Speed: 4.1ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a99fcc-e26717df.jpg: 384x640 1 person, 7 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a9b6ca-010d823b.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1153/10000 [00:36<04:56, 29.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4a9b6ca-b621ed11.jpg: 384x640 4 persons, 3 cars, 3 traffic lights, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aa2f44-023fb7df.jpg: 384x640 3 cars, 2 buss, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aa2f44-0c91b13d.jpg: 384x640 2 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aa7fc1-2c1fdd4c.jpg: 384x640 4 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1157/10000 [00:36<04:39, 31.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aabd48-38c15aba.jpg: 384x640 3 persons, 7 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aabd48-612afbae.jpg: 384x640 2 persons, 1 bicycle, 6 cars, 2 buss, 2 trucks, 2 traffic lights, 18.5ms\n",
            "Speed: 4.3ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aabd48-89db54e4.jpg: 384x640 15 persons, 1 bicycle, 8 cars, 2 traffic lights, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ad4365-c1607665.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1161/10000 [00:37<04:58, 29.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ad971b-6ca3cd79.jpg: 384x640 5 cars, 1 traffic light, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ae70d9-a8099055.jpg: 384x640 1 person, 11 cars, 1 truck, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aefa17-2444bcc7.jpg: 384x640 10 persons, 6 cars, 1 traffic light, 1 handbag, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aefa17-93a7efac.jpg: 384x640 6 cars, 2 trucks, 1 traffic light, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1165/10000 [00:37<04:52, 30.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4aefa17-a90ffac2.jpg: 384x640 16 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b07c88-3e6d65a0.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b07c88-e71768f1.jpg: 384x640 4 cars, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b083a0-820bc2c4.jpg: 384x640 7 cars, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1169/10000 [00:37<04:53, 30.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b09f5b-11633a17.jpg: 384x640 5 cars, 1 traffic light, 18.8ms\n",
            "Speed: 2.0ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b09f5b-c3870eca.jpg: 384x640 6 cars, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b15ff2-16c70581.jpg: 384x640 2 cars, 19.7ms\n",
            "Speed: 3.3ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b1aa64-e3cbad0f.jpg: 384x640 13 cars, 1 bus, 1 truck, 3 traffic lights, 17.1ms\n",
            "Speed: 2.5ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1173/10000 [00:37<05:25, 27.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b2f8e1-18accb75.jpg: 384x640 2 persons, 1 car, 1 traffic light, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b2f8e1-75b238e1.jpg: 384x640 1 car, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b2f8e1-99a5df57.jpg: 384x640 3 cars, 1 bus, 3 traffic lights, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b394c2-148397ab.jpg: 384x640 (no detections), 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1177/10000 [00:37<05:05, 28.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b394c2-e2f83664.jpg: 384x640 1 car, 1 traffic light, 12.6ms\n",
            "Speed: 4.4ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b47b81-90c3dbae.jpg: 384x640 2 cars, 3 traffic lights, 15.4ms\n",
            "Speed: 6.0ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b4b979-a64f258c.jpg: 384x640 1 person, 3 cars, 1 truck, 2 traffic lights, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1180/10000 [00:37<05:20, 27.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b581ea-93722c60.jpg: 384x640 1 motorcycle, 18.8ms\n",
            "Speed: 2.9ms preprocess, 18.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b68779-1c75351a.jpg: 384x640 5 cars, 12 traffic lights, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b6fd78-9b7cfe0c.jpg: 384x640 1 person, 1 car, 2 traffic lights, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1183/10000 [00:37<05:30, 26.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b6fd78-b1f488c2.jpg: 384x640 1 car, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b6fd78-e96e5ab8.jpg: 384x640 4 traffic lights, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b7133e-5672ca28.jpg: 384x640 12 cars, 1 truck, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1186/10000 [00:37<05:28, 26.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b7133e-94c56651.jpg: 384x640 18 cars, 22.7ms\n",
            "Speed: 2.1ms preprocess, 22.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b7133e-f6650d64.jpg: 384x640 10 cars, 1 truck, 16.7ms\n",
            "Speed: 2.1ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b7133e-fdf86606.jpg: 384x640 14 cars, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1189/10000 [00:38<05:49, 25.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b98434-f30f1d1e.jpg: 384x640 1 person, 6 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b99a3e-21dfc344.jpg: 384x640 (no detections), 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b99a3e-76e632f3.jpg: 384x640 2 cars, 1 traffic light, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b99a3e-e90cbb5a.jpg: 384x640 1 car, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1193/10000 [00:38<05:19, 27.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4b9c39d-6409d1fd.jpg: 384x640 1 person, 5 cars, 19.2ms\n",
            "Speed: 3.8ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ba0552-53249a02.jpg: 384x640 3 cars, 1 traffic light, 19.2ms\n",
            "Speed: 2.0ms preprocess, 19.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4bd3c3c-71724e6f.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1196/10000 [00:38<05:30, 26.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4be0173-249b5f2f.jpg: 384x640 1 car, 13.1ms\n",
            "Speed: 4.1ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c0a877-66fc6239.jpg: 384x640 6 cars, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c0a877-7bdedc86.jpg: 384x640 1 person, 6 cars, 1 bus, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c0a877-dff9f7bb.jpg: 384x640 5 cars, 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1200/10000 [00:38<05:06, 28.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c195ae-4dfb18d9.jpg: 384x640 1 person, 4 cars, 1 truck, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c29ddd-808b41d7.jpg: 384x640 2 cars, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c29ddd-b9e5cb5e.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c5ea2e-1a3ea72a.jpg: 384x640 12 cars, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1204/10000 [00:38<04:59, 29.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c62929-8d5e3448.jpg: 384x640 7 cars, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c733a8-46d78670.jpg: 384x640 4 cars, 1 bus, 1 truck, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c755fa-1ce17fa3.jpg: 384x640 1 person, 3 cars, 1 truck, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c86653-08648e05.jpg: 384x640 7 cars, 2 traffic lights, 14.7ms\n",
            "Speed: 2.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1208/10000 [00:38<04:52, 30.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c86653-3594c3a4.jpg: 384x640 2 persons, 7 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c86653-580097b3.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c86653-91c24c62.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 4.0ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c86653-a1c9c48e.jpg: 384x640 2 cars, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1212/10000 [00:38<04:41, 31.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c86653-a5abaf4e.jpg: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c86653-aafa1676.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c86653-d9ba99f4.jpg: 384x640 3 persons, 2 cars, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c89ab1-5c72cd7d.jpg: 384x640 1 person, 4 cars, 1 truck, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1216/10000 [00:38<04:30, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4c8a6c7-56206227.jpg: 384x640 6 persons, 1 car, 2 traffic lights, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ca8154-1d0ea164.jpg: 384x640 1 person, 5 cars, 1 bus, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ca8154-8453f431.jpg: 384x640 2 persons, 1 car, 1 bus, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ca8154-fd2ddd24.jpg: 384x640 2 cars, 2 buss, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1220/10000 [00:39<04:20, 33.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ccb561-d750f8fc.jpg: 384x640 3 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ccfe4f-6585fb74.jpg: 384x640 3 persons, 6 cars, 1 truck, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4cf12d5-61fc3b07.jpg: 384x640 14 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d0e72d-3b208072.jpg: 384x640 1 car, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1224/10000 [00:39<04:18, 33.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d18d1a-030f0601.jpg: 384x640 6 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d18d1a-193e24a1.jpg: 384x640 10 cars, 3 traffic lights, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d18d1a-44ae201b.jpg: 384x640 1 car, 3 traffic lights, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d18d1a-6007c930.jpg: 384x640 3 cars, 1 truck, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1228/10000 [00:39<04:23, 33.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d18d1a-b72bb7eb.jpg: 384x640 8 cars, 14.8ms\n",
            "Speed: 2.0ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d18d1a-e9faf80a.jpg: 384x640 1 car, 1 truck, 14.2ms\n",
            "Speed: 2.0ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d18d1a-fca70785.jpg: 384x640 5 cars, 20.6ms\n",
            "Speed: 2.0ms preprocess, 20.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d2dede-0f9169f5.jpg: 384x640 1 person, 5 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1232/10000 [00:39<04:50, 30.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d2dede-18dc0cd0.jpg: 384x640 3 cars, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d2dede-9b67d0bd.jpg: 384x640 13 cars, 14.2ms\n",
            "Speed: 3.7ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d35abd-b35897b3.jpg: 384x640 10 persons, 4 cars, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d65110-23299ece.jpg: 384x640 15 cars, 1 truck, 14.7ms\n",
            "Speed: 9.7ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1236/10000 [00:39<05:08, 28.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d65110-ac665389.jpg: 384x640 4 cars, 4 trucks, 22.3ms\n",
            "Speed: 1.9ms preprocess, 22.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d72ad8-ae73962e.jpg: 384x640 5 cars, 1 bus, 1 truck, 18.0ms\n",
            "Speed: 2.6ms preprocess, 18.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d73ce8-d5b360f5.jpg: 384x640 6 cars, 2 traffic lights, 18.0ms\n",
            "Speed: 2.1ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1239/10000 [00:39<05:27, 26.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4d9b889-6662ff4a.jpg: 384x640 1 car, 10.9ms\n",
            "Speed: 5.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4dd1c23-355940ff.jpg: 384x640 4 cars, 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4dff9f4-bcac8fae.jpg: 384x640 9 cars, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1242/10000 [00:39<05:23, 27.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e3816e-2319f39e.jpg: 384x640 1 car, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e3816e-6cd8a1fe.jpg: 384x640 4 cars, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e3e68f-3aa63f29.jpg: 384x640 3 cars, 1 umbrella, 1 chair, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e58e8f-dff21e6a.jpg: 384x640 2 cars, 3 traffic lights, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▏        | 1246/10000 [00:39<04:55, 29.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e6cf20-6f6762ab.jpg: 384x640 7 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e7cde5-3ae908a3.jpg: 384x640 2 persons, 3 cars, 1 bus, 2 potted plants, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e7cde5-bc961dfe.jpg: 384x640 3 persons, 7 cars, 1 bus, 1 truck, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e84636-fd3e7810.jpg: 384x640 2 cars, 1 bus, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  12%|█▎        | 1250/10000 [00:40<04:35, 31.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e86b41-b15ff7cb.jpg: 384x640 1 car, 3 traffic lights, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e927af-828f4a9b.jpg: 384x640 8 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e97132-0dbc3f9f.jpg: 384x640 5 cars, 4 traffic lights, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4e97132-88561223.jpg: 384x640 6 cars, 1 bench, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1254/10000 [00:40<04:22, 33.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ea9ae8-35554080.jpg: 384x640 6 cars, 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4eac100-0eaffca3.jpg: 384x640 2 cars, 14.8ms\n",
            "Speed: 3.8ms preprocess, 14.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4eac100-53651d93.jpg: 384x640 4 cars, 1 airplane, 16.7ms\n",
            "Speed: 4.0ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4eac100-c2a05392.jpg: 384x640 2 cars, 1 truck, 14.6ms\n",
            "Speed: 5.3ms preprocess, 14.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1258/10000 [00:40<04:44, 30.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4eb79bd-288f1507.jpg: 384x640 1 person, 1 car, 1 bus, 1 traffic light, 14.3ms\n",
            "Speed: 2.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4eb79bd-6ab32eb7.jpg: 384x640 5 cars, 1 airplane, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ec8b36-e81e510a.jpg: 384x640 1 person, 5 cars, 1 bus, 1 traffic light, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ecb933-08326feb.jpg: 384x640 11 cars, 1 bus, 1 truck, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1262/10000 [00:40<04:53, 29.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ed5563-12753b3c.jpg: 384x640 1 car, 1 bus, 1 truck, 1 traffic light, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ed5563-e22cb18a.jpg: 384x640 8 cars, 2 traffic lights, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ee5320-cb16ec42.jpg: 384x640 6 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4eee282-a7157230.jpg: 384x640 3 cars, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1266/10000 [00:40<04:41, 31.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ef573f-199846ab.jpg: 384x640 3 cars, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ef573f-5122732a.jpg: 384x640 6 cars, 1 bus, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ef573f-8a8e0ea3.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ef573f-a98f72d3.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ef573f-c11cbaee.jpg: 384x640 1 person, 3 cars, 1 traffic light, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1271/10000 [00:40<04:18, 33.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f1500e-901fb4e6.jpg: 384x640 16 cars, 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f2a76c-3ce3d91e.jpg: 384x640 5 cars, 1 bus, 12.7ms\n",
            "Speed: 3.0ms preprocess, 12.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f2a76c-6b0c22e6.jpg: 384x640 3 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f360ca-78e0a64c.jpg: 384x640 1 traffic light, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1275/10000 [00:40<04:21, 33.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f49565-abd6b20b.jpg: 384x640 4 persons, 5 cars, 4 traffic lights, 11.2ms\n",
            "Speed: 3.9ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f49565-ccd350b6.jpg: 384x640 2 persons, 2 traffic lights, 11.3ms\n",
            "Speed: 7.3ms preprocess, 11.3ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f4bd95-70f45b0f.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f4bd95-a097514a.jpg: 384x640 (no detections), 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1279/10000 [00:41<04:37, 31.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f4e648-58e39e89.jpg: 384x640 7 cars, 2 traffic lights, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f542b3-534c29f9.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f59eb4-2992dd6d.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f65b32-ff644e07.jpg: 384x640 7 cars, 1 traffic light, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1283/10000 [00:41<04:23, 33.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f85748-11ae5a20.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f85748-94942db6.jpg: 384x640 1 car, 1 stop sign, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f85748-c4be0117.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f9084d-207afc6e.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f9084d-22f60127.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1288/10000 [00:41<04:03, 35.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f9084d-7cc2f042.jpg: 384x640 10 cars, 3 traffic lights, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f9084d-86d982ab.jpg: 384x640 4 cars, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4f9f50c-35823e7c.jpg: 384x640 4 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fa53bd-ca8d0317.jpg: 384x640 2 persons, 6 cars, 13.8ms\n",
            "Speed: 2.5ms preprocess, 13.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1292/10000 [00:41<04:28, 32.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fb7979-16f87335.jpg: 384x640 3 cars, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fca1a4-f7e84f0b.jpg: 384x640 9 cars, 15.5ms\n",
            "Speed: 2.0ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fce2f5-d8eee5bb.jpg: 384x640 2 persons, 1 bicycle, 11 cars, 1 bus, 11.5ms\n",
            "Speed: 6.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fce2f5-ffc1247f.jpg: 384x640 10 cars, 3 traffic lights, 20.2ms\n",
            "Speed: 3.5ms preprocess, 20.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1296/10000 [00:41<05:01, 28.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fcf852-0d288dba.jpg: 384x640 5 cars, 16.7ms\n",
            "Speed: 2.0ms preprocess, 16.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fd3ecf-25548ea4.jpg: 384x640 8 cars, 1 fire hydrant, 18.8ms\n",
            "Speed: 3.7ms preprocess, 18.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fe0b47-77c4f249.jpg: 384x640 12 cars, 13.8ms\n",
            "Speed: 3.9ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fe0b47-a7819060.jpg: 384x640 8 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1300/10000 [00:41<05:03, 28.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fe8907-23618458.jpg: 384x640 5 cars, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4fe9ed3-7e469f87.jpg: 384x640 2 cars, 1 bus, 12.4ms\n",
            "Speed: 3.6ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b4ff6bda-27a63ee8.jpg: 384x640 2 persons, 2 cars, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5004c9e-d21fdd6e.jpg: 384x640 9 cars, 2 trucks, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1304/10000 [00:41<04:59, 29.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b501bb52-7282ae0d.jpg: 384x640 2 cars, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b501bb52-aab37014.jpg: 384x640 3 cars, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5022e95-a691dc1c.jpg: 384x640 9 cars, 1 bus, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5032e1d-d2f24352.jpg: 384x640 12 cars, 1 bus, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1308/10000 [00:41<04:47, 30.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5032e1d-dad95b60.jpg: 384x640 9 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5042634-1034573c.jpg: 384x640 5 cars, 1 truck, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5042634-4b1e927b.jpg: 384x640 3 persons, 9 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5042634-d0148524.jpg: 384x640 7 persons, 3 cars, 3 traffic lights, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1312/10000 [00:42<04:49, 30.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5042634-edf42094.jpg: 384x640 3 cars, 2 traffic lights, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5046f1e-0674657f.jpg: 384x640 2 trains, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5046f1e-340a743a.jpg: 384x640 (no detections), 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5046f1e-7b9d98d0.jpg: 384x640 4 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1316/10000 [00:42<04:35, 31.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5046f1e-97a3a2e5.jpg: 384x640 2 persons, 1 car, 2 traffic lights, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5046f1e-99be1b00.jpg: 384x640 1 person, 7 cars, 1 bus, 1 truck, 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5046f1e-b1ef44b9.jpg: 384x640 2 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5046f1e-fa3ac127.jpg: 384x640 2 persons, 3 cars, 1 motorcycle, 1 traffic light, 15.7ms\n",
            "Speed: 2.3ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1320/10000 [00:42<04:42, 30.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5047c50-e1facff6.jpg: 384x640 9 cars, 2 trucks, 17.8ms\n",
            "Speed: 2.4ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5058691-1fb39daf.jpg: 384x640 1 person, 4 cars, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b509067e-188e1123.jpg: 384x640 13 cars, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b50cb586-d808d404.jpg: 384x640 1 person, 14 cars, 1 bus, 1 truck, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1324/10000 [00:42<04:56, 29.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b50e6154-4aace8a1.jpg: 384x640 4 cars, 16.9ms\n",
            "Speed: 1.9ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b50fa05b-602f124c.jpg: 384x640 1 person, 5 cars, 1 truck, 1 traffic light, 13.1ms\n",
            "Speed: 3.2ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b50ff9e2-ebb775d4.jpg: 384x640 10 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1327/10000 [00:42<04:57, 29.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b510fa10-390f3d97.jpg: 384x640 2 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5110041-5e70bd90.jpg: 384x640 5 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5115080-37a89b9c.jpg: 384x640 5 cars, 18.8ms\n",
            "Speed: 1.8ms preprocess, 18.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5172858-da5e71cc.jpg: 384x640 5 persons, 2 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1331/10000 [00:42<04:50, 29.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b517726f-0cd9b6ae.jpg: 384x640 2 persons, 1 umbrella, 16.7ms\n",
            "Speed: 1.9ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5183558-782ad31c.jpg: 384x640 9 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5188a0e-89f2392d.jpg: 384x640 3 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b518f838-62048659.jpg: 384x640 1 car, 1 traffic light, 16.1ms\n",
            "Speed: 2.0ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1335/10000 [00:42<04:49, 29.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5191523-6c028236.jpg: 384x640 5 cars, 1 bus, 1 truck, 1 traffic light, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5191523-949f83bd.jpg: 384x640 15 cars, 18.4ms\n",
            "Speed: 1.8ms preprocess, 18.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5191523-9c2c4c83.jpg: 384x640 2 cars, 1 truck, 9.8ms\n",
            "Speed: 5.9ms preprocess, 9.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5191523-af1c9a30.jpg: 384x640 3 cars, 13.7ms\n",
            "Speed: 3.7ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1339/10000 [00:42<04:49, 29.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5191523-cc623777.jpg: 384x640 4 cars, 1 truck, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5191523-f5721cd1.jpg: 384x640 1 person, 2 cars, 1 bus, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5191523-f7e4f533.jpg: 384x640 6 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b519a9a4-6dd5b989.jpg: 384x640 11 cars, 1 traffic light, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1343/10000 [00:43<04:40, 30.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b51aa35f-0b962e5d.jpg: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b51aa35f-672053a6.jpg: 384x640 2 cars, 1 bus, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b51aa35f-90f3f3f8.jpg: 384x640 6 cars, 1 truck, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b51d0756-8c5120da.jpg: 384x640 2 persons, 1 car, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b51daa04-f4e62d2f.jpg: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  13%|█▎        | 1348/10000 [00:43<04:16, 33.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b51dfd71-9599e952.jpg: 384x640 2 persons, 11 cars, 1 backpack, 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b51eb969-25bb6a5d.jpg: 384x640 3 cars, 1 bus, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b51fc067-22ddb158.jpg: 384x640 2 persons, 2 cars, 17.3ms\n",
            "Speed: 2.0ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b520b60a-e31c352d.jpg: 384x640 7 cars, 14.8ms\n",
            "Speed: 4.2ms preprocess, 14.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▎        | 1352/10000 [00:43<04:41, 30.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5238f1c-f5d779fc.jpg: 384x640 2 cars, 18.9ms\n",
            "Speed: 2.6ms preprocess, 18.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5261cec-aac2f91a.jpg: 384x640 2 cars, 14.4ms\n",
            "Speed: 4.3ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b52640e9-d1fa335f.jpg: 384x640 1 person, 13 cars, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5264a14-892dc259.jpg: 384x640 2 cars, 17.2ms\n",
            "Speed: 2.2ms preprocess, 17.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▎        | 1356/10000 [00:43<04:49, 29.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b52793ed-49faf8b6.jpg: 384x640 2 persons, 1 bicycle, 7 cars, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b52949cd-2439cac6.jpg: 384x640 3 cars, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5296e2a-25ab57d6.jpg: 384x640 5 cars, 3 traffic lights, 11.9ms\n",
            "Speed: 2.5ms preprocess, 11.9ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5296e2a-37df633f.jpg: 384x640 9 persons, 2 cars, 1 bus, 1 truck, 14.4ms\n",
            "Speed: 3.5ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▎        | 1360/10000 [00:43<04:57, 29.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5296e2a-fde16219.jpg: 384x640 8 persons, 10 cars, 1 bus, 7 traffic lights, 17.8ms\n",
            "Speed: 2.5ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b52c65b9-31ad0690.jpg: 384x640 1 person, 7 cars, 1 bus, 1 umbrella, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b52e3ad8-aebd0e55.jpg: 384x640 3 cars, 1 truck, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▎        | 1363/10000 [00:43<05:12, 27.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b52e49e5-d1e36124.jpg: 384x640 4 persons, 7 cars, 1 traffic light, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b52e7443-1a4b1fbc.jpg: 384x640 2 persons, 1 car, 1 stop sign, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b52f1b58-e49099e8.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53215a2-d9aa49d8.jpg: 384x640 13 cars, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▎        | 1367/10000 [00:43<05:06, 28.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b533db8e-4abfcb54.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b533db8e-7e5a6abb.jpg: 384x640 2 persons, 3 cars, 1 train, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b533db8e-afb2e60c.jpg: 384x640 15 cars, 1 motorcycle, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b533db8e-f41851e8.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▎        | 1371/10000 [00:44<04:50, 29.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5345bb2-a1424882.jpg: 384x640 4 cars, 1 traffic light, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b534864a-d2eb867c.jpg: 384x640 6 cars, 1 fire hydrant, 10.5ms\n",
            "Speed: 3.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b535fb0a-845db498.jpg: 384x640 10 cars, 1 traffic light, 10.5ms\n",
            "Speed: 3.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▎        | 1374/10000 [00:44<04:49, 29.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5362410-762b4521.jpg: 384x640 6 cars, 1 bus, 18.9ms\n",
            "Speed: 1.9ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b536decd-ecd4653e.jpg: 384x640 5 cars, 18.0ms\n",
            "Speed: 6.9ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5380a66-b76d418a.jpg: 384x640 2 persons, 3 cars, 1 bus, 1 truck, 2 traffic lights, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1377/10000 [00:44<05:09, 27.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5380a66-f8c670ed.jpg: 384x640 6 cars, 1 bus, 16.9ms\n",
            "Speed: 1.8ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b539383c-a697cb3b.jpg: 384x640 8 cars, 16.7ms\n",
            "Speed: 4.1ms preprocess, 16.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b539383c-b57307bc.jpg: 384x640 14 cars, 12.7ms\n",
            "Speed: 3.3ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1380/10000 [00:44<05:17, 27.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b539383c-e6e6528d.jpg: 384x640 4 cars, 2 buss, 1 truck, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53a0e33-2c56289b.jpg: 384x640 12 cars, 1 truck, 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53a1501-29d2e507.jpg: 384x640 7 cars, 5 traffic lights, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1383/10000 [00:44<05:14, 27.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53a1501-745a59ef.jpg: 384x640 7 cars, 1 traffic light, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53a1501-92a39535.jpg: 384x640 6 cars, 5 traffic lights, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53a1501-eaa0de18.jpg: 384x640 1 car, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53a1501-f21dfab8.jpg: 384x640 1 car, 1 traffic light, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1387/10000 [00:44<05:03, 28.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53a1501-fa79fefc.jpg: 384x640 11 cars, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53cb17b-4df01599.jpg: 384x640 2 cars, 1 bus, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53cb17b-e5d64f59.jpg: 384x640 5 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1390/10000 [00:44<05:00, 28.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53e1aa8-c49fd7ef.jpg: 384x640 3 cars, 2 trucks, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b53f23c3-3d2cea8b.jpg: 384x640 12 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5402d64-6759c697.jpg: 384x640 15 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1393/10000 [00:44<05:03, 28.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b541e2e6-f5256160.jpg: 384x640 3 persons, 3 cars, 2 traffic lights, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b543836f-add08be6.jpg: 384x640 1 car, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5450d0c-ccc3fb86.jpg: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54578dc-10332bd1.jpg: 384x640 3 traffic lights, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1397/10000 [00:44<04:42, 30.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54578dc-5120800c.jpg: 384x640 5 cars, 12.1ms\n",
            "Speed: 4.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54578dc-5a2c0b63.jpg: 384x640 5 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54578dc-807f5298.jpg: 384x640 1 car, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54578dc-95b41097.jpg: 384x640 1 car, 16.8ms\n",
            "Speed: 2.0ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1401/10000 [00:45<04:43, 30.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54578dc-ad675a62.jpg: 384x640 3 cars, 15.4ms\n",
            "Speed: 4.5ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5460637-3b501a2e.jpg: 384x640 5 persons, 1 stop sign, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-0aad0ec3.jpg: 384x640 3 cars, 1 bus, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-0c78bf95.jpg: 384x640 4 cars, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1405/10000 [00:45<04:43, 30.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-42759087.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-45c537f7.jpg: 384x640 4 cars, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-5b162b85.jpg: 384x640 3 cars, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-5bed4504.jpg: 384x640 4 cars, 4 traffic lights, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1409/10000 [00:45<04:39, 30.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-63fb651f.jpg: 384x640 3 cars, 1 truck, 3 traffic lights, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-7858e23d.jpg: 384x640 1 traffic light, 11.2ms\n",
            "Speed: 4.0ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-b2fb645f.jpg: 384x640 8 cars, 2 trucks, 15.7ms\n",
            "Speed: 3.4ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-c4d582f4.jpg: 384x640 5 cars, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1413/10000 [00:45<04:49, 29.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-d7ccca91.jpg: 384x640 2 cars, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-dd8af9d0.jpg: 384x640 5 cars, 3 traffic lights, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-ec871ec7.jpg: 384x640 8 cars, 18.7ms\n",
            "Speed: 3.6ms preprocess, 18.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1416/10000 [00:45<05:11, 27.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5465c6e-fe04d577.jpg: 384x640 10 cars, 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54735e3-4c968f67.jpg: 384x640 2 persons, 7 cars, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54735e3-65f77c99.jpg: 384x640 1 person, 13 cars, 1 traffic light, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1419/10000 [00:45<05:19, 26.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54735e3-b251b872.jpg: 384x640 1 person, 3 cars, 1 traffic light, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5478d5c-290f5e15.jpg: 384x640 9 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5478d5c-e846649e.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5479087-1e95039f.jpg: 384x640 2 cars, 1 bus, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1423/10000 [00:45<04:58, 28.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5479087-2d452243.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5479087-2e92b8f5.jpg: 384x640 4 cars, 1 truck, 10.9ms\n",
            "Speed: 1.7ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5479087-69c9f292.jpg: 384x640 7 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5479087-b68aa812.jpg: 384x640 9 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1427/10000 [00:45<04:37, 30.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5479087-b94125dc.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5479087-faffcc28.jpg: 384x640 3 cars, 1 traffic light, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54793ac-3770583a.jpg: 384x640 3 traffic lights, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54793ac-9f413e5e.jpg: 384x640 1 truck, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1431/10000 [00:46<04:26, 32.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54a8089-aa62f142.jpg: 384x640 1 car, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54a8089-d1989d8f.jpg: 384x640 16 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54c065e-8b13cfe7.jpg: 384x640 3 cars, 1 truck, 1 fire hydrant, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54c48fe-0633723b.jpg: 384x640 2 persons, 2 cars, 1 bus, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1435/10000 [00:46<04:14, 33.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54d9c61-18c33e21.jpg: 384x640 10 cars, 1 bus, 1 traffic light, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54d9c61-9647a82e.jpg: 384x640 4 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54eb6de-06e04487.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b54fd2cd-829309c7.jpg: 384x640 5 cars, 16.4ms\n",
            "Speed: 2.9ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1439/10000 [00:46<04:23, 32.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b552a0b7-0472099a.jpg: 384x640 8 cars, 1 train, 1 traffic light, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b552a4cb-fbd465af.jpg: 384x640 2 persons, 2 cars, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b55305bd-f66ad8fb.jpg: 384x640 5 cars, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5548481-6ffc0c74.jpg: 384x640 1 car, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1443/10000 [00:46<04:28, 31.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b554e4c9-dd8f7f1f.jpg: 384x640 4 cars, 1 train, 1 truck, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b55569e8-282a99fe.jpg: 384x640 1 car, 1 traffic light, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b555790d-111bb9b8.jpg: 384x640 4 cars, 4 traffic lights, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b555790d-59bad5ab.jpg: 384x640 8 cars, 14.8ms\n",
            "Speed: 6.5ms preprocess, 14.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  14%|█▍        | 1447/10000 [00:46<04:46, 29.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b555790d-628dc96b.jpg: 384x640 6 cars, 1 train, 17.6ms\n",
            "Speed: 1.9ms preprocess, 17.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b555790d-cfb88988.jpg: 384x640 2 persons, 1 bicycle, 3 cars, 17.4ms\n",
            "Speed: 5.0ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b555790d-d715196b.jpg: 384x640 1 person, 17 cars, 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b555790d-e81a454b.jpg: 384x640 1 person, 5 cars, 1 traffic light, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1451/10000 [00:46<05:15, 27.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b555790d-ef09fa96.jpg: 384x640 15 cars, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b555a636-270a146b.jpg: 384x640 3 persons, 3 cars, 1 bus, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b557283b-51959094.jpg: 384x640 1 person, 5 cars, 6 buss, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1454/10000 [00:46<05:10, 27.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b557283b-523d9a0c.jpg: 384x640 9 cars, 1 traffic light, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b557283b-705f9d96.jpg: 384x640 16 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b557283b-dee9d9ed.jpg: 384x640 3 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b557d9d0-bff2bed2.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1458/10000 [00:47<04:56, 28.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b559d3b0-dd72ed94.jpg: 384x640 2 cars, 1 traffic light, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b55bd14f-50306d5f.jpg: 384x640 8 cars, 1 truck, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b55c17aa-3a1df47a.jpg: 384x640 2 cars, 3 traffic lights, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b55c17aa-b31ce64a.jpg: 384x640 1 car, 1 truck, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1462/10000 [00:47<04:34, 31.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b55e257d-9db57de1.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5614611-ae322079.jpg: 384x640 4 cars, 3 traffic lights, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b561705d-e341bae9.jpg: 384x640 10 cars, 1 motorcycle, 3 traffic lights, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b563b270-0fe8e937.jpg: 384x640 8 cars, 1 traffic light, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1466/10000 [00:47<04:37, 30.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b563b270-1a5c6c73.jpg: 384x640 4 cars, 16.1ms\n",
            "Speed: 3.3ms preprocess, 16.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b563b270-47d67962.jpg: 384x640 1 person, 5 cars, 1 truck, 3 traffic lights, 1 potted plant, 13.2ms\n",
            "Speed: 7.2ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b563b270-63d4d8fc.jpg: 384x640 5 cars, 1 truck, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b563b270-8df1c342.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1470/10000 [00:47<04:49, 29.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b563b270-d18e77f6.jpg: 384x640 4 cars, 1 truck, 16.4ms\n",
            "Speed: 2.0ms preprocess, 16.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b565c328-1e663060.jpg: 384x640 2 persons, 3 cars, 3 traffic lights, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b565d4cc-2e6cb390.jpg: 384x640 3 cars, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b565d4cc-3605a023.jpg: 384x640 13 cars, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1474/10000 [00:47<04:46, 29.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5661732-20179325.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5661732-3684230b.jpg: 384x640 11 cars, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b566fee4-453e3805.jpg: 384x640 9 cars, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b568371d-1a142858.jpg: 384x640 4 persons, 6 cars, 2 traffic lights, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1478/10000 [00:47<04:39, 30.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b568371d-1ea8d400.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b568371d-a596d2d4.jpg: 384x640 4 cars, 1 train, 1 traffic light, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b568371d-db4fb582.jpg: 384x640 3 cars, 2 traffic lights, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b569029a-37e190cc.jpg: 384x640 1 person, 2 cars, 13.2ms\n",
            "Speed: 3.4ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1482/10000 [00:47<04:32, 31.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b569a737-a960c153.jpg: 384x640 (no detections), 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b569f76a-33d451fe.jpg: 384x640 1 car, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56a0885-1c282ea8.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56a8196-9b3b361b.jpg: 384x640 3 cars, 1 truck, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1486/10000 [00:47<04:14, 33.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56c225e-83596ac0.jpg: 384x640 2 persons, 2 cars, 2 trucks, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56c225e-a71598cd.jpg: 384x640 2 persons, 2 cars, 1 bus, 1 truck, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56c225e-a7a78ad7.jpg: 384x640 2 persons, 5 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56edcfa-49d5dd9e.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1490/10000 [00:48<04:07, 34.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56edcfa-cf47f5af.jpg: 384x640 2 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56f1366-4819fdc4.jpg: 384x640 22 cars, 2 traffic lights, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b56f50cd-07390326.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57077d8-ae0b13ca.jpg: 384x640 3 cars, 1 truck, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1494/10000 [00:48<04:04, 34.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b570f833-3bd87d01.jpg: 384x640 5 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b570f833-dd98c0f2.jpg: 384x640 1 person, 2 cars, 1 motorcycle, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57417a0-5c16cbfc.jpg: 384x640 3 cars, 1 truck, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5753b26-33163d42.jpg: 384x640 6 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▍        | 1498/10000 [00:48<04:00, 35.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5762ed7-cad32ee3.jpg: 384x640 2 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5764fb7-2bc5ec36.jpg: 384x640 2 persons, 9 cars, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5764fb7-c47fa3ec.jpg: 384x640 9 cars, 1 truck, 12.9ms\n",
            "Speed: 3.9ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5767ace-b5db9504.jpg: 384x640 2 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1502/10000 [00:48<04:12, 33.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b576be97-6a52f4bb.jpg: 384x640 10 cars, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5770084-83b143c9.jpg: 384x640 2 cars, 1 truck, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5770084-9b15155d.jpg: 384x640 13 cars, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5771e6f-97a285f4.jpg: 384x640 4 cars, 19.0ms\n",
            "Speed: 3.6ms preprocess, 19.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1506/10000 [00:48<04:29, 31.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b577827c-006a84cc.jpg: 384x640 13 cars, 1 truck, 18.4ms\n",
            "Speed: 2.7ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b577827c-28fc9b0d.jpg: 384x640 5 cars, 1 traffic light, 19.3ms\n",
            "Speed: 3.1ms preprocess, 19.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5780de7-94313c5f.jpg: 384x640 1 person, 4 cars, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b578f3d3-40453bfb.jpg: 384x640 6 cars, 1 bus, 1 truck, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1510/10000 [00:48<04:54, 28.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57a2edf-402297bc.jpg: 384x640 7 cars, 1 traffic light, 16.4ms\n",
            "Speed: 3.2ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57a2edf-60fd75be.jpg: 384x640 4 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57a2edf-71efe713.jpg: 384x640 1 person, 2 cars, 15.9ms\n",
            "Speed: 4.1ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1513/10000 [00:48<04:57, 28.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57a2edf-b0c2ff52.jpg: 384x640 15 cars, 1 motorcycle, 15.8ms\n",
            "Speed: 4.9ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57a2edf-c3e81131.jpg: 384x640 2 cars, 1 airplane, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57a6b0c-531adc6d.jpg: 384x640 2 persons, 6 cars, 2 traffic lights, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1516/10000 [00:48<05:07, 27.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57a6b0c-86b6e489.jpg: 384x640 7 cars, 15.0ms\n",
            "Speed: 3.1ms preprocess, 15.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57b533b-58103d3d.jpg: 384x640 5 persons, 8 cars, 2 trucks, 19.4ms\n",
            "Speed: 3.3ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57b533b-cabdbef5.jpg: 384x640 4 persons, 5 cars, 1 traffic light, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1519/10000 [00:49<05:28, 25.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57b9ee8-3e089c95.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57b9ee8-e2a6d34d.jpg: 384x640 (no detections), 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57bf234-f74a8d43.jpg: 384x640 9 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57bfcbd-60692014.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1523/10000 [00:49<04:56, 28.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57c8f5a-86e42ab4.jpg: 384x640 1 car, 1 traffic light, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57c8f5a-b427a4b7.jpg: 384x640 1 traffic light, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57cc50e-b947b833.jpg: 384x640 5 cars, 1 traffic light, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57dee9d-959d4057.jpg: 384x640 12 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1527/10000 [00:49<04:47, 29.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b57dee9d-e5bd3142.jpg: 384x640 6 persons, 4 cars, 1 traffic light, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b581255d-1c6658b4.jpg: 384x640 5 cars, 1 truck, 5 traffic lights, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b582c0e7-5f9f8860.jpg: 384x640 14 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1530/10000 [00:49<04:53, 28.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b583e115-1ba9114c.jpg: 384x640 6 cars, 1 traffic light, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b583e4f4-00c17995.jpg: 384x640 5 cars, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58436bb-213f1b3d.jpg: 384x640 4 cars, 3 traffic lights, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58436bb-5790dfd3.jpg: 384x640 4 cars, 1 truck, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1534/10000 [00:49<04:31, 31.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5859b97-9d5532a9.jpg: 384x640 15 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b585f637-93030b36.jpg: 384x640 11 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5868878-8faf33a2.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b586b979-c563c3e2.jpg: 384x640 10 cars, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1538/10000 [00:49<04:28, 31.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5872c48-7dc6d18e.jpg: 384x640 5 cars, 10.9ms\n",
            "Speed: 4.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b588c233-8a21f0be.jpg: 384x640 7 cars, 1 bus, 1 truck, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58aff80-4fd89ca0.jpg: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58aff80-a12e3de6.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1542/10000 [00:49<04:14, 33.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58aff80-bea21173.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58be279-fe1ea9be.jpg: 384x640 2 persons, 6 cars, 1 fire hydrant, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58d74f7-ba3a38d3.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58f8128-3d42f144.jpg: 384x640 11 cars, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  15%|█▌        | 1546/10000 [00:49<04:06, 34.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b58f8128-5be35778.jpg: 384x640 3 cars, 1 motorcycle, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b590ba79-1c95c8d9.jpg: 384x640 4 cars, 1 truck, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59413ff-4e4f3109.jpg: 384x640 3 cars, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59413ff-5885b827.jpg: 384x640 5 persons, 2 cars, 1 truck, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1550/10000 [00:49<04:06, 34.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59413ff-9094612f.jpg: 384x640 8 persons, 12 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59413ff-c3bc3d25.jpg: 384x640 1 car, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5948795-913b4fee.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5961057-5e258e5e.jpg: 384x640 9 cars, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1554/10000 [00:50<04:17, 32.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5969c96-c9135ccb.jpg: 384x640 19 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b596ea23-44b2e05a.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59d9baf-5fe6c3c0.jpg: 384x640 7 persons, 6 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59d9baf-e6b58cf2.jpg: 384x640 6 persons, 5 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1558/10000 [00:50<04:19, 32.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59dd81f-45c8300a.jpg: 384x640 2 persons, 8 cars, 3 traffic lights, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59dd81f-b8ebeb56.jpg: 384x640 3 cars, 1 traffic light, 15.5ms\n",
            "Speed: 3.3ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59e50fa-ca034dd0.jpg: 384x640 11 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59f0750-f228a9a2.jpg: 384x640 5 cars, 12.0ms\n",
            "Speed: 2.8ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1562/10000 [00:50<04:37, 30.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59f6555-89b070c8.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59f6555-a562f4f9.jpg: 384x640 5 cars, 1 traffic light, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b59fa0de-b520450e.jpg: 384x640 6 persons, 6 cars, 2 trucks, 4 traffic lights, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a0301b-517db15b.jpg: 384x640 10 cars, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1566/10000 [00:50<04:41, 29.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09124-0c5ec091.jpg: 384x640 1 person, 6 cars, 11.6ms\n",
            "Speed: 3.7ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09124-8d4e6518.jpg: 384x640 9 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-13bc9a70.jpg: 384x640 3 persons, 1 bicycle, 6 cars, 16.5ms\n",
            "Speed: 3.2ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-1a28e788.jpg: 384x640 11 cars, 2 trucks, 2 traffic lights, 21.8ms\n",
            "Speed: 2.0ms preprocess, 21.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1570/10000 [00:50<04:53, 28.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-3178a653.jpg: 384x640 7 cars, 1 traffic light, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-33ffdc75.jpg: 384x640 3 persons, 6 cars, 1 truck, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-34f155de.jpg: 384x640 3 persons, 7 cars, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1573/10000 [00:50<04:59, 28.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-44ade539.jpg: 384x640 4 cars, 3 traffic lights, 13.7ms\n",
            "Speed: 5.1ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-48e9ac41.jpg: 384x640 6 cars, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-555079c9.jpg: 384x640 6 cars, 1 bus, 15.0ms\n",
            "Speed: 2.5ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1576/10000 [00:50<05:03, 27.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-69dd5d9f.jpg: 384x640 15 persons, 3 cars, 1 motorcycle, 1 traffic light, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-86af51ad.jpg: 384x640 1 car, 1 truck, 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-b79f0f6e.jpg: 384x640 1 person, 6 cars, 1 bus, 16.3ms\n",
            "Speed: 2.1ms preprocess, 16.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1579/10000 [00:50<05:08, 27.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-c93a9d5d.jpg: 384x640 7 persons, 6 cars, 1 bus, 2 traffic lights, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a09604-d9d9aaa9.jpg: 384x640 8 cars, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a407d5-c2abd312.jpg: 384x640 5 persons, 2 cars, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a4b486-1e78745e.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1583/10000 [00:51<04:50, 28.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a4b486-35c3edb4.jpg: 384x640 1 car, 4 traffic lights, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a4b486-dde596cb.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a4db41-1b4f91b0.jpg: 384x640 2 cars, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a50c2d-0c1d06e0.jpg: 384x640 3 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1587/10000 [00:51<04:25, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a50c2d-113da15f.jpg: 384x640 3 cars, 1 traffic light, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a50c2d-a18ba669.jpg: 384x640 1 person, 1 car, 3 traffic lights, 1 backpack, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a50c2d-ccafe43a.jpg: 384x640 2 cars, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a52ea9-2e1f4066.jpg: 384x640 2 cars, 1 truck, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1591/10000 [00:51<04:25, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a72f23-5cb9552b.jpg: 384x640 6 cars, 1 bus, 1 truck, 2 traffic lights, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a72f23-72643897.jpg: 384x640 15 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a72f23-dfdc4b86.jpg: 384x640 2 cars, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5a8594c-049fa1ef.jpg: 384x640 2 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1595/10000 [00:51<04:27, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5aa55af-b01f8749.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5aa77fa-b1916843.jpg: 384x640 1 car, 1 truck, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ab0e46-19655ca4.jpg: 384x640 12 cars, 4 traffic lights, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ab0e46-8eab4733.jpg: 384x640 2 cars, 4 trucks, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1599/10000 [00:51<04:16, 32.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ac257d-5a34b3fa.jpg: 384x640 5 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5afd0ea-222fae7e.jpg: 384x640 2 cars, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b023a6-de26d2b2.jpg: 384x640 3 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b02b31-283dcc5c.jpg: 384x640 1 person, 6 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1603/10000 [00:51<04:13, 33.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b02b31-753a8a4a.jpg: 384x640 9 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b02b31-f19988fb.jpg: 384x640 (no detections), 14.7ms\n",
            "Speed: 2.0ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b17442-2f6d4b97.jpg: 384x640 3 persons, 1 car, 1 truck, 1 bench, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b17442-48053f00.jpg: 384x640 4 persons, 4 cars, 1 bus, 2 traffic lights, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1607/10000 [00:51<04:16, 32.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b17442-ad1dc2ea.jpg: 384x640 5 persons, 2 bicycles, 5 cars, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b17442-df28704b.jpg: 384x640 6 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b2267c-d3a26985.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b256fd-0c2be0a6.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1611/10000 [00:51<04:03, 34.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b2f593-25b7b157.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b2f593-63606879.jpg: 384x640 7 cars, 16.7ms\n",
            "Speed: 1.9ms preprocess, 16.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b40b5f-da80498b.jpg: 384x640 9 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b44d2d-60f87448.jpg: 384x640 14 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1615/10000 [00:52<04:10, 33.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b63915-697fb8c1.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b71e8e-96a024a9.jpg: 384x640 11 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b78553-b7c03da2.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b78553-f3a480a1.jpg: 384x640 (no detections), 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1619/10000 [00:52<04:01, 34.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b79bf9-36cbce30.jpg: 384x640 7 cars, 5 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b7d0a6-e63e539f.jpg: 384x640 13 cars, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b8e198-730252e5.jpg: 384x640 3 cars, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b8e198-9f61fa4b.jpg: 384x640 7 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▌        | 1623/10000 [00:52<04:07, 33.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b8e198-b661f016.jpg: 384x640 (no detections), 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b94ff0-26c04398.jpg: 384x640 1 person, 4 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b94ff0-c8b06edc.jpg: 384x640 1 person, 12 cars, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5b9915f-71ed958e.jpg: 384x640 1 car, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▋        | 1627/10000 [00:52<04:09, 33.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5baa2a5-1fe22e65.jpg: 384x640 3 cars, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bb11f2-227b8c25.jpg: 384x640 2 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bd48b6-0d0d597f.jpg: 384x640 5 cars, 1 traffic light, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bd48b6-14ea233a.jpg: 384x640 5 cars, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▋        | 1631/10000 [00:52<04:11, 33.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bd48b6-57b53578.jpg: 384x640 10 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bd48b6-c1f01e7a.jpg: 384x640 1 car, 14.2ms\n",
            "Speed: 4.7ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bd628c-d1f3b854.jpg: 384x640 5 cars, 2 trucks, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5be6006-83d630d5.jpg: 384x640 4 cars, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▋        | 1635/10000 [00:52<04:16, 32.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5be77ad-b861ba83.jpg: 384x640 6 cars, 1 traffic light, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bf322d-0a139ab3.jpg: 384x640 12 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bf322d-9e707096.jpg: 384x640 12 cars, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bfa85b-d0700971.jpg: 384x640 5 cars, 1 traffic light, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▋        | 1639/10000 [00:52<04:19, 32.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5bfa85b-f1387252.jpg: 384x640 7 cars, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c12993-1b9c5f96.jpg: 384x640 5 cars, 2 buss, 1 truck, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c12993-4c3d9135.jpg: 384x640 1 person, 4 cars, 1 truck, 2 traffic lights, 10.2ms\n",
            "Speed: 6.2ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c12993-8cba5224.jpg: 384x640 4 cars, 1 truck, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▋        | 1643/10000 [00:52<04:15, 32.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c204e0-17acc044.jpg: 384x640 11 cars, 1 truck, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c259f3-b10eeca5.jpg: 384x640 1 person, 7 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c30297-f0b3279b.jpg: 384x640 7 cars, 1 truck, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c324dc-68f1aa1d.jpg: 384x640 4 cars, 1 truck, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  16%|█▋        | 1647/10000 [00:53<04:13, 32.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c351d3-b02bda28.jpg: 384x640 4 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5c6d506-d687e2ab.jpg: 384x640 5 cars, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ca1339-b9f4a4e0.jpg: 384x640 6 cars, 1 bus, 1 truck, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5cb11ce-46ac0ae7.jpg: 384x640 4 persons, 5 cars, 1 truck, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1651/10000 [00:53<04:17, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5cb8753-b8a2ddb5.jpg: 384x640 2 cars, 1 truck, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5cc7455-d2f5900f.jpg: 384x640 2 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5cd3939-44dd0c20.jpg: 384x640 6 persons, 1 car, 1 bus, 2 traffic lights, 1 handbag, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5cd3939-4a911068.jpg: 384x640 1 person, 6 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1655/10000 [00:53<04:12, 33.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5cd3939-a7dffd2d.jpg: 384x640 8 cars, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5cd5f72-32232751.jpg: 384x640 8 cars, 1 truck, 2 traffic lights, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5cf8afa-b54535d2.jpg: 384x640 5 persons, 8 cars, 2 traffic lights, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d06d78-e4ecfa0c.jpg: 384x640 5 persons, 17.3ms\n",
            "Speed: 2.5ms preprocess, 17.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1659/10000 [00:53<04:28, 31.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d4dc8d-99e1e150.jpg: 384x640 6 cars, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d4dc8d-f867ef92.jpg: 384x640 1 person, 12 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d5d39c-73e4471c.jpg: 384x640 5 cars, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d63e8d-061c1a6f.jpg: 384x640 2 cars, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1663/10000 [00:53<04:24, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d63e8d-be6df898.jpg: 384x640 6 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d6e647-0bf0a7e9.jpg: 384x640 2 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d6e647-12d214ab.jpg: 384x640 3 cars, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d6e647-3760c7b9.jpg: 384x640 1 person, 2 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1667/10000 [00:53<04:13, 32.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d6e647-38b01d56.jpg: 384x640 5 cars, 1 bus, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d6e647-44af4f17.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d7832a-63caf5b3.jpg: 384x640 2 cars, 1 traffic light, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d7f73a-ec61468b.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1671/10000 [00:53<04:05, 33.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d8894a-d99dbb00.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5d9531f-48222cf3.jpg: 384x640 4 cars, 2 trucks, 1 stop sign, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dc7a6d-8ef7e8b8.jpg: 384x640 3 persons, 8 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd20c5-250725fa.jpg: 384x640 (no detections), 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1675/10000 [00:53<03:59, 34.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd20c5-4e1112c7.jpg: 384x640 2 persons, 5 cars, 1 bus, 1 traffic light, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd20c5-4f784dcf.jpg: 384x640 2 persons, 1 car, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd20c5-544163f6.jpg: 384x640 1 car, 2 traffic lights, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd20c5-ac20e15b.jpg: 384x640 5 cars, 1 traffic light, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1679/10000 [00:53<04:01, 34.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd20c5-ed2da652.jpg: 384x640 1 car, 1 fire hydrant, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd8a5f-431c4fc2.jpg: 384x640 5 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd8a5f-9e1a2077.jpg: 384x640 4 cars, 1 bus, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dd8a5f-ef468c83.jpg: 384x640 1 car, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ddbb54-248e17be.jpg: 384x640 3 cars, 1 traffic light, 11.3ms\n",
            "Speed: 5.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1684/10000 [00:54<03:54, 35.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ddd07f-ef2cf011.jpg: 384x640 6 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dec5e7-065a0bb3.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dec5e7-58274881.jpg: 384x640 3 cars, 1 bus, 6 traffic lights, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dec5e7-5d59cc3b.jpg: 384x640 2 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1688/10000 [00:54<04:07, 33.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5dec5e7-8066e35c.jpg: 384x640 1 car, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5df49b8-73e68ecb.jpg: 384x640 6 cars, 1 traffic light, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e0b513-da3b4402.jpg: 384x640 11 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e1a441-3bc3277c.jpg: 384x640 1 person, 3 cars, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1692/10000 [00:54<04:12, 32.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e247fe-c9599f82.jpg: 384x640 9 cars, 3 traffic lights, 14.3ms\n",
            "Speed: 3.1ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e387a7-6a010e5e.jpg: 384x640 5 cars, 1 traffic light, 17.4ms\n",
            "Speed: 2.7ms preprocess, 17.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e387a7-9c4a9214.jpg: 384x640 1 person, 2 cars, 1 traffic light, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e387a7-e3a60891.jpg: 384x640 8 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1696/10000 [00:54<04:38, 29.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e3b8c6-cdc3804c.jpg: 384x640 6 cars, 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e3b8c6-e50a2999.jpg: 384x640 1 car, 2 traffic lights, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e3d0f7-4ed391cd.jpg: 384x640 3 cars, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e52b21-46c57b31.jpg: 384x640 3 cars, 16.5ms\n",
            "Speed: 2.1ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1700/10000 [00:54<04:29, 30.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e6efc0-345b365d.jpg: 384x640 1 person, 4 cars, 1 traffic light, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e6efc0-ac69d492.jpg: 384x640 24 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e6efc0-d83e76ab.jpg: 384x640 5 cars, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5e9c2d4-cc0c1c73.jpg: 384x640 5 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1704/10000 [00:54<04:29, 30.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5eaada1-27688041.jpg: 384x640 2 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ece4bd-17087c46.jpg: 384x640 2 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ecfd7e-fcdaceb0.jpg: 384x640 4 persons, 7 cars, 2 fire hydrants, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ed8eaa-03e27c26.jpg: 384x640 3 cars, 1 truck, 5 traffic lights, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1708/10000 [00:54<04:17, 32.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ed8eaa-3fb2802d.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f057ab-791ac474.jpg: 384x640 13 cars, 1 truck, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f14913-d70897d9.jpg: 384x640 (no detections), 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f2f881-edaf9a01.jpg: 384x640 1 car, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1712/10000 [00:55<04:05, 33.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f5d0e1-200575fc.jpg: 384x640 1 car, 1 bus, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f6f399-ca14804c.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f7a789-10124031.jpg: 384x640 1 car, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f7a789-6a9ed4ef.jpg: 384x640 5 persons, 13 cars, 4 traffic lights, 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1716/10000 [00:55<04:04, 33.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f7a789-c02a194e.jpg: 384x640 6 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f84825-4e6d3b68.jpg: 384x640 4 cars, 2 traffic lights, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f84825-956ae1a6.jpg: 384x640 1 car, 1 fire hydrant, 12.9ms\n",
            "Speed: 3.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f84825-c97df380.jpg: 384x640 7 cars, 2 traffic lights, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1720/10000 [00:55<04:17, 32.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5f9cb1e-c84e2ce9.jpg: 384x640 7 cars, 1 truck, 18.3ms\n",
            "Speed: 2.0ms preprocess, 18.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fa32f1-4e9c7d32.jpg: 384x640 16 cars, 16.1ms\n",
            "Speed: 5.6ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fac784-638336fd.jpg: 384x640 20 cars, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fc0f1e-882a7cce.jpg: 384x640 1 train, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1724/10000 [00:55<04:45, 28.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fc1373-94aaab40.jpg: 384x640 7 cars, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fca52d-b459be9c.jpg: 384x640 9 cars, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fcec51-bb59c567.jpg: 384x640 5 cars, 1 train, 2 traffic lights, 11.6ms\n",
            "Speed: 4.0ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1727/10000 [00:55<04:50, 28.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fd8bf6-fa9be3ca.jpg: 384x640 7 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fe17dd-52352131.jpg: 384x640 9 cars, 5 traffic lights, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fe17dd-84fab99d.jpg: 384x640 7 cars, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1730/10000 [00:55<04:56, 27.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5fe17dd-b6648364.jpg: 384x640 2 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ff07b5-3411352a.jpg: 384x640 6 cars, 1 bus, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ff07b5-b983e1a5.jpg: 384x640 4 cars, 1 bus, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b5ff07b5-c8fe49f4.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1734/10000 [00:55<04:30, 30.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60011a3-6490e0d9.jpg: 384x640 14 cars, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60011a3-7449f997.jpg: 384x640 3 persons, 6 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60011a3-fff85077.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6018b92-f949cae0.jpg: 384x640 9 cars, 1 truck, 1 stop sign, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1738/10000 [00:55<04:30, 30.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6036b55-6bc2eeef.jpg: 384x640 4 cars, 3 trucks, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b603f785-b94d2adc.jpg: 384x640 3 cars, 1 truck, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b603f785-de5db004.jpg: 384x640 3 persons, 7 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b605d5d8-7d6ea5cc.jpg: 384x640 3 cars, 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1742/10000 [00:56<04:26, 31.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b605d5d8-a398208d.jpg: 384x640 1 person, 5 cars, 1 traffic light, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b605d5d8-aec799ca.jpg: 384x640 3 cars, 1 bus, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b605d5d8-d9310a5c.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b605d5d8-ec6fab2b.jpg: 384x640 4 cars, 1 truck, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  17%|█▋        | 1746/10000 [00:56<04:23, 31.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b605ed2a-06f43bb3.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6061c91-ebddb67e.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b607dd6a-1d8f33b9.jpg: 384x640 1 person, 11 cars, 1 bus, 2 trucks, 1 traffic light, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60a5583-0fe24e80.jpg: 384x640 11 cars, 1 traffic light, 18.0ms\n",
            "Speed: 5.7ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1750/10000 [00:56<04:25, 31.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60a623a-4df2b0c0.jpg: 384x640 7 cars, 1 bus, 1 truck, 1 traffic light, 13.8ms\n",
            "Speed: 4.0ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60da546-ee383124.jpg: 384x640 2 cars, 16.5ms\n",
            "Speed: 4.0ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60db8b3-7cb88369.jpg: 384x640 5 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60ea3fe-609eecca.jpg: 384x640 3 cars, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1754/10000 [00:56<04:42, 29.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60f1db0-5032d338.jpg: 384x640 4 cars, 1 truck, 1 fire hydrant, 14.8ms\n",
            "Speed: 3.6ms preprocess, 14.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60f1db0-b9889ec7.jpg: 384x640 11 persons, 5 cars, 3 traffic lights, 17.1ms\n",
            "Speed: 2.7ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b60f1db0-cded4772.jpg: 384x640 2 persons, 9 cars, 1 bus, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1757/10000 [00:56<04:54, 27.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b610204c-e3c8c65f.jpg: 384x640 15 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b610c819-6f782f77.jpg: 384x640 3 persons, 10 cars, 3 traffic lights, 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61212a0-3ddd6209.jpg: 384x640 4 cars, 1 traffic light, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1760/10000 [00:56<04:59, 27.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61212a0-44b799c0.jpg: 384x640 7 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61212a0-78ccafee.jpg: 384x640 3 cars, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61212a0-ca782534.jpg: 384x640 3 cars, 1 train, 11.6ms\n",
            "Speed: 2.6ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6123103-45edd1d3.jpg: 384x640 15 cars, 1 traffic light, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1764/10000 [00:56<04:50, 28.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b612e792-38b302a3.jpg: 384x640 1 car, 1 truck, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b612e792-38fc9d6d.jpg: 384x640 9 cars, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61456bb-5bfb50ee.jpg: 384x640 2 persons, 1 car, 1 fire hydrant, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61459f8-ae92ce64.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1768/10000 [00:56<04:38, 29.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6149edb-63dcde71.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61527e7-207eccc6.jpg: 384x640 1 car, 3 traffic lights, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61527e7-ed487cc5.jpg: 384x640 7 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 4.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1771/10000 [00:57<04:40, 29.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61659ca-b9aded69.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6174277-7c80aaa7.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61a8404-29009d48.jpg: 384x640 5 cars, 2 trucks, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61aec41-121a3d3a.jpg: 384x640 1 person, 2 cars, 1 bus, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1775/10000 [00:57<04:18, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61aec41-15e06558.jpg: 384x640 4 cars, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61aec41-7b16e55c.jpg: 384x640 9 cars, 2 traffic lights, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61aec41-95a44c1c.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61aec41-fe792c56.jpg: 384x640 10 cars, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1779/10000 [00:57<04:08, 33.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61d661f-2d7bac86.jpg: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61f162d-b6e10f56.jpg: 384x640 1 person, 2 cars, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61f19ba-2f34ba9f.jpg: 384x640 6 cars, 7 traffic lights, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61f19ba-48885e8c.jpg: 384x640 7 cars, 1 traffic light, 1 stop sign, 15.7ms\n",
            "Speed: 5.1ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1783/10000 [00:57<04:33, 30.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61f19ba-ae781838.jpg: 384x640 8 cars, 3 traffic lights, 14.2ms\n",
            "Speed: 6.5ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61f7b3d-1e5fa9ff.jpg: 384x640 2 persons, 7 cars, 3 trucks, 2 traffic lights, 1 clock, 17.0ms\n",
            "Speed: 2.6ms preprocess, 17.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61fda8b-dbcf61c1.jpg: 384x640 9 cars, 1 bus, 1 truck, 10.7ms\n",
            "Speed: 3.9ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b61fda8b-fc0a3fe7.jpg: 384x640 5 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1787/10000 [00:57<04:57, 27.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6200832-fe3e43b0.jpg: 384x640 3 cars, 1 traffic light, 16.6ms\n",
            "Speed: 1.8ms preprocess, 16.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b620b595-74b20761.jpg: 384x640 1 car, 15.2ms\n",
            "Speed: 4.8ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b620fed9-6d88be73.jpg: 384x640 5 persons, 1 bicycle, 6 cars, 14.7ms\n",
            "Speed: 6.9ms preprocess, 14.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1790/10000 [00:57<04:57, 27.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b621872c-51db2c14.jpg: 384x640 1 person, 2 cars, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6219281-0695c9fd.jpg: 384x640 1 person, 5 cars, 2 traffic lights, 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6219281-2b4b9493.jpg: 384x640 2 persons, 1 car, 1 motorcycle, 1 bus, 4 traffic lights, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1793/10000 [00:57<04:51, 28.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6219281-861a5ba7.jpg: 384x640 4 cars, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6219281-9780cb21.jpg: 384x640 3 cars, 1 bus, 1 truck, 1 stop sign, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62279e2-0a5adb4c.jpg: 384x640 2 cars, 1 bus, 1 train, 1 truck, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62279e2-257b5cc0.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1797/10000 [00:57<04:32, 30.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6227ecd-ecc44823.jpg: 384x640 1 car, 1 train, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6228f2b-42996a33.jpg: 384x640 1 car, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6230fb4-02138607.jpg: 384x640 4 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b624162c-dd74b4df.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1801/10000 [00:57<04:15, 32.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6241b17-301c2e2e.jpg: 384x640 1 person, 13 cars, 1 traffic light, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6241b17-840feb5b.jpg: 384x640 11 cars, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6241b17-b82f1b25.jpg: 384x640 1 person, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6250d40-d51c7992.jpg: 384x640 11 cars, 1 truck, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1805/10000 [00:58<04:12, 32.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6270d75-6999f310.jpg: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b629c466-a0893075.jpg: 384x640 12 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62b4989-3b60bb9c.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62bef56-29a2dde5.jpg: 384x640 2 cars, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62bef56-3f15e2c9.jpg: 384x640 1 person, 3 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1810/10000 [00:58<03:56, 34.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62bef56-b08de744.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62c825e-75f4cc31.jpg: 384x640 2 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62e6504-1be1ddd7.jpg: 384x640 9 cars, 2 trucks, 2 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b62e6504-687ea24f.jpg: 384x640 2 cars, 1 bus, 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1814/10000 [00:58<03:59, 34.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b63368bc-17582ebd.jpg: 384x640 3 cars, 2 traffic lights, 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b63368bc-37bc42c5.jpg: 384x640 4 cars, 1 truck, 4 traffic lights, 15.0ms\n",
            "Speed: 2.2ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b633ed08-08a8b4ce.jpg: 384x640 1 person, 6 cars, 1 truck, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b634ca9d-c0211c64.jpg: 384x640 10 cars, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1818/10000 [00:58<04:06, 33.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6359092-fc2faab6.jpg: 384x640 19 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6375e65-94027fd8.jpg: 384x640 5 persons, 4 cars, 2 buss, 1 traffic light, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6375e65-d6e0692e.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6377978-3fa655d3.jpg: 384x640 1 person, 10 cars, 1 bus, 1 truck, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1822/10000 [00:58<04:06, 33.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b63a501b-90039f36.jpg: 384x640 4 cars, 1 truck, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b63ae329-24084d65.jpg: 384x640 7 cars, 1 truck, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b63b1c14-f01a2f6b.jpg: 384x640 4 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b63f0379-f0b444b5.jpg: 384x640 12 cars, 3 trucks, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1826/10000 [00:58<03:59, 34.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b63fe296-4c1819fe.jpg: 384x640 1 person, 9 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b641595b-a1ea9ccc.jpg: 384x640 7 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b641595b-ab8e24d2.jpg: 384x640 2 persons, 2 cars, 1 bus, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b643ea5a-af37c824.jpg: 384x640 7 persons, 4 cars, 1 bus, 1 potted plant, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1830/10000 [00:58<04:00, 33.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b643ed1d-7fbdd446.jpg: 384x640 2 persons, 5 cars, 1 bus, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b643ed1d-e4a05157.jpg: 384x640 10 persons, 4 cars, 1 truck, 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b645271a-42c7ec52.jpg: 384x640 2 persons, 5 cars, 3 traffic lights, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b645271a-cd9ec256.jpg: 384x640 5 cars, 13.5ms\n",
            "Speed: 4.6ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1834/10000 [00:59<04:23, 30.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b645e381-3d9a5456.jpg: 384x640 1 car, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6478560-1d584e43.jpg: 384x640 3 cars, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6487a3e-0761a2ae.jpg: 384x640 2 persons, 1 car, 1 bus, 2 trucks, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6487a3e-2ddb32e0.jpg: 384x640 11 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1838/10000 [00:59<04:11, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b64e5796-3aa7adc0.jpg: 384x640 2 cars, 1 traffic light, 1 tv, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b64e5796-be9c7667.jpg: 384x640 1 person, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b64e7cbc-d7dba7f9.jpg: 384x640 6 cars, 1 bus, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65081c3-7ace0408.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65081c3-9fb008e3.jpg: 384x640 2 cars, 1 traffic light, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1843/10000 [00:59<03:54, 34.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65081c3-a3dde936.jpg: 384x640 8 cars, 13.9ms\n",
            "Speed: 4.1ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b651ca9e-a11f85d6.jpg: 384x640 1 person, 10 cars, 14.6ms\n",
            "Speed: 5.2ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6530006-b43698a3.jpg: 384x640 2 persons, 3 cars, 13.9ms\n",
            "Speed: 5.2ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6541edc-7408a6a4.jpg: 384x640 8 persons, 2 cars, 1 fire hydrant, 1 stop sign, 13.3ms\n",
            "Speed: 6.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  18%|█▊        | 1847/10000 [00:59<04:26, 30.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6541edc-ecc17d4b.jpg: 384x640 14 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65688be-a25d3375.jpg: 384x640 10 cars, 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6579e76-1d48651a.jpg: 384x640 1 person, 9 cars, 1 train, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6579e76-4fee87d1.jpg: 384x640 4 persons, 5 cars, 4 trucks, 4 traffic lights, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▊        | 1851/10000 [00:59<04:54, 27.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6579e76-7415d4ba.jpg: 384x640 13 cars, 1 bus, 15.8ms\n",
            "Speed: 5.0ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6579e76-9da25188.jpg: 384x640 1 person, 2 cars, 1 bus, 2 traffic lights, 13.7ms\n",
            "Speed: 3.9ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6579e76-e438da36.jpg: 384x640 3 persons, 2 cars, 2 traffic lights, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▊        | 1854/10000 [00:59<04:58, 27.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6579e76-e88b3d6d.jpg: 384x640 1 person, 4 cars, 6 traffic lights, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6579e76-f2a13f71.jpg: 384x640 6 cars, 14.3ms\n",
            "Speed: 3.9ms preprocess, 14.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b657d595-3f1fa3ca.jpg: 384x640 5 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▊        | 1857/10000 [00:59<04:58, 27.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b657d595-af4a9aee.jpg: 384x640 1 person, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b657d595-e1026272.jpg: 384x640 (no detections), 10.0ms\n",
            "Speed: 4.2ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6592e95-0eaf85a5.jpg: 384x640 1 person, 3 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6592e95-6e497868.jpg: 384x640 10 persons, 2 traffic lights, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▊        | 1861/10000 [00:59<04:31, 29.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65db570-815a9c9a.jpg: 384x640 1 traffic light, 1 tv, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65fadaa-c6abbbaa.jpg: 384x640 1 person, 2 cars, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65fd3df-39bd79aa.jpg: 384x640 4 cars, 2 trucks, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65fd3df-87ed965a.jpg: 384x640 11 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▊        | 1865/10000 [01:00<04:31, 30.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b65ff14a-fc05765f.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6606454-86d77cb2.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6606454-a4fca360.jpg: 384x640 8 cars, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6630cba-4950a75a.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6642e30-6d6af891.jpg: 384x640 2 persons, 5 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▊        | 1870/10000 [01:00<04:05, 33.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6642e30-93accfbe.jpg: 384x640 9 cars, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6642e30-d87afdb2.jpg: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b66462a4-ce0558e1.jpg: 384x640 11 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6658d33-6dbf3405.jpg: 384x640 3 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▊        | 1874/10000 [01:00<04:01, 33.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6658d33-adfea9cf.jpg: 384x640 (no detections), 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6658d33-e6bc8c60.jpg: 384x640 1 person, 5 cars, 16.9ms\n",
            "Speed: 6.3ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6658d33-fe2d18f8.jpg: 384x640 1 car, 19.4ms\n",
            "Speed: 3.6ms preprocess, 19.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6663f36-805c1a0e.jpg: 384x640 4 cars, 18.8ms\n",
            "Speed: 2.9ms preprocess, 18.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1878/10000 [01:00<04:35, 29.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b666b95d-c38366c7.jpg: 384x640 8 cars, 1 bus, 1 truck, 16.3ms\n",
            "Speed: 4.7ms preprocess, 16.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6673f98-1e13354a.jpg: 384x640 5 cars, 18.8ms\n",
            "Speed: 4.0ms preprocess, 18.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6673f98-662b331b.jpg: 384x640 6 cars, 1 bus, 1 truck, 4 traffic lights, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6673f98-d6661115.jpg: 384x640 5 cars, 2 trucks, 3 traffic lights, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1882/10000 [01:00<05:04, 26.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b668a2f1-71cdf31d.jpg: 384x640 11 cars, 1 truck, 11.7ms\n",
            "Speed: 4.2ms preprocess, 11.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6695a33-42d20aa3.jpg: 384x640 2 persons, 1 car, 1 train, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b66c8021-7cb6d587.jpg: 384x640 7 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1885/10000 [01:00<04:56, 27.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b66c89a6-0e3787ab.jpg: 384x640 3 cars, 10.9ms\n",
            "Speed: 4.7ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b66ecd35-8de7da84.jpg: 384x640 5 cars, 1 truck, 3 traffic lights, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b66f7339-b14741dc.jpg: 384x640 6 cars, 1 traffic light, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1888/10000 [01:00<04:55, 27.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b670cde3-068b52ad.jpg: 384x640 4 cars, 1 truck, 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b67206f2-c8c9f269.jpg: 384x640 3 cars, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6741a2c-5a933eb6.jpg: 384x640 1 person, 3 cars, 1 traffic light, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1891/10000 [01:00<04:54, 27.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6741a2c-5fd7704c.jpg: 384x640 2 cars, 10.2ms\n",
            "Speed: 6.6ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b674bc13-24a7836b.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b674bc13-27dd7ecf.jpg: 384x640 1 car, 1 bus, 12.5ms\n",
            "Speed: 4.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b674bc13-2b4cdef3.jpg: 384x640 3 cars, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1895/10000 [01:01<04:36, 29.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b674bc13-3e309d54.jpg: 384x640 3 traffic lights, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b674bc13-41fca4db.jpg: 384x640 (no detections), 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b674bc13-8a296606.jpg: 384x640 3 cars, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b674bc13-dceb1013.jpg: 384x640 1 car, 3 traffic lights, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1899/10000 [01:01<04:23, 30.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b674bc13-f5f68ca6.jpg: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6763bf3-348c7b94.jpg: 384x640 1 person, 2 cars, 12.4ms\n",
            "Speed: 5.5ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6769965-61689289.jpg: 384x640 5 cars, 1 bus, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6770025-04eaf87d.jpg: 384x640 4 persons, 5 cars, 1 truck, 1 traffic light, 18.2ms\n",
            "Speed: 1.9ms preprocess, 18.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1903/10000 [01:01<04:28, 30.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6770025-c81ef5ed.jpg: 384x640 6 cars, 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6770a65-4fe52fcb.jpg: 384x640 1 car, 15.1ms\n",
            "Speed: 4.0ms preprocess, 15.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b677a46e-fb00fe82.jpg: 384x640 1 car, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b678cf28-16eac9dc.jpg: 384x640 10 cars, 1 truck, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1907/10000 [01:01<04:51, 27.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6795a21-1fab0f9e.jpg: 384x640 5 cars, 1 bus, 2 traffic lights, 20.9ms\n",
            "Speed: 2.0ms preprocess, 20.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b67a1d26-573dee1f.jpg: 384x640 1 person, 7 cars, 2 traffic lights, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b67cbe89-ef413620.jpg: 384x640 2 cars, 24.0ms\n",
            "Speed: 11.3ms preprocess, 24.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1910/10000 [01:01<05:27, 24.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b67d5d14-90c181ab.jpg: 384x640 5 cars, 9.6ms\n",
            "Speed: 7.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b67d5d14-ecdff820.jpg: 384x640 6 cars, 1 bus, 1 truck, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b67d5d14-fbc8866e.jpg: 384x640 5 cars, 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1913/10000 [01:01<05:36, 24.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6804637-851a6e28.jpg: 384x640 3 cars, 1 train, 15.6ms\n",
            "Speed: 4.1ms preprocess, 15.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b680f9ff-3edc5eee.jpg: 384x640 6 cars, 1 traffic light, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b680f9ff-c3577e59.jpg: 384x640 6 cars, 3 traffic lights, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1916/10000 [01:01<05:24, 24.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6818d65-6cfd37c8.jpg: 384x640 1 person, 1 car, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b683b494-0b21b850.jpg: 384x640 5 cars, 1 train, 18.4ms\n",
            "Speed: 1.9ms preprocess, 18.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b683c5c9-94747d74.jpg: 384x640 2 cars, 1 traffic light, 13.5ms\n",
            "Speed: 6.0ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1919/10000 [01:02<05:17, 25.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68445f5-cf8714b0.jpg: 384x640 3 persons, 5 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68445f5-fcfc98f7.jpg: 384x640 2 cars, 1 stop sign, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b685046c-a16279b4.jpg: 384x640 1 person, 2 bicycles, 3 cars, 17.1ms\n",
            "Speed: 1.9ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1922/10000 [01:02<05:05, 26.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b685cf4e-30eb4efa.jpg: 384x640 9 persons, 1 bicycle, 2 cars, 1 truck, 2 traffic lights, 14.3ms\n",
            "Speed: 6.1ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b685cf4e-e1378204.jpg: 384x640 1 person, 8 cars, 1 truck, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b685eb37-dc649de0.jpg: 384x640 2 cars, 1 traffic light, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1925/10000 [01:02<05:06, 26.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6876a74-8532d216.jpg: 384x640 7 cars, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68913f1-029e9d1a.jpg: 384x640 2 cars, 2 trucks, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b689c867-5a0ac45a.jpg: 384x640 6 cars, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68a000f-9a8091f9.jpg: 384x640 7 cars, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1929/10000 [01:02<04:44, 28.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68a0153-2c58a0e3.jpg: 384x640 4 cars, 2 traffic lights, 16.3ms\n",
            "Speed: 2.1ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68e35b5-0881c831.jpg: 384x640 3 persons, 5 cars, 2 buss, 1 traffic light, 15.4ms\n",
            "Speed: 2.6ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68e35b5-865cf5ee.jpg: 384x640 2 persons, 8 cars, 1 bus, 3 traffic lights, 19.5ms\n",
            "Speed: 4.9ms preprocess, 19.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1932/10000 [01:02<05:05, 26.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68e35b5-a135e64a.jpg: 384x640 4 persons, 8 cars, 2 trucks, 2 traffic lights, 20.3ms\n",
            "Speed: 2.0ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b68fe1ec-4c1094e2.jpg: 384x640 5 cars, 1 truck, 14.6ms\n",
            "Speed: 4.4ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b690989d-07e39c92.jpg: 384x640 2 persons, 13 cars, 1 traffic light, 1 bench, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1935/10000 [01:02<05:18, 25.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b690989d-919a2775.jpg: 384x640 2 persons, 6 cars, 2 trucks, 4 traffic lights, 15.4ms\n",
            "Speed: 2.0ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b690e7dd-1a1d38d1.jpg: 384x640 1 person, 1 bicycle, 5 cars, 1 bus, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69173a4-d0c92583.jpg: 384x640 3 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1938/10000 [01:02<05:07, 26.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69191ad-9c9cfe44.jpg: 384x640 7 cars, 14.6ms\n",
            "Speed: 4.0ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69603b2-8a99f37d.jpg: 384x640 8 cars, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69656bc-cd6901d3.jpg: 384x640 2 cars, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1941/10000 [01:02<04:57, 27.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b696cc35-68871f2a.jpg: 384x640 5 cars, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b696ed52-a487c213.jpg: 384x640 4 cars, 1 truck, 2 traffic lights, 19.4ms\n",
            "Speed: 1.8ms preprocess, 19.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6976dce-0810ee45.jpg: 384x640 2 cars, 1 truck, 16.5ms\n",
            "Speed: 1.8ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1944/10000 [01:02<04:52, 27.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6976dce-3c045c22.jpg: 384x640 3 cars, 2 traffic lights, 17.4ms\n",
            "Speed: 1.8ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69876fe-79c5a97a.jpg: 384x640 1 person, 6 cars, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b699a1df-6e9e269d.jpg: 384x640 4 cars, 1 truck, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b699c424-44ce61e2.jpg: 384x640 2 persons, 4 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  19%|█▉        | 1948/10000 [01:03<04:35, 29.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69a7e04-1dea4bd1.jpg: 384x640 4 cars, 1 bus, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69a7e04-226ce8c3.jpg: 384x640 3 persons, 10 cars, 2 trucks, 10.9ms\n",
            "Speed: 3.7ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69a7e04-794b786c.jpg: 384x640 5 cars, 1 traffic light, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69b040b-15424e43.jpg: 384x640 17 cars, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1952/10000 [01:03<04:31, 29.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69b7d13-a9c704af.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69d5b1d-03bd6daa.jpg: 384x640 2 cars, 1 truck, 17.2ms\n",
            "Speed: 5.0ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69d5b1d-99133316.jpg: 384x640 2 cars, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1955/10000 [01:03<04:37, 29.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69d81dd-35fbc1cf.jpg: 384x640 5 cars, 16.5ms\n",
            "Speed: 2.1ms preprocess, 16.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69e6a5d-a9cb966f.jpg: 384x640 3 cars, 1 traffic light, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b69fc2ae-156d58aa.jpg: 384x640 7 persons, 9 cars, 1 truck, 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1958/10000 [01:03<04:52, 27.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a0a684-b46f896b.jpg: 384x640 3 cars, 1 truck, 13.9ms\n",
            "Speed: 3.4ms preprocess, 13.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a0a684-e1ce5607.jpg: 384x640 6 cars, 5 trucks, 15.1ms\n",
            "Speed: 3.0ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a146ff-7491aafb.jpg: 384x640 1 person, 4 cars, 1 traffic light, 16.8ms\n",
            "Speed: 3.0ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1961/10000 [01:03<05:03, 26.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a1d94c-6e3fcf27.jpg: 384x640 1 car, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a5e5f0-73e9525b.jpg: 384x640 10 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a6df2d-3911b7c3.jpg: 384x640 1 person, 3 cars, 2 trucks, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1964/10000 [01:03<04:54, 27.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a6df2d-435493e8.jpg: 384x640 2 persons, 7 cars, 2 traffic lights, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a6df2d-743bf863.jpg: 384x640 4 cars, 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a6df2d-8f9cc4cf.jpg: 384x640 5 cars, 2 traffic lights, 15.7ms\n",
            "Speed: 2.7ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1967/10000 [01:03<04:59, 26.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a6df2d-cc93b4c6.jpg: 384x640 1 car, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a7a3ef-1151ebda.jpg: 384x640 3 cars, 13.7ms\n",
            "Speed: 3.4ms preprocess, 13.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a8503c-4991b168.jpg: 384x640 4 cars, 1 train, 16.1ms\n",
            "Speed: 3.9ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1970/10000 [01:03<04:54, 27.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a8503c-52e3490b.jpg: 384x640 1 car, 1 traffic light, 15.9ms\n",
            "Speed: 1.8ms preprocess, 15.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a8503c-5e7375a8.jpg: 384x640 8 cars, 14.3ms\n",
            "Speed: 3.5ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a8503c-a797867c.jpg: 384x640 3 cars, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1973/10000 [01:03<04:55, 27.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a8503c-b04e247c.jpg: 384x640 4 cars, 1 truck, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a936f4-483e5144.jpg: 384x640 5 cars, 1 truck, 3 traffic lights, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6a936f4-f54cef7f.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6aa41ba-04780705.jpg: 384x640 1 person, 1 car, 1 traffic light, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1977/10000 [01:04<04:32, 29.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6aa41ba-08564ca8.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6aa41ba-6ac62da0.jpg: 384x640 1 car, 2 traffic lights, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6aa41ba-736c9da7.jpg: 384x640 4 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6aa41ba-768fdf21.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1981/10000 [01:04<04:15, 31.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6accff3-eb28ad4f.jpg: 384x640 3 cars, 1 truck, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6aeb288-6615a6dc.jpg: 384x640 3 cars, 2 traffic lights, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6aeb288-c860c9a2.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6af8c92-ba98fb91.jpg: 384x640 8 cars, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1985/10000 [01:04<04:19, 30.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6afe56b-ec85d002.jpg: 384x640 5 cars, 5 traffic lights, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b01f9f-5ed424ca.jpg: 384x640 12 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b01f9f-f6aa5d75.jpg: 384x640 4 cars, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b047b4-3fccc761.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1989/10000 [01:04<04:24, 30.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b047b4-7bdf1e93.jpg: 384x640 6 persons, 4 cars, 1 truck, 3 traffic lights, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b047b4-ca577730.jpg: 384x640 5 cars, 1 bus, 2 trucks, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b047b4-e61f09a7.jpg: 384x640 2 cars, 1 bus, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b0d831-7abd7933.jpg: 384x640 4 cars, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1993/10000 [01:04<04:17, 31.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b536f4-c90f357e.jpg: 384x640 5 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b616b3-979e75c3.jpg: 384x640 1 car, 1 truck, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b6fd86-ab4d10f6.jpg: 384x640 3 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b7800d-bdecc6bc.jpg: 384x640 1 person, 1 car, 3 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|█▉        | 1997/10000 [01:04<04:05, 32.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b871e8-e0718c93.jpg: 384x640 9 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b8d59f-e8059575.jpg: 384x640 1 person, 1 car, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b9069a-4908df6a.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b9069a-5417277d.jpg: 384x640 5 cars, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2001/10000 [01:04<03:57, 33.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6b9d3c1-d683dfce.jpg: 384x640 21 cars, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ba23a1-4d9e1f20.jpg: 384x640 2 cars, 1 bus, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ba23a1-98fd0d6b.jpg: 384x640 1 car, 1 traffic light, 10.0ms\n",
            "Speed: 3.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6bac30c-216dc02e.jpg: 384x640 1 person, 3 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2005/10000 [01:04<03:58, 33.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6bb7bc8-795f455a.jpg: 384x640 2 persons, 3 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6bd79c8-c94f5c10.jpg: 384x640 7 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6bdb46e-2c60ecc3.jpg: 384x640 4 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6bdb46e-3709d206.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2009/10000 [01:05<03:49, 34.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6bec9b9-3ceaf9b6.jpg: 384x640 7 cars, 1 bus, 4 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6bec9b9-a964c43a.jpg: 384x640 1 person, 11 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c0964a-87b5d540.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c22033-a2105050.jpg: 384x640 6 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2013/10000 [01:05<03:51, 34.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c2a409-b0dacc13.jpg: 384x640 3 cars, 2 traffic lights, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c2d715-ba5d6ecc.jpg: 384x640 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c3cbb0-1c4e006c.jpg: 384x640 7 cars, 1 traffic light, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c6e6fe-1c5ab635.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2017/10000 [01:05<03:47, 35.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c6e6fe-f325bc62.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c771db-9c243cab.jpg: 384x640 2 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c771db-a92c32e3.jpg: 384x640 1 person, 1 bicycle, 3 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c771db-f15d8a40.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2021/10000 [01:05<03:48, 34.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c89a7e-23a41125.jpg: 384x640 7 cars, 2 traffic lights, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c938b0-7bc5d2b8.jpg: 384x640 4 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c938b0-a748acc1.jpg: 384x640 5 cars, 1 traffic light, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6c938b0-c1d453f8.jpg: 384x640 3 persons, 2 cars, 2 traffic lights, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2025/10000 [01:05<03:56, 33.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ca7400-0ed0dc64.jpg: 384x640 4 cars, 1 truck, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6cad0b4-56d2e2d9.jpg: 384x640 1 person, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6cbfcf4-ce2bfe3b.jpg: 384x640 2 cars, 1 umbrella, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6cbfcf4-cfa37f13.jpg: 384x640 1 car, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2029/10000 [01:05<03:53, 34.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ceb8b8-0aeb8a64.jpg: 384x640 1 car, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6cebd5a-5ca64f5f.jpg: 384x640 9 cars, 3 traffic lights, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d0b46a-ec482777.jpg: 384x640 1 person, 4 cars, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d0b9d1-3460a220.jpg: 384x640 3 cars, 1 traffic light, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2033/10000 [01:05<03:50, 34.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d0b9d1-97b198c7.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d0b9d1-9e750bae.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d0b9d1-a2c6c924.jpg: 384x640 2 persons, 2 cars, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d0b9d1-bfbc7861.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d0b9d1-d643d86a.jpg: 384x640 3 cars, 1 traffic light, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2038/10000 [01:05<03:40, 36.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d0b9d1-f5531bf3.jpg: 384x640 5 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d1c1f6-998f36f3.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d2717a-6e17bbb1.jpg: 384x640 (no detections), 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d2717a-a24fc378.jpg: 384x640 (no detections), 11.3ms\n",
            "Speed: 4.0ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2042/10000 [01:05<03:48, 34.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d2717a-d8d1bc0c.jpg: 384x640 2 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d5b39b-710032ac.jpg: 384x640 8 cars, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d6e4f6-cc416656.jpg: 384x640 13 cars, 1 truck, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d82c09-389f4f78.jpg: 384x640 4 persons, 8 cars, 1 truck, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2046/10000 [01:06<03:59, 33.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d82c09-e7005951.jpg: 384x640 7 persons, 9 cars, 2 traffic lights, 1 umbrella, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d855a5-38d55a26.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d855a5-c1d5a996.jpg: 384x640 4 persons, 2 cars, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6d9b0ba-a0a7525e.jpg: 384x640 2 cars, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  20%|██        | 2050/10000 [01:06<04:02, 32.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6db090c-2b1971cf.jpg: 384x640 1 car, 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6db6674-29fd8e88.jpg: 384x640 7 cars, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6db6674-74fe17d1.jpg: 384x640 3 persons, 1 bicycle, 9 cars, 1 truck, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6db6674-bd255464.jpg: 384x640 10 cars, 2 traffic lights, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2054/10000 [01:06<04:14, 31.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ddc104-54cc00e3.jpg: 384x640 2 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ddc104-b6089ee2.jpg: 384x640 5 cars, 1 truck, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ddc104-dd647db8.jpg: 384x640 7 cars, 2 trains, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6de6d24-bfcf2de4.jpg: 384x640 1 car, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2058/10000 [01:06<04:14, 31.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6decb24-0de96f8c.jpg: 384x640 2 persons, 12 cars, 1 truck, 5 traffic lights, 18.4ms\n",
            "Speed: 1.8ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6decb24-390c9ae7.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 18.1ms\n",
            "Speed: 2.7ms preprocess, 18.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6decb24-3f0404d4.jpg: 384x640 5 persons, 2 traffic lights, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6decb24-75789742.jpg: 384x640 1 person, 2 trucks, 3 traffic lights, 1 fire hydrant, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2062/10000 [01:06<04:37, 28.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6decb24-7fbd99e8.jpg: 384x640 2 persons, 5 cars, 1 bus, 2 trucks, 1 traffic light, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6decb24-82234e11.jpg: 384x640 1 person, 2 cars, 2 buss, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6decb24-fffc40f7.jpg: 384x640 4 persons, 5 cars, 1 truck, 1 stop sign, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6df605f-34527b5f.jpg: 384x640 1 person, 2 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2066/10000 [01:06<04:30, 29.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6df605f-51c158b8.jpg: 384x640 1 person, 3 cars, 1 bus, 2 traffic lights, 9.1ms\n",
            "Speed: 4.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6df605f-5f035267.jpg: 384x640 9 cars, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6df605f-acdccf67.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e264cf-d2600371.jpg: 384x640 8 cars, 1 fire hydrant, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2070/10000 [01:06<04:18, 30.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e2a815-20a3637b.jpg: 384x640 4 cars, 1 bus, 2 traffic lights, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e2a815-6106646d.jpg: 384x640 5 cars, 1 truck, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e49a81-ca7f9e9d.jpg: 384x640 1 person, 10 cars, 4 traffic lights, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e4a55e-0684fdec.jpg: 384x640 5 cars, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2074/10000 [01:07<04:14, 31.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e4a55e-2e6228cc.jpg: 384x640 2 cars, 2 buss, 1 train, 3 trucks, 1 traffic light, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e4a55e-4a7068f1.jpg: 384x640 4 cars, 2 trucks, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e591bd-d509b54b.jpg: 384x640 7 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e5b2fd-1e596798.jpg: 384x640 2 cars, 1 traffic light, 7.7ms\n",
            "Speed: 2.0ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2078/10000 [01:07<04:07, 32.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e602b3-50bfb157.jpg: 384x640 5 persons, 1 bicycle, 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e683d2-84d2dfbf.jpg: 384x640 3 persons, 3 cars, 2 traffic lights, 1 dog, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e683d2-bd7cdcbb.jpg: 384x640 1 person, 8 cars, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6e90f9b-3f3431d4.jpg: 384x640 4 cars, 2 trucks, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2082/10000 [01:07<04:04, 32.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ea0cd9-aa1cbdf5.jpg: 384x640 7 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ea0cd9-b9cec75f.jpg: 384x640 2 cars, 1 bus, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ea1520-1bd7b870.jpg: 384x640 6 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ea1520-1c9df539.jpg: 384x640 5 persons, 2 bicycles, 8 cars, 1 traffic light, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2086/10000 [01:07<04:02, 32.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6eda03e-50c604c1.jpg: 384x640 2 traffic lights, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f2176b-20c2f527.jpg: 384x640 7 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f2176b-fcca7545.jpg: 384x640 6 persons, 4 cars, 2 trucks, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f40904-693d5d3d.jpg: 384x640 12 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2090/10000 [01:07<04:00, 32.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f4b139-527d7e55.jpg: 384x640 4 cars, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f4b139-744f76c0.jpg: 384x640 4 persons, 7 cars, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f4b139-d7311df5.jpg: 384x640 8 persons, 6 cars, 2 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f77fda-02b6e75b.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2094/10000 [01:07<03:55, 33.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f77fda-2531c3a3.jpg: 384x640 2 persons, 2 cars, 1 bus, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f77fda-33d2260f.jpg: 384x640 11 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f77fda-46184a8c.jpg: 384x640 16 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f81988-1083f3fa.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2098/10000 [01:07<03:54, 33.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f85287-cde20f1d.jpg: 384x640 17 cars, 1 bus, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f8a510-6f70445f.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f95b33-d54400d9.jpg: 384x640 2 cars, 1 train, 1 truck, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6f9afd4-63573be9.jpg: 384x640 3 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2102/10000 [01:07<03:47, 34.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6fae313-657598b1.jpg: 384x640 5 cars, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ff1331-f6d3fba8.jpg: 384x640 14 cars, 1 truck, 1 bird, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffd606-322ba017.jpg: 384x640 6 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-017de39c.jpg: 384x640 6 cars, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2106/10000 [01:08<03:56, 33.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-1e0d5145.jpg: 384x640 2 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-35e5adfb.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-735e0b0a.jpg: 384x640 1 person, 1 car, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-7c91eac9.jpg: 384x640 2 persons, 4 cars, 1 bus, 10.8ms\n",
            "Speed: 4.0ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2110/10000 [01:08<03:55, 33.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-a0d0cd8d.jpg: 384x640 6 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-a462948c.jpg: 384x640 2 cars, 1 stop sign, 1 bench, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-ca9d4b5b.jpg: 384x640 11 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-d13595c6.jpg: 384x640 5 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2114/10000 [01:08<03:52, 33.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-d7a0f83e.jpg: 384x640 2 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-d8f2c88e.jpg: 384x640 1 car, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-f7d2cdce.jpg: 384x640 7 cars, 15.3ms\n",
            "Speed: 1.7ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b6ffe7bd-fd52b51e.jpg: 384x640 2 cars, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2118/10000 [01:08<03:51, 34.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7007510-f6b3b182.jpg: 384x640 5 cars, 14.5ms\n",
            "Speed: 2.2ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b700e409-b6515113.jpg: 384x640 2 persons, 2 cars, 2 traffic lights, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b701e0ad-0179d536.jpg: 384x640 3 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b701e0ad-899d1610.jpg: 384x640 3 persons, 3 cars, 1 traffic light, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██        | 2122/10000 [01:08<03:59, 32.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b701e0ad-f824d54b.jpg: 384x640 1 person, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7041acc-6de39959.jpg: 384x640 6 cars, 1 truck, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7041acc-a64aa9d2.jpg: 384x640 5 cars, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7049e6e-fa515af6.jpg: 384x640 3 persons, 8 cars, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██▏       | 2126/10000 [01:08<04:00, 32.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b705004b-c5606783.jpg: 384x640 5 persons, 2 cars, 1 truck, 3 traffic lights, 12.8ms\n",
            "Speed: 4.8ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7064abc-24deedb3.jpg: 384x640 2 cars, 12.9ms\n",
            "Speed: 2.5ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7064abc-4ed592fe.jpg: 384x640 5 cars, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7064abc-878a912c.jpg: 384x640 2 umbrellas, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██▏       | 2130/10000 [01:08<04:00, 32.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70692e1-fcb7203c.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7072ec0-3a3b64a5.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b709801c-c2f5bc24.jpg: 384x640 8 persons, 2 cars, 3 buss, 1 truck, 2 traffic lights, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70b64da-024e0355.jpg: 384x640 8 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██▏       | 2134/10000 [01:08<03:53, 33.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70b64da-2a532ff1.jpg: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70b64da-396bfbd3.jpg: 384x640 12 cars, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70b64da-73d75639.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70b7cdc-c4dcd88b.jpg: 384x640 6 cars, 2 traffic lights, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██▏       | 2138/10000 [01:08<03:47, 34.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70c8fba-827bc9c7.jpg: 384x640 1 person, 3 cars, 1 traffic light, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70d1e4a-467d8c58.jpg: 384x640 2 cars, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b70f200b-ad49ec36.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b710d831-df5ce01b.jpg: 384x640 6 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██▏       | 2142/10000 [01:09<03:42, 35.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b710d831-faa2aa67.jpg: 384x640 3 persons, 3 cars, 1 traffic light, 1 fire hydrant, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7147430-2a111946.jpg: 384x640 1 car, 1 truck, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b714a088-861a043b.jpg: 384x640 1 person, 8 cars, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b714a088-e91ac24f.jpg: 384x640 1 person, 6 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  21%|██▏       | 2146/10000 [01:09<03:51, 33.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b715a46a-32d2d7eb.jpg: 384x640 2 cars, 2 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71bb4df-b9837e9c.jpg: 384x640 3 cars, 1 truck, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71bf87d-528e531c.jpg: 384x640 3 cars, 1 bus, 2 trucks, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71bf87d-894c1a21.jpg: 384x640 3 cars, 1 truck, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2150/10000 [01:09<03:49, 34.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71cef92-3492a923.jpg: 384x640 3 cars, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71d7574-015d9d5d.jpg: 384x640 6 cars, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71d7574-2af6ba2d.jpg: 384x640 (no detections), 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71d7574-92c4aeba.jpg: 384x640 10 persons, 7 cars, 2 traffic lights, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2154/10000 [01:09<04:02, 32.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71d7574-c6113b75.jpg: 384x640 1 car, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71d7574-e6bc43e9.jpg: 384x640 7 persons, 1 bicycle, 4 cars, 1 truck, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71e2cab-7a7494cf.jpg: 384x640 1 person, 10 cars, 1 bus, 1 truck, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71e9235-4012ac22.jpg: 384x640 2 persons, 5 cars, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2158/10000 [01:09<04:06, 31.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71ecc5a-7a837d0a.jpg: 384x640 9 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71f13d6-b07faf5f.jpg: 384x640 1 person, 3 cars, 1 traffic light, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b71f7e68-578dfb43.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7205754-4faa3862.jpg: 384x640 1 car, 2 trucks, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b720f8cf-eb23da16.jpg: 384x640 1 person, 5 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2163/10000 [01:09<03:47, 34.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b721bf1b-be4e2e12.jpg: 384x640 5 persons, 11 cars, 1 truck, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b721f994-43356f34.jpg: 384x640 9 cars, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7226661-1ba4dc1a.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7226661-33b4c4ff.jpg: 384x640 7 cars, 3 traffic lights, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2167/10000 [01:09<03:48, 34.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7226661-aff64877.jpg: 384x640 8 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7234188-8102b743.jpg: 384x640 1 person, 6 cars, 1 bus, 3 traffic lights, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b72393ac-a136bc1e.jpg: 384x640 5 cars, 1 bus, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b72393ac-b071c025.jpg: 384x640 13 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2171/10000 [01:09<03:50, 33.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b724e1f0-cffecdc5.jpg: 384x640 3 persons, 9 cars, 1 traffic light, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b726242a-53eb7489.jpg: 384x640 1 car, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b726c429-11f5acde.jpg: 384x640 5 persons, 4 cars, 1 umbrella, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b726c429-299fdd6b.jpg: 384x640 2 persons, 1 car, 1 bus, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2175/10000 [01:10<03:47, 34.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b726c429-726588e2.jpg: 384x640 10 cars, 3 traffic lights, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b726c429-8f45fe47.jpg: 384x640 7 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b726c429-9789a231.jpg: 384x640 1 person, 17 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b726c429-b84a63c2.jpg: 384x640 8 cars, 5 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2179/10000 [01:10<03:56, 33.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b726c429-c334aa54.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 17.3ms\n",
            "Speed: 1.8ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7279e9d-fcd59829.jpg: 384x640 1 person, 1 bicycle, 2 cars, 1 traffic light, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b72812e8-c636249b.jpg: 384x640 7 cars, 2 trucks, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b728b79a-14e09f31.jpg: 384x640 13 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2183/10000 [01:10<04:04, 32.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b728b79a-15b4e229.jpg: 384x640 10 cars, 1 motorcycle, 1 stop sign, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b728b79a-b1757497.jpg: 384x640 2 persons, 5 cars, 1 bus, 1 train, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7298f0f-00fb851b.jpg: 384x640 5 cars, 1 truck, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b729d050-af382d96.jpg: 384x640 4 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2187/10000 [01:10<04:05, 31.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b729d9e2-1a443f51.jpg: 384x640 4 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b729d9e2-a4d95e09.jpg: 384x640 8 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b72b3974-07848804.jpg: 384x640 12 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b72b3974-552bb7d7.jpg: 384x640 8 cars, 2 trucks, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2191/10000 [01:10<04:03, 32.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b72b3974-9667b29a.jpg: 384x640 1 person, 12 cars, 2 trucks, 2 traffic lights, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b72f72e4-02ac60a7.jpg: 384x640 1 person, 9 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7301a4a-b25a846a.jpg: 384x640 7 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b730ab01-492b4489.jpg: 384x640 11 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2195/10000 [01:10<04:05, 31.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b73282b1-7bc49185.jpg: 384x640 (no detections), 10.7ms\n",
            "Speed: 5.0ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b733092e-68a5b8e9.jpg: 384x640 3 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b733b13d-e5dccc44.jpg: 384x640 1 person, 8 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7341ecf-4be3bdcb.jpg: 384x640 7 cars, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2199/10000 [01:10<04:03, 32.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7348a27-496f5f92.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b735df0d-e7bf4c09.jpg: 384x640 3 cars, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b736a729-8e235005.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b736c477-ce5093ac.jpg: 384x640 3 cars, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2203/10000 [01:10<03:54, 33.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b736c477-fb345fa9.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b73737dc-0fac3a01.jpg: 384x640 3 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b737b268-3e81c0e9.jpg: 384x640 8 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b738d22a-6ac5e1d6.jpg: 384x640 2 persons, 6 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2207/10000 [01:11<03:51, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7390768-06a6a4a0.jpg: 384x640 1 car, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7394616-aff8fb86.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b73a59ee-a81b5085.jpg: 384x640 3 cars, 1 bus, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b73a793e-ebf5917d.jpg: 384x640 8 cars, 3 traffic lights, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2211/10000 [01:11<03:52, 33.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b73dd344-03413fbf.jpg: 384x640 9 cars, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b73de6c1-1eb67050.jpg: 384x640 4 cars, 1 bus, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b73de6c1-907ea814.jpg: 384x640 5 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b73f18e7-6341f45b.jpg: 384x640 1 person, 19 cars, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2215/10000 [01:11<04:00, 32.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7404583-645b7fd7.jpg: 384x640 1 bicycle, 9 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7404583-b504d500.jpg: 384x640 1 person, 7 cars, 2 trucks, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b740e2ac-c01ee78f.jpg: 384x640 1 car, 2 trucks, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74111eb-27276099.jpg: 384x640 6 persons, 5 cars, 1 truck, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2219/10000 [01:11<04:10, 31.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74111eb-d21a119b.jpg: 384x640 12 persons, 1 car, 1 truck, 3 traffic lights, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7416b8c-5b0fcd5e.jpg: 384x640 3 cars, 1 truck, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b741c25b-5d56239a.jpg: 384x640 5 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b742a9e3-7fbcedaa.jpg: 384x640 1 car, 3 traffic lights, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2223/10000 [01:11<04:07, 31.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b743317c-44e297ee.jpg: 384x640 1 car, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b743b808-c7c4e44d.jpg: 384x640 5 persons, 1 bicycle, 8 cars, 1 bus, 1 truck, 3 traffic lights, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7446774-29ac1db2.jpg: 384x640 7 cars, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7446774-2faa796d.jpg: 384x640 7 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2227/10000 [01:11<04:10, 31.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7446774-60e761ec.jpg: 384x640 8 cars, 1 truck, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b744c27e-b87d6875.jpg: 384x640 3 persons, 2 bicycles, 3 cars, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7457987-06803d89.jpg: 384x640 1 car, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7457987-4f89d5e8.jpg: 384x640 2 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2231/10000 [01:11<03:56, 32.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7457987-72d06293.jpg: 384x640 1 person, 4 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7457987-9bccf8c4.jpg: 384x640 1 person, 4 cars, 4 traffic lights, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b747a85e-79f375a1.jpg: 384x640 11 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b747a85e-9e012bdf.jpg: 384x640 9 cars, 2 trucks, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2235/10000 [01:11<03:51, 33.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b747a85e-d46dde6a.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b747b30e-991436c7.jpg: 384x640 5 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7480124-540c4b41.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7497244-1b64c54d.jpg: 384x640 7 persons, 4 cars, 1 truck, 1 handbag, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2239/10000 [01:12<03:44, 34.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74bedfc-036616d8.jpg: 384x640 6 cars, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74bedfc-6187ffd8.jpg: 384x640 10 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74bedfc-9adcb4ef.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74ca6c1-38f5c3c8.jpg: 384x640 3 persons, 5 cars, 2 trucks, 1 traffic light, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2243/10000 [01:12<03:40, 35.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74d1efd-b4b4590f.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74e7806-60077058.jpg: 384x640 12 cars, 1 traffic light, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74f9c57-2a44aec1.jpg: 384x640 2 persons, 4 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74f9c57-420c7d6e.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  22%|██▏       | 2247/10000 [01:12<03:39, 35.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74f9c57-90451f20.jpg: 384x640 1 person, 14 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74f9c57-f542adef.jpg: 384x640 7 cars, 2 motorcycles, 1 bus, 1 potted plant, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b74fa71d-b72c24a3.jpg: 384x640 15 persons, 6 cars, 3 trucks, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b750dfba-288937b9.jpg: 384x640 6 persons, 4 cars, 2 benchs, 16.7ms\n",
            "Speed: 2.3ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2251/10000 [01:12<04:03, 31.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7537b2b-acc8384f.jpg: 384x640 2 traffic lights, 11.9ms\n",
            "Speed: 3.9ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7548e7c-9b143316.jpg: 384x640 2 cars, 12.9ms\n",
            "Speed: 2.5ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b754a2e4-8785a25d.jpg: 384x640 12 cars, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7559b8d-1ca5f88f.jpg: 384x640 2 cars, 1 airplane, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2255/10000 [01:12<04:03, 31.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7559b8d-8c71431d.jpg: 384x640 7 cars, 1 truck, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75781e5-27729a7d.jpg: 384x640 3 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75781e5-a44bc5af.jpg: 384x640 2 cars, 1 traffic light, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b757ae91-a9093726.jpg: 384x640 13 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2259/10000 [01:12<03:53, 33.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b757ae91-c4ae9ab1.jpg: 384x640 3 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b757f147-6a20b38f.jpg: 384x640 9 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7586523-724c2502.jpg: 384x640 7 cars, 2 traffic lights, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75bda07-d83a04eb.jpg: 384x640 7 persons, 5 cars, 1 fire hydrant, 2 handbags, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2263/10000 [01:12<03:47, 34.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75cb43c-159062d9.jpg: 384x640 1 car, 3 traffic lights, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75da19e-2d5038ce.jpg: 384x640 2 persons, 8 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75da19e-78c2c800.jpg: 384x640 4 persons, 7 cars, 1 truck, 3 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75da19e-a1d997ec.jpg: 384x640 10 cars, 3 trucks, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2267/10000 [01:12<03:55, 32.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75da19e-a29454b7.jpg: 384x640 1 car, 3 trucks, 2 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75da19e-c1bea5b4.jpg: 384x640 5 cars, 1 bus, 2 trucks, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75da19e-ce52c274.jpg: 384x640 3 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75ed92c-c9116263.jpg: 384x640 2 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2271/10000 [01:12<03:43, 34.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75f355e-32bd06af.jpg: 384x640 4 cars, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75f355e-837e1a01.jpg: 384x640 2 persons, 9 cars, 1 bus, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75f355e-b3f098b9.jpg: 384x640 12 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75f355e-b8ecbd7e.jpg: 384x640 7 cars, 1 traffic light, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2275/10000 [01:13<03:41, 34.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75f814e-4b7257ae.jpg: 384x640 3 cars, 1 bus, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75f814e-9861df41.jpg: 384x640 1 car, 1 traffic light, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b75f814e-f533da40.jpg: 384x640 1 car, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b760329b-611024b4.jpg: 384x640 8 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2279/10000 [01:13<03:34, 36.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7610ba3-9eabe8e3.jpg: 384x640 1 person, 6 cars, 2 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b761b4a6-ba62a4ae.jpg: 384x640 6 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b761cf92-05ed0ba2.jpg: 384x640 6 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b761cf92-0ec720b9.jpg: 384x640 8 cars, 1 bus, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2283/10000 [01:13<03:37, 35.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b761cf92-3127cc34.jpg: 384x640 3 persons, 3 cars, 1 truck, 1 traffic light, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b762e497-59b064e0.jpg: 384x640 9 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7636303-2036ba2d.jpg: 384x640 4 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b764f1b2-7ce1c79f.jpg: 384x640 3 cars, 2 traffic lights, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2287/10000 [01:13<03:42, 34.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b766079c-62ff02f3.jpg: 384x640 1 person, 5 cars, 1 motorcycle, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7668116-0f00b768.jpg: 384x640 16 cars, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7668116-71da4033.jpg: 384x640 1 person, 4 cars, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7676214-60e4d9eb.jpg: 384x640 9 persons, 5 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2291/10000 [01:13<03:56, 32.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7676214-b10e4e0e.jpg: 384x640 7 cars, 1 truck, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b76792cb-0b0d99c9.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b76792cb-2998adba.jpg: 384x640 7 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b768b26a-f90ad09d.jpg: 384x640 2 persons, 4 cars, 1 motorcycle, 1 bus, 1 truck, 3 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2295/10000 [01:13<03:46, 34.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b768ec39-d32827c2.jpg: 384x640 4 cars, 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-026548da.jpg: 384x640 3 persons, 1 bicycle, 7 cars, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-12edf532.jpg: 384x640 2 persons, 1 bicycle, 4 cars, 1 truck, 1 traffic light, 1 stop sign, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-317151bf.jpg: 384x640 1 person, 3 cars, 2 buss, 1 traffic light, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2299/10000 [01:13<03:43, 34.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-867bf3b3.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-902d2ff3.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-9473432d.jpg: 384x640 2 bicycles, 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-9be9a666.jpg: 384x640 1 person, 3 cars, 1 truck, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2303/10000 [01:13<03:35, 35.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-ac5f60c7.jpg: 384x640 9 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b769f2fa-adedab4b.jpg: 384x640 2 persons, 1 bicycle, 3 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b76fff5c-46f35d4c.jpg: 384x640 8 cars, 5 traffic lights, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b770f56a-3e8cba7a.jpg: 384x640 1 car, 2 trucks, 2 traffic lights, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2307/10000 [01:14<03:35, 35.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7711ddf-0f0035a8.jpg: 384x640 5 cars, 1 traffic light, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7719f1d-8245d9ce.jpg: 384x640 3 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7719f1d-e6e580dd.jpg: 384x640 9 cars, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77405dc-08d4db28.jpg: 384x640 14 cars, 1 traffic light, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2311/10000 [01:14<03:46, 34.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b775af1c-b71a7f85.jpg: 384x640 1 person, 7 cars, 1 truck, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b775af1c-bb5afbe3.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77826c3-b22372a9.jpg: 384x640 10 cars, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7789d1a-353aa20d.jpg: 384x640 3 persons, 5 cars, 4 trucks, 1 fire hydrant, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2315/10000 [01:14<03:56, 32.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7789d1a-92fe7627.jpg: 384x640 3 persons, 4 cars, 1 fire hydrant, 1 stop sign, 17.2ms\n",
            "Speed: 2.7ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7799f64-736f7f7e.jpg: 384x640 4 cars, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77a6ed6-5661f543.jpg: 384x640 6 persons, 7 cars, 1 truck, 2 traffic lights, 14.0ms\n",
            "Speed: 2.1ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77c4440-56fe6db9.jpg: 384x640 1 person, 6 cars, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2319/10000 [01:14<04:09, 30.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77d1f5b-db4b275d.jpg: 384x640 (no detections), 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77d2f48-007d3dbd.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77d2f48-020ecd39.jpg: 384x640 1 person, 11 cars, 13.7ms\n",
            "Speed: 3.8ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77d2f48-a010995e.jpg: 384x640 3 cars, 1 fire hydrant, 16.5ms\n",
            "Speed: 3.9ms preprocess, 16.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2323/10000 [01:14<04:08, 30.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77dc345-6d549a1b.jpg: 384x640 1 person, 8 cars, 1 traffic light, 15.7ms\n",
            "Speed: 2.5ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77dc345-d1f9b91c.jpg: 384x640 1 person, 11 cars, 2 trucks, 1 stop sign, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77df2a1-b2c5d1bb.jpg: 384x640 6 persons, 8 cars, 1 motorcycle, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77e197d-572d6c7b.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2327/10000 [01:14<04:15, 30.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b77f3729-fcbf9b93.jpg: 384x640 1 person, 3 cars, 9.4ms\n",
            "Speed: 5.5ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b780088d-0bf9e946.jpg: 384x640 2 persons, 14 cars, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b780088d-b85f1b00.jpg: 384x640 1 person, 15 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b78032b6-f85e30bb.jpg: 384x640 3 cars, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2331/10000 [01:14<04:15, 30.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b782a90c-b8670a3c.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b782f9ad-6bc1d4ee.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7831880-0327e785.jpg: 384x640 2 persons, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b783536b-93708b03.jpg: 384x640 5 cars, 5 traffic lights, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2335/10000 [01:14<04:16, 29.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7841cd5-1fe9c108.jpg: 384x640 1 person, 10 cars, 3 trucks, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b784ff27-14060d57.jpg: 384x640 2 persons, 8 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b784ff27-58c39a23.jpg: 384x640 5 cars, 1 bus, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b784ff27-a05a848e.jpg: 384x640 5 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2339/10000 [01:15<04:06, 31.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b784ff27-baf00daa.jpg: 384x640 9 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7872bf3-ddf64f77.jpg: 384x640 6 cars, 1 truck, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b788c509-56f6a40a.jpg: 384x640 5 cars, 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b788c509-9ba17da1.jpg: 384x640 1 bus, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2343/10000 [01:15<04:07, 30.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b788c509-9d3284e8.jpg: 384x640 7 cars, 2 traffic lights, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b78a38de-5b7a6b2f.jpg: 384x640 (no detections), 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b78cb53c-14d14771.jpg: 384x640 3 persons, 6 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b78cb53c-65159143.jpg: 384x640 5 cars, 1 traffic light, 18.6ms\n",
            "Speed: 3.6ms preprocess, 18.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  23%|██▎       | 2347/10000 [01:15<04:16, 29.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b78dd814-86a01e2e.jpg: 384x640 2 cars, 1 bus, 15.5ms\n",
            "Speed: 2.8ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b78dd814-b57822af.jpg: 384x640 5 cars, 1 traffic light, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7910b55-a1ab1901.jpg: 384x640 8 cars, 3 trucks, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b792daf1-52513869.jpg: 384x640 11 cars, 1 truck, 2 traffic lights, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▎       | 2351/10000 [01:15<04:17, 29.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b792daf1-e95167d2.jpg: 384x640 2 persons, 18 cars, 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79307e6-6cfc1c5b.jpg: 384x640 2 cars, 1 bus, 17.2ms\n",
            "Speed: 3.8ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7935597-0fb3bad7.jpg: 384x640 1 person, 10 cars, 1 truck, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▎       | 2354/10000 [01:15<04:37, 27.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7935597-13c4b9dd.jpg: 384x640 14 cars, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b797647c-5f2154db.jpg: 384x640 7 cars, 4 traffic lights, 15.5ms\n",
            "Speed: 3.5ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b797647c-674197dc.jpg: 384x640 6 cars, 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▎       | 2357/10000 [01:15<04:41, 27.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7979b09-89a5a8ea.jpg: 384x640 7 cars, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b797d23a-a415ce55.jpg: 384x640 11 cars, 13.4ms\n",
            "Speed: 5.0ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7984475-0a28901d.jpg: 384x640 2 cars, 1 bus, 1 train, 1 traffic light, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▎       | 2360/10000 [01:15<04:45, 26.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7993af5-b544c0da.jpg: 384x640 (no detections), 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79c1f8d-235c1229.jpg: 384x640 4 persons, 6 cars, 1 motorcycle, 1 traffic light, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79c1f8d-33e358e0.jpg: 384x640 3 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79c1f8d-8409e845.jpg: 384x640 1 person, 7 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▎       | 2364/10000 [01:15<04:23, 28.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79c1f8d-87a1881a.jpg: 384x640 6 persons, 1 car, 3 motorcycles, 1 bus, 1 truck, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79c1f8d-f34cbff5.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79d2bd8-b3eb6fa9.jpg: 384x640 1 car, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79d7247-1b5a4f2c.jpg: 384x640 7 cars, 1 bus, 2 trucks, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▎       | 2368/10000 [01:16<04:22, 29.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b79d7247-6750fc90.jpg: 384x640 4 cars, 1 bus, 1 truck, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a16331-0c817de1.jpg: 384x640 (no detections), 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a16331-728c61ea.jpg: 384x640 3 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a175e0-52e0bbc9.jpg: 384x640 (no detections), 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▎       | 2372/10000 [01:16<04:14, 29.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a175e0-ea597801.jpg: 384x640 2 cars, 19.6ms\n",
            "Speed: 1.9ms preprocess, 19.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a3fc87-1c0a396b.jpg: 384x640 2 cars, 16.2ms\n",
            "Speed: 3.5ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a43d54-9a0a14f5.jpg: 384x640 7 cars, 3 buss, 1 truck, 1 traffic light, 17.8ms\n",
            "Speed: 2.0ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2375/10000 [01:16<04:30, 28.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a8e795-056b3c79.jpg: 384x640 16 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a8e795-06d17ead.jpg: 384x640 22 cars, 1 truck, 18.5ms\n",
            "Speed: 1.9ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a8e795-06dce576.jpg: 384x640 12 cars, 3 traffic lights, 21.1ms\n",
            "Speed: 3.3ms preprocess, 21.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2378/10000 [01:16<05:22, 23.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a8e795-0ff55db2.jpg: 384x640 5 cars, 17.2ms\n",
            "Speed: 2.0ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a8e795-1e7e5390.jpg: 384x640 14 cars, 16.7ms\n",
            "Speed: 3.9ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a8e795-36cc1230.jpg: 384x640 11 cars, 1 truck, 3 traffic lights, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2381/10000 [01:16<05:36, 22.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a8e795-779e8c02.jpg: 384x640 3 persons, 7 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a8e795-ff80fddf.jpg: 384x640 2 persons, 12 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a97cb6-1d099495.jpg: 384x640 2 cars, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2384/10000 [01:16<05:22, 23.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a97cb6-a10ac1b2.jpg: 384x640 1 car, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a9b166-01d09e6b.jpg: 384x640 1 person, 12 cars, 2 trucks, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a9b166-176e18ae.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 9.8ms\n",
            "Speed: 1.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a9b166-341c551a.jpg: 384x640 10 cars, 1 train, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2388/10000 [01:16<04:52, 26.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a9b166-52309c81.jpg: 384x640 5 cars, 1 truck, 8.4ms\n",
            "Speed: 4.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a9b166-5c58b563.jpg: 384x640 7 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a9b166-7d9db10e.jpg: 384x640 3 cars, 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a9b166-a7b6abec.jpg: 384x640 11 cars, 1 bus, 1 truck, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2392/10000 [01:17<04:31, 27.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7a9b166-fd70d717.jpg: 384x640 2 cars, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7aa329e-25d68dec.jpg: 384x640 4 cars, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ab6225-743ee003.jpg: 384x640 7 cars, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ab6225-7a1edecd.jpg: 384x640 4 cars, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2396/10000 [01:17<04:11, 30.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7abfbea-3067ba7b.jpg: 384x640 1 person, 1 car, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ad4512-145bbccb.jpg: 384x640 9 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ad4512-5b2510d8.jpg: 384x640 1 person, 7 cars, 2 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ad4512-be6f5823.jpg: 384x640 10 cars, 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2400/10000 [01:17<04:07, 30.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ad967b-5ffacb53.jpg: 384x640 2 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ada391-dd104c12.jpg: 384x640 1 person, 1 car, 19.0ms\n",
            "Speed: 2.4ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b07700-7dd6ec37.jpg: 384x640 (no detections), 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b07700-ba279921.jpg: 384x640 1 car, 1 bus, 1 traffic light, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2404/10000 [01:17<04:17, 29.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b09a19-d9ce1598.jpg: 384x640 (no detections), 14.6ms\n",
            "Speed: 3.9ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b110ca-fac51d5b.jpg: 384x640 2 persons, 3 traffic lights, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b1242b-3c255af6.jpg: 384x640 2 cars, 15.7ms\n",
            "Speed: 4.2ms preprocess, 15.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2407/10000 [01:17<04:22, 28.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b132fc-12fe1b49.jpg: 384x640 1 person, 8 cars, 2 trucks, 17.2ms\n",
            "Speed: 2.0ms preprocess, 17.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b132fc-72617f81.jpg: 384x640 10 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b132fc-ba819254.jpg: 384x640 3 persons, 6 cars, 1 bus, 2 trucks, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2410/10000 [01:17<04:31, 27.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b1f657-c3290194.jpg: 384x640 8 cars, 1 bus, 1 traffic light, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b32a5f-87311a3a.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b32a5f-90bce6e1.jpg: 384x640 5 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b3a558-45775f2e.jpg: 384x640 3 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2414/10000 [01:17<04:13, 29.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b3a558-82db42a5.jpg: 384x640 1 traffic light, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b3a558-cacc0e78.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 4.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b3a558-f047b273.jpg: 384x640 2 cars, 1 bus, 2 traffic lights, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b554e4-753c2c08.jpg: 384x640 12 cars, 3 trucks, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2418/10000 [01:17<04:04, 30.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b58fcc-1ac3ea04.jpg: 384x640 6 cars, 1 truck, 4 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b7c088-13945e4c.jpg: 384x640 1 car, 14.3ms\n",
            "Speed: 1.8ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b7c088-2fda29df.jpg: 384x640 1 car, 1 bus, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7b89e71-e92f6983.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2422/10000 [01:18<04:03, 31.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ba2ed7-7f381040.jpg: 384x640 9 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ba8fee-e6a5e940.jpg: 384x640 2 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ba8fee-fcbd00e5.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ba9ad7-f89df072.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2426/10000 [01:18<03:46, 33.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb0d6e-0fa5f5ae.jpg: 384x640 1 car, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb0d6e-1922b34d.jpg: 384x640 6 cars, 1 traffic light, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb0d6e-19d84993.jpg: 384x640 2 persons, 7 cars, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb0d6e-552b4dd9.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb0d6e-87e194fd.jpg: 384x640 1 car, 15.1ms\n",
            "Speed: 1.8ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2431/10000 [01:18<03:37, 34.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb0d6e-b018e560.jpg: 384x640 2 cars, 15.2ms\n",
            "Speed: 5.9ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb37d8-95dcf32f.jpg: 384x640 2 cars, 1 train, 2 trucks, 14.8ms\n",
            "Speed: 3.9ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb37d8-c413361a.jpg: 384x640 2 cars, 15.4ms\n",
            "Speed: 3.8ms preprocess, 15.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb37d8-da8a74d7.jpg: 384x640 2 cars, 15.4ms\n",
            "Speed: 3.6ms preprocess, 15.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2435/10000 [01:18<03:58, 31.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bb64a4-885f7346.jpg: 384x640 8 cars, 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bbb1fe-1cec6316.jpg: 384x640 5 cars, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-17f66377.jpg: 384x640 10 cars, 6 traffic lights, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-3d51ea5e.jpg: 384x640 12 cars, 20.0ms\n",
            "Speed: 2.8ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2439/10000 [01:18<04:17, 29.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-6d53c833.jpg: 384x640 2 cars, 15.5ms\n",
            "Speed: 2.8ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-72df68f9.jpg: 384x640 10 cars, 1 bus, 1 truck, 1 traffic light, 8.4ms\n",
            "Speed: 3.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-7feae7dd.jpg: 384x640 1 car, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-8838a45e.jpg: 384x640 6 cars, 1 stop sign, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2443/10000 [01:18<04:16, 29.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-c3da43c8.jpg: 384x640 4 cars, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-cb639c92.jpg: 384x640 4 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bcc17a-cd0f0f68.jpg: 384x640 11 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bd8b85-9f43d43e.jpg: 384x640 1 car, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  24%|██▍       | 2447/10000 [01:18<04:00, 31.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7becb56-e97b2d91.jpg: 384x640 1 car, 1 traffic light, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bf181d-8a32731e.jpg: 384x640 8 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bfad97-89e3ef28.jpg: 384x640 4 persons, 12 cars, 1 traffic light, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bfad97-abd8ddef.jpg: 384x640 4 cars, 1 traffic light, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2451/10000 [01:18<04:10, 30.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7bfad97-d095e272.jpg: 384x640 1 person, 9 cars, 3 trucks, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c448a7-d2d6ae03.jpg: 384x640 8 cars, 1 traffic light, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c48676-355433ae.jpg: 384x640 1 person, 6 cars, 1 bus, 2 trucks, 8.1ms\n",
            "Speed: 6.0ms preprocess, 8.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c48676-79eba8a1.jpg: 384x640 4 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2455/10000 [01:19<04:08, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c48676-d61a6e81.jpg: 384x640 9 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c5b8ef-5c9960a8.jpg: 384x640 2 cars, 9.9ms\n",
            "Speed: 4.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c5b8ef-b233d513.jpg: 384x640 11 cars, 3 traffic lights, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c8c7f6-54290bbc.jpg: 384x640 3 cars, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2459/10000 [01:19<04:04, 30.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c8c7f6-899b3996.jpg: 384x640 3 cars, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7c91476-fe3e68ec.jpg: 384x640 4 cars, 1 traffic light, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7cf9504-dfc7bd99.jpg: 384x640 1 person, 5 cars, 3 traffic lights, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d13f97-0aec1868.jpg: 384x640 1 person, 1 car, 2 traffic lights, 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2463/10000 [01:19<04:14, 29.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d13f97-221ebf7b.jpg: 384x640 1 car, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d13f97-2952d459.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d13f97-3df013fa.jpg: 384x640 3 cars, 1 traffic light, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d13f97-55885a3b.jpg: 384x640 (no detections), 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2467/10000 [01:19<04:02, 31.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d13f97-74ae37ed.jpg: 384x640 1 person, 1 traffic light, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d13f97-9f4fcb90.jpg: 384x640 1 person, 4 traffic lights, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d277b3-26d83b90.jpg: 384x640 4 cars, 1 traffic light, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d277b3-a6f32171.jpg: 384x640 5 cars, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2471/10000 [01:19<03:57, 31.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d277b3-fc03ae80.jpg: 384x640 4 cars, 2 traffic lights, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d34a28-7404150e.jpg: 384x640 8 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d3916f-ab5b5296.jpg: 384x640 1 person, 12 cars, 10.3ms\n",
            "Speed: 4.5ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d46034-88afd89c.jpg: 384x640 2 persons, 4 cars, 3 traffic lights, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2475/10000 [01:19<04:01, 31.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d46034-cd47154f.jpg: 384x640 8 cars, 16.5ms\n",
            "Speed: 2.2ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d7713a-0ce4c8f1.jpg: 384x640 9 cars, 1 truck, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d7713a-a58eef67.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d7b438-7e499016.jpg: 384x640 4 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2479/10000 [01:19<04:02, 31.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d875e8-35d6222a.jpg: 384x640 2 persons, 5 cars, 1 traffic light, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d8cd90-a01c6422.jpg: 384x640 1 car, 1 truck, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7d9a95e-f9901594.jpg: 384x640 6 cars, 2 trucks, 3 traffic lights, 16.3ms\n",
            "Speed: 2.0ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7da46cc-c6b02c40.jpg: 384x640 5 cars, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2483/10000 [01:19<04:17, 29.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7db31d1-06d2afc1.jpg: 384x640 9 cars, 1 bus, 1 truck, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7db31d1-188d4a34.jpg: 384x640 18 cars, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7db31d1-7ccff061.jpg: 384x640 5 cars, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2486/10000 [01:20<04:17, 29.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7db31d1-fa13a84a.jpg: 384x640 17 cars, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7dbc526-68892204.jpg: 384x640 2 persons, 12 cars, 4 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7dbe50a-3738a448.jpg: 384x640 3 cars, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7dc9921-4c58cd1b.jpg: 384x640 7 cars, 2 traffic lights, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2490/10000 [01:20<04:16, 29.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7dc9921-8ae7e873.jpg: 384x640 3 cars, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7dc9921-b99688d2.jpg: 384x640 9 cars, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7dc9921-fcfe3332.jpg: 384x640 1 car, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7de4b01-2a16dfe7.jpg: 384x640 2 persons, 2 cars, 1 traffic light, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2494/10000 [01:20<04:02, 30.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7def2fa-8283e208.jpg: 384x640 1 person, 16 cars, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7df0c5f-293b7be6.jpg: 384x640 8 cars, 1 traffic light, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7df0c5f-654d495d.jpg: 384x640 7 cars, 1 traffic light, 14.9ms\n",
            "Speed: 4.2ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7e1237b-25dec3f7.jpg: 384x640 11 cars, 16.1ms\n",
            "Speed: 2.5ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▍       | 2498/10000 [01:20<04:27, 28.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7e1237b-876a427c.jpg: 384x640 (no detections), 20.6ms\n",
            "Speed: 3.9ms preprocess, 20.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7e1237b-f08b7c08.jpg: 384x640 13 persons, 3 cars, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7e17f40-859096c9.jpg: 384x640 1 car, 4 traffic lights, 20.8ms\n",
            "Speed: 6.6ms preprocess, 20.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2501/10000 [01:20<04:38, 26.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7e347d4-8ab9f4b5.jpg: 384x640 15 cars, 18.5ms\n",
            "Speed: 1.9ms preprocess, 18.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7e68039-9ea5f87c.jpg: 384x640 17 cars, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7e8932c-3f90dbfc.jpg: 384x640 9 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7e98aaf-df117cd8.jpg: 384x640 9 cars, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2505/10000 [01:20<04:30, 27.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ea55c1-8385ec70.jpg: 384x640 1 person, 3 cars, 2 trucks, 13.3ms\n",
            "Speed: 3.5ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7eb6c3d-e1598570.jpg: 384x640 6 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7eb7b11-2ba05f4f.jpg: 384x640 1 person, 22 cars, 1 truck, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2508/10000 [01:20<04:36, 27.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ec8e2f-b673fc33.jpg: 384x640 1 person, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ec9c7e-816b5937.jpg: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ec9c7e-cfdf4a45.jpg: 384x640 2 persons, 4 cars, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7edcfdc-f018989f.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2512/10000 [01:21<04:12, 29.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7f1241e-05749fee.jpg: 384x640 2 cars, 2 traffic lights, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7f1241e-1f691c01.jpg: 384x640 1 car, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7f1241e-de8783e8.jpg: 384x640 8 cars, 2 traffic lights, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7f136f3-1a77da25.jpg: 384x640 6 persons, 2 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2516/10000 [01:21<04:00, 31.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7f43f41-b1354d92.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7f452e4-1e5669ab.jpg: 384x640 1 bicycle, 6 cars, 1 motorcycle, 1 traffic light, 1 umbrella, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7f452e4-1e8b6f3a.jpg: 384x640 1 car, 1 bus, 1 truck, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7f75fad-1c1c419b.jpg: 384x640 2 cars, 14.8ms\n",
            "Speed: 4.3ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2520/10000 [01:21<03:56, 31.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fbffdb-62f685ff.jpg: 384x640 1 person, 7 cars, 2 trucks, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fbffdb-7dd0268d.jpg: 384x640 3 persons, 1 car, 2 trucks, 2 traffic lights, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fbffdb-e6bc2ef1.jpg: 384x640 4 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fc572c-6a4b1de5.jpg: 384x640 5 cars, 2 buss, 12.8ms\n",
            "Speed: 3.5ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2524/10000 [01:21<04:01, 30.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fc572c-aff1b54d.jpg: 384x640 1 person, 7 cars, 14.3ms\n",
            "Speed: 3.5ms preprocess, 14.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fc572c-d84b9bc6.jpg: 384x640 4 persons, 5 cars, 1 truck, 2 traffic lights, 22.8ms\n",
            "Speed: 1.8ms preprocess, 22.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fc572c-f8a3e313.jpg: 384x640 2 persons, 1 car, 1 motorcycle, 18.1ms\n",
            "Speed: 3.7ms preprocess, 18.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fc87bf-8ac3359e.jpg: 384x640 1 airplane, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2528/10000 [01:21<04:15, 29.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fcda2b-05f3fc09.jpg: 384x640 2 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fcda2b-2e4d36ef.jpg: 384x640 2 persons, 10 cars, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd2970-d748193c.jpg: 384x640 13 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd2970-e46faf78.jpg: 384x640 9 cars, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2532/10000 [01:21<04:04, 30.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd2c7d-1c250dfc.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd3f86-2750b2d7.jpg: 384x640 3 cars, 1 bus, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd3f86-3536dfed.jpg: 384x640 1 person, 2 cars, 1 truck, 2 traffic lights, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd3f86-4716e687.jpg: 384x640 2 cars, 1 truck, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd3f86-5366a23c.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2537/10000 [01:21<03:42, 33.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd3f86-ba8bf79c.jpg: 384x640 5 cars, 1 traffic light, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fd3f86-c4f5da2e.jpg: 384x640 2 persons, 11 cars, 1 bus, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7fe6285-5f64b006.jpg: 384x640 4 cars, 9.8ms\n",
            "Speed: 1.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b7ff9d09-5bef519f.jpg: 384x640 6 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2541/10000 [01:21<03:37, 34.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b80018ef-3a620af0.jpg: 384x640 6 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8015ebc-0445a4e2.jpg: 384x640 10 cars, 1 truck, 11.6ms\n",
            "Speed: 1.7ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8025b43-80a46fe5.jpg: 384x640 4 cars, 12.5ms\n",
            "Speed: 4.0ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8025b43-db6cdd13.jpg: 384x640 7 cars, 2 trucks, 1 traffic light, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2545/10000 [01:22<03:47, 32.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8026c7f-d0cb54f3.jpg: 384x640 2 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b803d91d-10ed2f67.jpg: 384x640 3 cars, 1 bus, 2 trucks, 13.0ms\n",
            "Speed: 4.1ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b803d91d-17b149ce.jpg: 384x640 5 persons, 6 cars, 2 traffic lights, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b803d91d-64200a2d.jpg: 384x640 6 persons, 5 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  25%|██▌       | 2549/10000 [01:22<04:00, 30.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b803d91d-6687e7f0.jpg: 384x640 2 persons, 1 bicycle, 10 cars, 1 bus, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b803d91d-671b8cff.jpg: 384x640 1 person, 2 trucks, 16.1ms\n",
            "Speed: 2.0ms preprocess, 16.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b803d91d-e65a9c14.jpg: 384x640 1 person, 7 cars, 2 trucks, 16.8ms\n",
            "Speed: 2.0ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b803d91d-ff86709c.jpg: 384x640 1 person, 9 cars, 1 truck, 15.0ms\n",
            "Speed: 2.6ms preprocess, 15.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2553/10000 [01:22<04:19, 28.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b804f988-233a12a1.jpg: 384x640 1 car, 1 traffic light, 14.9ms\n",
            "Speed: 2.6ms preprocess, 14.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b804f988-6eff91ef.jpg: 384x640 1 person, 2 cars, 1 bus, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b804f988-eb510a9a.jpg: 384x640 2 trucks, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8086e12-1f7655aa.jpg: 384x640 14 cars, 1 truck, 14.9ms\n",
            "Speed: 2.6ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2557/10000 [01:22<04:15, 29.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8086e12-68a9bab2.jpg: 384x640 4 persons, 6 cars, 1 truck, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8086e12-c35af994.jpg: 384x640 1 person, 10 cars, 2 traffic lights, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8086e12-d6b50340.jpg: 384x640 6 cars, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2560/10000 [01:22<04:17, 28.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b80b91c9-527a346a.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b80b91c9-9a644aba.jpg: 384x640 2 cars, 2 trucks, 1 traffic light, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b80ccebf-3de2a87d.jpg: 384x640 1 car, 1 traffic light, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b80fb9b6-b12f0c90.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2564/10000 [01:22<03:59, 31.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8125aef-74d00aed.jpg: 384x640 1 person, 2 cars, 1 truck, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8125aef-ae843995.jpg: 384x640 1 person, 13 cars, 1 truck, 3 traffic lights, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b81771ca-32f6b949.jpg: 384x640 1 car, 2 tvs, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b817df43-48a371e7.jpg: 384x640 6 persons, 3 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2568/10000 [01:22<03:55, 31.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b818033e-1407617c.jpg: 384x640 9 cars, 1 truck, 3 traffic lights, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b818033e-482dae8c.jpg: 384x640 18 cars, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b818033e-87034df2.jpg: 384x640 1 person, 2 cars, 1 truck, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b818033e-f4657ed3.jpg: 384x640 5 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2572/10000 [01:22<03:57, 31.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b81b8523-024d30e0.jpg: 384x640 8 cars, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b81b8523-57ccb331.jpg: 384x640 3 cars, 11.8ms\n",
            "Speed: 4.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b81b8523-9ca9cab9.jpg: 384x640 1 person, 2 cars, 2 buss, 1 truck, 11.6ms\n",
            "Speed: 3.9ms preprocess, 11.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b81c68cc-cdcfdff5.jpg: 384x640 3 cars, 1 truck, 1 stop sign, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2576/10000 [01:23<03:58, 31.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b81d060a-b2203c99.jpg: 384x640 10 cars, 1 bus, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b81d060a-fddedd4f.jpg: 384x640 6 cars, 1 fire hydrant, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8201476-b9dba8dd.jpg: 384x640 10 cars, 2 trucks, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b821ab2e-089c3379.jpg: 384x640 4 cars, 1 truck, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2580/10000 [01:23<04:04, 30.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8222542-d055faeb.jpg: 384x640 8 cars, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82366c4-3fb8da58.jpg: 384x640 1 person, 7 cars, 2 buss, 1 truck, 2 traffic lights, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b825dfb7-442f3c75.jpg: 384x640 1 person, 4 cars, 1 train, 1 truck, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82609d8-eef37c99.jpg: 384x640 7 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2584/10000 [01:23<03:57, 31.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82ad485-481e148c.jpg: 384x640 1 bus, 3 traffic lights, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82b19c9-17011ac5.jpg: 384x640 7 cars, 2 trucks, 4 traffic lights, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82b19c9-929701e6.jpg: 384x640 7 cars, 1 traffic light, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82cf799-a135768f.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2588/10000 [01:23<03:54, 31.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82e22f1-40b5aa11.jpg: 384x640 4 cars, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82f7901-62715883.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82f7901-6d67cfe8.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82f91d7-7c84fdc5.jpg: 384x640 2 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2592/10000 [01:23<03:39, 33.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82f91d7-808670c6.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82f91d7-a21bb033.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b82f91d7-bfddb3c7.jpg: 384x640 4 cars, 1 truck, 4 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b830e68f-29ab7518.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8322a8e-438f9ef0.jpg: 384x640 4 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2597/10000 [01:23<03:26, 35.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83235c2-32416553.jpg: 384x640 4 persons, 5 cars, 3 traffic lights, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b832508c-8f2be0ee.jpg: 384x640 4 persons, 2 cars, 1 traffic light, 1 umbrella, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b832634b-1a0dc8b0.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b832634b-be31b364.jpg: 384x640 6 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2601/10000 [01:23<03:24, 36.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b834f9a4-5a72945a.jpg: 384x640 12 cars, 1 bus, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b836b14a-fb13c905.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b836ef61-1a8aa776.jpg: 384x640 2 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83869a3-3023291d.jpg: 384x640 2 cars, 1 stop sign, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83869a3-7fc42be5.jpg: 384x640 2 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2606/10000 [01:23<03:17, 37.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b839982e-68902593.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83a044e-2926e767.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83a044e-9b529b91.jpg: 384x640 8 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83b8572-29d97c92.jpg: 384x640 7 cars, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2610/10000 [01:24<03:16, 37.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83d28bd-a9ab3f1d.jpg: 384x640 2 persons, 10 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83d7cf3-4e193818.jpg: 384x640 1 person, 5 cars, 1 truck, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83e4275-fe67ecbd.jpg: 384x640 3 cars, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83e94b9-fc9ee1c7.jpg: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2614/10000 [01:24<03:15, 37.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83ec6be-8147e6f9.jpg: 384x640 4 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83ec6be-953a634b.jpg: 384x640 4 cars, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83ec6be-c9cddfb2.jpg: 384x640 7 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b83ec6be-edf04b3c.jpg: 384x640 3 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2618/10000 [01:24<03:14, 37.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8407cb8-71fdf808.jpg: 384x640 4 cars, 15.4ms\n",
            "Speed: 3.7ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b841106c-4b71146c.jpg: 384x640 2 cars, 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b841230d-fada32c4.jpg: 384x640 3 cars, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84146a1-a5f588ef.jpg: 384x640 8 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▌       | 2622/10000 [01:24<03:30, 35.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b842809b-8900f4f0.jpg: 384x640 1 car, 2 traffic lights, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b842809b-9b11bab7.jpg: 384x640 1 car, 1 traffic light, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b842809b-ae95b9bc.jpg: 384x640 4 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b842809b-d8519a33.jpg: 384x640 2 traffic lights, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▋       | 2626/10000 [01:24<03:27, 35.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b842dbf5-4b5b09b7.jpg: 384x640 1 person, 4 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84371bc-170edf5a.jpg: 384x640 1 person, 3 cars, 1 bus, 1 traffic light, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b843ef1b-2756a85d.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b843ef1b-f173bd21.jpg: 384x640 7 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▋       | 2630/10000 [01:24<03:30, 35.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84507e4-4f69e97b.jpg: 384x640 3 cars, 2 traffic lights, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84507e4-7ba43134.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84507e4-868d08d2.jpg: 384x640 5 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84507e4-e4553a8d.jpg: 384x640 1 car, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▋       | 2634/10000 [01:24<03:28, 35.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84a1117-338ddf33.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84a1117-3673ce8a.jpg: 384x640 6 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84a1117-72c360e2.jpg: 384x640 4 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84ba7d0-583269f1.jpg: 384x640 8 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▋       | 2638/10000 [01:24<03:21, 36.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84d51df-7094c862.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84da41b-2d3fce12.jpg: 384x640 1 person, 2 cars, 2 trucks, 1 stop sign, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84da41b-fe80f694.jpg: 384x640 1 person, 2 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84dbc8e-94bbc315.jpg: 384x640 3 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▋       | 2642/10000 [01:24<03:17, 37.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84eef86-eb4bb6e0.jpg: 384x640 4 persons, 4 bicycles, 1 car, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84f4f83-30ec3e22.jpg: 384x640 2 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b84f4f83-c6842bd6.jpg: 384x640 9 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b851c0af-630d8381.jpg: 384x640 4 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  26%|██▋       | 2646/10000 [01:24<03:14, 37.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b851c0af-7345afd1.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b851f39f-b965b196.jpg: 384x640 4 persons, 2 cars, 1 stop sign, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b851f39f-d8f42807.jpg: 384x640 1 car, 2 trucks, 2 traffic lights, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85420e2-ea146a8a.jpg: 384x640 4 cars, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b855a117-5b67fec3.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2651/10000 [01:25<03:11, 38.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b857eb06-2a0d9098.jpg: 384x640 5 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b857eb06-3c8b7034.jpg: 384x640 10 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b857eb06-434af6c0.jpg: 384x640 10 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b857eb06-4601a3a0.jpg: 384x640 20 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2655/10000 [01:25<03:21, 36.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b857eb06-7ec70e8b.jpg: 384x640 3 cars, 19.2ms\n",
            "Speed: 2.7ms preprocess, 19.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b857eb06-9698b02c.jpg: 384x640 4 cars, 1 truck, 10.5ms\n",
            "Speed: 2.7ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b857eb06-a85b37f5.jpg: 384x640 9 cars, 3 traffic lights, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b857eb06-ef3987ae.jpg: 384x640 5 cars, 1 truck, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2659/10000 [01:25<03:40, 33.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8588ac6-afc0184a.jpg: 384x640 14 cars, 1 bus, 1 truck, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85a3ec7-4296bad6.jpg: 384x640 8 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85b0853-e2b7537e.jpg: 384x640 3 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85b0853-ea43f17c.jpg: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2663/10000 [01:25<03:43, 32.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85ba05d-90605ae4.jpg: 384x640 2 tvs, 1 laptop, 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85d7504-1eef8eea.jpg: 384x640 2 cars, 12.2ms\n",
            "Speed: 4.1ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85eb331-920d81fe.jpg: 384x640 1 person, 4 cars, 16.4ms\n",
            "Speed: 3.4ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85f5cc9-44db10f1.jpg: 384x640 3 persons, 2 cars, 1 truck, 2 traffic lights, 1 fire hydrant, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2667/10000 [01:25<03:50, 31.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b85fb98d-41e7213c.jpg: 384x640 6 cars, 1 truck, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b86294f6-781fa55d.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b863bd5e-d1ff4b7c.jpg: 384x640 4 cars, 1 truck, 2 traffic lights, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b86413b9-35499361.jpg: 384x640 3 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2671/10000 [01:25<03:41, 33.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b86413b9-c5b79892.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8649bc8-519bbee6.jpg: 384x640 4 cars, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8677b56-9edba15a.jpg: 384x640 5 cars, 1 truck, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8685330-d275b328.jpg: 384x640 1 person, 4 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2675/10000 [01:25<03:37, 33.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8697036-9589cddf.jpg: 384x640 4 persons, 5 cars, 1 traffic light, 1 skateboard, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b869965a-5dbee4b1.jpg: 384x640 5 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b869965a-88ad8b77.jpg: 384x640 1 person, 2 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b869965a-f5ff417c.jpg: 384x640 2 cars, 2 trucks, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2679/10000 [01:25<03:40, 33.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b869965a-fa59f431.jpg: 384x640 3 cars, 1 bus, 1 truck, 13.7ms\n",
            "Speed: 5.8ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b86a2705-bf3761b9.jpg: 384x640 1 bus, 1 traffic light, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b86aaaf8-2496c37d.jpg: 384x640 3 cars, 2 traffic lights, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b86ab068-8556a229.jpg: 384x640 2 cars, 2 trucks, 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2683/10000 [01:26<03:42, 32.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b86f9b95-e4651840.jpg: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b86fc3d9-021f0bb5.jpg: 384x640 11 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b871e00c-825caf56.jpg: 384x640 7 cars, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87299bf-d30f284c.jpg: 384x640 9 cars, 2 trucks, 20.0ms\n",
            "Speed: 2.0ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2687/10000 [01:26<03:48, 31.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87366af-3fb3389e.jpg: 384x640 12 cars, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b873b095-4530040c.jpg: 384x640 1 person, 3 cars, 1 truck, 14.9ms\n",
            "Speed: 3.6ms preprocess, 14.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b873c993-1d508f5a.jpg: 384x640 6 persons, 4 cars, 1 bus, 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b873c993-69e9f8fb.jpg: 384x640 4 persons, 5 cars, 19.8ms\n",
            "Speed: 2.0ms preprocess, 19.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2691/10000 [01:26<04:09, 29.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b875ad93-deec14af.jpg: 384x640 5 cars, 1 truck, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b875ad93-f21a6d0a.jpg: 384x640 2 cars, 2 trucks, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b877b18a-52e00f70.jpg: 384x640 (no detections), 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8781f69-76c72b31.jpg: 384x640 10 cars, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2695/10000 [01:26<04:04, 29.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8781f69-81bcdb6a.jpg: 384x640 1 person, 1 bicycle, 3 cars, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87a03a9-1ddfba47.jpg: 384x640 1 person, 4 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87a03a9-c9da2b1a.jpg: 384x640 3 persons, 3 cars, 15.9ms\n",
            "Speed: 2.1ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87a5067-734a1f45.jpg: 384x640 6 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2699/10000 [01:26<04:07, 29.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87b8504-1e1d6dcd.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87b8bce-987990d0.jpg: 384x640 3 cars, 5 traffic lights, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87b8bce-d9f8e55e.jpg: 384x640 2 traffic lights, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2702/10000 [01:26<04:06, 29.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87bd38d-55fd58cd.jpg: 384x640 4 cars, 1 traffic light, 15.6ms\n",
            "Speed: 4.1ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87bd38d-9f7f07c3.jpg: 384x640 4 cars, 1 traffic light, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87ca2c5-47ae44e3.jpg: 384x640 9 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2705/10000 [01:26<04:09, 29.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87ca2c5-c3c18e68.jpg: 384x640 2 persons, 3 cars, 4 trucks, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87ca2c5-c3c6e7ce.jpg: 384x640 10 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87d3733-161f6a8f.jpg: 384x640 3 cars, 1 truck, 2 traffic lights, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87d3733-83cb66cc.jpg: 384x640 1 person, 6 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2709/10000 [01:27<04:06, 29.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87e8d90-a0917f70.jpg: 384x640 3 persons, 2 cars, 2 traffic lights, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87ee3bb-1242c008.jpg: 384x640 5 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87ee3bb-be0b1bb6.jpg: 384x640 1 person, 3 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87ee3bb-c5b70e4f.jpg: 384x640 3 cars, 3 traffic lights, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2713/10000 [01:27<03:55, 30.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87fb508-f8374c1f.jpg: 384x640 5 cars, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b87fe215-0f7b05e0.jpg: 384x640 4 persons, 5 cars, 1 truck, 1 traffic light, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b88522ea-e38b4bec.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8854854-756c468f.jpg: 384x640 3 persons, 12 cars, 3 traffic lights, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2717/10000 [01:27<03:48, 31.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b886a0b8-cb75e3a6.jpg: 384x640 2 cars, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b888e048-8018b284.jpg: 384x640 7 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b888e048-80f768fc.jpg: 384x640 13 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b88a00df-65e5355b.jpg: 384x640 1 person, 4 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2721/10000 [01:27<03:50, 31.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b88a00df-b4d6d3d8.jpg: 384x640 4 cars, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b88a00df-e8484d02.jpg: 384x640 2 persons, 4 cars, 1 bus, 1 traffic light, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b88b6624-3b54ae18.jpg: 384x640 6 cars, 1 bus, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b88b6624-e1aabf99.jpg: 384x640 8 cars, 1 truck, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2725/10000 [01:27<03:43, 32.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b892f130-8828257e.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b892f130-90ed9d1f.jpg: 384x640 1 car, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b893983a-265a0b70.jpg: 384x640 6 cars, 1 fire hydrant, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b893983a-c10ac3c6.jpg: 384x640 9 persons, 1 bicycle, 5 cars, 1 truck, 2 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2729/10000 [01:27<03:40, 32.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89581ec-5a14165f.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89581ec-e0ee3038.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b896b680-ce014e4d.jpg: 384x640 1 person, 9 cars, 1 motorcycle, 1 truck, 9.2ms\n",
            "Speed: 3.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89886bb-e171a804.jpg: 384x640 4 cars, 2 trucks, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2733/10000 [01:27<03:33, 34.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89886bb-f019c7eb.jpg: 384x640 (no detections), 8.1ms\n",
            "Speed: 2.8ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b898a22f-d6bcd9d3.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89981b7-bdacced7.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89aded3-23603d87.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2737/10000 [01:27<03:25, 35.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89aded3-532a51a7.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89aded3-c4e4fb25.jpg: 384x640 8 cars, 1 traffic light, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89bf84d-04301b8b.jpg: 384x640 8 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89bf84d-046670ed.jpg: 384x640 12 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2741/10000 [01:27<03:26, 35.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89bf84d-280b87dd.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89bf84d-75cc37b6.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b89bf84d-d2c2e5a7.jpg: 384x640 10 cars, 4 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a135c9-3cbeb1c8.jpg: 384x640 6 cars, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2745/10000 [01:28<03:22, 35.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a135c9-434a126d.jpg: 384x640 12 cars, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a135c9-8c38e7ba.jpg: 384x640 13 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a135c9-d4ff358a.jpg: 384x640 1 person, 9 cars, 1 traffic light, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a158fd-1e9c1bd7.jpg: 384x640 2 cars, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  27%|██▋       | 2749/10000 [01:28<03:32, 34.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a158fd-a1917370.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a1bed9-da501372.jpg: 384x640 3 cars, 1 train, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a28c17-05487707.jpg: 384x640 1 car, 4 traffic lights, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a28c17-3dcc2922.jpg: 384x640 2 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2753/10000 [01:28<03:35, 33.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a28c17-5befd35a.jpg: 384x640 1 car, 1 bus, 1 traffic light, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a52657-426c14ae.jpg: 384x640 9 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a52657-64748163.jpg: 384x640 2 cars, 2 traffic lights, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a52657-f74f7fd0.jpg: 384x640 6 cars, 1 traffic light, 15.4ms\n",
            "Speed: 3.8ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2757/10000 [01:28<03:45, 32.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a795ee-21cbb3d1.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a795ee-b1680470.jpg: 384x640 2 cars, 4 traffic lights, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a795ee-c1ce7ac0.jpg: 384x640 12 cars, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a835db-34608613.jpg: 384x640 10 cars, 1 traffic light, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2761/10000 [01:28<03:53, 31.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a835db-a66cff4d.jpg: 384x640 4 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a835db-b2b7aed0.jpg: 384x640 7 cars, 1 traffic light, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a835db-c49dfee5.jpg: 384x640 16 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8a9d382-3bd7d3e4.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2765/10000 [01:28<03:49, 31.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ab4367-297944fb.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8acc534-23eb2531.jpg: 384x640 1 car, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8acc534-d5b64200.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8adc715-5a335a7e.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ae99b0-c70e5800.jpg: 384x640 6 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2770/10000 [01:28<03:33, 33.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8af5bc3-97aa5976.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8afaffa-21f32286.jpg: 384x640 2 persons, 2 cars, 1 bus, 2 trucks, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8afaffa-5ec67bbb.jpg: 384x640 4 cars, 3 trucks, 3 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8affcd1-29901d90.jpg: 384x640 1 car, 1 boat, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2774/10000 [01:28<03:24, 35.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8affcd1-b2781fa1.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b03ee1-9444cbd8.jpg: 384x640 14 cars, 4 traffic lights, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b0554a-35795cdf.jpg: 384x640 7 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b0554a-ecca669e.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2778/10000 [01:29<03:26, 34.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b06f77-5b618032.jpg: 384x640 5 persons, 4 cars, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b15e54-2ccd7fd0.jpg: 384x640 3 persons, 1 bicycle, 13 cars, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b15e54-4c278512.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b15e54-f8461121.jpg: 384x640 5 cars, 1 bus, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2782/10000 [01:29<03:25, 35.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b18469-00a140bf.jpg: 384x640 10 cars, 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b18469-55e564e3.jpg: 384x640 3 cars, 3 trucks, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b2be1e-3a26a65d.jpg: 384x640 10 cars, 1 truck, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b2be1e-4c0bf0b9.jpg: 384x640 7 cars, 1 traffic light, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2786/10000 [01:29<03:30, 34.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b2be1e-e42d11d8.jpg: 384x640 2 persons, 10 cars, 1 truck, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b3e840-06f018d3.jpg: 384x640 1 person, 17 cars, 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b4115a-19b5976e.jpg: 384x640 1 car, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b4115a-ea1a60b6.jpg: 384x640 7 cars, 1 truck, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2790/10000 [01:29<03:39, 32.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b69c99-e0c0b8bb.jpg: 384x640 6 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b84774-309883b2.jpg: 384x640 6 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b84774-58b7527d.jpg: 384x640 6 cars, 1 traffic light, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b84774-c0740817.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2794/10000 [01:29<03:33, 33.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b9ffae-042b50eb.jpg: 384x640 13 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8b9ffae-d3cb2bbd.jpg: 384x640 12 cars, 1 bus, 1 truck, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8bb2022-164d8e4f.jpg: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8bb2022-6ef7291e.jpg: 384x640 1 person, 3 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2798/10000 [01:29<03:29, 34.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8bb2022-f22d2908.jpg: 384x640 1 car, 1 train, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8bf322e-36122f48.jpg: 384x640 10 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c0457f-3c7b553c.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c0457f-d7a1d2b7.jpg: 384x640 4 cars, 1 traffic light, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2802/10000 [01:29<03:22, 35.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c0457f-fa2eacb4.jpg: 384x640 1 person, 4 cars, 1 truck, 4 traffic lights, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c0d4a5-0b8ec726.jpg: 384x640 6 cars, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c0d4a5-63b97dfb.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c0d4a5-e8d3393a.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2806/10000 [01:29<03:16, 36.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c1f257-22c2b2cc.jpg: 384x640 1 person, 3 cars, 1 bench, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c1f257-b16e7b78.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c21306-2ef89045.jpg: 384x640 8 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c21917-b001727c.jpg: 384x640 2 persons, 5 cars, 1 truck, 5 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2810/10000 [01:29<03:18, 36.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c2c8e8-bfe9cb41.jpg: 384x640 2 persons, 3 cars, 1 train, 5 traffic lights, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c3f870-c6c86746.jpg: 384x640 10 cars, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c3f870-d6a887c8.jpg: 384x640 2 cars, 2 trucks, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c3f870-db0f236f.jpg: 384x640 7 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2814/10000 [01:30<03:19, 36.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c3f870-e1c1bd34.jpg: 384x640 10 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c60cba-d52cfc92.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c66e31-37045eec.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c7c957-84df8251.jpg: 384x640 6 cars, 1 bus, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2818/10000 [01:30<03:17, 36.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c7c957-b05e784c.jpg: 384x640 3 cars, 1 truck, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8c95e55-7cc3b9b1.jpg: 384x640 (no detections), 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ca6c5d-22de751a.jpg: 384x640 6 cars, 2 trucks, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8cca913-a59e1a1b.jpg: 384x640 2 persons, 1 car, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2822/10000 [01:30<03:18, 36.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8cd6a1b-84ae1442.jpg: 384x640 2 cars, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8cd6a1b-8abed2d8.jpg: 384x640 6 cars, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ce5e42-34aa3275.jpg: 384x640 9 cars, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8cf7112-d0f7365c.jpg: 384x640 (no detections), 17.5ms\n",
            "Speed: 3.0ms preprocess, 17.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2826/10000 [01:30<03:24, 35.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8cff548-cc30b88a.jpg: 384x640 4 cars, 1 bus, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8d24edf-3349ee71.jpg: 384x640 12 cars, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8d24edf-51edf6f2.jpg: 384x640 6 cars, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8d24edf-70279ee0.jpg: 384x640 2 cars, 1 truck, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2830/10000 [01:30<03:30, 34.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8d26b85-e5941e4b.jpg: 384x640 (no detections), 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8d6eb5f-c1f21fe4.jpg: 384x640 3 persons, 1 car, 1 bus, 2 traffic lights, 21.8ms\n",
            "Speed: 1.8ms preprocess, 21.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8da2353-3f632c8a.jpg: 384x640 3 cars, 14.7ms\n",
            "Speed: 8.0ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8da2353-61f13dfb.jpg: 384x640 3 cars, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2834/10000 [01:30<03:51, 30.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8dce66a-004c2b9d.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8e06f7a-f11a9604.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8e2eae6-9b3f3a2f.jpg: 384x640 3 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8e638c5-c29e3eba.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2838/10000 [01:30<03:39, 32.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8e63e55-1b48cdef.jpg: 384x640 4 cars, 1 bus, 1 truck, 1 traffic light, 13.3ms\n",
            "Speed: 1.7ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8e63e55-369d821c.jpg: 384x640 4 persons, 7 cars, 3 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8e675b0-2345da2d.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8e675b0-b18c870f.jpg: 384x640 15 cars, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2842/10000 [01:30<03:38, 32.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8e675b0-eeb01556.jpg: 384x640 5 cars, 3 trucks, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ecdc10-763b27b8.jpg: 384x640 8 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ecdc10-e0148c98.jpg: 384x640 12 cars, 2 trucks, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ee7220-99de1efc.jpg: 384x640 15 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2846/10000 [01:31<03:34, 33.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ee7220-b9b59d51.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ee7220-ee251c9a.jpg: 384x640 6 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ef1613-c936238e.jpg: 384x640 8 cars, 1 truck, 1 traffic light, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8ef1613-cabb90be.jpg: 384x640 1 person, 9 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  28%|██▊       | 2850/10000 [01:31<03:27, 34.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8efe857-6eb8e35f.jpg: 384x640 6 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8efe857-90dec33b.jpg: 384x640 1 person, 2 cars, 1 traffic light, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f0315c-0fb7602c.jpg: 384x640 6 cars, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f0315c-2506aedf.jpg: 384x640 7 cars, 1 truck, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▊       | 2854/10000 [01:31<03:24, 34.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f0315c-6d83432c.jpg: 384x640 1 person, 6 cars, 2 traffic lights, 1 backpack, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f0b141-c00fd8b4.jpg: 384x640 11 cars, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f2d63d-22dbb72d.jpg: 384x640 7 cars, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f2d63d-6a944fa4.jpg: 384x640 1 car, 1 bus, 1 truck, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▊       | 2858/10000 [01:31<03:32, 33.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f2d63d-6aac4195.jpg: 384x640 3 cars, 1 truck, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f2d63d-9a3923f7.jpg: 384x640 12 cars, 1 traffic light, 1 fire hydrant, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f44a4f-c3682a11.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f5912b-5dd97fdd.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▊       | 2862/10000 [01:31<03:30, 33.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f5cc6a-32756cda.jpg: 384x640 1 person, 6 cars, 3 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f63f02-014464f6.jpg: 384x640 4 persons, 9 cars, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f63f02-c999a811.jpg: 384x640 8 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f63f02-f3d4d3ef.jpg: 384x640 10 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▊       | 2866/10000 [01:31<03:28, 34.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f63f02-f5b555a9.jpg: 384x640 9 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f63f02-f78a7452.jpg: 384x640 3 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f65e48-10600b5e.jpg: 384x640 1 person, 7 cars, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f65e48-96ce1959.jpg: 384x640 6 persons, 1 bicycle, 3 cars, 2 buss, 1 truck, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▊       | 2870/10000 [01:31<03:33, 33.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8f781de-a5f9cdfa.jpg: 384x640 10 cars, 4 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8fa884b-5cad0e15.jpg: 384x640 2 persons, 5 cars, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8fb5451-6c0e5ec6.jpg: 384x640 11 cars, 1 bus, 2 trucks, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8fcdf93-4aac8105.jpg: 384x640 5 cars, 3 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▊       | 2874/10000 [01:31<03:38, 32.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8fe1054-42625c45.jpg: 384x640 8 cars, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8fe9f2b-012851c9.jpg: 384x640 6 persons, 4 cars, 3 trucks, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8fe9f2b-270e73a0.jpg: 384x640 4 persons, 2 cars, 1 bus, 1 truck, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b8fe9f2b-d63131a3.jpg: 384x640 9 cars, 1 bus, 3 trucks, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2878/10000 [01:31<03:37, 32.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9012b42-ba320de2.jpg: 384x640 6 cars, 1 bus, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b901a3e5-7ca95a7c.jpg: 384x640 8 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90327ce-1fd6eed8.jpg: 384x640 5 cars, 1 bus, 2 trucks, 1 fire hydrant, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90327ce-86c1d1f4.jpg: 384x640 2 cars, 1 bus, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90327ce-8bdda545.jpg: 384x640 8 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2883/10000 [01:32<03:23, 34.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9047aca-4064a447.jpg: 384x640 10 cars, 1 bus, 1 truck, 2 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9047aca-41787983.jpg: 384x640 1 person, 3 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9054a76-5266134b.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9079f4e-13bafb7b.jpg: 384x640 1 car, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2887/10000 [01:32<03:16, 36.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b907b620-74e79e9c.jpg: 384x640 5 cars, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9087534-f5d49005.jpg: 384x640 3 traffic lights, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9094f83-df5b86f1.jpg: 384x640 13 cars, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9097b2d-0eb8ce24.jpg: 384x640 6 cars, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2891/10000 [01:32<03:28, 34.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b909a526-1971fba7.jpg: 384x640 5 cars, 19.3ms\n",
            "Speed: 1.8ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b909df8f-51c5470e.jpg: 384x640 5 cars, 1 truck, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90a1ed5-653861b3.jpg: 384x640 6 cars, 2 trucks, 16.4ms\n",
            "Speed: 3.2ms preprocess, 16.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90b45ad-a54b1fbf.jpg: 384x640 2 cars, 2 traffic lights, 17.5ms\n",
            "Speed: 3.3ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2895/10000 [01:32<03:51, 30.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90bcbaa-99b962db.jpg: 384x640 6 cars, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90bcbaa-d26f06dc.jpg: 384x640 4 cars, 1 traffic light, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90ca71f-3cf69251.jpg: 384x640 1 person, 7 cars, 4 trucks, 1 traffic light, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90cbc2c-4f9a1c58.jpg: 384x640 1 car, 17.3ms\n",
            "Speed: 3.2ms preprocess, 17.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2899/10000 [01:32<04:14, 27.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90d0148-081f5e0b.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90d0148-2d15443f.jpg: 384x640 3 cars, 12.7ms\n",
            "Speed: 5.3ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90d0148-6d64cd06.jpg: 384x640 (no detections), 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90d0148-bbecdb11.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2903/10000 [01:32<03:58, 29.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90ed33f-2b527be4.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90f7487-17bb6cb9.jpg: 384x640 1 person, 8 cars, 1 truck, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b90f7487-7fb37cf4.jpg: 384x640 3 persons, 4 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9102500-70bcb1c3.jpg: 384x640 1 person, 13 cars, 1 truck, 7.9ms\n",
            "Speed: 1.6ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2907/10000 [01:32<03:46, 31.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9117002-548fd684.jpg: 384x640 1 person, 8 cars, 1 truck, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9117002-f2ff0c31.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b911a419-7bb3a8a4.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91383d9-1f2454a4.jpg: 384x640 1 truck, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2911/10000 [01:33<03:33, 33.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9152ae2-21189b28.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b915526f-f22f5cc4.jpg: 384x640 1 traffic light, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b919f6f7-9c71d913.jpg: 384x640 3 buss, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91af789-f9098734.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91c609b-171a17e0.jpg: 384x640 8 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2916/10000 [01:33<03:19, 35.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91cdc5d-bce994ce.jpg: 384x640 10 cars, 1 fire hydrant, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91dd730-8e0a1a8f.jpg: 384x640 1 car, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91ddba0-93eda7e1.jpg: 384x640 6 cars, 1 truck, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91ddba0-946e0059.jpg: 384x640 14 cars, 1 traffic light, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2920/10000 [01:33<03:25, 34.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91df396-3a32db81.jpg: 384x640 3 cars, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b91eae9e-c8fb98e5.jpg: 384x640 6 cars, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9206eb1-08915f67.jpg: 384x640 4 persons, 1 car, 4 traffic lights, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92246fc-03731d6b.jpg: 384x640 1 car, 1 traffic light, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2924/10000 [01:33<03:28, 33.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b924005d-3e1ae14d.jpg: 384x640 4 cars, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9254d2f-df7dd6b1.jpg: 384x640 1 person, 6 cars, 1 truck, 2 traffic lights, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b928271b-35145ad6.jpg: 384x640 5 cars, 1 truck, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b928271b-fe5cc5d1.jpg: 384x640 3 cars, 1 truck, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2928/10000 [01:33<03:35, 32.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b928cd75-1fb70c18.jpg: 384x640 (no detections), 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92a7fe6-0042ff16.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92a7fe6-01adecfd.jpg: 384x640 3 cars, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92a7fe6-714c37c2.jpg: 384x640 1 car, 1 traffic light, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2932/10000 [01:33<03:28, 33.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92c0cf0-2f0621ad.jpg: 384x640 1 person, 4 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92c4dd3-3a659a03.jpg: 384x640 3 persons, 5 cars, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92c4dd3-7ed54ec0.jpg: 384x640 1 traffic light, 11.5ms\n",
            "Speed: 1.7ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92c4dd3-856ff7b7.jpg: 384x640 8 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2936/10000 [01:33<03:23, 34.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92c4dd3-91991711.jpg: 384x640 7 cars, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92c7b7c-af420847.jpg: 384x640 13 cars, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92caf7e-4fc447e8.jpg: 384x640 4 cars, 1 bus, 1 truck, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92d48c3-f7812f84.jpg: 384x640 4 cars, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2940/10000 [01:33<03:38, 32.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92e15f8-bf91ff53.jpg: 384x640 4 cars, 12.8ms\n",
            "Speed: 1.7ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b92e5a9f-28900b6b.jpg: 384x640 1 person, 7 cars, 1 bus, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93085e8-4dcee882.jpg: 384x640 14 cars, 1 truck, 17.6ms\n",
            "Speed: 1.8ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b931fe93-10ef5680.jpg: 384x640 4 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2944/10000 [01:34<03:45, 31.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b931fe93-37b7cffb.jpg: 384x640 4 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b931fe93-5ee3a9ba.jpg: 384x640 3 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b931fe93-614568d3.jpg: 384x640 5 cars, 1 traffic light, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b931fe93-db7bffaf.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  29%|██▉       | 2948/10000 [01:34<03:40, 32.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b931fe93-f0b441ba.jpg: 384x640 2 persons, 4 cars, 1 bus, 9.4ms\n",
            "Speed: 2.6ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9332578-307665bc.jpg: 384x640 1 bus, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b934dfc0-55ee2773.jpg: 384x640 1 person, 5 cars, 2 trucks, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93616ca-eaeb3f71.jpg: 384x640 3 persons, 9 cars, 1 bus, 2 traffic lights, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2952/10000 [01:34<03:41, 31.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b936e35e-55e17398.jpg: 384x640 16 cars, 20.3ms\n",
            "Speed: 2.1ms preprocess, 20.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b936e35e-e46a87e6.jpg: 384x640 1 boat, 19.2ms\n",
            "Speed: 4.8ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b936e35e-f493bf16.jpg: 384x640 1 person, 1 car, 12.7ms\n",
            "Speed: 5.3ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b938ff6a-6eeaa410.jpg: 384x640 5 cars, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2956/10000 [01:34<04:14, 27.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93942f9-441a4817.jpg: 384x640 1 person, 4 cars, 1 traffic light, 20.1ms\n",
            "Speed: 3.0ms preprocess, 20.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93942f9-65eda0a3.jpg: 384x640 13 cars, 1 traffic light, 19.5ms\n",
            "Speed: 2.0ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93942f9-d722e1d0.jpg: 384x640 4 cars, 2 traffic lights, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2959/10000 [01:34<04:26, 26.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93942f9-ff411dce.jpg: 384x640 1 person, 1 car, 1 bus, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93a8e92-044ff223.jpg: 384x640 2 persons, 8 cars, 1 bus, 1 truck, 8 traffic lights, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93a8e92-e5a0589d.jpg: 384x640 7 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93bd867-726d338b.jpg: 384x640 13 cars, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2963/10000 [01:34<04:15, 27.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93c2c35-3533f822.jpg: 384x640 2 persons, 3 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93c2c35-9a03812d.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93d4555-02be04c1.jpg: 384x640 (no detections), 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2966/10000 [01:34<04:10, 28.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93db0b2-fd5012d5.jpg: 384x640 5 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93e0d1b-5e1e35f8.jpg: 384x640 3 cars, 1 truck, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93e190c-5253eaff.jpg: 384x640 3 cars, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2969/10000 [01:34<04:06, 28.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93e190c-b3e4728f.jpg: 384x640 3 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93e2268-2106a029.jpg: 384x640 1 person, 3 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93e2268-394c7031.jpg: 384x640 2 cars, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93e2268-40e27a6d.jpg: 384x640 4 cars, 1 truck, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2973/10000 [01:35<03:50, 30.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93e2268-4b277928.jpg: 384x640 5 cars, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93ecb20-598666a0.jpg: 384x640 2 cars, 1 truck, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93f2cee-48325ee0.jpg: 384x640 7 persons, 4 cars, 1 bus, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b93f2cee-c44ef489.jpg: 384x640 4 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2977/10000 [01:35<03:41, 31.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94071ab-d4385c1a.jpg: 384x640 1 person, 4 cars, 1 truck, 2 traffic lights, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b940ba87-26950497.jpg: 384x640 1 car, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b940ba87-435d34a8.jpg: 384x640 1 car, 8.1ms\n",
            "Speed: 5.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b940c3b2-149d028e.jpg: 384x640 6 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2981/10000 [01:35<03:30, 33.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9429f07-33ae3ff1.jpg: 384x640 6 cars, 1 truck, 1 traffic light, 13.8ms\n",
            "Speed: 4.1ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9429f07-a95e6db3.jpg: 384x640 2 cars, 1 motorcycle, 1 truck, 14.3ms\n",
            "Speed: 1.8ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9429f07-e59c4a8c.jpg: 384x640 5 cars, 2 trucks, 25.6ms\n",
            "Speed: 2.0ms preprocess, 25.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94313c9-962b4c59.jpg: 384x640 2 cars, 17.1ms\n",
            "Speed: 4.0ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2985/10000 [01:35<03:59, 29.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b944121b-910a65e5.jpg: 384x640 6 cars, 1 bus, 1 truck, 1 traffic light, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9443e30-c9275e4a.jpg: 384x640 12 cars, 17.4ms\n",
            "Speed: 2.0ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b946a4cf-ef1b308e.jpg: 384x640 3 persons, 3 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9470f2d-aa9b22f2.jpg: 384x640 1 person, 5 cars, 1 truck, 14.7ms\n",
            "Speed: 1.8ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2989/10000 [01:35<04:17, 27.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9471202-68f658bd.jpg: 384x640 3 cars, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94781aa-a48a3555.jpg: 384x640 2 cars, 8.2ms\n",
            "Speed: 3.6ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b947b09d-0221b791.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b947b09d-ed9cc136.jpg: 384x640 1 car, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94a9ed0-08112e6a.jpg: 384x640 3 cars, 1 train, 2 trucks, 12.8ms\n",
            "Speed: 1.7ms preprocess, 12.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2994/10000 [01:35<03:52, 30.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94afe66-3fe18fd1.jpg: 384x640 1 person, 2 cars, 7.9ms\n",
            "Speed: 5.8ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94b1f35-b8e48adf.jpg: 384x640 10 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94cd5b4-26c295e5.jpg: 384x640 13 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94d2c84-bfed761a.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|██▉       | 2998/10000 [01:35<03:42, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94daedc-7045933e.jpg: 384x640 7 cars, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94eb13b-6189d792.jpg: 384x640 10 cars, 1 bus, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94ef562-0e37552c.jpg: 384x640 14 cars, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b94f6bc8-32f10d36.jpg: 384x640 8 cars, 1 motorcycle, 2 potted plants, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3002/10000 [01:35<03:45, 31.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9524a81-89273957.jpg: 384x640 5 cars, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b953a340-049ea536.jpg: 384x640 1 person, 9 cars, 1 train, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b953a340-298cb3fb.jpg: 384x640 4 persons, 8 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b953a340-d188ea90.jpg: 384x640 11 cars, 2 buss, 1 truck, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3006/10000 [01:36<03:50, 30.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b953a340-d936cbba.jpg: 384x640 9 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b953ef60-6c2cb9a1.jpg: 384x640 (no detections), 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b953efc6-455bdde1.jpg: 384x640 7 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b953efc6-f40d4290.jpg: 384x640 4 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b955232a-62397ff4.jpg: 384x640 6 persons, 4 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3011/10000 [01:36<03:33, 32.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b95709b5-53705d83.jpg: 384x640 2 persons, 18 cars, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9586e5c-33b83562.jpg: 384x640 3 cars, 1 truck, 3 traffic lights, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9597719-09a2458c.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9597719-4d141a98.jpg: 384x640 3 persons, 3 cars, 1 truck, 2 traffic lights, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3015/10000 [01:36<03:45, 31.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9597719-81050919.jpg: 384x640 11 cars, 15.2ms\n",
            "Speed: 4.0ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9597719-cd9a176f.jpg: 384x640 6 cars, 1 truck, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b959dc9b-1c7fc954.jpg: 384x640 2 traffic lights, 13.3ms\n",
            "Speed: 3.8ms preprocess, 13.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b95bc6e9-34c711c1.jpg: 384x640 (no detections), 16.8ms\n",
            "Speed: 2.0ms preprocess, 16.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3019/10000 [01:36<03:55, 29.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b95c97a9-48663434.jpg: 384x640 5 cars, 1 truck, 17.4ms\n",
            "Speed: 1.9ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b95dcb10-45d68fcc.jpg: 384x640 3 persons, 3 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b95dcb10-4ff5c14d.jpg: 384x640 11 cars, 1 bus, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3022/10000 [01:36<04:04, 28.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b95dcb10-5838c763.jpg: 384x640 7 cars, 12.3ms\n",
            "Speed: 5.3ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b95feaae-690faa76.jpg: 384x640 4 cars, 1 bus, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b965ce1b-ad83b0ff.jpg: 384x640 2 cars, 1 bus, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b967b2a7-2003bfd2.jpg: 384x640 1 person, 4 cars, 1 bus, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3026/10000 [01:36<03:50, 30.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b96c88de-058de530.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b96c88de-92c2d62b.jpg: 384x640 7 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b96c88de-bf71b865.jpg: 384x640 2 cars, 1 truck, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b96d19af-4b6a5a63.jpg: 384x640 2 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3030/10000 [01:36<03:34, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97124d9-bea19450.jpg: 384x640 6 cars, 1 bus, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9742173-21a140e8.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9742173-3b584111.jpg: 384x640 10 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b975a665-43da0ef1.jpg: 384x640 1 person, 5 cars, 5 traffic lights, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3034/10000 [01:36<03:35, 32.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b975a665-66f04c31.jpg: 384x640 10 cars, 1 truck, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b975a665-7b202002.jpg: 384x640 9 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b975a665-aed15a8d.jpg: 384x640 3 persons, 2 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b976b144-844de03e.jpg: 384x640 6 persons, 1 car, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3038/10000 [01:37<03:28, 33.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9772de9-8fef5466.jpg: 384x640 (no detections), 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9782b2a-681c4b4d.jpg: 384x640 7 cars, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b979217b-015bcb98.jpg: 384x640 1 person, 1 bicycle, 1 car, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b979217b-09ba51bd.jpg: 384x640 6 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b979217b-32f86fea.jpg: 384x640 3 cars, 22.4ms\n",
            "Speed: 1.8ms preprocess, 22.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3043/10000 [01:37<03:25, 33.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b979217b-53523d64.jpg: 384x640 1 person, 4 cars, 14.8ms\n",
            "Speed: 2.0ms preprocess, 14.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b979b89c-388674d4.jpg: 384x640 6 cars, 13.1ms\n",
            "Speed: 4.8ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b979b89c-b359ef70.jpg: 384x640 (no detections), 16.4ms\n",
            "Speed: 3.8ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b979b89c-d7e084b9.jpg: 384x640 15 cars, 16.5ms\n",
            "Speed: 2.0ms preprocess, 16.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  30%|███       | 3047/10000 [01:37<03:48, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97aa948-8ab1108f.jpg: 384x640 2 cars, 4 traffic lights, 19.5ms\n",
            "Speed: 3.3ms preprocess, 19.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97aa948-d53ee60d.jpg: 384x640 1 car, 2 traffic lights, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97b9ee8-0dfbbe35.jpg: 384x640 1 person, 2 cars, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97b9ee8-612c36ef.jpg: 384x640 1 person, 4 cars, 3 trucks, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3051/10000 [01:37<04:01, 28.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97b9ee8-8fbf044e.jpg: 384x640 7 persons, 4 cars, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97b9ee8-ea15f29a.jpg: 384x640 7 cars, 11.0ms\n",
            "Speed: 4.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97c553a-004a5913.jpg: 384x640 2 cars, 1 airplane, 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3054/10000 [01:37<04:07, 28.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97e697f-1c37913f.jpg: 384x640 2 persons, 9 cars, 1 truck, 1 traffic light, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97f47c3-906ebdd5.jpg: 384x640 9 cars, 1 truck, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b97f9acb-5c677268.jpg: 384x640 2 persons, 5 cars, 1 truck, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3057/10000 [01:37<04:14, 27.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9800035-7c61cb6d.jpg: 384x640 4 cars, 1 bus, 1 truck, 1 traffic light, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b980ce70-c9f24d8f.jpg: 384x640 (no detections), 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b981b2ec-9368ed56.jpg: 384x640 3 cars, 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3060/10000 [01:37<04:14, 27.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b981c36d-a66bb611.jpg: 384x640 1 person, 2 bicycles, 8 cars, 1 traffic light, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b981e7e3-4ccaf6b5.jpg: 384x640 13 cars, 1 fire hydrant, 16.6ms\n",
            "Speed: 2.1ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b981e7e3-958b5ba2.jpg: 384x640 9 cars, 1 truck, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3063/10000 [01:38<04:21, 26.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b981e7e3-e965dc31.jpg: 384x640 1 person, 1 car, 1 bus, 3 trucks, 10.3ms\n",
            "Speed: 6.7ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b981e7e3-f39b9a1b.jpg: 384x640 11 cars, 10.2ms\n",
            "Speed: 4.2ms preprocess, 10.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b982723f-84848a7f.jpg: 384x640 5 cars, 1 traffic light, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3066/10000 [01:38<04:19, 26.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98578b9-f52d7f86.jpg: 384x640 (no detections), 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98682bb-a0142ac9.jpg: 384x640 12 cars, 1 truck, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b988086f-1811f9d3.jpg: 384x640 8 cars, 1 traffic light, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3069/10000 [01:38<04:21, 26.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b988086f-caed8036.jpg: 384x640 9 cars, 1 traffic light, 19.3ms\n",
            "Speed: 2.0ms preprocess, 19.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b989ad0d-a1513cc2.jpg: 384x640 5 persons, 2 cars, 1 truck, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b989ad0d-b8f7d12a.jpg: 384x640 3 cars, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3072/10000 [01:38<04:28, 25.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98bd627-8593fa24.jpg: 384x640 2 cars, 20.0ms\n",
            "Speed: 1.9ms preprocess, 20.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98bd627-ef76afa3.jpg: 384x640 5 cars, 19.4ms\n",
            "Speed: 2.4ms preprocess, 19.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98c2fe7-a1ba769e.jpg: 384x640 4 persons, 5 cars, 1 truck, 2 traffic lights, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3075/10000 [01:38<04:28, 25.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98e3a45-2af2c615.jpg: 384x640 11 cars, 1 truck, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98e3a45-608c1fb2.jpg: 384x640 2 cars, 1 stop sign, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98e3a45-c94a8f44.jpg: 384x640 4 cars, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3078/10000 [01:38<04:17, 26.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98eabcc-573dccd2.jpg: 384x640 2 persons, 4 cars, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b98f4bb1-100931bb.jpg: 384x640 3 persons, 5 cars, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99169cf-98e77225.jpg: 384x640 8 cars, 19.3ms\n",
            "Speed: 1.9ms preprocess, 19.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3081/10000 [01:38<04:12, 27.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9947c32-6074d84c.jpg: 384x640 7 cars, 1 truck, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b995794d-66208231.jpg: 384x640 2 persons, 5 cars, 2 trucks, 2 traffic lights, 16.9ms\n",
            "Speed: 1.8ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b995df4d-4bf935df.jpg: 384x640 2 cars, 1 traffic light, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3084/10000 [01:38<04:07, 27.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b995df4d-c889890c.jpg: 384x640 4 cars, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9966b34-d7579b48.jpg: 384x640 9 cars, 1 truck, 1 stop sign, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9966b34-db0fb6ba.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b996d83b-2f6ef415.jpg: 384x640 2 cars, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3088/10000 [01:38<03:51, 29.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b997ec7a-20d90044.jpg: 384x640 8 cars, 1 traffic light, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b997ec7a-af29d0ca.jpg: 384x640 1 car, 1 truck, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9990002-f103f7d9.jpg: 384x640 4 cars, 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b999b5f5-38c7b100.jpg: 384x640 15 cars, 1 truck, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3092/10000 [01:39<03:51, 29.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99aea27-68a2c988.jpg: 384x640 7 cars, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99b108b-4422b287.jpg: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99b66a0-308f25ed.jpg: 384x640 2 persons, 6 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99c17a7-bc6ee752.jpg: 384x640 1 person, 4 cars, 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3096/10000 [01:39<03:53, 29.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99c5931-2ded1a3c.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99c5931-4e76f057.jpg: 384x640 1 car, 1 truck, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99c5931-81b850be.jpg: 384x640 3 cars, 21.3ms\n",
            "Speed: 1.9ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3099/10000 [01:39<04:05, 28.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99c5931-834bb88c.jpg: 384x640 2 trucks, 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99eeedd-f211870f.jpg: 384x640 1 car, 1 truck, 2 traffic lights, 19.4ms\n",
            "Speed: 3.0ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99f250d-375965e8.jpg: 384x640 1 car, 1 truck, 1 traffic light, 16.2ms\n",
            "Speed: 3.9ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3102/10000 [01:39<04:24, 26.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99f250d-81828357.jpg: 384x640 4 cars, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99f250d-886111c5.jpg: 384x640 1 car, 1 traffic light, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99f250d-97172b16.jpg: 384x640 1 person, 2 cars, 1 traffic light, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3105/10000 [01:39<04:18, 26.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99f250d-c69113f1.jpg: 384x640 5 cars, 1 bus, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99f7c8d-b97ed7dc.jpg: 384x640 1 person, 14 cars, 14.3ms\n",
            "Speed: 6.3ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b99fd3ff-95f75133.jpg: 384x640 2 cars, 2 traffic lights, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3108/10000 [01:39<04:24, 26.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9a0d48b-05b491ac.jpg: 384x640 2 cars, 1 train, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9a0d48b-a89007f6.jpg: 384x640 8 cars, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9a0d48b-c9dfdd87.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9a2146e-1fcf3af6.jpg: 384x640 6 cars, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3112/10000 [01:39<04:00, 28.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9a2146e-2f27d574.jpg: 384x640 2 persons, 5 cars, 2 trucks, 2 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9a6cd2a-0cea14f6.jpg: 384x640 6 cars, 3 traffic lights, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9a8d20a-4c0028f7.jpg: 384x640 6 cars, 1 traffic light, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9aabdcf-d1433a19.jpg: 384x640 3 persons, 4 cars, 2 trucks, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3116/10000 [01:39<03:52, 29.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9aca3ce-181f2909.jpg: 384x640 1 person, 1 bicycle, 2 cars, 2 traffic lights, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9af5d7a-58dc5c98.jpg: 384x640 1 car, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9b12c49-3f874f30.jpg: 384x640 2 cars, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9b16444-2929cf9e.jpg: 384x640 7 cars, 2 traffic lights, 1 sports ball, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3120/10000 [01:40<03:47, 30.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9b16444-feb0b3a5.jpg: 384x640 3 cars, 2 trucks, 1 traffic light, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9b53753-91a5d5f8.jpg: 384x640 1 person, 9 cars, 1 bus, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9baae14-474c5be2.jpg: 384x640 6 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-051addc0.jpg: 384x640 1 car, 2 traffic lights, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███       | 3124/10000 [01:40<03:43, 30.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-195389c9.jpg: 384x640 1 person, 3 cars, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-20a70f87.jpg: 384x640 4 cars, 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-27d8078f.jpg: 384x640 1 person, 8 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-4b999671.jpg: 384x640 1 car, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███▏      | 3128/10000 [01:40<03:43, 30.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-758fc13c.jpg: 384x640 8 cars, 15.6ms\n",
            "Speed: 2.0ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-933c3c94.jpg: 384x640 6 cars, 1 truck, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-9d12fc05.jpg: 384x640 4 cars, 16.6ms\n",
            "Speed: 1.8ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-f0d23559.jpg: 384x640 2 cars, 1 truck, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███▏      | 3132/10000 [01:40<03:49, 29.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bafa5a-f6a3f4da.jpg: 384x640 1 car, 16.2ms\n",
            "Speed: 3.0ms preprocess, 16.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bd0109-531e640f.jpg: 384x640 7 cars, 1 traffic light, 1 stop sign, 18.8ms\n",
            "Speed: 2.6ms preprocess, 18.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9bdeae4-ee607bbc.jpg: 384x640 2 cars, 17.6ms\n",
            "Speed: 2.1ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███▏      | 3135/10000 [01:40<03:57, 28.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c067bf-9bc4ccd1.jpg: 384x640 5 cars, 1 traffic light, 14.6ms\n",
            "Speed: 3.0ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c11ffc-52766c9e.jpg: 384x640 8 cars, 15.5ms\n",
            "Speed: 2.0ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c11ffc-8c6c2eb0.jpg: 384x640 5 cars, 19.1ms\n",
            "Speed: 1.8ms preprocess, 19.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███▏      | 3138/10000 [01:40<04:04, 28.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c2521e-2db68bde.jpg: 384x640 13 cars, 1 truck, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c30b68-2d208deb.jpg: 384x640 6 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c34a53-f1f42d75.jpg: 384x640 2 cars, 18.5ms\n",
            "Speed: 2.0ms preprocess, 18.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███▏      | 3141/10000 [01:40<04:09, 27.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c52ee6-7709a9c2.jpg: 384x640 6 cars, 2 trucks, 19.0ms\n",
            "Speed: 2.1ms preprocess, 19.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c5e7c2-5d214ecd.jpg: 384x640 8 cars, 2 traffic lights, 20.5ms\n",
            "Speed: 2.2ms preprocess, 20.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c66ce6-57fa7e69.jpg: 384x640 4 cars, 2 traffic lights, 19.9ms\n",
            "Speed: 2.1ms preprocess, 19.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███▏      | 3144/10000 [01:40<04:22, 26.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c71d97-416ef91d.jpg: 384x640 6 cars, 1 truck, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c71ec0-1a77e45e.jpg: 384x640 8 cars, 1 truck, 11.6ms\n",
            "Speed: 3.8ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c7f347-97b374b1.jpg: 384x640 3 persons, 10 cars, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  31%|███▏      | 3147/10000 [01:41<04:19, 26.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c7f347-fbc28cb2.jpg: 384x640 8 cars, 1 truck, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9c9d815-3f9d9a8a.jpg: 384x640 6 cars, 1 truck, 1 traffic light, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ca8abd-dc5cd337.jpg: 384x640 12 cars, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3150/10000 [01:41<04:15, 26.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ca94a2-7f349303.jpg: 384x640 6 cars, 1 bus, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ca94a2-df527b5a.jpg: 384x640 1 person, 10 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ca94a2-f35ce63b.jpg: 384x640 4 persons, 2 cars, 2 traffic lights, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9cabddd-e49dded9.jpg: 384x640 1 person, 4 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3154/10000 [01:41<04:03, 28.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9cb54f8-a8ad3ed2.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9cd5de4-5614ed70.jpg: 384x640 5 cars, 2 birds, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d11a21-9cc4a8bb.jpg: 384x640 1 car, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d11a21-9cff3219.jpg: 384x640 2 cars, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3158/10000 [01:41<03:53, 29.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d12c48-050117dc.jpg: 384x640 5 cars, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d12c48-1cdf1b03.jpg: 384x640 6 cars, 1 traffic light, 15.6ms\n",
            "Speed: 1.8ms preprocess, 15.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d12c48-d855b440.jpg: 384x640 2 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3161/10000 [01:41<03:57, 28.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d24e81-a9679e2a.jpg: 384x640 6 cars, 1 train, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-2c3b1ab3.jpg: 384x640 6 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-40ed613e.jpg: 384x640 10 cars, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-4ce3c7d9.jpg: 384x640 10 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3165/10000 [01:41<03:50, 29.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-5d3c8bcf.jpg: 384x640 5 cars, 1 bus, 1 truck, 3 traffic lights, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-68942f09.jpg: 384x640 11 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-809d2dd4.jpg: 384x640 1 car, 1 truck, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-8c9c4807.jpg: 384x640 9 cars, 4 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3169/10000 [01:41<03:45, 30.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-96333c9b.jpg: 384x640 10 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-d648a4c1.jpg: 384x640 2 persons, 3 cars, 1 truck, 4 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d34460-eb5b8d34.jpg: 384x640 12 cars, 5 traffic lights, 9.9ms\n",
            "Speed: 3.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d42546-22bbbe03.jpg: 384x640 (no detections), 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3173/10000 [01:41<03:35, 31.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d42546-2901d42d.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d47fe7-858753e0.jpg: 384x640 5 persons, 6 cars, 1 bus, 1 truck, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d9e358-7dadc57c.jpg: 384x640 1 person, 9 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9d9ed4e-66448e19.jpg: 384x640 5 cars, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3177/10000 [01:41<03:28, 32.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9db357e-512d7f3f.jpg: 384x640 8 cars, 1 truck, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9db357e-cd30a8ae.jpg: 384x640 13 cars, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9dcf6ba-53401992.jpg: 384x640 2 cars, 5 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9de552a-0e2a01b8.jpg: 384x640 8 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3181/10000 [01:42<03:27, 32.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9df54a4-314e9e5e.jpg: 384x640 2 persons, 3 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9df54a4-66f58812.jpg: 384x640 4 persons, 1 truck, 1 skateboard, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9df54a4-8203d67b.jpg: 384x640 3 cars, 1 bus, 1 train, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9df54a4-84660617.jpg: 384x640 3 persons, 6 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3185/10000 [01:42<03:18, 34.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9df54a4-91295fbc.jpg: 384x640 26 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9dfba7c-1c8f50a1.jpg: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9dfba7c-ffdd8fd3.jpg: 384x640 2 persons, 6 cars, 1 motorcycle, 1 traffic light, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e12f59-40d0d945.jpg: 384x640 5 cars, 1 traffic light, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3189/10000 [01:42<03:26, 33.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e197fb-1e3721e0.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e1e369-72bfc6bb.jpg: 384x640 4 persons, 2 cars, 1 truck, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e1e369-c7cc0c47.jpg: 384x640 2 cars, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e2c847-48127b39.jpg: 384x640 2 cars, 11.9ms\n",
            "Speed: 2.8ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3193/10000 [01:42<03:21, 33.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e4cb3d-975f9d1d.jpg: 384x640 3 persons, 1 car, 1 truck, 13.7ms\n",
            "Speed: 3.8ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e4cb3d-98ed4484.jpg: 384x640 8 cars, 1 truck, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e4cb3d-eaf3d4ad.jpg: 384x640 4 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e6660b-bc8236e7.jpg: 384x640 2 persons, 4 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3197/10000 [01:42<03:28, 32.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e7e326-693b4ae7.jpg: 384x640 1 person, 12 cars, 1 truck, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e91422-2d610458.jpg: 384x640 7 persons, 1 truck, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9e91422-944c7a2f.jpg: 384x640 9 cars, 1 truck, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9eae343-b296ccb7.jpg: 384x640 (no detections), 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3201/10000 [01:42<03:23, 33.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9eae343-d73328b2.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9eb4605-1024d23c.jpg: 384x640 4 cars, 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9eb4605-a9631712.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ecc316-2fdb6c92.jpg: 384x640 10 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ecc316-529acd3c.jpg: 384x640 1 person, 8 cars, 1 truck, 1 traffic light, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3206/10000 [01:42<03:11, 35.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ed6e80-1782fc7b.jpg: 384x640 1 car, 2 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ed70c8-edc3834b.jpg: 384x640 1 car, 4 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ed9a4e-4f2897e5.jpg: 384x640 1 person, 11 cars, 2 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ef03d3-92a377cc.jpg: 384x640 1 airplane, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3210/10000 [01:42<03:06, 36.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9ef58f6-dbfd3b12.jpg: 384x640 1 person, 6 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9efb2a4-bad8be38.jpg: 384x640 8 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9f22148-5d881ca7.jpg: 384x640 1 person, 6 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9f22148-6ad84326.jpg: 384x640 14 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3214/10000 [01:43<03:10, 35.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9f22148-bb552f30.jpg: 384x640 1 person, 2 cars, 2 trucks, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9f22148-fee94d83.jpg: 384x640 5 cars, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9f30ada-2c42a2f8.jpg: 384x640 11 cars, 1 traffic light, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9f83545-6c082fdd.jpg: 384x640 4 persons, 5 cars, 1 truck, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3218/10000 [01:43<03:05, 36.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9f83545-eb28b690.jpg: 384x640 6 cars, 1 bus, 1 truck, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fa66d8-a5fce3c5.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fb5382-36e88642.jpg: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fb5382-5cf0f1a7.jpg: 384x640 1 car, 2 traffic lights, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3222/10000 [01:43<03:03, 36.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fb5382-76c75580.jpg: 384x640 5 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fb5382-990e8173.jpg: 384x640 4 cars, 1 traffic light, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fb5382-a15fb1a6.jpg: 384x640 1 person, 4 cars, 1 traffic light, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fb5382-d590d1f3.jpg: 384x640 1 person, 5 cars, 1 traffic light, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3226/10000 [01:43<03:08, 35.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fb5382-de164886.jpg: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fb8b07-28df834c.jpg: 384x640 8 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fc97df-397f8a5d.jpg: 384x640 2 persons, 6 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fc97df-9b839325.jpg: 384x640 6 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3230/10000 [01:43<03:09, 35.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fde896-2829683e.jpg: 384x640 9 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fdf8bf-42564342.jpg: 384x640 5 cars, 2 trucks, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fdf8bf-9de2321b.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/b9fdf8bf-a7d770dc.jpg: 384x640 11 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3234/10000 [01:43<03:22, 33.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba01e424-d3effc2d.jpg: 384x640 11 persons, 5 cars, 1 truck, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba01e424-e21752bb.jpg: 384x640 8 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba01e7b7-4c136c35.jpg: 384x640 5 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba075b35-6fb4c8fc.jpg: 384x640 1 car, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3238/10000 [01:43<03:22, 33.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba08174b-15c134f7.jpg: 384x640 1 person, 1 car, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba087e53-ef362be0.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba09810a-a1c9c327.jpg: 384x640 2 persons, 22 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba09810a-ac2ef27d.jpg: 384x640 18 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3242/10000 [01:43<03:29, 32.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0a3619-31d30af9.jpg: 384x640 2 persons, 7 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0a3619-e721c302.jpg: 384x640 2 cars, 1 truck, 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0a827b-06f3b51a.jpg: 384x640 5 cars, 1 traffic light, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0a827b-dfcec16f.jpg: 384x640 2 cars, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▏      | 3246/10000 [01:44<03:26, 32.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0a9afb-ba786259.jpg: 384x640 2 persons, 4 cars, 2 trucks, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0b31f2-067b826c.jpg: 384x640 7 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0b31f2-c45b879b.jpg: 384x640 3 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0d2a3f-0c429b61.jpg: 384x640 6 cars, 1 bus, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  32%|███▎      | 3250/10000 [01:44<03:21, 33.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba0f292a-bb8b14af.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba112f29-22498dfa.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba112f29-5452cd9f.jpg: 384x640 8 cars, 5 traffic lights, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba112f29-96213b92.jpg: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3254/10000 [01:44<03:12, 34.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba112f29-9da834a0.jpg: 384x640 5 cars, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba112f29-be7a8dfc.jpg: 384x640 1 car, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba122c97-403fd75d.jpg: 384x640 10 cars, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba122c97-69a4038b.jpg: 384x640 4 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3258/10000 [01:44<03:12, 35.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba147ca3-583de3f4.jpg: 384x640 7 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba14f1ef-178edc04.jpg: 384x640 2 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba15261b-0cded4cf.jpg: 384x640 1 car, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba15261b-46e2755d.jpg: 384x640 3 cars, 1 stop sign, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3262/10000 [01:44<03:09, 35.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba15abfa-53c4fa38.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba1612fa-392883a2.jpg: 384x640 3 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba1612fa-624ac188.jpg: 384x640 5 cars, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba1612fa-c9ac53d1.jpg: 384x640 2 cars, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3266/10000 [01:44<03:06, 36.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba163cd8-1403cad9.jpg: 384x640 4 cars, 1 truck, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba181cb9-341963b1.jpg: 384x640 3 cars, 1 traffic light, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba19e1c4-a9bca6af.jpg: 384x640 3 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba19e1c4-c243da22.jpg: 384x640 12 cars, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3270/10000 [01:44<03:15, 34.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba1ab927-a44a701b.jpg: 384x640 2 cars, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba1c5b5f-bc36c5fa.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba1f5489-3f8e2762.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba1f97fc-214aaccb.jpg: 384x640 4 cars, 1 airplane, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3274/10000 [01:44<03:13, 34.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba1f97fc-5b4826df.jpg: 384x640 6 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba21db9d-1fa50667.jpg: 384x640 9 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba22eaaf-b6fad89d.jpg: 384x640 6 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2610cc-76fb5c2d.jpg: 384x640 3 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3278/10000 [01:44<03:06, 36.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2905e2-145d9cfc.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2db972-f29458c8.jpg: 384x640 1 person, 5 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2e8260-126fca3e.jpg: 384x640 5 cars, 2 trucks, 1 traffic light, 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2e8260-2f6c9b36.jpg: 384x640 12 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3282/10000 [01:45<03:07, 35.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2e8260-5b48768d.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 1 fire hydrant, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2e8c76-9064d1ee.jpg: 384x640 1 person, 4 cars, 1 bus, 1 truck, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2e8c76-bc128eda.jpg: 384x640 1 person, 5 cars, 1 bus, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2e8c76-d41571cb.jpg: 384x640 9 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3286/10000 [01:45<03:06, 36.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2e8c76-d7ca505e.jpg: 384x640 2 persons, 10 cars, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba2ef5fa-0924e7c4.jpg: 384x640 1 car, 1 train, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba31ed47-117c074b.jpg: 384x640 6 persons, 3 cars, 1 bus, 1 truck, 1 traffic light, 1 bench, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba320af6-9ebfd69c.jpg: 384x640 1 person, 3 cars, 1 bus, 2 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3290/10000 [01:45<03:04, 36.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba336fcb-24158015.jpg: 384x640 2 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba336fcb-f0afaac6.jpg: 384x640 3 cars, 1 bus, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba35cdf3-e104174c.jpg: 384x640 2 cars, 2 traffic lights, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba362b8d-2855bf4e.jpg: 384x640 8 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3294/10000 [01:45<03:06, 36.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba362b8d-991d1837.jpg: 384x640 5 cars, 1 truck, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba36b0a9-6c380330.jpg: 384x640 (no detections), 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba37b3d4-a8126899.jpg: 384x640 2 persons, 2 cars, 1 bus, 3 trucks, 1 traffic light, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba3878a5-a6be090b.jpg: 384x640 12 cars, 1 truck, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3298/10000 [01:45<03:11, 35.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba3d031c-e85b19e4.jpg: 384x640 13 cars, 1 bus, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba3dc656-c88512cc.jpg: 384x640 1 person, 1 car, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba3dfc2c-1b22491c.jpg: 384x640 8 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba3f4265-46c99d41.jpg: 384x640 4 cars, 1 truck, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3302/10000 [01:45<03:12, 34.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba3f4265-77da2806.jpg: 384x640 1 car, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba3f4265-d8adfa71.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba3ffa1d-05ce6de4.jpg: 384x640 1 person, 9 cars, 1 motorcycle, 1 truck, 10.6ms\n",
            "Speed: 1.7ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba402b44-b17beb78.jpg: 384x640 3 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3306/10000 [01:45<03:07, 35.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba41a907-1793986f.jpg: 384x640 5 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba41a907-c8e44897.jpg: 384x640 3 cars, 1 traffic light, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4432a9-35b2f81e.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4432a9-3956a266.jpg: 384x640 1 person, 3 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3310/10000 [01:45<03:07, 35.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4432a9-5439b6db.jpg: 384x640 10 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4432a9-9df2cbad.jpg: 384x640 16 cars, 1 truck, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4432a9-d3c31edf.jpg: 384x640 1 person, 11 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4576b4-2b165aea.jpg: 384x640 9 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3314/10000 [01:45<03:10, 35.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba465f46-6ec77334.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba467364-d5d97e59.jpg: 384x640 5 cars, 1 truck, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba47021e-ec2f1a4a.jpg: 384x640 5 cars, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba475d4d-ed2daa1d.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3318/10000 [01:46<03:06, 35.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba477574-906b0b32.jpg: 384x640 2 persons, 3 cars, 2 traffic lights, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba477574-b5e29f22.jpg: 384x640 6 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba479cb3-1909b5d7.jpg: 384x640 3 persons, 2 cars, 1 bus, 3 trucks, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba479cb3-5949ad38.jpg: 384x640 4 cars, 1 truck, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3322/10000 [01:46<03:28, 32.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba479cb3-7d06a26f.jpg: 384x640 5 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba479cb3-a99a833a.jpg: 384x640 1 person, 13 cars, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba479cb3-b04e9be2.jpg: 384x640 5 cars, 1 truck, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba479cb3-f5cd5cdf.jpg: 384x640 8 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3326/10000 [01:46<03:27, 32.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba47af6d-548205ea.jpg: 384x640 3 persons, 5 cars, 1 tv, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba49e65a-773f5f54.jpg: 384x640 1 car, 1 bus, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4a95e2-388b7299.jpg: 384x640 2 cars, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4adf3d-27e3cae5.jpg: 384x640 1 person, 1 car, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3330/10000 [01:46<03:25, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4bcdc5-06e22f87.jpg: 384x640 14 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4bcdc5-31c36605.jpg: 384x640 1 person, 11 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4bcdc5-3d4f7a56.jpg: 384x640 8 cars, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4bcdc5-fe7847d3.jpg: 384x640 11 cars, 3 traffic lights, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3334/10000 [01:46<03:33, 31.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4bd5ae-583b01d5.jpg: 384x640 4 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4d05f6-24c9c3cf.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4d05f6-8b126390.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4d05f6-e11a4967.jpg: 384x640 8 cars, 1 bus, 3 traffic lights, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3338/10000 [01:46<03:27, 32.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4e5982-c64a8dfa.jpg: 384x640 10 cars, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba4fbdd7-43dccdf9.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba508231-1b6ab5b0.jpg: 384x640 9 cars, 1 bus, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba508231-2158c29b.jpg: 384x640 1 person, 6 cars, 1 bus, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3342/10000 [01:46<03:25, 32.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba510a80-edefe47f.jpg: 384x640 5 cars, 1 stop sign, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba510a80-f9582aea.jpg: 384x640 4 cars, 1 truck, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba52422d-dbf0a992.jpg: 384x640 16 cars, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba528af9-121c1347.jpg: 384x640 5 persons, 2 cars, 1 train, 1 truck, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  33%|███▎      | 3346/10000 [01:46<03:26, 32.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba54b31c-819571fe.jpg: 384x640 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba54b31c-dbca96b4.jpg: 384x640 2 cars, 1 truck, 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba54b6fd-896b735c.jpg: 384x640 3 cars, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba54b6fd-8cf056a0.jpg: 384x640 17 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▎      | 3350/10000 [01:47<03:21, 33.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5516aa-14ba6efa.jpg: 384x640 7 cars, 2 trucks, 9.7ms\n",
            "Speed: 1.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba59cdbb-15506193.jpg: 384x640 20 cars, 1 truck, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba59cdbb-be899b38.jpg: 384x640 4 cars, 4 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5ab643-35e0fae3.jpg: 384x640 7 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▎      | 3354/10000 [01:47<03:26, 32.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5ab643-993c5f56.jpg: 384x640 1 person, 7 cars, 1 truck, 1 stop sign, 1 bench, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5c4fbb-6815f84b.jpg: 384x640 10 cars, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5c759c-1913a624.jpg: 384x640 3 cars, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5c759c-2bfd1d3c.jpg: 384x640 2 persons, 7 cars, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▎      | 3358/10000 [01:47<03:29, 31.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5c759c-45dd7a4f.jpg: 384x640 12 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5c759c-623fcd9d.jpg: 384x640 1 car, 2 trucks, 6 traffic lights, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5d93c3-c082cdd4.jpg: 384x640 3 cars, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5df354-9ff8402c.jpg: 384x640 6 cars, 1 truck, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▎      | 3362/10000 [01:47<03:34, 30.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5df354-c3a0694a.jpg: 384x640 18 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba5df354-db132aac.jpg: 384x640 4 cars, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba60e97a-3b02b136.jpg: 384x640 10 cars, 1 bus, 2 trucks, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba619544-5fd6de8f.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▎      | 3366/10000 [01:47<03:35, 30.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba635a0a-fd69cb62.jpg: 384x640 9 cars, 3 trucks, 1 traffic light, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba64e51b-f88ab62e.jpg: 384x640 19 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba65317f-d4aba330.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba65c274-162fb09c.jpg: 384x640 10 cars, 1 bus, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▎      | 3370/10000 [01:47<03:35, 30.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba65c274-e0f6a546.jpg: 384x640 2 persons, 6 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba665bd8-d582ba49.jpg: 384x640 6 cars, 1 traffic light, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba6aa28c-fd3beb1c.jpg: 384x640 9 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba6bfd07-6a9ddced.jpg: 384x640 8 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▎      | 3374/10000 [01:47<03:29, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba6c1b09-24293108.jpg: 384x640 4 cars, 1 truck, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba6f0064-18848d0f.jpg: 384x640 (no detections), 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba70dfe3-111e78f4.jpg: 384x640 5 cars, 1 truck, 9.7ms\n",
            "Speed: 1.7ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba70dfe3-23dc1691.jpg: 384x640 1 person, 3 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3378/10000 [01:47<03:17, 33.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba70dfe3-4cfe0efb.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba70dfe3-4fd952a1.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba70dfe3-62b01bd8.jpg: 384x640 4 cars, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba70dfe3-69c229dd.jpg: 384x640 3 cars, 1 bus, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba70dfe3-b948e66d.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3383/10000 [01:48<03:03, 35.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7279cd-c80768c3.jpg: 384x640 6 cars, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba731feb-01fd61a2.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 1 chair, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba73ab52-4980c05c.jpg: 384x640 5 persons, 7 cars, 1 train, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba786070-0826a5d7.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3387/10000 [01:48<02:59, 36.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba79a103-c606265f.jpg: 384x640 1 person, 4 cars, 1 truck, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba79d911-8254c418.jpg: 384x640 1 person, 4 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7ad79b-d9c40465.jpg: 384x640 14 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7b9df0-a0b062ab.jpg: 384x640 15 persons, 1 bicycle, 1 car, 1 bus, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3391/10000 [01:48<03:01, 36.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7dcfa6-66589c64.jpg: 384x640 1 person, 3 cars, 1 truck, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7dcfa6-82aaecf5.jpg: 384x640 6 cars, 1 bus, 2 trucks, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7ef348-fb387cab.jpg: 384x640 9 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7ef348-fcf901f3.jpg: 384x640 2 cars, 3 traffic lights, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3395/10000 [01:48<03:09, 34.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7efc39-b198d2da.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7efc39-dea175db.jpg: 384x640 6 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7efc39-e3e9eecf.jpg: 384x640 7 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba7fb420-b647764f.jpg: 384x640 1 person, 5 cars, 1 bus, 1 traffic light, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3399/10000 [01:48<03:14, 33.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba81149b-bb88d2ac.jpg: 384x640 11 cars, 2 trucks, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8138ba-3a90a8bf.jpg: 384x640 1 person, 13 cars, 2 buss, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba85bff0-70955e40.jpg: 384x640 4 persons, 5 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba85dccd-ad3b457d.jpg: 384x640 1 person, 1 motorcycle, 1 train, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3403/10000 [01:48<03:18, 33.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba87390f-22dabe83.jpg: 384x640 9 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba87390f-75ebd274.jpg: 384x640 1 car, 1 traffic light, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba87390f-cc97ecd7.jpg: 384x640 5 cars, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba87390f-eebfd9d1.jpg: 384x640 4 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3407/10000 [01:48<03:13, 34.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba893ca0-7ad6a523.jpg: 384x640 3 persons, 1 car, 2 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8a21ad-c1970314.jpg: 384x640 4 cars, 1 truck, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8a41c9-fabd0516.jpg: 384x640 5 cars, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8b1e05-027a7e4a.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8b1e05-8ec0219a.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3412/10000 [01:48<03:02, 36.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8c90a0-b82731e9.jpg: 384x640 1 person, 5 cars, 1 traffic light, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8d52a0-b4af712f.jpg: 384x640 5 cars, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8df251-f17bd4a5.jpg: 384x640 4 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8df917-d4cd5e36.jpg: 384x640 3 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3416/10000 [01:48<03:03, 35.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba8f00d0-c16ca207.jpg: 384x640 3 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba908c74-4e0a63ae.jpg: 384x640 8 persons, 4 cars, 1 bus, 2 trucks, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba908c74-f486f96e.jpg: 384x640 1 person, 2 cars, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba91b65d-886141fd.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3420/10000 [01:49<02:59, 36.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba97a966-4d0c78a3.jpg: 384x640 10 cars, 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba982bf6-10d32995.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba99033d-2acd5337.jpg: 384x640 2 cars, 2 trucks, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba99033d-82ea8fb8.jpg: 384x640 4 cars, 2 trucks, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3424/10000 [01:49<02:58, 36.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba99464b-64917c10.jpg: 384x640 2 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba99464b-ca1ef680.jpg: 384x640 6 cars, 1 traffic light, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9a0c7f-77967cea.jpg: 384x640 1 car, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9ac2e8-67f85af0.jpg: 384x640 1 person, 4 cars, 3 traffic lights, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3428/10000 [01:49<03:03, 35.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9ac2e8-cc9600b9.jpg: 384x640 2 cars, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9ac2e8-f236d74f.jpg: 384x640 4 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9aff77-5e161292.jpg: 384x640 7 cars, 1 fire hydrant, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9baf3d-415342a2.jpg: 384x640 5 cars, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3432/10000 [01:49<03:10, 34.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9e2861-004544a0.jpg: 384x640 4 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9f23d8-741fa7f7.jpg: 384x640 1 person, 1 tv, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9f23d8-a50cd80e.jpg: 384x640 8 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9f6c98-2a75a096.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3436/10000 [01:49<03:12, 34.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ba9f6c98-c7216bf4.jpg: 384x640 5 cars, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa03c1f-82d03594.jpg: 384x640 6 cars, 11.6ms\n",
            "Speed: 2.4ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa09f40-a72f5fa3.jpg: 384x640 4 cars, 3 traffic lights, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa0bfdb-0267b9d2.jpg: 384x640 1 car, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3440/10000 [01:49<03:16, 33.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa0cbfb-46b96329.jpg: 384x640 3 cars, 1 truck, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa255c5-5c99a79a.jpg: 384x640 10 cars, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa50786-856eefa3.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa50786-e1613030.jpg: 384x640 17 cars, 1 truck, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3444/10000 [01:49<03:15, 33.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa57aaf-81957283.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa57aaf-b80b0054.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa59d18-90fc3158.jpg: 384x640 3 persons, 3 cars, 1 bus, 1 truck, 1 potted plant, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa618bf-40e56190.jpg: 384x640 6 cars, 1 bus, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  34%|███▍      | 3448/10000 [01:49<03:09, 34.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa79505-36d4add5.jpg: 384x640 1 car, 2 trucks, 1 umbrella, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa79505-43ff4345.jpg: 384x640 5 cars, 1 truck, 17.2ms\n",
            "Speed: 1.8ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa88157-4026332f.jpg: 384x640 10 cars, 1 traffic light, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baa9acbe-f3af19f6.jpg: 384x640 3 cars, 1 bus, 1 truck, 2 traffic lights, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3452/10000 [01:50<03:12, 34.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baab5a30-8d713374.jpg: 384x640 2 cars, 1 bus, 2 trucks, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baacc55a-84627b23.jpg: 384x640 19 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baaeb0ec-6ef45755.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baaf4c9c-c88fe684.jpg: 384x640 10 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3456/10000 [01:50<03:16, 33.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab0332c-a7074812.jpg: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab0332c-b043a76c.jpg: 384x640 1 car, 1 traffic light, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab09f26-0e237051.jpg: 384x640 11 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab09f26-8751de4f.jpg: 384x640 13 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3460/10000 [01:50<03:11, 34.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab22965-312b92a3.jpg: 384x640 6 cars, 2 traffic lights, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab22965-3e7b33e9.jpg: 384x640 1 person, 3 traffic lights, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab26b8d-deaa5510.jpg: 384x640 4 cars, 2 trucks, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab45acf-4b4387fb.jpg: 384x640 1 car, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3464/10000 [01:50<03:13, 33.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab48a4e-2f184c90.jpg: 384x640 (no detections), 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab48a4e-43fa0dfe.jpg: 384x640 2 cars, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab48a4e-6722401f.jpg: 384x640 2 cars, 1 traffic light, 10.9ms\n",
            "Speed: 3.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab52aba-0b87a64b.jpg: 384x640 9 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3468/10000 [01:50<03:14, 33.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab52aba-45bf005b.jpg: 384x640 2 cars, 1 truck, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab52aba-766e7f39.jpg: 384x640 6 cars, 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab692c9-35904fdb.jpg: 384x640 14 cars, 1 clock, 18.7ms\n",
            "Speed: 1.8ms preprocess, 18.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab692c9-3cd892ff.jpg: 384x640 1 person, 10 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3472/10000 [01:50<03:31, 30.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab692c9-4d1f2bdd.jpg: 384x640 9 cars, 1 truck, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab692c9-78e8ac63.jpg: 384x640 3 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab692c9-922ed2ea.jpg: 384x640 9 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab692c9-a16f15b4.jpg: 384x640 1 person, 16 cars, 1 backpack, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3476/10000 [01:50<03:37, 29.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab692c9-ce1abc2d.jpg: 384x640 8 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab692c9-efde0b04.jpg: 384x640 6 cars, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab6be6b-14db4536.jpg: 384x640 5 cars, 1 truck, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab6fead-bc74d699.jpg: 384x640 7 cars, 1 bus, 1 truck, 2 traffic lights, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3480/10000 [01:50<03:38, 29.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab90acb-5e9f3a31.jpg: 384x640 6 persons, 5 cars, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab97280-a3c6a37c.jpg: 384x640 16 persons, 2 cars, 2 trucks, 17.4ms\n",
            "Speed: 3.8ms preprocess, 17.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab98f04-a1010c10.jpg: 384x640 5 cars, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bab9f7f7-1cc4e542.jpg: 384x640 2 traffic lights, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3484/10000 [01:51<03:44, 29.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/babc7a6c-b72195cc.jpg: 384x640 2 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/babc7a6c-c5941835.jpg: 384x640 (no detections), 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/babd6d42-754e86fe.jpg: 384x640 3 persons, 7 cars, 2 buss, 3 traffic lights, 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/babf991d-a86f60ab.jpg: 384x640 3 cars, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3488/10000 [01:51<03:32, 30.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/babf991d-b4102dd2.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac1a0cf-45bef9f0.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac25f5a-af4fd9fd.jpg: 384x640 1 person, 11 cars, 2 traffic lights, 22.7ms\n",
            "Speed: 2.1ms preprocess, 22.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac391de-5885bad6.jpg: 384x640 14 cars, 1 truck, 2 traffic lights, 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3492/10000 [01:51<03:50, 28.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac391de-f53d733c.jpg: 384x640 10 cars, 17.5ms\n",
            "Speed: 2.0ms preprocess, 17.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac443ab-eb1694f5.jpg: 384x640 4 cars, 17.9ms\n",
            "Speed: 2.0ms preprocess, 17.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac52af2-81952c8d.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3495/10000 [01:51<04:04, 26.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac52b21-a8316888.jpg: 384x640 11 cars, 17.1ms\n",
            "Speed: 1.8ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac52b21-f294dffd.jpg: 384x640 3 persons, 3 cars, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac52b21-ffc2453b.jpg: 384x640 10 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▍      | 3498/10000 [01:51<04:06, 26.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac66ed2-5f02fccc.jpg: 384x640 14 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac8434c-a3f0f643.jpg: 384x640 2 cars, 15.9ms\n",
            "Speed: 1.8ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac84858-9f795ab4.jpg: 384x640 1 person, 2 cars, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3501/10000 [01:51<03:58, 27.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac8aa4e-a4321ac0.jpg: 384x640 10 cars, 1 traffic light, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac8fe51-1b610115.jpg: 384x640 2 cars, 2 traffic lights, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac8fe51-6b258bd9.jpg: 384x640 2 persons, 5 cars, 1 bus, 1 traffic light, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3504/10000 [01:51<03:53, 27.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bac9c292-e91eed49.jpg: 384x640 9 cars, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bacbfdaa-837ca39c.jpg: 384x640 1 person, 16 cars, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bacfd285-7f7bf1ce.jpg: 384x640 1 person, 9 cars, 1 bus, 1 truck, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3507/10000 [01:51<03:56, 27.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad479df-d2e02382.jpg: 384x640 3 traffic lights, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad4932f-06acec3c.jpg: 384x640 3 persons, 13 cars, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad5a7e9-b1d91b1a.jpg: 384x640 2 cars, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3510/10000 [01:52<04:03, 26.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad7f33d-7e31e0d2.jpg: 384x640 1 person, 2 trucks, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad81f09-0d02e84b.jpg: 384x640 1 person, 8 cars, 1 traffic light, 1 fire hydrant, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad89ad9-af1926ac.jpg: 384x640 7 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad89ad9-f1f414d4.jpg: 384x640 5 cars, 1 truck, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3514/10000 [01:52<03:41, 29.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad909d4-8de038fe.jpg: 384x640 4 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bad9944c-bdf6dd4f.jpg: 384x640 6 cars, 1 bus, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/badcea48-c3d19600.jpg: 384x640 3 persons, 1 car, 3 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bade898f-11350592.jpg: 384x640 4 persons, 7 cars, 1 bus, 1 truck, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3518/10000 [01:52<03:27, 31.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae16c60-044a4822.jpg: 384x640 11 cars, 1 truck, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae16c60-c2949e41.jpg: 384x640 5 cars, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae16c60-cf344206.jpg: 384x640 9 cars, 1 bus, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae16c60-e19bbf7a.jpg: 384x640 4 cars, 1 truck, 16.4ms\n",
            "Speed: 2.0ms preprocess, 16.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3522/10000 [01:52<03:28, 31.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae18530-9d734d71.jpg: 384x640 3 cars, 14.1ms\n",
            "Speed: 3.2ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae322f4-c995abe0.jpg: 384x640 9 cars, 1 traffic light, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae32983-3c9e09c4.jpg: 384x640 9 cars, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae32983-ef4277dc.jpg: 384x640 1 car, 1 traffic light, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3526/10000 [01:52<03:27, 31.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae32983-efef09dd.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae47c98-102dd98e.jpg: 384x640 9 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae47c98-40551cdd.jpg: 384x640 2 cars, 3 buss, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae4f394-11239e42.jpg: 384x640 1 car, 1 bus, 1 truck, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae4f394-24bc3bbe.jpg: 384x640 1 car, 2 traffic lights, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3531/10000 [01:52<03:10, 33.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae4f394-d4a6c04a.jpg: 384x640 3 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae552dc-36e0fe4e.jpg: 384x640 1 person, 3 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae552dc-4ee0cab7.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae5905c-b009aff3.jpg: 384x640 1 person, 8 cars, 1 traffic light, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae5dc33-65cbc3f4.jpg: 384x640 6 cars, 2 trucks, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3536/10000 [01:52<02:59, 36.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae778fd-4cc0d9be.jpg: 384x640 1 car, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae88538-8f433246.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae92945-2f6f01d7.jpg: 384x640 13 cars, 3 traffic lights, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae92945-99223ba6.jpg: 384x640 4 cars, 1 traffic light, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3540/10000 [01:52<03:08, 34.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae9f15e-0f68c902.jpg: 384x640 10 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bae9f15e-4c858350.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baea519f-f4a57477.jpg: 384x640 6 cars, 1 bus, 1 teddy bear, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baeab53a-2e79e160.jpg: 384x640 4 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3544/10000 [01:53<03:05, 34.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baeab53a-cefd6619.jpg: 384x640 4 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baeb1657-6169cccd.jpg: 384x640 2 cars, 1 truck, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baeb1657-c8c65444.jpg: 384x640 9 cars, 4 traffic lights, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baeb68f6-9abb3aaf.jpg: 384x640 3 cars, 1 train, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  35%|███▌      | 3548/10000 [01:53<03:08, 34.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baeb920c-a950cb02.jpg: 384x640 3 persons, 1 train, 1 traffic light, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baec74cf-6bdcae72.jpg: 384x640 7 cars, 1 bus, 1 traffic light, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baecebd1-0c93fa0d.jpg: 384x640 5 cars, 1 motorcycle, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baed9d4e-efe3a64e.jpg: 384x640 4 cars, 1 stop sign, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3552/10000 [01:53<03:12, 33.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baee6fb9-390cd194.jpg: 384x640 20 cars, 1 truck, 14.0ms\n",
            "Speed: 2.1ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baee6fb9-8438c345.jpg: 384x640 1 person, 17 cars, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baee6fb9-f28ac93d.jpg: 384x640 17 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baef72b1-4fd009a7.jpg: 384x640 5 persons, 5 cars, 1 truck, 1 traffic light, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3556/10000 [01:53<03:29, 30.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baef72b1-809d1abe.jpg: 384x640 7 persons, 5 cars, 1 truck, 1 traffic light, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baef72b1-9274c60c.jpg: 384x640 2 persons, 4 cars, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baef72b1-f2680c40.jpg: 384x640 2 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baef8908-b0802135.jpg: 384x640 1 person, 3 cars, 6 buss, 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3560/10000 [01:53<03:23, 31.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baefbbd2-83ba702b.jpg: 384x640 11 cars, 2 traffic lights, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baefe65c-bb9793d9.jpg: 384x640 10 cars, 2 trucks, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baefe65c-de9ef3eb.jpg: 384x640 5 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf019d9-986608ff.jpg: 384x640 (no detections), 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3564/10000 [01:53<03:10, 33.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf019d9-da5f9843.jpg: 384x640 1 person, 13 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf1c81c-d909d4dc.jpg: 384x640 7 cars, 4 traffic lights, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf1fb8b-258ca9a9.jpg: 384x640 9 cars, 1 truck, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf1fb8b-9280a668.jpg: 384x640 3 cars, 1 bus, 1 truck, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3568/10000 [01:53<03:11, 33.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf24e00-1fbb8a3b.jpg: 384x640 7 cars, 7.6ms\n",
            "Speed: 5.7ms preprocess, 7.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf24e00-7742132f.jpg: 384x640 4 cars, 1 truck, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf29436-f6375fa4.jpg: 384x640 1 bicycle, 8 cars, 1 truck, 1 traffic light, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf2f38d-596d1bc4.jpg: 384x640 2 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3572/10000 [01:53<03:13, 33.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf399e3-e2f279fa.jpg: 384x640 8 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf567e1-5ffa6b77.jpg: 384x640 11 cars, 1 traffic light, 14.5ms\n",
            "Speed: 1.7ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf6c5b1-9236f4d1.jpg: 384x640 2 persons, 1 bicycle, 3 cars, 1 truck, 11.5ms\n",
            "Speed: 5.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf870f0-44119a5e.jpg: 384x640 4 cars, 1 bus, 1 truck, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3576/10000 [01:54<03:19, 32.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf870f0-a1a64cd6.jpg: 384x640 2 persons, 7 cars, 1 bus, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf89af3-091fba23.jpg: 384x640 (no detections), 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf89af3-46fd3da9.jpg: 384x640 4 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/baf89af3-64d570fc.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3580/10000 [01:54<03:14, 32.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafa2401-045c70c7.jpg: 384x640 4 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafacab2-a1bafb37.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafad57f-2e29ac87.jpg: 384x640 6 cars, 1 truck, 9.8ms\n",
            "Speed: 1.7ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafb04fb-119f164b.jpg: 384x640 4 cars, 3 trucks, 1 kite, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3584/10000 [01:54<03:08, 34.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafcc992-a5faf18d.jpg: 384x640 5 cars, 1 truck, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafcc992-dcddfe75.jpg: 384x640 2 cars, 3 trucks, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafe41f1-96b00f10.jpg: 384x640 1 person, 1 car, 1 bus, 2 traffic lights, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafe41f1-e8a0fac7.jpg: 384x640 3 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3588/10000 [01:54<03:12, 33.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafe41f1-fa3e0ccf.jpg: 384x640 2 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafeadd4-255dc46e.jpg: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bafeadd4-9add2eaf.jpg: 384x640 1 car, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb01eaee-b8f0ebe3.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3592/10000 [01:54<03:06, 34.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0475d9-dda53a5a.jpg: 384x640 15 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0479a0-b3c8e0ea.jpg: 384x640 2 persons, 1 car, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb051d4e-49d5fed8.jpg: 384x640 1 person, 5 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb087b1c-6c9e904f.jpg: 384x640 9 persons, 1 bicycle, 5 cars, 1 motorcycle, 1 truck, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3596/10000 [01:54<03:06, 34.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0af861-7e6c3e30.jpg: 384x640 1 car, 3 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0b99d2-a91aab3d.jpg: 384x640 5 cars, 1 bus, 2 trucks, 1 traffic light, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0c13d5-3a2adbe3.jpg: 384x640 6 cars, 1 truck, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0c13d5-ef1bd4e0.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0cf6a9-ce0fdf2c.jpg: 384x640 4 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3601/10000 [01:54<02:54, 36.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0d0a55-6e9e48be.jpg: 384x640 2 persons, 6 cars, 3 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0dced8-65a75aec.jpg: 384x640 3 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0dced8-7c117b8e.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0ea699-3d008331.jpg: 384x640 6 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3605/10000 [01:54<02:55, 36.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb0ea699-e350eac6.jpg: 384x640 3 persons, 7 cars, 1 bus, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb110f9d-f9e57c74.jpg: 384x640 3 persons, 1 bicycle, 5 cars, 3 traffic lights, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb122fa3-1b6b0150.jpg: 384x640 3 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb123691-777cee95.jpg: 384x640 7 cars, 3 trucks, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3609/10000 [01:54<02:54, 36.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1288a9-e1fd25fa.jpg: 384x640 6 cars, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb145d9b-5ae8376f.jpg: 384x640 6 cars, 1 traffic light, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb160b7f-0553000b.jpg: 384x640 7 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb16329e-7ddd640e.jpg: 384x640 5 persons, 9 cars, 1 bus, 2 trucks, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3613/10000 [01:55<02:59, 35.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb16d9b5-588275af.jpg: 384x640 2 cars, 1 stop sign, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb172cd0-523870b7.jpg: 384x640 2 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb17665d-27525f20.jpg: 384x640 2 cars, 1 traffic light, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb17665d-8f5794bb.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3617/10000 [01:55<02:57, 35.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb185003-ebc11af9.jpg: 384x640 2 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb198c24-1f5691ed.jpg: 384x640 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb198c24-2d2ae5c5.jpg: 384x640 2 cars, 1 fire hydrant, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb198c24-66cf3fcb.jpg: 384x640 4 cars, 2 traffic lights, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb198c24-924a7794.jpg: 384x640 5 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▌      | 3622/10000 [01:55<02:49, 37.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb198c24-b046e976.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb198c24-c5d65870.jpg: 384x640 9 cars, 14.5ms\n",
            "Speed: 2.2ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb198c24-d7f4344c.jpg: 384x640 5 cars, 15.4ms\n",
            "Speed: 2.0ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1a255a-60ecb81a.jpg: 384x640 11 cars, 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▋      | 3626/10000 [01:55<03:06, 34.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1a255a-99414370.jpg: 384x640 5 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1a255a-dc60ef57.jpg: 384x640 4 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1b7d8c-916a2c96.jpg: 384x640 1 car, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1b7e42-48b281a3.jpg: 384x640 16 cars, 1 traffic light, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▋      | 3630/10000 [01:55<03:06, 34.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1b7e42-67806924.jpg: 384x640 11 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1b7e42-9608265e.jpg: 384x640 5 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1b7e42-b17da5d0.jpg: 384x640 4 cars, 3 traffic lights, 22.5ms\n",
            "Speed: 1.8ms preprocess, 22.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb1d71e5-5ce653ff.jpg: 384x640 1 car, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▋      | 3634/10000 [01:55<03:12, 33.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb204299-557172b1.jpg: 384x640 7 cars, 1 bus, 1 truck, 11.9ms\n",
            "Speed: 2.8ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb21e706-33f63a66.jpg: 384x640 13 cars, 17.5ms\n",
            "Speed: 3.0ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb269a85-bd43ab11.jpg: 384x640 1 truck, 1 dog, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb269a85-eba0cd5a.jpg: 384x640 2 cars, 16.9ms\n",
            "Speed: 1.8ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▋      | 3638/10000 [01:55<03:22, 31.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2888a8-ca075f36.jpg: 384x640 5 cars, 5 trucks, 17.0ms\n",
            "Speed: 2.0ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb289fdb-3de1932f.jpg: 384x640 7 cars, 1 truck, 19.7ms\n",
            "Speed: 1.8ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb289fdb-4bc01501.jpg: 384x640 (no detections), 12.3ms\n",
            "Speed: 6.6ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb289fdb-b3d91709.jpg: 384x640 6 cars, 19.6ms\n",
            "Speed: 1.8ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▋      | 3642/10000 [01:55<03:37, 29.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb289fdb-b6763201.jpg: 384x640 1 car, 1 traffic light, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb298f1a-55b463fb.jpg: 384x640 5 cars, 1 bus, 1 truck, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2c3ff8-a1444b2b.jpg: 384x640 1 person, 2 cars, 12.7ms\n",
            "Speed: 4.4ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▋      | 3645/10000 [01:56<03:41, 28.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2c5719-1244dd67.jpg: 384x640 1 person, 3 cars, 1 traffic light, 1 umbrella, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2c5719-38a69465.jpg: 384x640 10 persons, 4 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2c8f70-d58d2ef6.jpg: 384x640 7 cars, 1 truck, 15.1ms\n",
            "Speed: 1.8ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  36%|███▋      | 3648/10000 [01:56<03:40, 28.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2cabeb-2c0701d4.jpg: 384x640 (no detections), 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2cabeb-91cfe8d5.jpg: 384x640 1 car, 13.3ms\n",
            "Speed: 4.4ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2e43e4-5e7a7129.jpg: 384x640 2 persons, 7 cars, 2 traffic lights, 15.5ms\n",
            "Speed: 2.1ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3651/10000 [01:56<03:40, 28.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2ec277-7aa1721e.jpg: 384x640 2 cars, 1 traffic light, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2ecd61-c580ebaf.jpg: 384x640 6 cars, 1 bus, 20.5ms\n",
            "Speed: 1.9ms preprocess, 20.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2ecd61-fa37afd5.jpg: 384x640 4 cars, 23.6ms\n",
            "Speed: 2.6ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3654/10000 [01:56<03:50, 27.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2f678a-73bc87ec.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 3.9ms preprocess, 15.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2f678a-92915562.jpg: 384x640 5 cars, 19.0ms\n",
            "Speed: 3.4ms preprocess, 19.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2f678a-9364842a.jpg: 384x640 4 cars, 1 train, 2 trucks, 18.4ms\n",
            "Speed: 4.5ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3657/10000 [01:56<04:00, 26.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2f678a-af43ed71.jpg: 384x640 7 cars, 19.1ms\n",
            "Speed: 2.6ms preprocess, 19.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb2f678a-c2ed5fd5.jpg: 384x640 6 cars, 1 truck, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb300252-63610170.jpg: 384x640 1 car, 1 truck, 1 stop sign, 18.8ms\n",
            "Speed: 1.9ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3660/10000 [01:56<03:56, 26.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb310e6e-bf25b98d.jpg: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb32113e-e50b51e1.jpg: 384x640 (no detections), 18.5ms\n",
            "Speed: 1.9ms preprocess, 18.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb321d10-119ded2e.jpg: 384x640 9 cars, 4 traffic lights, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3663/10000 [01:56<03:56, 26.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb34331a-41c530d0.jpg: 384x640 13 cars, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb34331a-56aba0b3.jpg: 384x640 8 cars, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb370e7e-4c296bfb.jpg: 384x640 19 cars, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3666/10000 [01:56<04:09, 25.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb390224-2ea34fb1.jpg: 384x640 (no detections), 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb391d59-6b05b7a0.jpg: 384x640 1 person, 2 cars, 1 truck, 1 traffic light, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb391d59-8c851310.jpg: 384x640 2 persons, 9 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3669/10000 [01:56<03:58, 26.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3a75fa-b0b71066.jpg: 384x640 1 person, 5 cars, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3ada23-9d8e8e6e.jpg: 384x640 1 person, 4 cars, 1 truck, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-169af65a.jpg: 384x640 3 cars, 1 traffic light, 12.2ms\n",
            "Speed: 5.1ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3672/10000 [01:57<03:52, 27.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-2ef3abc6.jpg: 384x640 2 cars, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-4fa74f43.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-89d55028.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-8eeee166.jpg: 384x640 2 cars, 1 bus, 1 truck, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3676/10000 [01:57<03:31, 29.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-90ca2bee.jpg: 384x640 9 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-b32626a2.jpg: 384x640 10 cars, 2 buss, 17.9ms\n",
            "Speed: 4.8ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-c140b72f.jpg: 384x640 4 persons, 6 cars, 1 bus, 1 truck, 3 traffic lights, 24.4ms\n",
            "Speed: 2.0ms preprocess, 24.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3bb8c0-c83acdad.jpg: 384x640 2 cars, 1 traffic light, 20.2ms\n",
            "Speed: 2.9ms preprocess, 20.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3680/10000 [01:57<03:59, 26.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3be317-6db8a61d.jpg: 384x640 1 traffic light, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3d0123-3c8183bd.jpg: 384x640 1 kite, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3d0b90-44758857.jpg: 384x640 6 cars, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3683/10000 [01:57<04:06, 25.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3d0b90-81400890.jpg: 384x640 2 cars, 1 traffic light, 18.5ms\n",
            "Speed: 1.8ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb3f49d9-ca104345.jpg: 384x640 1 car, 1 traffic light, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb423617-10625110.jpg: 384x640 (no detections), 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3686/10000 [01:57<03:57, 26.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb425c3f-4e35dc9d.jpg: 384x640 7 cars, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb429905-508d2ae6.jpg: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb429905-efd7b1aa.jpg: 384x640 2 cars, 2 trucks, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3689/10000 [01:57<03:53, 27.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb42e52c-ee27bde3.jpg: 384x640 3 cars, 1 traffic light, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb437280-03a2bf81.jpg: 384x640 1 person, 5 cars, 1 stop sign, 1 umbrella, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb43e180-96b21056.jpg: 384x640 5 cars, 2 trucks, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb46a3b5-6fb47078.jpg: 384x640 20 cars, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3693/10000 [01:57<03:45, 27.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb46f3cd-b72d2152.jpg: 384x640 2 persons, 6 cars, 1 truck, 1 traffic light, 16.4ms\n",
            "Speed: 1.8ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb476629-bb31855e.jpg: 384x640 3 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb48c235-d9aae9be.jpg: 384x640 7 cars, 1 fire hydrant, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3696/10000 [01:57<03:41, 28.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb48e84b-6ae45e5f.jpg: 384x640 5 cars, 12.4ms\n",
            "Speed: 1.7ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb49071c-4b99a704.jpg: 384x640 10 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb49071c-b290d284.jpg: 384x640 1 person, 4 cars, 2 traffic lights, 15.0ms\n",
            "Speed: 3.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3699/10000 [01:58<03:44, 28.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb4935b0-e3fcded0.jpg: 384x640 9 cars, 1 truck, 10.7ms\n",
            "Speed: 2.7ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb49532f-ae2b40d1.jpg: 384x640 5 cars, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb4ab21e-60851cf9.jpg: 384x640 2 cars, 12.5ms\n",
            "Speed: 1.7ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3702/10000 [01:58<03:40, 28.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb4abf02-01cd2796.jpg: 384x640 5 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb4abf02-2651a845.jpg: 384x640 5 persons, 5 cars, 1 truck, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb4fca33-008f9178.jpg: 384x640 5 cars, 15.3ms\n",
            "Speed: 4.1ms preprocess, 15.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3705/10000 [01:58<03:41, 28.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb4fca33-75125e31.jpg: 384x640 12 cars, 1 bus, 17.9ms\n",
            "Speed: 1.9ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb52662e-0257c8b3.jpg: 384x640 1 person, 2 trains, 17.0ms\n",
            "Speed: 2.1ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb53a532-a6465a0b.jpg: 384x640 11 cars, 1 truck, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3708/10000 [01:58<03:54, 26.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb541ef2-1c0906c0.jpg: 384x640 2 persons, 9 cars, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb55f0e2-e5501b3c.jpg: 384x640 11 cars, 1 truck, 20.0ms\n",
            "Speed: 1.8ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb5620b4-1b9fa58e.jpg: 384x640 8 cars, 1 stop sign, 16.7ms\n",
            "Speed: 1.8ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3711/10000 [01:58<03:57, 26.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb576239-017d1d62.jpg: 384x640 13 cars, 1 traffic light, 12.2ms\n",
            "Speed: 1.7ms preprocess, 12.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb57d41c-506beec8.jpg: 384x640 1 person, 1 car, 1 traffic light, 24.2ms\n",
            "Speed: 1.8ms preprocess, 24.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb599cda-d1fdd751.jpg: 384x640 3 persons, 4 cars, 16.4ms\n",
            "Speed: 1.8ms preprocess, 16.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3714/10000 [01:58<04:01, 26.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb5a3238-ab2ba223.jpg: 384x640 7 cars, 1 truck, 2 traffic lights, 15.5ms\n",
            "Speed: 3.8ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb5cc516-235bb167.jpg: 384x640 2 cars, 1 truck, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb5cc516-3ac130c2.jpg: 384x640 3 cars, 1 parking meter, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3717/10000 [01:58<03:51, 27.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb5cc516-c0b64937.jpg: 384x640 2 cars, 1 fire hydrant, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb5cc516-c98d1fbe.jpg: 384x640 7 cars, 1 bus, 1 truck, 16.6ms\n",
            "Speed: 1.8ms preprocess, 16.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb5cc516-eb91e8c8.jpg: 384x640 1 person, 3 cars, 1 truck, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3720/10000 [01:58<03:48, 27.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb5d0b6a-99b062c6.jpg: 384x640 4 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb61c2ee-35ca0081.jpg: 384x640 3 cars, 4 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6264e8-08299561.jpg: 384x640 4 persons, 11 cars, 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6264e8-a591635c.jpg: 384x640 8 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3724/10000 [01:58<03:43, 28.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6264e8-e8dfd14d.jpg: 384x640 2 persons, 3 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb627372-de7438d2.jpg: 384x640 5 cars, 1 traffic light, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6292eb-0a9cbd38.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6292eb-90b37ce9.jpg: 384x640 1 bus, 1 truck, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3728/10000 [01:59<03:27, 30.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6292eb-cfbccc0b.jpg: 384x640 3 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb655f15-825903ad.jpg: 384x640 2 persons, 3 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6575eb-90478df6.jpg: 384x640 1 car, 1 stop sign, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6590aa-7a73c07e.jpg: 384x640 3 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3732/10000 [01:59<03:15, 32.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6643fa-a2b42d16.jpg: 384x640 3 persons, 2 cars, 2 traffic lights, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb69d2b0-fc67c3d9.jpg: 384x640 11 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6ad474-86b26884.jpg: 384x640 6 cars, 1 truck, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6b9678-771c7e62.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3736/10000 [01:59<03:20, 31.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6e6241-1fdd0e57.jpg: 384x640 2 persons, 8 cars, 1 bus, 1 truck, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6e9fc4-35369ff6.jpg: 384x640 1 person, 7 cars, 1 bus, 4 traffic lights, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6f381e-02e9cc6b.jpg: 384x640 1 person, 3 cars, 1 bus, 2 trucks, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb6fb6cd-6f571799.jpg: 384x640 11 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3740/10000 [01:59<03:37, 28.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb71ba86-3204e97e.jpg: 384x640 4 persons, 5 cars, 1 truck, 4 traffic lights, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb725082-6cfb3269.jpg: 384x640 7 cars, 1 truck, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb72d33c-aa1919f1.jpg: 384x640 1 car, 1 fire hydrant, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7444d5-e76820f4.jpg: 384x640 2 traffic lights, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3744/10000 [01:59<03:31, 29.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb74d006-0aad91f1.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb76958b-e0a8bc7a.jpg: 384x640 8 cars, 7.6ms\n",
            "Speed: 2.1ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7696a2-4c117c92.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb769d08-290df018.jpg: 384x640 8 cars, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  37%|███▋      | 3748/10000 [01:59<03:27, 30.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb76a219-47562e4c.jpg: 384x640 3 cars, 11.6ms\n",
            "Speed: 2.9ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb76c63a-586a2668.jpg: 384x640 11 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb76c63a-f232154d.jpg: 384x640 2 persons, 4 cars, 1 truck, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7792f1-83be8b82.jpg: 384x640 3 persons, 11 cars, 1 bus, 3 traffic lights, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3752/10000 [01:59<03:31, 29.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7792f1-e7ef3677.jpg: 384x640 14 persons, 2 cars, 1 motorcycle, 1 traffic light, 1 backpack, 1 handbag, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb77aa36-6aeefd56.jpg: 384x640 3 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb78624a-098bd29a.jpg: 384x640 13 cars, 1 truck, 9.3ms\n",
            "Speed: 1.7ms preprocess, 9.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb78624a-907eb4f3.jpg: 384x640 1 car, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3756/10000 [02:00<03:22, 30.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb78fe06-3994d745.jpg: 384x640 3 cars, 2 trucks, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb793416-9423221d.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb799f71-b5357135.jpg: 384x640 4 cars, 4 traffic lights, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb799f71-b76b80fc.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7be34b-0d28c0d9.jpg: 384x640 3 traffic lights, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3761/10000 [02:00<03:06, 33.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7cffc0-5a54a6d9.jpg: 384x640 2 persons, 9 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7e324a-0517fdbe.jpg: 384x640 4 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7fcbb9-cef5777d.jpg: 384x640 7 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7fd291-10af39c3.jpg: 384x640 16 cars, 1 bus, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3765/10000 [02:00<03:05, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb7fd291-bf28c0b5.jpg: 384x640 6 cars, 1 traffic light, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb80de49-c7d12d6a.jpg: 384x640 1 car, 1 fire hydrant, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb81a7a9-4469e43e.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb820c34-c959c253.jpg: 384x640 13 cars, 1 truck, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3769/10000 [02:00<03:08, 33.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb848f84-44cbc584.jpg: 384x640 1 car, 1 train, 1 traffic light, 17.0ms\n",
            "Speed: 2.0ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb856696-8aa6a20a.jpg: 384x640 7 cars, 2 trucks, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb890202-d9d48310.jpg: 384x640 7 cars, 12.1ms\n",
            "Speed: 2.5ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8a6035-7229656b.jpg: 384x640 2 cars, 1 truck, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3773/10000 [02:00<03:16, 31.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8b844a-ed14e8b9.jpg: 384x640 12 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8d2c06-e1a6a306.jpg: 384x640 1 person, 2 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-1be28493.jpg: 384x640 12 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-2560a871.jpg: 384x640 3 cars, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3777/10000 [02:00<03:14, 31.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-3537805c.jpg: 384x640 1 car, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-50af5a1e.jpg: 384x640 6 cars, 1 truck, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-5eb6b6b5.jpg: 384x640 8 cars, 1 truck, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-90b88fdf.jpg: 384x640 6 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3781/10000 [02:00<03:09, 32.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-9f4540b7.jpg: 384x640 9 cars, 1 truck, 13.3ms\n",
            "Speed: 6.0ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-b6abbfb0.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-bfa8dcd2.jpg: 384x640 13 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8dba97-c7ec77a3.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3785/10000 [02:00<03:09, 32.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8debd8-33cabcd9.jpg: 384x640 8 cars, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8debd8-5eb5bcfa.jpg: 384x640 5 cars, 1 truck, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8debd8-700f312a.jpg: 384x640 4 cars, 1 traffic light, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8e2033-6c418fc7.jpg: 384x640 8 cars, 2 stop signs, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3789/10000 [02:01<03:09, 32.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8e2033-cef919f8.jpg: 384x640 9 cars, 1 bus, 1 truck, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8e2033-cfd64d62.jpg: 384x640 2 persons, 5 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8f6c9a-3900261c.jpg: 384x640 3 cars, 3 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8f6c9a-690cfda6.jpg: 384x640 8 cars, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3793/10000 [02:01<03:16, 31.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8f6c9a-9be5142a.jpg: 384x640 8 cars, 1 bus, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb8f6c9a-e2c6dc5a.jpg: 384x640 8 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9071ac-46abc696.jpg: 384x640 9 cars, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9071ac-4a15cb23.jpg: 384x640 11 cars, 3 traffic lights, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3797/10000 [02:01<03:14, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9071ac-4b105539.jpg: 384x640 3 cars, 1 truck, 16.8ms\n",
            "Speed: 2.0ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9071ac-4ee8ed8c.jpg: 384x640 11 persons, 4 cars, 1 bus, 5 trucks, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9071ac-6b111ce9.jpg: 384x640 2 persons, 5 cars, 17.4ms\n",
            "Speed: 1.9ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9071ac-8e2bc8fe.jpg: 384x640 4 cars, 3 trucks, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3801/10000 [02:01<03:30, 29.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9071ac-9f4af9b1.jpg: 384x640 3 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9071ac-eb6e330c.jpg: 384x640 6 cars, 1 bus, 4 traffic lights, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb919332-5e30df54.jpg: 384x640 (no detections), 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb919332-8ea8b53f.jpg: 384x640 3 cars, 12.1ms\n",
            "Speed: 3.6ms preprocess, 12.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3805/10000 [02:01<03:27, 29.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb92ddee-aea40f05.jpg: 384x640 14 cars, 17.7ms\n",
            "Speed: 1.8ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb94c68a-4e6236bc.jpg: 384x640 14 cars, 1 traffic light, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb94c68a-820fd793.jpg: 384x640 9 cars, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb94d14a-39633f6b.jpg: 384x640 1 traffic light, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3809/10000 [02:01<03:39, 28.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb95526b-7123f6e0.jpg: 384x640 4 cars, 1 truck, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb95526b-ceac3ace.jpg: 384x640 6 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9712ba-8ec90d89.jpg: 384x640 6 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb974084-83d5efd3.jpg: 384x640 7 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3813/10000 [02:01<03:31, 29.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb974084-c0e23420.jpg: 384x640 2 cars, 2 trucks, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb97c366-2adf3cdc.jpg: 384x640 9 persons, 7 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb97c366-7664643f.jpg: 384x640 6 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb99539a-4fd21cfa.jpg: 384x640 2 cars, 1 truck, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3817/10000 [02:01<03:25, 30.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb99a578-c060f56f.jpg: 384x640 1 person, 11 cars, 1 traffic light, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb99dc60-942f3785.jpg: 384x640 16 cars, 1 truck, 8.8ms\n",
            "Speed: 3.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9a0374-e9c6de20.jpg: 384x640 2 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9a3460-97d249c3.jpg: 384x640 7 cars, 1 traffic light, 1 fire hydrant, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3821/10000 [02:02<03:24, 30.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9bd0cf-56fce493.jpg: 384x640 2 persons, 3 cars, 2 buss, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9c9020-21673e60.jpg: 384x640 2 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9d32ae-a1246a1e.jpg: 384x640 5 cars, 1 truck, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9d32ae-e5859cbf.jpg: 384x640 5 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3825/10000 [02:02<03:15, 31.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9d3fc8-c2a034bd.jpg: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9d4d12-6cc166e9.jpg: 384x640 5 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9e60a8-3a61f409.jpg: 384x640 1 car, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9e9d40-1d4d54db.jpg: 384x640 (no detections), 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3829/10000 [02:02<03:14, 31.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9e9d40-886fb5e0.jpg: 384x640 2 cars, 2 traffic lights, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9f3476-4fc600dc.jpg: 384x640 4 cars, 1 truck, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9f45f3-e6fb2c1f.jpg: 384x640 2 cars, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9f498e-5ea84006.jpg: 384x640 5 cars, 2 trucks, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3833/10000 [02:02<03:18, 31.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9f498e-62cc407e.jpg: 384x640 9 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9fb09f-c2a5e3d5.jpg: 384x640 3 cars, 2 buss, 1 truck, 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bb9fbfbe-f18bd5e5.jpg: 384x640 12 cars, 1 truck, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba066cf-355f858a.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3837/10000 [02:02<03:26, 29.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba322fa-9479b922.jpg: 384x640 5 persons, 4 cars, 1 bus, 2 traffic lights, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba45236-0fffd225.jpg: 384x640 (no detections), 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba45236-90850465.jpg: 384x640 1 traffic light, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba4ee51-12cbf4ff.jpg: 384x640 6 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3841/10000 [02:02<03:18, 31.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba4ee51-3badc9f8.jpg: 384x640 1 person, 11 cars, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba4ee51-616d23a7.jpg: 384x640 8 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba4fd9f-9e4fce7a.jpg: 384x640 13 cars, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba686c2-056961ec.jpg: 384x640 10 cars, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3845/10000 [02:02<03:26, 29.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba686c2-2e7b039d.jpg: 384x640 1 person, 5 cars, 11.9ms\n",
            "Speed: 4.4ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba6b17c-417567f2.jpg: 384x640 1 person, 5 cars, 1 truck, 1 surfboard, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba7999b-5dc320b4.jpg: 384x640 17 cars, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba7d3fc-86ab3822.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  38%|███▊      | 3849/10000 [02:03<03:23, 30.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba94727-03cd03e0.jpg: 384x640 1 person, 5 cars, 2 traffic lights, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba9d58b-18c62a06.jpg: 384x640 5 cars, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bba9d58b-afdc737b.jpg: 384x640 2 persons, 7 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbac8de0-3e6d9391.jpg: 384x640 1 car, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▊      | 3853/10000 [02:03<03:18, 30.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbac8de0-997098ef.jpg: 384x640 1 car, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbacbe02-4299b6a9.jpg: 384x640 1 person, 11 cars, 1 traffic light, 1 fire hydrant, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbadf190-864c9a43.jpg: 384x640 8 cars, 2 trucks, 3 traffic lights, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbaf1cf2-5c7315e0.jpg: 384x640 4 persons, 8 cars, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▊      | 3857/10000 [02:03<03:21, 30.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbaf54a0-217653b8.jpg: 384x640 1 person, 5 cars, 1 traffic light, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb01fbb-f2064005.jpg: 384x640 1 person, 13 cars, 1 truck, 1 traffic light, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb08020-5a72fc33.jpg: 384x640 1 person, 6 cars, 1 train, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb1289a-a3fbe37f.jpg: 384x640 4 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▊      | 3861/10000 [02:03<03:28, 29.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb1289a-b49fe5de.jpg: 384x640 12 cars, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb2487c-578aa473.jpg: 384x640 3 persons, 1 car, 1 truck, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb25499-f602899d.jpg: 384x640 1 person, 1 car, 1 truck, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb28508-bd7a8e64.jpg: 384x640 1 person, 5 cars, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▊      | 3865/10000 [02:03<03:28, 29.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb28508-c109f395.jpg: 384x640 5 cars, 1 traffic light, 15.1ms\n",
            "Speed: 2.6ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb458ab-6cd36285.jpg: 384x640 2 cars, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb46475-1bfc3090.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb46ace-1e415c05.jpg: 384x640 7 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▊      | 3869/10000 [02:03<03:20, 30.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb46ace-fd1c3344.jpg: 384x640 7 cars, 1 truck, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb5073b-401c9a78.jpg: 384x640 4 cars, 2 traffic lights, 16.8ms\n",
            "Speed: 1.7ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbb7bb8e-85124fbf.jpg: 384x640 1 person, 7 cars, 1 bus, 2 trucks, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbbe5a28-c070f32d.jpg: 384x640 2 cars, 3 boats, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▊      | 3873/10000 [02:03<03:19, 30.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbbf73f0-bd9c9571.jpg: 384x640 2 persons, 7 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbbffbd6-e260a6c2.jpg: 384x640 (no detections), 14.6ms\n",
            "Speed: 3.6ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-11e26c79.jpg: 384x640 7 cars, 1 truck, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-134b08d2.jpg: 384x640 10 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3877/10000 [02:03<03:13, 31.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-258b4f53.jpg: 384x640 8 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-271b20d7.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 3.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-287249d4.jpg: 384x640 6 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-2dc7912c.jpg: 384x640 2 cars, 4 traffic lights, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3881/10000 [02:04<03:16, 31.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-64bcf017.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-9f5efff2.jpg: 384x640 2 cars, 2 trains, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-aa1ed8ea.jpg: 384x640 4 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-ab6674c8.jpg: 384x640 3 cars, 1 traffic light, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3885/10000 [02:04<03:08, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-aba95b88.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-c51fe677.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-cc607874.jpg: 384x640 3 persons, 3 traffic lights, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc06e30-d687d6f0.jpg: 384x640 2 cars, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3889/10000 [02:04<03:00, 33.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc0f7ea-2bceb55e.jpg: 384x640 11 cars, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc0f7ea-3435af88.jpg: 384x640 1 car, 2 boats, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc0f7ea-39a32393.jpg: 384x640 1 person, 8 cars, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc0f7ea-77bee0c4.jpg: 384x640 2 persons, 14 cars, 1 truck, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3893/10000 [02:04<03:10, 32.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc0f7ea-8623a974.jpg: 384x640 11 cars, 1 truck, 1 traffic light, 21.9ms\n",
            "Speed: 2.5ms preprocess, 21.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc19191-6e9a792b.jpg: 384x640 2 persons, 9 cars, 1 truck, 1 boat, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc19191-fb681730.jpg: 384x640 5 cars, 1 bus, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc19c5e-51fd9cc0.jpg: 384x640 1 person, 5 cars, 3 trucks, 17.8ms\n",
            "Speed: 2.8ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3897/10000 [02:04<03:33, 28.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc2fba6-22f48e9a.jpg: 384x640 10 cars, 17.4ms\n",
            "Speed: 3.4ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc357f2-ddaa5e79.jpg: 384x640 12 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc46835-58ccfd96.jpg: 384x640 1 person, 5 cars, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3900/10000 [02:04<03:35, 28.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc4e74d-7ae9336b.jpg: 384x640 1 person, 2 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc64a91-4df79c20.jpg: 384x640 5 cars, 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc64a91-b3bf5a63.jpg: 384x640 8 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc755d2-7719fa91.jpg: 384x640 7 persons, 5 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3904/10000 [02:04<03:26, 29.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc755d2-e35a6b06.jpg: 384x640 10 persons, 9 cars, 5 traffic lights, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc9db98-2a592de3.jpg: 384x640 4 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc9db98-4a7fb607.jpg: 384x640 15 cars, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbc9ec36-8e63f11e.jpg: 384x640 4 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3908/10000 [02:04<03:20, 30.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcd82d7-0528d099.jpg: 384x640 6 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcd82d7-522d7b83.jpg: 384x640 6 cars, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcdfc12-745c6e19.jpg: 384x640 2 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcdfc12-87ca1f44.jpg: 384x640 6 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3912/10000 [02:05<03:19, 30.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbce4e17-9ff136be.jpg: 384x640 1 person, 1 car, 1 bus, 1 clock, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbce5b2c-df2c682b.jpg: 384x640 3 persons, 5 cars, 3 traffic lights, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcf4d70-162ec709.jpg: 384x640 9 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcf6d54-2e46ed62.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3916/10000 [02:05<03:13, 31.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcf6d54-4923f0f0.jpg: 384x640 8 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcf6d54-580e2911.jpg: 384x640 2 persons, 5 cars, 2 traffic lights, 19.5ms\n",
            "Speed: 1.8ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcf6d54-9e66bc23.jpg: 384x640 4 persons, 4 cars, 3 traffic lights, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcf6d54-a28d17b9.jpg: 384x640 3 cars, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3920/10000 [02:05<03:20, 30.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcf6d54-cccd1867.jpg: 384x640 4 persons, 4 cars, 1 truck, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbcf6d54-e39b0c22.jpg: 384x640 1 person, 6 cars, 1 traffic light, 13.0ms\n",
            "Speed: 4.1ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd03dac-457dcb31.jpg: 384x640 8 cars, 14.7ms\n",
            "Speed: 1.8ms preprocess, 14.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd20d96-3f8c363a.jpg: 384x640 6 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3924/10000 [02:05<03:27, 29.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd5188d-1a9b5ef0.jpg: 384x640 3 cars, 2 trucks, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd5188d-894df529.jpg: 384x640 2 cars, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd5188d-91d0926f.jpg: 384x640 4 cars, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3927/10000 [02:05<03:26, 29.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd5285a-a92367c9.jpg: 384x640 3 persons, 2 cars, 1 traffic light, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd5b9b2-5d171163.jpg: 384x640 3 cars, 1 bus, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd6019b-2c9ea14f.jpg: 384x640 1 person, 10 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbd63d3e-5e1ed924.jpg: 384x640 10 cars, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3931/10000 [02:05<03:17, 30.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbda6802-894aa456.jpg: 384x640 9 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbdad86e-abcab1f8.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbdb533c-9863d46e.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbddd5fa-1fb3ae4e.jpg: 384x640 7 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3935/10000 [02:05<03:07, 32.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbde8dba-93d1eb1f.jpg: 384x640 4 cars, 1 train, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbdfa37f-03ac6f5e.jpg: 384x640 7 cars, 1 truck, 1 sports ball, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbdfa37f-a37db6bd.jpg: 384x640 2 persons, 4 cars, 1 truck, 6 traffic lights, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe207fc-8ab7e608.jpg: 384x640 1 car, 2 traffic lights, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3939/10000 [02:05<03:02, 33.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe207fc-bee772a7.jpg: 384x640 5 persons, 13 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe207fc-d52c3f26.jpg: 384x640 5 cars, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe207fc-fc226573.jpg: 384x640 7 cars, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe207fc-fdb1b49f.jpg: 384x640 13 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3943/10000 [02:06<03:10, 31.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe2ac68-e15af654.jpg: 384x640 1 car, 4 traffic lights, 9.5ms\n",
            "Speed: 4.6ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe4ec31-2932af48.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe57528-3722fc17.jpg: 384x640 1 person, 8 cars, 1 bus, 2 trucks, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe7c596-88457d26.jpg: 384x640 5 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  39%|███▉      | 3947/10000 [02:06<03:04, 32.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe7c7e2-0d1dac56.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe7c7e2-ac32659a.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe88e6d-c0e7b375.jpg: 384x640 2 cars, 1 truck, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe91656-17f3e492.jpg: 384x640 3 cars, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3951/10000 [02:06<03:01, 33.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe91656-3ca9f506.jpg: 384x640 4 cars, 14.3ms\n",
            "Speed: 3.0ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe95ad4-1df76d9d.jpg: 384x640 12 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbe95ad4-8870089d.jpg: 384x640 1 person, 12 cars, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbea4013-25cf6227.jpg: 384x640 6 cars, 16.0ms\n",
            "Speed: 1.8ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3955/10000 [02:06<03:11, 31.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbebc8cb-5ff7981f.jpg: 384x640 4 persons, 8 cars, 1 traffic light, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbebc8cb-c0c59383.jpg: 384x640 2 cars, 15.1ms\n",
            "Speed: 1.8ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbec733f-32b81849.jpg: 384x640 14 cars, 1 truck, 20.6ms\n",
            "Speed: 1.8ms preprocess, 20.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbec733f-f92d5a38.jpg: 384x640 15 cars, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3959/10000 [02:06<03:32, 28.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbecbb69-bd7c745a.jpg: 384x640 4 persons, 8 cars, 1 truck, 1 traffic light, 1 clock, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbeefd23-dbf4d60e.jpg: 384x640 13 persons, 6 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbef1eae-960724af.jpg: 384x640 6 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3962/10000 [02:06<03:33, 28.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbef1eae-ab6f884c.jpg: 384x640 4 cars, 1 truck, 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbef1eae-c59b44b1.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbefae56-1d886e4e.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf0f5d7-e849d5f5.jpg: 384x640 9 cars, 1 truck, 14.7ms\n",
            "Speed: 1.8ms preprocess, 14.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3966/10000 [02:06<03:25, 29.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf0f5d7-ea2f1cc3.jpg: 384x640 2 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf29c70-20e48f5b.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf2ad0f-5458cb78.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf2bd83-1f5c87da.jpg: 384x640 7 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3970/10000 [02:06<03:12, 31.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf2bd83-750c3f46.jpg: 384x640 8 cars, 1 tv, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf2bd83-99456c75.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf2bd83-b7d61805.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf2bd83-fb721687.jpg: 384x640 10 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3974/10000 [02:07<03:06, 32.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf2c809-5fe910e9.jpg: 384x640 3 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf2c809-6d93ddf1.jpg: 384x640 1 person, 6 cars, 1 traffic light, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf38397-6c3d4ef5.jpg: 384x640 1 car, 3 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf3d83d-1a478458.jpg: 384x640 2 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3978/10000 [02:07<03:05, 32.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf3d83d-332ac457.jpg: 384x640 3 cars, 1 traffic light, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf3d83d-d6265b06.jpg: 384x640 1 person, 6 cars, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf3d83d-f15c5dd8.jpg: 384x640 2 cars, 1 stop sign, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf48d08-b6a11dd8.jpg: 384x640 2 cars, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3982/10000 [02:07<03:01, 33.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf48d08-f32427fa.jpg: 384x640 10 cars, 1 traffic light, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf5747b-35f769d6.jpg: 384x640 14 cars, 4 traffic lights, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf69eae-71b25b22.jpg: 384x640 2 persons, 3 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf6edef-5d90487a.jpg: 384x640 13 cars, 2 traffic lights, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3986/10000 [02:07<03:18, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf7e280-19aed161.jpg: 384x640 4 persons, 4 cars, 1 train, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf7e280-5abb97f2.jpg: 384x640 7 cars, 14.2ms\n",
            "Speed: 1.7ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf7e280-e5ccb014.jpg: 384x640 7 cars, 1 bus, 1 truck, 4 traffic lights, 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf86f8f-87b564dc.jpg: 384x640 11 cars, 1 motorcycle, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3990/10000 [02:07<03:22, 29.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbf8af11-a27cc76f.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbfa7b2b-9c71f471.jpg: 384x640 14 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbfc1b2e-43566392.jpg: 384x640 8 cars, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbfcd002-865258a4.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3994/10000 [02:07<03:14, 30.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbfcd002-f8531a65.jpg: 384x640 4 cars, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbfe3b4f-354e4430.jpg: 384x640 3 cars, 3 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbfe3b4f-5137ff9f.jpg: 384x640 5 persons, 2 bicycles, 7 cars, 1 bus, 1 truck, 5 traffic lights, 1 potted plant, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbfe3b4f-71b57b40.jpg: 384x640 (no detections), 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|███▉      | 3998/10000 [02:07<03:09, 31.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbff5146-286eae73.jpg: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbff5146-4b928b85.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbff5146-6ab95f34.jpg: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bbff5146-d503a17e.jpg: 384x640 3 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc013163-09158f28.jpg: 384x640 8 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4003/10000 [02:07<02:54, 34.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc053dc7-55612a00.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc053dc7-b7da4689.jpg: 384x640 1 car, 17.7ms\n",
            "Speed: 1.7ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc053dc7-f2d3aa91.jpg: 384x640 (no detections), 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc05c126-3c1f8300.jpg: 384x640 11 cars, 1 bus, 1 truck, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4007/10000 [02:08<02:53, 34.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc05c126-b5aff837.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc05c126-d00aeb9c.jpg: 384x640 11 cars, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc05da8e-e0eda9bd.jpg: 384x640 2 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc07bbae-a3783fe4.jpg: 384x640 11 cars, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4011/10000 [02:08<02:59, 33.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc07d865-43cc5bfc.jpg: 384x640 7 cars, 1 bus, 2 trucks, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc07d865-b2971089.jpg: 384x640 1 car, 1 truck, 16.4ms\n",
            "Speed: 2.6ms preprocess, 16.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc07d865-f526e4d9.jpg: 384x640 8 cars, 1 truck, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc082805-7738f543.jpg: 384x640 4 persons, 1 car, 1 truck, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4015/10000 [02:08<03:03, 32.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc0932fb-416a9475.jpg: 384x640 2 cars, 1 traffic light, 1 fire hydrant, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc0932fb-f2731c60.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc0e1045-7a8d0c04.jpg: 384x640 2 cars, 1 truck, 2 traffic lights, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc0e43fd-10fc4231.jpg: 384x640 8 cars, 1 truck, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4019/10000 [02:08<03:06, 32.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc101f0f-2bd5f9ec.jpg: 384x640 1 person, 10 cars, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc101f0f-6b6d71e7.jpg: 384x640 5 cars, 1 truck, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc101f0f-6efce9bc.jpg: 384x640 7 cars, 1 bus, 4 trucks, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc101f0f-7607f480.jpg: 384x640 3 cars, 1 train, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4023/10000 [02:08<03:08, 31.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc11304f-da51cfda.jpg: 384x640 7 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc140c47-28089dad.jpg: 384x640 2 persons, 4 cars, 1 motorcycle, 1 bus, 3 trucks, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc140c47-76775eb4.jpg: 384x640 3 cars, 3 trucks, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc140c47-7caca472.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4027/10000 [02:08<02:58, 33.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc14daff-30e5ade2.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc14daff-59f11746.jpg: 384x640 4 cars, 1 truck, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc16f8e9-7d69afdb.jpg: 384x640 5 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc16f8e9-930d98ee.jpg: 384x640 5 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4031/10000 [02:08<02:53, 34.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc16f8e9-b5faca03.jpg: 384x640 2 cars, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc171ee0-b1f4fca6.jpg: 384x640 2 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc18b981-f4361b9d.jpg: 384x640 10 cars, 12.6ms\n",
            "Speed: 1.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc197c3b-458c6a12.jpg: 384x640 2 persons, 5 cars, 2 buss, 1 traffic light, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4035/10000 [02:08<02:55, 34.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc197c3b-6c5c377d.jpg: 384x640 5 persons, 1 car, 2 buss, 3 traffic lights, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc197c3b-9d39a36a.jpg: 384x640 11 cars, 2 traffic lights, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc197c3b-fc1e2d41.jpg: 384x640 8 persons, 2 cars, 2 motorcycles, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc19b631-363ccccc.jpg: 384x640 2 cars, 1 truck, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4039/10000 [02:09<03:05, 32.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc19c993-2b635099.jpg: 384x640 12 cars, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc19c993-c0a0f85f.jpg: 384x640 7 cars, 3 trucks, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc19c993-e257683c.jpg: 384x640 4 cars, 1 truck, 4 traffic lights, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc1a4b69-ed3eed6e.jpg: 384x640 7 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4043/10000 [02:09<03:03, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc1af7c9-f48843d6.jpg: 384x640 4 cars, 12.2ms\n",
            "Speed: 5.7ms preprocess, 12.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc1e4645-5c81c3c1.jpg: 384x640 1 person, 4 cars, 1 bus, 1 truck, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc1e4645-76a7fd0e.jpg: 384x640 1 person, 12 cars, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc1fe060-06feda96.jpg: 384x640 11 cars, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  40%|████      | 4047/10000 [02:09<03:11, 31.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc201d0d-71877e7e.jpg: 384x640 1 person, 9 cars, 1 truck, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc208c84-18481db5.jpg: 384x640 2 cars, 2 traffic lights, 15.4ms\n",
            "Speed: 2.4ms preprocess, 15.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc214770-39035c6c.jpg: 384x640 17 cars, 1 traffic light, 16.6ms\n",
            "Speed: 3.9ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc223780-c88ddd93.jpg: 384x640 1 boat, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4051/10000 [02:09<03:24, 29.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc223780-e6658085.jpg: 384x640 1 car, 4 traffic lights, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc230811-8caf576d.jpg: 384x640 3 persons, 7 cars, 2 trucks, 18.1ms\n",
            "Speed: 3.5ms preprocess, 18.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc24e2f5-286f9781.jpg: 384x640 7 cars, 2 traffic lights, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4054/10000 [02:09<03:26, 28.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc24e2f5-b39b7137.jpg: 384x640 1 person, 1 car, 1 bus, 1 truck, 2 traffic lights, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc24f222-27a9e3d1.jpg: 384x640 1 car, 2 traffic lights, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc24f222-2acc4952.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc24f222-4fdb5e23.jpg: 384x640 5 cars, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4058/10000 [02:09<03:15, 30.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc24f222-538f2ee5.jpg: 384x640 6 cars, 1 truck, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc24f222-dad76e37.jpg: 384x640 1 person, 1 car, 1 traffic light, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc24f222-f198b643.jpg: 384x640 1 car, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2552ff-c72260e0.jpg: 384x640 9 cars, 1 truck, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4062/10000 [02:09<03:15, 30.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc25b12f-c0e0bf75.jpg: 384x640 1 car, 1 traffic light, 10.8ms\n",
            "Speed: 3.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc277e93-208f225f.jpg: 384x640 1 person, 4 cars, 1 traffic light, 12.4ms\n",
            "Speed: 1.7ms preprocess, 12.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc280a80-42084620.jpg: 384x640 1 car, 8.1ms\n",
            "Speed: 4.1ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc29fd13-8d640e8a.jpg: 384x640 7 cars, 2 trucks, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4066/10000 [02:09<03:07, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2a1273-18d05a08.jpg: 384x640 5 cars, 1 bus, 1 truck, 2 traffic lights, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2a1273-31065eb2.jpg: 384x640 4 cars, 1 traffic light, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2a1273-b863f5dd.jpg: 384x640 1 person, 5 cars, 2 trucks, 1 traffic light, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2a3aa8-1dfd52d1.jpg: 384x640 1 person, 5 cars, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4070/10000 [02:10<03:09, 31.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2a3aa8-65f56ef8.jpg: 384x640 4 cars, 2 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2de22a-b7c57049.jpg: 384x640 7 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2e185c-229fdd44.jpg: 384x640 7 cars, 1 truck, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2e52cc-4270d2b7.jpg: 384x640 4 cars, 1 traffic light, 8.1ms\n",
            "Speed: 5.0ms preprocess, 8.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4074/10000 [02:10<03:04, 32.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc2e52cc-cbd2ddae.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc308aee-322913df.jpg: 384x640 10 cars, 4 traffic lights, 1 fire hydrant, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc308aee-b3a48c42.jpg: 384x640 2 cars, 14.6ms\n",
            "Speed: 3.4ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc310129-634dbe96.jpg: 384x640 10 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4078/10000 [02:10<03:08, 31.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc31a829-278a9e0f.jpg: 384x640 6 cars, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc31a829-85e563f4.jpg: 384x640 5 cars, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc31a829-c73df3f7.jpg: 384x640 8 cars, 1 motorcycle, 13.4ms\n",
            "Speed: 1.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc31b583-be060375.jpg: 384x640 1 person, 1 car, 2 traffic lights, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4082/10000 [02:10<03:12, 30.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc325ce3-9cd329ba.jpg: 384x640 3 cars, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc328c1f-28b41b8d.jpg: 384x640 5 persons, 7 cars, 1 truck, 3 traffic lights, 11.3ms\n",
            "Speed: 2.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc33a49f-cd384f4a.jpg: 384x640 2 persons, 1 bicycle, 4 cars, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc35c318-8faf42b4.jpg: 384x640 2 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4086/10000 [02:10<03:06, 31.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc375490-55d90369.jpg: 384x640 7 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc39bd15-d825bd1d.jpg: 384x640 7 cars, 1 train, 1 truck, 9.2ms\n",
            "Speed: 3.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc39d438-0d513b75.jpg: 384x640 2 persons, 13 cars, 8.1ms\n",
            "Speed: 5.4ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc39d438-7a6fb2dc.jpg: 384x640 8 cars, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4090/10000 [02:10<03:08, 31.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc3aa991-84d583c6.jpg: 384x640 1 person, 4 cars, 1 truck, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc3c9f73-86d9b80c.jpg: 384x640 1 person, 1 car, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc3edef9-98053500.jpg: 384x640 1 person, 1 bicycle, 2 cars, 2 trucks, 1 traffic light, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc3edef9-bc5df407.jpg: 384x640 11 cars, 1 traffic light, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4094/10000 [02:10<03:05, 31.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc3f2e88-543a7c3e.jpg: 384x640 3 persons, 1 bicycle, 9 cars, 1 truck, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc430537-56669f07.jpg: 384x640 12 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc45ad96-42d305c5.jpg: 384x640 1 car, 1 traffic light, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc46dc69-94e689ae.jpg: 384x640 5 cars, 1 traffic light, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4098/10000 [02:10<03:13, 30.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc470fd9-1cbc318c.jpg: 384x640 2 persons, 17.6ms\n",
            "Speed: 1.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc4712a2-1bb55ccc.jpg: 384x640 5 cars, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc4712a2-b5a5966b.jpg: 384x640 4 cars, 1 bus, 1 truck, 15.9ms\n",
            "Speed: 1.9ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc4799bc-bc14f187.jpg: 384x640 14 cars, 14.2ms\n",
            "Speed: 7.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4102/10000 [02:11<03:18, 29.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc48608f-1d8fb508.jpg: 384x640 10 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc4a16d5-a4cc1adf.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc4a16d5-cefa77b6.jpg: 384x640 4 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc4b0294-c59cadbf.jpg: 384x640 3 cars, 2 buss, 1 truck, 1 traffic light, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4106/10000 [02:11<03:11, 30.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc4c31e2-f36ad7e8.jpg: 384x640 5 cars, 2 traffic lights, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc4fb79c-561bbfc5.jpg: 384x640 1 person, 2 cars, 1 bus, 3 trucks, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc574681-0a675ff3.jpg: 384x640 (no detections), 13.7ms\n",
            "Speed: 5.9ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc574681-398fb5d1.jpg: 384x640 2 traffic lights, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4110/10000 [02:11<03:14, 30.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc574681-412ec1a0.jpg: 384x640 (no detections), 16.0ms\n",
            "Speed: 5.8ms preprocess, 16.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc574681-b63afd9b.jpg: 384x640 1 car, 1 truck, 1 tv, 14.6ms\n",
            "Speed: 5.9ms preprocess, 14.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5bcfab-07883191.jpg: 384x640 4 cars, 1 bus, 1 truck, 1 traffic light, 14.5ms\n",
            "Speed: 4.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5bcfab-23b275db.jpg: 384x640 1 car, 1 tv, 17.8ms\n",
            "Speed: 2.0ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4114/10000 [02:11<03:26, 28.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5bcfab-a639a82e.jpg: 384x640 3 cars, 1 traffic light, 15.5ms\n",
            "Speed: 3.9ms preprocess, 15.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5bcfab-d233043b.jpg: 384x640 8 cars, 1 traffic light, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5c87da-f8979312.jpg: 384x640 1 person, 3 cars, 2 traffic lights, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4117/10000 [02:11<03:36, 27.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5e32e9-73480461.jpg: 384x640 4 cars, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5e32e9-9471ac2d.jpg: 384x640 5 cars, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5e32e9-f71674c4.jpg: 384x640 4 cars, 1 bus, 16.7ms\n",
            "Speed: 1.8ms preprocess, 16.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5f4677-58898054.jpg: 384x640 1 person, 4 cars, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4121/10000 [02:11<03:25, 28.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5fa92b-97ad7b5d.jpg: 384x640 2 persons, 8 cars, 5 traffic lights, 1 bench, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5fadac-47398ddc.jpg: 384x640 6 cars, 1 truck, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5fadac-790bcdec.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 14.5ms\n",
            "Speed: 4.9ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████      | 4124/10000 [02:11<03:31, 27.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5fadac-96776d48.jpg: 384x640 1 car, 2 trucks, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5fadac-bc6d38cd.jpg: 384x640 5 cars, 1 bus, 6 traffic lights, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc5fadac-fa6dd225.jpg: 384x640 2 cars, 11.1ms\n",
            "Speed: 4.9ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████▏     | 4127/10000 [02:11<03:27, 28.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6091c9-30b92a47.jpg: 384x640 9 cars, 1 truck, 1 traffic light, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6154a5-933918ac.jpg: 384x640 3 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc619446-d2608304.jpg: 384x640 7 cars, 1 truck, 18.3ms\n",
            "Speed: 1.9ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████▏     | 4130/10000 [02:12<03:33, 27.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc621584-2e17dc3d.jpg: 384x640 2 persons, 6 cars, 1 truck, 10.7ms\n",
            "Speed: 3.8ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc621584-f5b1895d.jpg: 384x640 1 person, 4 cars, 1 truck, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc621584-fdabaa99.jpg: 384x640 6 cars, 2 trucks, 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████▏     | 4133/10000 [02:12<03:32, 27.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc63cae9-0690f6dc.jpg: 384x640 5 cars, 1 traffic light, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc63cae9-937f8e06.jpg: 384x640 6 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc63cae9-e06137d7.jpg: 384x640 12 cars, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████▏     | 4136/10000 [02:12<03:36, 27.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc64dc6f-3693a933.jpg: 384x640 4 cars, 14.0ms\n",
            "Speed: 3.7ms preprocess, 14.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc64dc6f-f36a7b16.jpg: 384x640 7 cars, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc653df4-b0005237.jpg: 384x640 7 cars, 1 train, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████▏     | 4139/10000 [02:12<03:45, 26.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc66304a-d6caaab5.jpg: 384x640 2 cars, 3 traffic lights, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc66fedc-6649b88c.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc67b362-fb6767aa.jpg: 384x640 2 cars, 2 traffic lights, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████▏     | 4142/10000 [02:12<03:44, 26.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc67ddf0-874dcf8d.jpg: 384x640 1 person, 9 cars, 1 truck, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc692855-0e184c98.jpg: 384x640 12 cars, 8.3ms\n",
            "Speed: 3.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc692855-56d61af4.jpg: 384x640 5 cars, 1 traffic light, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc692855-7c087cf6.jpg: 384x640 4 cars, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  41%|████▏     | 4146/10000 [02:12<03:25, 28.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc692855-9a7e7c65.jpg: 384x640 4 cars, 1 motorcycle, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc692855-df958197.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6a2a77-88414eb2.jpg: 384x640 6 persons, 2 cars, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6a2a77-e9984397.jpg: 384x640 5 cars, 1 truck, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6a6534-8b519e81.jpg: 384x640 1 person, 7 cars, 1 bus, 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4151/10000 [02:12<03:00, 32.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6a6534-e950719c.jpg: 384x640 5 persons, 7 cars, 1 bus, 1 truck, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6da5d0-7ad70fbc.jpg: 384x640 (no detections), 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6dd79a-5dbc7538.jpg: 384x640 8 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6dd79a-72832b74.jpg: 384x640 4 cars, 3 traffic lights, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4155/10000 [02:12<03:01, 32.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc6dd79a-fa684758.jpg: 384x640 8 cars, 1 traffic light, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc709acb-5b7fbd2f.jpg: 384x640 2 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc715fc7-41291987.jpg: 384x640 2 persons, 7 cars, 2 traffic lights, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc715fc7-70c49d0a.jpg: 384x640 9 cars, 1 truck, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4159/10000 [02:13<03:01, 32.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc715fc7-87a29be4.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc715fc7-fab6edbb.jpg: 384x640 7 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc72e27e-3c6f35f0.jpg: 384x640 1 car, 1 airplane, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7325ea-2146b9aa.jpg: 384x640 12 cars, 1 bus, 1 truck, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4163/10000 [02:13<03:05, 31.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc79227e-0a58fb1d.jpg: 384x640 6 cars, 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc79227e-28da8a63.jpg: 384x640 2 cars, 17.3ms\n",
            "Speed: 5.9ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc79227e-51c8d967.jpg: 384x640 2 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7a0adc-260a111d.jpg: 384x640 8 cars, 1 truck, 19.8ms\n",
            "Speed: 2.0ms preprocess, 19.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4167/10000 [02:13<03:24, 28.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7a0adc-b360c4b1.jpg: 384x640 7 cars, 1 truck, 18.9ms\n",
            "Speed: 2.0ms preprocess, 18.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7a0adc-caf8512c.jpg: 384x640 13 cars, 17.9ms\n",
            "Speed: 1.9ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7a7a1f-45a47a4a.jpg: 384x640 10 cars, 1 truck, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4170/10000 [02:13<03:42, 26.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7a7a1f-4d88e416.jpg: 384x640 4 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7a7a1f-4e38c1f5.jpg: 384x640 5 cars, 1 truck, 18.1ms\n",
            "Speed: 2.0ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7a7a1f-64c449cc.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4173/10000 [02:13<03:48, 25.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7a7a1f-dbeb9406.jpg: 384x640 1 person, 3 cars, 3 traffic lights, 12.1ms\n",
            "Speed: 4.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7b78f1-bdbc2b5a.jpg: 384x640 5 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7bc1e5-2c8a6abe.jpg: 384x640 6 cars, 1 bus, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7bc1e5-b3223500.jpg: 384x640 3 persons, 7 cars, 1 traffic light, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4177/10000 [02:13<03:37, 26.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7c168c-18b8cc31.jpg: 384x640 2 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7caf3c-da14eed9.jpg: 384x640 9 cars, 15.6ms\n",
            "Speed: 2.0ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7cbf85-1a484d84.jpg: 384x640 8 cars, 1 truck, 1 traffic light, 14.3ms\n",
            "Speed: 2.2ms preprocess, 14.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4180/10000 [02:13<03:35, 27.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7cbf85-6f37fbdf.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7cbf85-85f4301c.jpg: 384x640 2 persons, 15 cars, 13.0ms\n",
            "Speed: 3.9ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7e7e2c-1714d279.jpg: 384x640 8 persons, 5 cars, 2 traffic lights, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4183/10000 [02:14<03:40, 26.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7e7e2c-3f42fbae.jpg: 384x640 2 cars, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7e7e2c-6388153c.jpg: 384x640 16 cars, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc7e80ed-0011e5a7.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4186/10000 [02:14<03:37, 26.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc80bb96-eca9a0d6.jpg: 384x640 6 cars, 1 truck, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc80e6a7-46e7ab16.jpg: 384x640 2 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc80e6a7-5df6e500.jpg: 384x640 2 cars, 1 bus, 1 truck, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc80e6a7-6cd79aeb.jpg: 384x640 1 car, 1 traffic light, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4190/10000 [02:14<03:18, 29.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc80e6a7-aafb7124.jpg: 384x640 2 persons, 3 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc83797e-8a4b2d6a.jpg: 384x640 3 cars, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc886b45-3b6d2883.jpg: 384x640 19 cars, 1 traffic light, 14.9ms\n",
            "Speed: 6.3ms preprocess, 14.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4193/10000 [02:14<03:33, 27.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc886d37-5b22c313.jpg: 384x640 2 cars, 1 train, 16.9ms\n",
            "Speed: 1.9ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc88c0cd-a78224ad.jpg: 384x640 4 cars, 1 truck, 2 traffic lights, 21.9ms\n",
            "Speed: 3.6ms preprocess, 21.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc88fd46-45149809.jpg: 384x640 6 persons, 6 cars, 1 truck, 3 traffic lights, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4196/10000 [02:14<03:49, 25.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc88fd46-c20f2648.jpg: 384x640 7 cars, 5 traffic lights, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc896c2e-27a21506.jpg: 384x640 3 cars, 16.0ms\n",
            "Speed: 1.9ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc896c2e-7b08a3ee.jpg: 384x640 3 cars, 12.9ms\n",
            "Speed: 4.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4199/10000 [02:14<03:48, 25.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc8c555a-5f402650.jpg: 384x640 3 persons, 4 cars, 12.6ms\n",
            "Speed: 3.6ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc8cb926-c12df6cb.jpg: 384x640 1 person, 3 cars, 1 truck, 2 traffic lights, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc8ccccd-bbc93b76.jpg: 384x640 14 cars, 1 bus, 2 trucks, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4202/10000 [02:14<03:43, 25.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc8e038e-dc636bde.jpg: 384x640 7 cars, 11.8ms\n",
            "Speed: 3.9ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc8e1605-4005ee7e.jpg: 384x640 9 cars, 1 stop sign, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc8e1605-5c57e4b3.jpg: 384x640 3 cars, 3 traffic lights, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc8f34d9-84c7849d.jpg: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4206/10000 [02:14<03:25, 28.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc8f58aa-05037d38.jpg: 384x640 9 cars, 2 trucks, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc915645-a19e009d.jpg: 384x640 2 cars, 3 traffic lights, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc92a87d-9d40035e.jpg: 384x640 3 cars, 10.9ms\n",
            "Speed: 1.7ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc92a87d-aaafd269.jpg: 384x640 1 person, 8 cars, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4210/10000 [02:14<03:16, 29.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc92c1d7-b310d9e8.jpg: 384x640 2 persons, 4 cars, 1 traffic light, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc92f518-fa316e88.jpg: 384x640 11 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc97328c-1869fa3c.jpg: 384x640 12 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4213/10000 [02:15<03:16, 29.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc97328c-8b9ba7ab.jpg: 384x640 2 persons, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc978e82-e82eee23.jpg: 384x640 1 person, 7 cars, 1 bus, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9880e2-42c6aaac.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 4.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc990749-20748014.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4217/10000 [02:15<03:08, 30.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9b5bfb-51ebcf39.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9cce42-b4577861.jpg: 384x640 6 cars, 1 truck, 5 traffic lights, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9da78f-b423cd9a.jpg: 384x640 3 cars, 16.0ms\n",
            "Speed: 2.0ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9df0ab-6113c685.jpg: 384x640 7 cars, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4221/10000 [02:15<03:14, 29.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9df0ab-9ab2350c.jpg: 384x640 7 cars, 21.0ms\n",
            "Speed: 1.8ms preprocess, 21.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9e1979-8b3e9fcc.jpg: 384x640 8 cars, 1 truck, 14.7ms\n",
            "Speed: 4.8ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9e1979-f1fb1692.jpg: 384x640 2 persons, 1 car, 1 bus, 1 traffic light, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4224/10000 [02:15<03:28, 27.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9f07c9-31204bc9.jpg: 384x640 2 cars, 15.0ms\n",
            "Speed: 3.7ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9f07c9-895feb80.jpg: 384x640 5 cars, 1 bus, 1 train, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9f8a23-228d01e9.jpg: 384x640 10 cars, 1 truck, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4227/10000 [02:15<03:28, 27.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9fdda7-9f95011e.jpg: 384x640 1 car, 1 bus, 1 truck, 9.3ms\n",
            "Speed: 4.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bc9fdda7-c7198a2e.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 3.8ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca10f4f-2deaf782.jpg: 384x640 3 persons, 5 cars, 1 motorcycle, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca15e46-5d0a4a30.jpg: 384x640 1 car, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4231/10000 [02:15<03:11, 30.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca15e46-a3bc3b7a.jpg: 384x640 8 cars, 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca15e46-df06e85a.jpg: 384x640 1 car, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca15e46-ea057e87.jpg: 384x640 1 car, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca1cbed-a81e3dba.jpg: 384x640 6 cars, 1 truck, 1 potted plant, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4235/10000 [02:15<03:11, 30.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca1da7b-ddeeddb1.jpg: 384x640 4 cars, 13.5ms\n",
            "Speed: 2.4ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca2410d-f8e930c3.jpg: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca28d76-e40b21eb.jpg: 384x640 5 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca36352-0381818e.jpg: 384x640 1 person, 3 cars, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4239/10000 [02:15<03:07, 30.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca36352-5de70a3f.jpg: 384x640 6 cars, 18.4ms\n",
            "Speed: 1.9ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca36352-acc82f86.jpg: 384x640 1 person, 2 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca3720a-3423755f.jpg: 384x640 5 cars, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca3720a-642376aa.jpg: 384x640 3 cars, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4243/10000 [02:16<03:04, 31.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca3720a-72374014.jpg: 384x640 1 traffic light, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca3720a-79a8dc89.jpg: 384x640 3 cars, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca3720a-93049dc4.jpg: 384x640 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca3720a-9c3aad8c.jpg: 384x640 6 cars, 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  42%|████▏     | 4247/10000 [02:16<02:57, 32.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca3720a-b4a6a4e4.jpg: 384x640 1 car, 1 traffic light, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca3720a-d372b6ae.jpg: 384x640 (no detections), 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca562b0-3ae25344.jpg: 384x640 5 cars, 1 bus, 17.4ms\n",
            "Speed: 1.8ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca84cbc-1ce525d6.jpg: 384x640 15 cars, 1 truck, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4251/10000 [02:16<03:03, 31.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bca84cbc-800427b6.jpg: 384x640 13 cars, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaa771b-5ace3b37.jpg: 384x640 3 cars, 1 bus, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaa771b-806e4fcd.jpg: 384x640 2 cars, 15.5ms\n",
            "Speed: 2.6ms preprocess, 15.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaa771b-a3595511.jpg: 384x640 1 person, 8 cars, 1 truck, 16.6ms\n",
            "Speed: 3.0ms preprocess, 16.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4255/10000 [02:16<03:21, 28.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcadb48c-9a41d823.jpg: 384x640 10 cars, 1 truck, 17.4ms\n",
            "Speed: 2.6ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcadbe99-a0a27cdc.jpg: 384x640 2 cars, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcade6d5-430ff8e0.jpg: 384x640 6 cars, 1 bus, 1 truck, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4258/10000 [02:16<03:29, 27.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcae6e67-059fedea.jpg: 384x640 6 persons, 1 bicycle, 13 cars, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf57de-8a71dbde.jpg: 384x640 9 cars, 1 traffic light, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-311f299e.jpg: 384x640 2 persons, 1 car, 1 traffic light, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4261/10000 [02:16<03:38, 26.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-3deecc6b.jpg: 384x640 8 cars, 14.1ms\n",
            "Speed: 3.3ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-434e24ad.jpg: 384x640 3 cars, 1 bus, 2 traffic lights, 13.9ms\n",
            "Speed: 3.9ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-48814a50.jpg: 384x640 2 cars, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4264/10000 [02:16<03:34, 26.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-64597611.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-6513f406.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-7b70b7bd.jpg: 384x640 3 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-7be6ff05.jpg: 384x640 5 persons, 2 cars, 1 train, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4268/10000 [02:16<03:16, 29.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-7d7baab1.jpg: 384x640 3 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-838a8ff1.jpg: 384x640 6 cars, 2 traffic lights, 13.5ms\n",
            "Speed: 1.7ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-9433521c.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-9c01f981.jpg: 384x640 11 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4272/10000 [02:17<03:07, 30.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-a0f73960.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-aaa1ce44.jpg: 384x640 7 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-c58fee95.jpg: 384x640 2 traffic lights, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-d16abb7a.jpg: 384x640 9 cars, 1 truck, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4276/10000 [02:17<02:54, 32.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-d7002106.jpg: 384x640 6 cars, 1 traffic light, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-da948771.jpg: 384x640 3 cars, 1 bus, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-e0c7165a.jpg: 384x640 1 person, 5 cars, 1 truck, 2 traffic lights, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcaf73c1-f32b1d31.jpg: 384x640 1 person, 3 cars, 1 truck, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4280/10000 [02:17<02:51, 33.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcafa205-40fde1da.jpg: 384x640 9 cars, 2 buss, 1 truck, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcafa205-9648f156.jpg: 384x640 1 person, 3 cars, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb10424-fd2d3e21.jpg: 384x640 2 cars, 1 traffic light, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb111bb-fed9e9ca.jpg: 384x640 3 cars, 2 trucks, 18.1ms\n",
            "Speed: 2.6ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4284/10000 [02:17<03:01, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb2c6fd-05ee678b.jpg: 384x640 15 cars, 19.7ms\n",
            "Speed: 2.6ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb2c6fd-060efb1b.jpg: 384x640 11 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb2c6fd-094b605f.jpg: 384x640 1 person, 12 cars, 1 traffic light, 15.6ms\n",
            "Speed: 3.3ms preprocess, 15.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb2c6fd-4999b083.jpg: 384x640 3 cars, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4288/10000 [02:17<03:25, 27.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb356f6-520dd65c.jpg: 384x640 18 cars, 1 bus, 1 truck, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb356f6-dc4b62fd.jpg: 384x640 10 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb3c18a-702288dc.jpg: 384x640 9 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4291/10000 [02:17<03:22, 28.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb3c18a-fad48b76.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcb441fc-a88da923.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbaa999-aeee8ed7.jpg: 384x640 2 cars, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbab238-93cacd35.jpg: 384x640 6 cars, 1 truck, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4295/10000 [02:17<03:10, 29.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbab238-e79b7395.jpg: 384x640 1 person, 19 cars, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbb5180-96cfedbe.jpg: 384x640 3 cars, 1 train, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbb5f4d-93c5f35d.jpg: 384x640 5 cars, 1 truck, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbbbb55-4245620b.jpg: 384x640 10 cars, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4299/10000 [02:17<03:09, 30.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbbfd82-1ca5bba1.jpg: 384x640 9 cars, 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbbfd82-add80c05.jpg: 384x640 12 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbbfd82-bcc937d0.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbbfe2a-33e57bea.jpg: 384x640 1 person, 15 cars, 3 traffic lights, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4303/10000 [02:18<03:12, 29.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbbfe2a-49d953fb.jpg: 384x640 8 cars, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbc98a8-5f8e6e4f.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbc98a8-a22cb67b.jpg: 384x640 2 cars, 3 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbc98a8-c87dc426.jpg: 384x640 5 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4307/10000 [02:18<03:02, 31.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbd5ef7-af0cef1a.jpg: 384x640 10 cars, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbd66a2-50519d2b.jpg: 384x640 13 cars, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbe3164-1af2bcb3.jpg: 384x640 9 cars, 1 truck, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbf328d-953430de.jpg: 384x640 12 cars, 1 traffic light, 17.3ms\n",
            "Speed: 3.0ms preprocess, 17.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4311/10000 [02:18<03:17, 28.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbf4834-88a0b878.jpg: 384x640 5 cars, 2 buss, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbf4834-ad592e12.jpg: 384x640 1 person, 7 cars, 1 traffic light, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbf4834-eed0f97c.jpg: 384x640 1 car, 2 buss, 1 truck, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4314/10000 [02:18<03:15, 29.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbfab33-5add26c9.jpg: 384x640 4 cars, 1 truck, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbfbfb8-297deca0.jpg: 384x640 7 cars, 2 buss, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcbfbfb8-5defbc12.jpg: 384x640 5 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4317/10000 [02:18<03:14, 29.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcc4efaf-023c2a93.jpg: 384x640 13 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcc567b5-5d1fd0d6.jpg: 384x640 9 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcc5eb03-0660b926.jpg: 384x640 2 cars, 3 traffic lights, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcc844b0-22c90a40.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4321/10000 [02:18<03:05, 30.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcc84a33-2b38c69f.jpg: 384x640 8 cars, 3 buss, 3 trucks, 1 traffic light, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcc942dc-d64dc48f.jpg: 384x640 4 cars, 2 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bccad38e-0f5097a8.jpg: 384x640 4 cars, 3 traffic lights, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bccbf939-28a692c6.jpg: 384x640 4 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4325/10000 [02:18<03:03, 30.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bccbf939-6f2751c6.jpg: 384x640 5 cars, 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bccd4f82-5c8f9f28.jpg: 384x640 1 person, 3 cars, 3 trucks, 1 traffic light, 9.3ms\n",
            "Speed: 5.7ms preprocess, 9.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd02ab4-27b39461.jpg: 384x640 1 person, 7 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd02ab4-440fd7e6.jpg: 384x640 7 cars, 1 bus, 2 trucks, 2 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4329/10000 [02:18<03:04, 30.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd02ab4-9a15965c.jpg: 384x640 9 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd02ab4-fc291124.jpg: 384x640 1 person, 4 cars, 2 traffic lights, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd166b2-944298cd.jpg: 384x640 1 person, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd32109-8b0b1eef.jpg: 384x640 11 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4333/10000 [02:19<03:01, 31.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd37eef-1b958ae3.jpg: 384x640 7 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd37eef-4eabe9f6.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd53258-8754ded0.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd596fa-74094968.jpg: 384x640 3 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4337/10000 [02:19<02:52, 32.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd596fa-d4c78bb9.jpg: 384x640 15 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd8fde8-51118aa7.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd900a7-02adf687.jpg: 384x640 6 cars, 2 trucks, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd9f474-7f12bf92.jpg: 384x640 3 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4341/10000 [02:19<02:53, 32.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcd9f474-c3a440b8.jpg: 384x640 1 traffic light, 1 fire hydrant, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcde71de-1bf86b19.jpg: 384x640 2 persons, 2 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcde71de-211d8a7d.jpg: 384x640 2 traffic lights, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcde71de-ac5c8c74.jpg: 384x640 13 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4345/10000 [02:19<02:55, 32.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcde71de-fcf3da5c.jpg: 384x640 1 person, 3 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcde8605-3775efc5.jpg: 384x640 9 cars, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce0262b-e0b48a31.jpg: 384x640 8 cars, 2 trucks, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce05158-6821fc1f.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  43%|████▎     | 4349/10000 [02:19<02:56, 32.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce0e6a5-b08b2906.jpg: 384x640 6 cars, 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce107ec-cae593c8.jpg: 384x640 8 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce15cb0-2d6aec27.jpg: 384x640 1 person, 6 cars, 1 bus, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce1e185-c51123bb.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▎     | 4353/10000 [02:19<02:49, 33.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce1e185-db36dbdc.jpg: 384x640 14 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce2038a-e0f8e4ba.jpg: 384x640 4 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce30c65-fbfaa66a.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce62e5c-19d7f2ce.jpg: 384x640 3 persons, 4 cars, 3 trucks, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▎     | 4357/10000 [02:19<02:45, 34.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce89210-5c5a9657.jpg: 384x640 2 cars, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bce8d1ba-60984f07.jpg: 384x640 2 persons, 1 car, 1 traffic light, 7.7ms\n",
            "Speed: 2.2ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcea7303-e7f7d067.jpg: 384x640 5 persons, 4 cars, 1 bus, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcea7303-fc913f70.jpg: 384x640 2 persons, 5 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▎     | 4361/10000 [02:19<02:48, 33.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bceab139-bcc7b224.jpg: 384x640 5 cars, 5 traffic lights, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcec9d23-1430d31c.jpg: 384x640 7 persons, 1 bicycle, 6 cars, 12.8ms\n",
            "Speed: 6.0ms preprocess, 12.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcec9d23-4e8e0704.jpg: 384x640 1 bus, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcecdb4d-825f09d4.jpg: 384x640 10 persons, 6 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▎     | 4365/10000 [02:20<02:59, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bced42eb-0b9944b1.jpg: 384x640 7 cars, 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bced42eb-bfff2d8f.jpg: 384x640 3 cars, 12.6ms\n",
            "Speed: 4.8ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bceeedca-f0bf8606.jpg: 384x640 1 person, 8 cars, 1 truck, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcef3e08-16df1f59.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▎     | 4369/10000 [02:20<02:53, 32.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcef3e08-801cf8bd.jpg: 384x640 8 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcef3e08-9d61dcb5.jpg: 384x640 4 cars, 2 traffic lights, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcef7536-5c2e5a49.jpg: 384x640 3 cars, 2 traffic lights, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf0401c-3f464d19.jpg: 384x640 4 persons, 4 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▎     | 4373/10000 [02:20<02:49, 33.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf483bd-153ab23c.jpg: 384x640 9 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf55067-920ad457.jpg: 384x640 3 persons, 6 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf55067-c58fe85b.jpg: 384x640 2 persons, 7 cars, 1 traffic light, 1 backpack, 17.4ms\n",
            "Speed: 3.5ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf70f06-5bd41cdd.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4377/10000 [02:20<03:02, 30.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf7f6b9-8819dc29.jpg: 384x640 1 car, 12.7ms\n",
            "Speed: 3.9ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf7f6b9-88bfed8f.jpg: 384x640 16 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf7f6b9-fc7c487f.jpg: 384x640 1 car, 1 bus, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf80398-cbb33b84.jpg: 384x640 2 persons, 3 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4381/10000 [02:20<03:04, 30.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf8b229-8bcd6901.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcf9cd99-5a125838.jpg: 384x640 9 cars, 2 traffic lights, 2 potted plants, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcfb58e2-8a7a1c9c.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcfc54ad-c713893a.jpg: 384x640 5 cars, 1 bus, 2 trucks, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4385/10000 [02:20<02:57, 31.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcfd6756-af532d4e.jpg: 384x640 5 cars, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcfdd6af-698c03e3.jpg: 384x640 1 person, 15 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bcfdd6af-c3d0b55a.jpg: 384x640 1 person, 2 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd026bc5-1d80043b.jpg: 384x640 4 persons, 4 cars, 1 traffic light, 8.7ms\n",
            "Speed: 2.6ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4389/10000 [02:20<02:51, 32.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd026bc5-7d3bf0ef.jpg: 384x640 8 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd026bc5-9418706c.jpg: 384x640 2 persons, 6 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0380e5-846f84bb.jpg: 384x640 8 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0380e5-8a498679.jpg: 384x640 7 cars, 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4393/10000 [02:20<02:51, 32.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0380e5-bc2886de.jpg: 384x640 3 cars, 1 train, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0380e5-de0cc7cb.jpg: 384x640 2 cars, 2 trucks, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0550ce-ad1da2ed.jpg: 384x640 7 cars, 1 traffic light, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd056a69-676260f6.jpg: 384x640 1 car, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4397/10000 [02:21<02:46, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd05c4b3-a22bd6c8.jpg: 384x640 14 cars, 11.9ms\n",
            "Speed: 6.3ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0829be-0bb0f1cb.jpg: 384x640 5 cars, 2 trucks, 1 traffic light, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0829be-8ed71976.jpg: 384x640 12 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0829be-ba790c09.jpg: 384x640 14 cars, 2 trucks, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4401/10000 [02:21<02:52, 32.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd08d471-cb9e4be6.jpg: 384x640 2 cars, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0a1433-99c735e8.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0b3e14-8b246958.jpg: 384x640 1 person, 8 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd0db9ed-cdca9422.jpg: 384x640 5 persons, 7 cars, 1 motorcycle, 1 traffic light, 1 umbrella, 1 handbag, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4405/10000 [02:21<02:54, 32.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd115f00-0b9baf0b.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd121728-992c6e4f.jpg: 384x640 5 cars, 1 truck, 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd137ab1-ab686c3d.jpg: 384x640 1 car, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd138b54-7e85623f.jpg: 384x640 5 cars, 1 bus, 2 traffic lights, 15.2ms\n",
            "Speed: 3.6ms preprocess, 15.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4409/10000 [02:21<02:57, 31.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1416c5-7de887bb.jpg: 384x640 3 cars, 1 truck, 16.8ms\n",
            "Speed: 2.3ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1416c5-e973335b.jpg: 384x640 4 cars, 20.6ms\n",
            "Speed: 1.7ms preprocess, 20.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1493ce-0aa8dff9.jpg: 384x640 4 cars, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1493ce-17a1f286.jpg: 384x640 1 truck, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4413/10000 [02:21<03:03, 30.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd14a97d-cb209ed9.jpg: 384x640 6 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd16d59f-bd4eedcd.jpg: 384x640 4 cars, 1 truck, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd16f675-095a9e20.jpg: 384x640 8 cars, 15.9ms\n",
            "Speed: 1.8ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd17816c-ad66db63.jpg: 384x640 11 cars, 1 truck, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4417/10000 [02:21<03:07, 29.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1a890a-bfdbea88.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1ae0c2-325d1820.jpg: 384x640 1 person, 9 cars, 1 truck, 4 traffic lights, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1ae0c2-a649baaa.jpg: 384x640 3 cars, 3 traffic lights, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1ae0c2-dfbaafca.jpg: 384x640 4 cars, 1 bus, 1 truck, 1 traffic light, 9.8ms\n",
            "Speed: 2.6ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4421/10000 [02:21<02:58, 31.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1b8b79-10f4b3af.jpg: 384x640 5 persons, 3 cars, 1 umbrella, 1 handbag, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1b8b79-16ecdafa.jpg: 384x640 4 persons, 1 bicycle, 5 cars, 4 traffic lights, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1b8b79-49b0729c.jpg: 384x640 4 cars, 2 traffic lights, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1b8b79-6a41406e.jpg: 384x640 1 car, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4425/10000 [02:21<02:51, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1b8b79-829e787f.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1b8b79-b42eda04.jpg: 384x640 4 cars, 1 bus, 1 truck, 1 traffic light, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1b8b79-ba219f33.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1b8b79-eb8f047f.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4429/10000 [02:22<02:42, 34.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1bdca8-3cc740b7.jpg: 384x640 10 cars, 2 traffic lights, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1c6dd5-1534269e.jpg: 384x640 3 cars, 1 bus, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1cf9f7-e0d0fcd9.jpg: 384x640 1 car, 1 traffic light, 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1d310c-f5fb429f.jpg: 384x640 3 persons, 1 bicycle, 6 cars, 1 motorcycle, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4433/10000 [02:22<02:44, 33.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1d6a81-01f9b2c4.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1e4e5b-2a9ffc3f.jpg: 384x640 5 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1e4e5b-694e62a6.jpg: 384x640 1 person, 6 cars, 1 traffic light, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1e4e5b-cefe603f.jpg: 384x640 1 person, 4 cars, 1 traffic light, 17.4ms\n",
            "Speed: 3.1ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4437/10000 [02:22<02:46, 33.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd1e9944-4fd7ac70.jpg: 384x640 2 cars, 3 trucks, 16.4ms\n",
            "Speed: 3.4ms preprocess, 16.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd204fcd-75ab6967.jpg: 384x640 10 cars, 1 truck, 18.2ms\n",
            "Speed: 3.1ms preprocess, 18.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd21d7a7-85941f4d.jpg: 384x640 5 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd22225e-3eeb6fda.jpg: 384x640 7 cars, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4441/10000 [02:22<03:05, 30.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd22225e-664f20be.jpg: 384x640 13 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd239c09-07398e07.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd239c09-f3112785.jpg: 384x640 1 person, 4 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd2646a4-977c94a5.jpg: 384x640 5 cars, 1 clock, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4445/10000 [02:22<02:59, 30.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd28ebc2-4de19d20.jpg: 384x640 9 cars, 1 truck, 1 stop sign, 10.8ms\n",
            "Speed: 5.9ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd290539-038f7b75.jpg: 384x640 1 car, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd290539-e1efc276.jpg: 384x640 2 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd290539-e7fe47b4.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  44%|████▍     | 4449/10000 [02:22<02:55, 31.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd2cad94-ee63e010.jpg: 384x640 12 cars, 1 truck, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd2dfe52-a557f832.jpg: 384x640 7 cars, 1 airplane, 1 bus, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd2fd996-71e2a020.jpg: 384x640 4 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd2fd996-9d659d30.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4453/10000 [02:22<02:50, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd31fb8b-28ae6a12.jpg: 384x640 1 person, 4 cars, 1 train, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd320d5f-f6fd0850.jpg: 384x640 10 cars, 1 truck, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd338426-4b27de63.jpg: 384x640 8 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd338426-a0b4e877.jpg: 384x640 2 cars, 1 truck, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4457/10000 [02:22<02:44, 33.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd34d992-8b08de8e.jpg: 384x640 1 car, 1 train, 1 stop sign, 9.1ms\n",
            "Speed: 2.8ms preprocess, 9.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd354e59-e5a9e8c6.jpg: 384x640 19 cars, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-3c7a6e8f.jpg: 384x640 1 person, 4 cars, 1 traffic light, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-5054cb5f.jpg: 384x640 19 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4461/10000 [02:23<02:52, 32.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-63dd68f2.jpg: 384x640 12 cars, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-677a5dc3.jpg: 384x640 7 cars, 1 traffic light, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-6e341b88.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-866c64d7.jpg: 384x640 1 car, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4465/10000 [02:23<02:50, 32.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-b2b25a24.jpg: 384x640 7 cars, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-bbc127e0.jpg: 384x640 2 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-bbe3eda5.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-be35dcf2.jpg: 384x640 1 person, 1 car, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4469/10000 [02:23<02:52, 32.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-c72ca547.jpg: 384x640 4 traffic lights, 15.4ms\n",
            "Speed: 3.2ms preprocess, 15.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-c7aa3ca3.jpg: 384x640 6 cars, 2 traffic lights, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd355fcc-e43df88a.jpg: 384x640 1 person, 5 cars, 1 train, 1 truck, 16.9ms\n",
            "Speed: 3.9ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd39c71a-5f45bcc3.jpg: 384x640 3 cars, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4473/10000 [02:23<03:10, 29.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3a9dfd-4b1dd476.jpg: 384x640 5 cars, 16.6ms\n",
            "Speed: 6.0ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3bd3ab-4c7b11e8.jpg: 384x640 4 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3bd3ab-79f6d287.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4476/10000 [02:23<03:09, 29.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3bd3ab-8e38f822.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3bd3ab-95751d80.jpg: 384x640 6 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3bd3ab-c51f41b3.jpg: 384x640 10 cars, 1 truck, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3bd3ab-cfd5b40e.jpg: 384x640 4 cars, 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4480/10000 [02:23<03:02, 30.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3bd3ab-d7f3de9e.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3bfd8d-733939c0.jpg: 384x640 1 person, 5 cars, 1 umbrella, 1 potted plant, 9.3ms\n",
            "Speed: 1.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3c3916-579aeb09.jpg: 384x640 2 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd3dc2ff-243f2c63.jpg: 384x640 5 cars, 1 bus, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4484/10000 [02:23<02:49, 32.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd415d27-9b1d4637.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd422ce5-0045fc82.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd442c6f-16ff171d.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd442c6f-29611c5e.jpg: 384x640 1 person, 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd442c6f-d404189c.jpg: 384x640 1 person, 14 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4489/10000 [02:23<02:37, 34.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4518ef-21d8ee40.jpg: 384x640 2 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4518ef-be6a7922.jpg: 384x640 1 person, 4 cars, 1 truck, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4518ef-c38baa13.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4518ef-d4c1fa7f.jpg: 384x640 8 cars, 5 traffic lights, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4493/10000 [02:24<02:37, 34.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd46953e-1bb2f914.jpg: 384x640 16 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd46953e-3f51d76e.jpg: 384x640 9 cars, 2 buss, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd46bba0-2990928d.jpg: 384x640 1 car, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd46bba0-926dc1db.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▍     | 4497/10000 [02:24<02:37, 35.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd46bba0-fadf1d6d.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4a61fd-4b64ea82.jpg: 384x640 5 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4a61fd-89e74e0f.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 5.8ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4a61fd-fb447d72.jpg: 384x640 9 cars, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4501/10000 [02:24<02:35, 35.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4aeaaf-a26c8bc2.jpg: 384x640 11 cars, 1 truck, 17.4ms\n",
            "Speed: 2.0ms preprocess, 17.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4c1d7e-24700e36.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4c1d7e-9edc4d74.jpg: 384x640 3 cars, 1 bus, 13.6ms\n",
            "Speed: 3.9ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4c8e34-0a6f19e0.jpg: 384x640 5 cars, 1 traffic light, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4505/10000 [02:24<02:46, 33.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd4f2165-76098163.jpg: 384x640 1 person, 3 cars, 1 tv, 11.4ms\n",
            "Speed: 2.7ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd50478a-4eb79ba3.jpg: 384x640 3 cars, 3 trucks, 5 traffic lights, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd50478a-7c1e236c.jpg: 384x640 3 cars, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd50478a-8a65e55f.jpg: 384x640 2 persons, 6 cars, 1 truck, 4 traffic lights, 12.4ms\n",
            "Speed: 2.6ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4509/10000 [02:24<02:49, 32.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd50478a-9599eab3.jpg: 384x640 3 cars, 1 bus, 1 truck, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd505c1f-26a9accf.jpg: 384x640 4 cars, 4 traffic lights, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd507fe5-c54d7cb2.jpg: 384x640 1 person, 3 cars, 1 truck, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd507fe5-eca39153.jpg: 384x640 3 persons, 5 cars, 1 truck, 1 traffic light, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4513/10000 [02:24<02:58, 30.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd50d9a3-1e2466bf.jpg: 384x640 (no detections), 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd512863-2e6735a4.jpg: 384x640 1 person, 5 cars, 1 truck, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd512863-814ab9b3.jpg: 384x640 1 car, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd51fb57-1ac69b0a.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4517/10000 [02:24<02:50, 32.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd51fb57-d6436f78.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd51fb57-fee52768.jpg: 384x640 7 cars, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd52701c-66ce9738.jpg: 384x640 (no detections), 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd554ae8-2c8c08df.jpg: 384x640 1 person, 5 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4521/10000 [02:24<02:41, 33.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd554ae8-bcb18664.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd57e60e-04fe485e.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd57e60e-187054e3.jpg: 384x640 4 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd57e60e-1e11a4e0.jpg: 384x640 12 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4525/10000 [02:24<02:35, 35.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd57e60e-504a870b.jpg: 384x640 1 car, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd57e60e-d36607eb.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd57e60e-f3226561.jpg: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5a0062-2a7bbf28.jpg: 384x640 3 traffic lights, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4529/10000 [02:25<02:30, 36.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5a0062-a5d1cf03.jpg: 384x640 5 cars, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5a0062-af4b8c8c.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5a0062-b4ca75f1.jpg: 384x640 5 cars, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5a0062-f2543986.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4533/10000 [02:25<02:28, 36.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5a0062-f462f63f.jpg: 384x640 1 person, 7 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5a17ac-7ca4403f.jpg: 384x640 1 person, 2 cars, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5bb58b-24a6f5e7.jpg: 384x640 2 cars, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5bb58b-7087c7f3.jpg: 384x640 2 persons, 2 cars, 1 truck, 15.4ms\n",
            "Speed: 2.6ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4537/10000 [02:25<02:31, 35.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5bb58b-7c049603.jpg: 384x640 2 cars, 18.8ms\n",
            "Speed: 2.9ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5bb58b-7daa536b.jpg: 384x640 1 person, 5 cars, 2 traffic lights, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5c34f4-32c7b145.jpg: 384x640 2 cars, 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5c34f4-52ef24cd.jpg: 384x640 6 cars, 21.6ms\n",
            "Speed: 1.8ms preprocess, 21.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4541/10000 [02:25<02:54, 31.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5c34f4-f39f6dfc.jpg: 384x640 1 car, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5cf21a-e6b9587e.jpg: 384x640 5 cars, 1 truck, 3 traffic lights, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5d35a0-1357b0da.jpg: 384x640 1 car, 15.6ms\n",
            "Speed: 1.8ms preprocess, 15.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5e7386-b01b09fb.jpg: 384x640 (no detections), 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4545/10000 [02:25<02:54, 31.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5e847a-dd8e1bb1.jpg: 384x640 3 cars, 6 traffic lights, 1 stop sign, 15.8ms\n",
            "Speed: 2.4ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5e847a-fff41819.jpg: 384x640 1 person, 5 trucks, 15.6ms\n",
            "Speed: 2.4ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5f0e20-1792f900.jpg: 384x640 4 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5f8f37-b3008fa1.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  45%|████▌     | 4549/10000 [02:25<03:05, 29.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5fe5fb-dfcd1cd2.jpg: 384x640 3 persons, 6 cars, 2 trucks, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd5ff552-c187e5df.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd60211c-05ed033f.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd60211c-07f21245.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4553/10000 [02:25<02:52, 31.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd60211c-16e100ad.jpg: 384x640 6 cars, 1 bus, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd605431-86ad04a8.jpg: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.7ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd60d984-66b1a49f.jpg: 384x640 12 cars, 1 bus, 1 truck, 1 traffic light, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd626633-996f4be9.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4557/10000 [02:25<02:44, 33.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd626633-ad3626a7.jpg: 384x640 5 persons, 2 cars, 1 train, 1 traffic light, 17.2ms\n",
            "Speed: 1.8ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd64fd99-26f9d430.jpg: 384x640 6 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd64fd99-8e69563f.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd656105-bfcf9d5c.jpg: 384x640 10 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4561/10000 [02:26<02:43, 33.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd656105-db296383.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd656105-ed6f8161.jpg: 384x640 3 persons, 10 cars, 2 traffic lights, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd656105-efa0deab.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd656502-f04cf4da.jpg: 384x640 1 person, 2 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4565/10000 [02:26<02:41, 33.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6587ba-95d6751f.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd65dd37-4c3cdf2d.jpg: 384x640 2 cars, 1 bus, 1 truck, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd67113a-5b83fcdb.jpg: 384x640 2 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd686201-03e84da0.jpg: 384x640 3 cars, 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4569/10000 [02:26<02:42, 33.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6a2c09-b3b84f57.jpg: 384x640 3 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6b95b2-28d783a3.jpg: 384x640 2 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6c7aef-750b28cc.jpg: 384x640 3 persons, 4 cars, 1 truck, 1 traffic light, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6c7aef-f3373443.jpg: 384x640 7 persons, 3 cars, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4573/10000 [02:26<02:49, 31.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6ca291-74e28b01.jpg: 384x640 2 persons, 7 cars, 1 bus, 2 trucks, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6ca291-923cc95a.jpg: 384x640 4 persons, 8 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6ca291-fe4a1b48.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6dcefc-3af00f57.jpg: 384x640 8 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4577/10000 [02:26<02:45, 32.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd6dcefc-68d695b9.jpg: 384x640 4 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd70577b-474e104b.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd70577b-57a066d8.jpg: 384x640 2 cars, 19.4ms\n",
            "Speed: 1.8ms preprocess, 19.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd70577b-b4dd3097.jpg: 384x640 5 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4581/10000 [02:26<02:45, 32.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd715c1c-09221d95.jpg: 384x640 7 cars, 1 traffic light, 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd735753-10912d8b.jpg: 384x640 12 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd735753-1451d21f.jpg: 384x640 7 cars, 1 bus, 3 trucks, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd735753-49b2ce68.jpg: 384x640 6 cars, 1 bus, 1 traffic light, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4585/10000 [02:26<02:45, 32.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd735753-5d67127a.jpg: 384x640 6 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd75454a-69e7f645.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd75e563-15ee6e1d.jpg: 384x640 1 person, 8 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd7c460d-4a317a77.jpg: 384x640 1 car, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4589/10000 [02:26<02:42, 33.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd7cb9e1-65b08f46.jpg: 384x640 2 cars, 1 tv, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd7cb9e1-eb5b2227.jpg: 384x640 2 cars, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd7ccf83-18bccb70.jpg: 384x640 (no detections), 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd7d1552-c7a94b06.jpg: 384x640 1 person, 8 cars, 1 truck, 3 traffic lights, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4593/10000 [02:27<02:45, 32.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd7f150c-c557afa7.jpg: 384x640 1 car, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd7f7061-601abafd.jpg: 384x640 1 truck, 1 traffic light, 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd812175-88bdcb99.jpg: 384x640 2 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd812175-d418c63b.jpg: 384x640 8 cars, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4597/10000 [02:27<02:43, 33.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd812175-fc557aa4.jpg: 384x640 1 car, 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd816a01-87bcd028.jpg: 384x640 2 cars, 17.1ms\n",
            "Speed: 1.8ms preprocess, 17.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd816a01-fa31ce3d.jpg: 384x640 3 cars, 1 traffic light, 19.5ms\n",
            "Speed: 2.4ms preprocess, 19.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd8268a2-a924aa0b.jpg: 384x640 9 cars, 19.1ms\n",
            "Speed: 2.1ms preprocess, 19.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4601/10000 [02:27<02:57, 30.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd82f517-793eb747.jpg: 384x640 8 cars, 1 truck, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd82f517-d1af5063.jpg: 384x640 3 persons, 6 bicycles, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd8aa347-4a6405a9.jpg: 384x640 4 cars, 17.5ms\n",
            "Speed: 2.2ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd8d420d-ec34c634.jpg: 384x640 1 person, 7 cars, 1 truck, 14.9ms\n",
            "Speed: 3.4ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4605/10000 [02:27<03:02, 29.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd8e0b69-64d450fe.jpg: 384x640 11 cars, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd8f4dfa-4e126a95.jpg: 384x640 1 train, 14.8ms\n",
            "Speed: 2.5ms preprocess, 14.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd8f4dfa-52cf9375.jpg: 384x640 6 cars, 1 bus, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd8f5fcd-2f54a72b.jpg: 384x640 6 persons, 13 cars, 19.1ms\n",
            "Speed: 2.0ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4609/10000 [02:27<03:08, 28.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd8f5fcd-e5d1d498.jpg: 384x640 10 cars, 1 truck, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd92c756-0eee51cd.jpg: 384x640 3 cars, 1 traffic light, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd92c756-1eafae31.jpg: 384x640 1 person, 2 cars, 1 bus, 2 trucks, 1 traffic light, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd92c756-d4b30972.jpg: 384x640 2 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4613/10000 [02:27<03:03, 29.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd92f6ee-8128cb11.jpg: 384x640 1 person, 9 cars, 16.4ms\n",
            "Speed: 1.8ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd92f6ee-e7e097b5.jpg: 384x640 2 cars, 1 fire hydrant, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd931a20-031fbc84.jpg: 384x640 12 cars, 17.1ms\n",
            "Speed: 1.9ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4616/10000 [02:27<03:02, 29.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd931a20-7ed66a53.jpg: 384x640 8 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd937f4d-6c06e8b4.jpg: 384x640 4 cars, 1 truck, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd956549-140a4edf.jpg: 384x640 8 persons, 2 cars, 1 traffic light, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd958472-d0a74e2f.jpg: 384x640 2 cars, 1 bench, 1 chair, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4620/10000 [02:27<03:01, 29.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd95af88-2228e86b.jpg: 384x640 9 cars, 1 potted plant, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9881c7-682619d1.jpg: 384x640 1 person, 2 cars, 1 truck, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd98917f-b19d03f7.jpg: 384x640 3 cars, 2 trucks, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▌     | 4623/10000 [02:28<03:03, 29.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd989210-0c8eacc1.jpg: 384x640 3 cars, 1 truck, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd989210-5855f1e4.jpg: 384x640 3 persons, 2 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd989210-afaf7243.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd989210-c3df0371.jpg: 384x640 2 persons, 7 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▋     | 4627/10000 [02:28<03:01, 29.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd989210-d2369f97.jpg: 384x640 4 cars, 14.8ms\n",
            "Speed: 2.0ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd989210-ecdee00d.jpg: 384x640 2 persons, 4 cars, 1 bus, 1 truck, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd998983-63d9420a.jpg: 384x640 7 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd99cc57-f7a56498.jpg: 384x640 10 cars, 1 fire hydrant, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▋     | 4631/10000 [02:28<02:55, 30.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd99da12-66a3321c.jpg: 384x640 10 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9ad5aa-3d7d3c6b.jpg: 384x640 12 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9ad5aa-fe1b1a19.jpg: 384x640 1 car, 18.3ms\n",
            "Speed: 1.9ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9d3b75-78d7026c.jpg: 384x640 2 cars, 1 truck, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▋     | 4635/10000 [02:28<02:52, 31.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9d3b75-c7800908.jpg: 384x640 7 cars, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9dbebc-30ccb9f3.jpg: 384x640 6 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9dbebc-c0b5de37.jpg: 384x640 3 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9dbebc-e5756011.jpg: 384x640 7 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▋     | 4639/10000 [02:28<02:46, 32.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9dbebc-fc042836.jpg: 384x640 3 cars, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9fdd5a-4c17304a.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9fdd5a-6ef5f943.jpg: 384x640 3 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9fdd5a-85eca2d7.jpg: 384x640 3 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▋     | 4643/10000 [02:28<02:38, 33.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bd9fdd5a-adc5bd8b.jpg: 384x640 3 persons, 4 cars, 2 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda04f67-927d28d6.jpg: 384x640 12 cars, 1 truck, 11.7ms\n",
            "Speed: 5.3ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda149bd-02d7100c.jpg: 384x640 6 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda1719b-476378b3.jpg: 384x640 3 cars, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  46%|████▋     | 4647/10000 [02:28<02:36, 34.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda1cdfa-5da26736.jpg: 384x640 7 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda1cdfa-a4626edd.jpg: 384x640 7 cars, 1 truck, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda1cdfa-ecdcbce2.jpg: 384x640 6 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda20cf9-07b680fc.jpg: 384x640 3 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4651/10000 [02:28<02:38, 33.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda20cf9-258f2c93.jpg: 384x640 10 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda2a452-8a54fc2c.jpg: 384x640 3 cars, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda2a452-dd99ae7d.jpg: 384x640 15 cars, 1 truck, 11.1ms\n",
            "Speed: 5.1ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda35230-332be7ac.jpg: 384x640 6 cars, 1 truck, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4655/10000 [02:29<02:45, 32.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda3c743-b1fd3647.jpg: 384x640 5 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda46285-116182b2.jpg: 384x640 6 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda46285-1ec1d198.jpg: 384x640 1 person, 11 cars, 1 truck, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda48a2c-ea6ab69b.jpg: 384x640 3 persons, 2 cars, 1 bus, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4659/10000 [02:29<02:38, 33.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda52dd7-f0a0dd1a.jpg: 384x640 1 car, 1 bus, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda60c48-07ab78ed.jpg: 384x640 1 car, 1 bus, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda73daa-db213864.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda88326-42cec697.jpg: 384x640 1 person, 2 cars, 1 bus, 1 truck, 1 fire hydrant, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4663/10000 [02:29<02:31, 35.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda8b780-12d402fd.jpg: 384x640 4 cars, 11.8ms\n",
            "Speed: 2.7ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda90d90-4fff70f2.jpg: 384x640 10 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bda9da90-68225671.jpg: 384x640 7 cars, 1 traffic light, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdaa85ab-e9df4c81.jpg: 384x640 5 cars, 11.7ms\n",
            "Speed: 2.3ms preprocess, 11.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4667/10000 [02:29<02:41, 33.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdaa98a5-d23583cb.jpg: 384x640 1 person, 6 cars, 1 truck, 2 traffic lights, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdabbd46-59d2ac28.jpg: 384x640 1 truck, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdabbd46-c58c1d2f.jpg: 384x640 1 person, 6 cars, 1 bus, 1 traffic light, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdacfa22-5563c8aa.jpg: 384x640 2 persons, 1 car, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4671/10000 [02:29<02:37, 33.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdad4028-be5b45a6.jpg: 384x640 3 cars, 2 traffic lights, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdae005f-1c0f2e8b.jpg: 384x640 3 cars, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdae005f-3d4f771f.jpg: 384x640 7 cars, 1 truck, 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdae005f-7823c05b.jpg: 384x640 4 cars, 2 trucks, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdae005f-7e7e0f56.jpg: 384x640 7 cars, 1 truck, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4676/10000 [02:29<02:30, 35.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdae005f-d0bb4101.jpg: 384x640 4 cars, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdae464f-1fc229cc.jpg: 384x640 1 person, 3 cars, 1 traffic light, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdae58fa-d3c8737c.jpg: 384x640 1 person, 8 cars, 1 traffic light, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdaeda37-6b0b9900.jpg: 384x640 5 cars, 1 truck, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4680/10000 [02:29<02:37, 33.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdaeda37-9cc73420.jpg: 384x640 1 car, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdaeda37-a0d637e0.jpg: 384x640 1 car, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdaeda37-dfe74a95.jpg: 384x640 4 cars, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdafde0d-03216895.jpg: 384x640 2 persons, 2 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4684/10000 [02:29<02:31, 35.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb035d5-c1048cf3.jpg: 384x640 4 cars, 2 traffic lights, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb26d74-327526b3.jpg: 384x640 (no detections), 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb2f6cb-5c0f0ee8.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb2f6cb-8da5fa42.jpg: 384x640 1 person, 6 cars, 7.8ms\n",
            "Speed: 3.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4688/10000 [02:30<02:32, 34.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb3c90f-095103e9.jpg: 384x640 1 person, 11 cars, 1 truck, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb3c90f-ad6c3d26.jpg: 384x640 12 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb3c90f-dba6400e.jpg: 384x640 2 cars, 1 bus, 1 truck, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb56045-34d3f697.jpg: 384x640 8 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4692/10000 [02:30<02:42, 32.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb56045-67e52488.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb56045-bbf84cef.jpg: 384x640 1 car, 1 traffic light, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb610dc-15dd7f0f.jpg: 384x640 8 cars, 1 truck, 1 parking meter, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb610dc-e64667d9.jpg: 384x640 7 cars, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4696/10000 [02:30<02:45, 32.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb615e0-d78e2a9c.jpg: 384x640 1 person, 4 cars, 2 traffic lights, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb658c2-01af4ab1.jpg: 384x640 1 person, 1 bicycle, 2 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb658c2-f38bc8c3.jpg: 384x640 6 cars, 1 bus, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb85450-4e8d9c80.jpg: 384x640 3 cars, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4700/10000 [02:30<02:45, 31.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb90975-a729ef7b.jpg: 384x640 3 cars, 17.7ms\n",
            "Speed: 6.0ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb95837-032891c3.jpg: 384x640 5 cars, 1 bus, 2 trucks, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb95837-0c2e3b2b.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb95837-2e514e25.jpg: 384x640 7 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4704/10000 [02:30<02:47, 31.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb95837-5a088ec1.jpg: 384x640 3 cars, 1 truck, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb95837-a553c52c.jpg: 384x640 (no detections), 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdb95837-a9465f1b.jpg: 384x640 2 persons, 9 cars, 6 traffic lights, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdba96db-510677bf.jpg: 384x640 (no detections), 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4708/10000 [02:30<02:42, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdba96db-85f26106.jpg: 384x640 8 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdbd6b9f-c0f31952.jpg: 384x640 5 cars, 1 truck, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdbdc4df-2f7a140d.jpg: 384x640 4 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdbdc4df-8b2c5f23.jpg: 384x640 1 car, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4712/10000 [02:30<02:34, 34.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdbfc024-03ba558f.jpg: 384x640 6 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdbfc024-d4ec7ef3.jpg: 384x640 7 cars, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc0dc52-b4d05890.jpg: 384x640 3 persons, 7 cars, 1 bus, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc15316-23cfff61.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4716/10000 [02:30<02:39, 33.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc15316-ac33f22c.jpg: 384x640 5 cars, 8.5ms\n",
            "Speed: 3.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc3e97b-12e4e776.jpg: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc3e97b-3ad23042.jpg: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc3e97b-67eee595.jpg: 384x640 3 cars, 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4720/10000 [02:30<02:38, 33.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc4990a-bd8d6052.jpg: 384x640 1 car, 15.9ms\n",
            "Speed: 1.9ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc7adfd-ac352f36.jpg: 384x640 3 cars, 1 traffic light, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc7ed93-19e4b08c.jpg: 384x640 2 cars, 1 truck, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc7ed93-686684d6.jpg: 384x640 6 cars, 1 bus, 3 traffic lights, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4724/10000 [02:31<02:42, 32.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc7ed93-75e5f442.jpg: 384x640 1 person, 8 cars, 1 bus, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc7ed93-f8378699.jpg: 384x640 2 cars, 1 boat, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdc89152-2b7aec87.jpg: 384x640 9 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcac585-ea8f25b1.jpg: 384x640 2 cars, 1 bus, 1 truck, 1 traffic light, 1 fire hydrant, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4728/10000 [02:31<02:37, 33.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcb68eb-1d074566.jpg: 384x640 1 car, 4 traffic lights, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcb68eb-4a3561a4.jpg: 384x640 2 cars, 1 bus, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcb68eb-8174c535.jpg: 384x640 6 cars, 2 traffic lights, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcb68eb-86671b13.jpg: 384x640 6 cars, 1 truck, 1 traffic light, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4732/10000 [02:31<02:43, 32.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcb68eb-e897551f.jpg: 384x640 5 cars, 19.8ms\n",
            "Speed: 4.8ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcd1ea1-ad1f4ec3.jpg: 384x640 7 cars, 4 traffic lights, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcd6f24-0b1af2bf.jpg: 384x640 12 cars, 1 bus, 15.1ms\n",
            "Speed: 3.4ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcd6f24-781a4629.jpg: 384x640 4 persons, 11 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4736/10000 [02:31<03:09, 27.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcd6f24-c646d15b.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 16.2ms\n",
            "Speed: 2.0ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcd6f24-e3a675af.jpg: 384x640 6 cars, 2 traffic lights, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcda664-848e5b1e.jpg: 384x640 5 cars, 19.3ms\n",
            "Speed: 1.9ms preprocess, 19.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4739/10000 [02:31<03:12, 27.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcf5742-bd173465.jpg: 384x640 2 persons, 4 cars, 3 buss, 1 truck, 1 umbrella, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdcff5f0-83dbf6d8.jpg: 384x640 7 cars, 17.5ms\n",
            "Speed: 1.8ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd0049d-8c592c39.jpg: 384x640 11 persons, 3 cars, 1 truck, 3 traffic lights, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4742/10000 [02:31<03:19, 26.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd20a54-d852fa69.jpg: 384x640 14 cars, 1 traffic light, 16.9ms\n",
            "Speed: 1.9ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd2e58a-f9784bf8.jpg: 384x640 5 cars, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd316c8-a0c21dcc.jpg: 384x640 8 cars, 1 stop sign, 19.4ms\n",
            "Speed: 1.8ms preprocess, 19.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4745/10000 [02:31<03:21, 26.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd3a05e-3d61cb4e.jpg: 384x640 8 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd3a05e-5d28f64d.jpg: 384x640 2 persons, 3 cars, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd3c8b3-ff26c094.jpg: 384x640 1 person, 1 car, 3 traffic lights, 9.5ms\n",
            "Speed: 5.5ms preprocess, 9.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  47%|████▋     | 4748/10000 [02:32<03:18, 26.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd42bec-5fe93b9b.jpg: 384x640 1 person, 8 cars, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd42bec-c050a953.jpg: 384x640 1 person, 6 cars, 1 truck, 3 traffic lights, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd463a8-387d221a.jpg: 384x640 11 cars, 2 trucks, 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4751/10000 [02:32<03:20, 26.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd463a8-94969b77.jpg: 384x640 4 persons, 5 cars, 1 truck, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd5b47b-d9ea627b.jpg: 384x640 8 cars, 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd645df-90aa8572.jpg: 384x640 2 cars, 1 bus, 4 trucks, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4754/10000 [02:32<03:13, 27.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd6d823-2c4989f0.jpg: 384x640 2 persons, 6 cars, 7 traffic lights, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd6d823-659f71fd.jpg: 384x640 6 cars, 1 truck, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd7290c-d5f718f4.jpg: 384x640 1 person, 2 cars, 1 motorcycle, 14.5ms\n",
            "Speed: 2.0ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4757/10000 [02:32<03:16, 26.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd7c984-3c3a2fc4.jpg: 384x640 1 car, 2 trains, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdd853b8-4b3664f3.jpg: 384x640 3 persons, 1 bicycle, 8 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdda4e2e-6d2bc480.jpg: 384x640 2 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bddb3423-37178861.jpg: 384x640 7 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4761/10000 [02:32<03:05, 28.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bddc1656-56674ab3.jpg: 384x640 3 persons, 7 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bddce207-87f8c60f.jpg: 384x640 1 car, 1 traffic light, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bddd9d1b-77a23376.jpg: 384x640 10 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bddd9d1b-b65a1301.jpg: 384x640 12 cars, 1 truck, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4765/10000 [02:32<03:00, 29.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdde507b-1ce1ac20.jpg: 384x640 1 person, 6 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bddeaad4-d1272691.jpg: 384x640 3 cars, 2 traffic lights, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde0caa6-d7d428b5.jpg: 384x640 8 cars, 11.0ms\n",
            "Speed: 1.7ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde10ba1-966885c2.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4769/10000 [02:32<02:49, 30.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde48a59-81b1f93a.jpg: 384x640 14 cars, 1 truck, 2 traffic lights, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde48e24-e9aba0dc.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 4.0ms preprocess, 11.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde48f5b-c09a6b7b.jpg: 384x640 8 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde4c586-85d19762.jpg: 384x640 1 car, 2 traffic lights, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4773/10000 [02:32<02:58, 29.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde6526d-224f7ea1.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde65a81-fb6b43cc.jpg: 384x640 4 persons, 5 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde6a41e-1935bf93.jpg: 384x640 7 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde7a73a-ee84f1a1.jpg: 384x640 15 cars, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4777/10000 [02:33<03:00, 28.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde8262d-4abf8f63.jpg: 384x640 1 car, 1 traffic light, 15.7ms\n",
            "Speed: 2.2ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde83a65-61f8f702.jpg: 384x640 4 cars, 1 truck, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde83a65-d8ce4ddc.jpg: 384x640 4 cars, 1 bus, 2 traffic lights, 1 stop sign, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4780/10000 [02:33<02:59, 29.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde95d2c-6c4a2eca.jpg: 384x640 1 car, 1 traffic light, 12.9ms\n",
            "Speed: 1.7ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde96867-d909dae7.jpg: 384x640 7 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bde9f2e6-e059e5e3.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdec2416-d18fb371.jpg: 384x640 2 cars, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4784/10000 [02:33<02:53, 30.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdec39d8-c94681b3.jpg: 384x640 5 cars, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdec39d8-f1063651.jpg: 384x640 7 cars, 1 truck, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bded2d56-8641bc0d.jpg: 384x640 7 cars, 1 truck, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bded2d56-9a09a78b.jpg: 384x640 5 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4788/10000 [02:33<02:51, 30.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdeec3db-2a9088a9.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdeec3db-4796d5a6.jpg: 384x640 1 car, 1 traffic light, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdeec3db-d7908ef3.jpg: 384x640 4 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf19076-c53d74c5.jpg: 384x640 1 car, 1 fire hydrant, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4792/10000 [02:33<02:42, 32.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf33dc4-ae128055.jpg: 384x640 13 persons, 2 cars, 1 traffic light, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf33dc4-d5b4181c.jpg: 384x640 4 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf33dc4-f1a43120.jpg: 384x640 4 cars, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf3c743-95dacd5d.jpg: 384x640 7 cars, 15.0ms\n",
            "Speed: 4.0ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4796/10000 [02:33<02:45, 31.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf58c55-33117846.jpg: 384x640 6 cars, 1 bus, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf58c55-dee0b9f7.jpg: 384x640 7 cars, 1 truck, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf6ab8b-3ebe8356.jpg: 384x640 2 cars, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf775d9-3cb15a15.jpg: 384x640 9 cars, 1 truck, 4 traffic lights, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4800/10000 [02:33<02:50, 30.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf8fcad-32d6edca.jpg: 384x640 7 cars, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf8fcad-9b37333e.jpg: 384x640 3 persons, 1 bicycle, 3 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf8fcad-dfe047d1.jpg: 384x640 9 cars, 2 traffic lights, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf8fcad-f9afb0af.jpg: 384x640 1 person, 8 cars, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4804/10000 [02:33<02:49, 30.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdf90fcb-d42380c0.jpg: 384x640 1 person, 9 cars, 1 truck, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdfa3a60-fdd4a2f9.jpg: 384x640 4 cars, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdfc0f1d-375eba4a.jpg: 384x640 1 person, 7 cars, 15.8ms\n",
            "Speed: 4.0ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdfc6bf1-523e96ae.jpg: 384x640 12 persons, 1 bicycle, 2 cars, 1 bus, 18.1ms\n",
            "Speed: 1.8ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4808/10000 [02:34<02:58, 29.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bdfd3a09-7a86654b.jpg: 384x640 1 car, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be005230-7facbb3e.jpg: 384x640 1 person, 4 cars, 1 truck, 1 traffic light, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be00866b-4eba6f90.jpg: 384x640 13 cars, 14.3ms\n",
            "Speed: 1.8ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be00937a-8e571604.jpg: 384x640 3 cars, 1 truck, 17.2ms\n",
            "Speed: 1.8ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4812/10000 [02:34<02:55, 29.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be00937a-98783429.jpg: 384x640 12 cars, 17.6ms\n",
            "Speed: 1.8ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be021235-7920ed09.jpg: 384x640 1 car, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be042f25-579f9c94.jpg: 384x640 5 persons, 2 cars, 1 bus, 1 chair, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4815/10000 [02:34<02:55, 29.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be0456d5-e34d2c07.jpg: 384x640 2 cars, 1 train, 1 traffic light, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be045ad5-53b75245.jpg: 384x640 2 cars, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be047105-0662bd2d.jpg: 384x640 7 cars, 1 truck, 17.4ms\n",
            "Speed: 2.6ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4818/10000 [02:34<03:04, 28.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be047105-ea277d1d.jpg: 384x640 13 cars, 1 truck, 18.0ms\n",
            "Speed: 3.2ms preprocess, 18.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be0571c8-03dae021.jpg: 384x640 5 cars, 24.9ms\n",
            "Speed: 3.2ms preprocess, 24.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be06ff35-0a94dfb1.jpg: 384x640 3 cars, 1 train, 13.7ms\n",
            "Speed: 3.5ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4821/10000 [02:34<03:17, 26.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be06ff35-5105ecff.jpg: 384x640 5 cars, 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be06ff35-ea007cf3.jpg: 384x640 6 cars, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be08673a-fe5b7035.jpg: 384x640 4 cars, 11.3ms\n",
            "Speed: 2.8ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be099a06-28b7d23f.jpg: 384x640 2 cars, 2 trucks, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4825/10000 [02:34<03:06, 27.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be099a06-dc3c20e8.jpg: 384x640 1 person, 4 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be09d50a-24bc5168.jpg: 384x640 3 persons, 2 cars, 3 trucks, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be0a188d-c47bac51.jpg: 384x640 2 cars, 10.4ms\n",
            "Speed: 2.5ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be0c9d29-04747419.jpg: 384x640 (no detections), 15.6ms\n",
            "Speed: 1.8ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4829/10000 [02:34<02:54, 29.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be0fdf82-5cb62b50.jpg: 384x640 1 car, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be0fdf82-972594ce.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be0fdf82-eb463749.jpg: 384x640 4 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be10fa73-121083df.jpg: 384x640 1 car, 10.6ms\n",
            "Speed: 1.7ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4833/10000 [02:34<02:46, 30.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be10fa73-799d904b.jpg: 384x640 2 cars, 2 traffic lights, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be10fa73-da2fa32f.jpg: 384x640 4 cars, 6 traffic lights, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be11b82c-0873ebca.jpg: 384x640 2 traffic lights, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be12aefd-283e0fe4.jpg: 384x640 5 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4837/10000 [02:35<02:43, 31.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be12aefd-dad8b385.jpg: 384x640 5 cars, 1 traffic light, 9.3ms\n",
            "Speed: 4.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be144a33-80fe4232.jpg: 384x640 3 cars, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be144a33-c0b91172.jpg: 384x640 4 cars, 3 traffic lights, 14.7ms\n",
            "Speed: 2.0ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be177534-4a736a9b.jpg: 384x640 1 person, 3 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4841/10000 [02:35<02:44, 31.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be18edca-1dac55eb.jpg: 384x640 11 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be18f4e6-a2770590.jpg: 384x640 4 cars, 1 truck, 3 traffic lights, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be1a0aee-7127f0d8.jpg: 384x640 1 car, 1 truck, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be1a8e59-2a59e33c.jpg: 384x640 4 cars, 1 stop sign, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4845/10000 [02:35<02:39, 32.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be1e235b-e033239e.jpg: 384x640 2 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be1ed8ce-38edbe34.jpg: 384x640 1 car, 1 truck, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2034df-1d272a6f.jpg: 384x640 3 cars, 3 traffic lights, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2034df-3fbd9d5b.jpg: 384x640 11 cars, 1 traffic light, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  48%|████▊     | 4849/10000 [02:35<02:44, 31.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2034df-a6b260a5.jpg: 384x640 5 cars, 2 trucks, 3 traffic lights, 19.3ms\n",
            "Speed: 3.2ms preprocess, 19.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be22622e-20122a8f.jpg: 384x640 11 cars, 14.9ms\n",
            "Speed: 3.8ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be22622e-3712dbc2.jpg: 384x640 1 person, 5 cars, 1 fire hydrant, 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be22a1e1-cbcd82a6.jpg: 384x640 1 car, 19.9ms\n",
            "Speed: 1.8ms preprocess, 19.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▊     | 4853/10000 [02:35<02:57, 29.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be269fc3-4ac017bd.jpg: 384x640 6 cars, 14.6ms\n",
            "Speed: 3.1ms preprocess, 14.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be26ac57-35dabb9c.jpg: 384x640 10 persons, 7 cars, 1 truck, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be273f87-6eaea9ee.jpg: 384x640 5 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▊     | 4856/10000 [02:35<02:56, 29.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be273f87-7aca9df7.jpg: 384x640 5 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be273f87-ab1ef50e.jpg: 384x640 5 cars, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be273f87-b164bca1.jpg: 384x640 2 cars, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be278041-2173a980.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 2.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▊     | 4860/10000 [02:35<02:45, 31.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2ad3df-225b267d.jpg: 384x640 4 persons, 4 cars, 1 truck, 2 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2b1f01-892bf2bb.jpg: 384x640 16 cars, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c1849-0713082f.jpg: 384x640 7 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c1849-5faf51d5.jpg: 384x640 3 persons, 2 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▊     | 4864/10000 [02:35<02:42, 31.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c1849-662a650d.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c1849-c797807b.jpg: 384x640 4 persons, 4 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c1849-e2e8cf17.jpg: 384x640 9 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c1849-ed1a9103.jpg: 384x640 2 persons, 1 car, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▊     | 4868/10000 [02:35<02:33, 33.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c4865-14b12388.jpg: 384x640 2 persons, 3 cars, 1 bus, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c4865-af9a958b.jpg: 384x640 3 persons, 1 car, 1 bus, 1 truck, 1 backpack, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2c66b0-2bc5eec8.jpg: 384x640 11 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2d3f1c-2644c9e3.jpg: 384x640 2 persons, 8 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▊     | 4872/10000 [02:36<02:28, 34.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2d5044-9707da3e.jpg: 384x640 8 cars, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2e23f5-7fdb7597.jpg: 384x640 1 car, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2ec34b-bcdc0b2a.jpg: 384x640 4 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be2fbf0b-5d71c655.jpg: 384x640 2 persons, 11 cars, 5 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4876/10000 [02:36<02:35, 33.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be307493-2750cf96.jpg: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be307493-a2247ebf.jpg: 384x640 2 cars, 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3147c4-1f271e92.jpg: 384x640 1 person, 2 cars, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3159f3-13250ffe.jpg: 384x640 6 cars, 1 bus, 1 truck, 1 traffic light, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4880/10000 [02:36<02:43, 31.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3159f3-16212270.jpg: 384x640 1 person, 1 car, 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3294d0-a580161f.jpg: 384x640 6 cars, 1 fire hydrant, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3294d0-e1c119ea.jpg: 384x640 6 persons, 1 bicycle, 9 cars, 3 traffic lights, 14.9ms\n",
            "Speed: 4.0ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3301b2-9bb342d3.jpg: 384x640 3 persons, 4 cars, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4884/10000 [02:36<02:50, 30.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3301b2-a86db4a9.jpg: 384x640 8 cars, 15.9ms\n",
            "Speed: 4.0ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3301b2-f3d95701.jpg: 384x640 5 cars, 1 bus, 4 trucks, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be35fa0d-caedd8ab.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3618b4-27d60dcd.jpg: 384x640 10 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4888/10000 [02:36<02:46, 30.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be362fff-99b5dd8b.jpg: 384x640 4 cars, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be377d8f-7c22e445.jpg: 384x640 6 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be37b92a-4873e7e0.jpg: 384x640 13 cars, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be395d23-22773837.jpg: 384x640 1 person, 4 cars, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4892/10000 [02:36<02:36, 32.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be395d23-2df9d7c9.jpg: 384x640 1 person, 4 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be39c92f-392bb50a.jpg: 384x640 1 fire hydrant, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be39c92f-cef221af.jpg: 384x640 2 cars, 4 traffic lights, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be39e3ab-8e532208.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4896/10000 [02:36<02:30, 33.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be39f3f1-2d48f83e.jpg: 384x640 3 cars, 2 buss, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3a20e2-7791c4b9.jpg: 384x640 2 persons, 4 cars, 1 motorcycle, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3a5c0b-16533792.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3b7c5d-d25131a7.jpg: 384x640 3 cars, 1 bus, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4900/10000 [02:36<02:24, 35.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3d3a81-326a032d.jpg: 384x640 2 cars, 1 truck, 3 traffic lights, 13.8ms\n",
            "Speed: 5.8ms preprocess, 13.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3e9c45-d47775f3.jpg: 384x640 10 cars, 2 trucks, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be3f0272-4444e669.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be40bcad-48aead92.jpg: 384x640 1 person, 6 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4904/10000 [02:37<02:31, 33.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be40c69d-16a90cda.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be41362b-587a17b4.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be41362b-a1a37afb.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be41362b-bf2985b5.jpg: 384x640 4 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be41362b-f6a4eb1c.jpg: 384x640 4 cars, 13.8ms\n",
            "Speed: 1.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4909/10000 [02:37<02:21, 35.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be415cb5-0f27b485.jpg: 384x640 2 cars, 17.9ms\n",
            "Speed: 1.9ms preprocess, 17.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be42bfaa-3ebf6b5c.jpg: 384x640 1 person, 7 cars, 1 truck, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be42e5e6-33445d5b.jpg: 384x640 1 traffic light, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be42e5e6-73d1f920.jpg: 384x640 7 cars, 1 traffic light, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4913/10000 [02:37<02:36, 32.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be448414-11891b58.jpg: 384x640 6 cars, 1 truck, 3 traffic lights, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be448414-f60b61c9.jpg: 384x640 12 cars, 16.6ms\n",
            "Speed: 3.4ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be449d8d-288c49bd.jpg: 384x640 5 cars, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be449d8d-c3a01551.jpg: 384x640 2 cars, 2 trucks, 1 traffic light, 14.9ms\n",
            "Speed: 3.1ms preprocess, 14.9ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4917/10000 [02:37<02:53, 29.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be45679b-3cf3ef8d.jpg: 384x640 1 car, 15.1ms\n",
            "Speed: 6.6ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4593fb-9e1ec483.jpg: 384x640 2 cars, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be463595-0ac17b97.jpg: 384x640 3 cars, 1 truck, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be463595-1fa1df9c.jpg: 384x640 5 cars, 1 traffic light, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4921/10000 [02:37<03:00, 28.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be463595-34d59d57.jpg: 384x640 5 cars, 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be463595-760f4698.jpg: 384x640 (no detections), 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be46639a-25990c25.jpg: 384x640 14 cars, 1 traffic light, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4924/10000 [02:37<03:00, 28.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be47d849-da84aa8a.jpg: 384x640 10 cars, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be49ae7a-1ffaa683.jpg: 384x640 1 person, 10 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be49ccee-b084e427.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 16.5ms\n",
            "Speed: 2.0ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4927/10000 [02:37<03:10, 26.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4a418e-8e95d178.jpg: 384x640 9 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4ca8c8-d651db6c.jpg: 384x640 2 cars, 1 traffic light, 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4cbd00-06f42982.jpg: 384x640 3 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4cbd00-97fec78b.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4931/10000 [02:38<02:52, 29.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4f207d-cd1dcff1.jpg: 384x640 2 persons, 2 cars, 1 bus, 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4f3873-33c738a5.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 4.1ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4f53be-3e8f170e.jpg: 384x640 11 cars, 2 trucks, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be4f53be-a7d26a38.jpg: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4935/10000 [02:38<02:51, 29.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be501fd0-e063aff3.jpg: 384x640 1 car, 1 truck, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be524f22-671e4f73.jpg: 384x640 8 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be52b29f-0ae76ecf.jpg: 384x640 9 cars, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be52b29f-10b6ef30.jpg: 384x640 3 cars, 21.6ms\n",
            "Speed: 1.9ms preprocess, 21.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4939/10000 [02:38<02:51, 29.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be52b29f-337d4ed4.jpg: 384x640 1 person, 3 cars, 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be52b29f-3c297726.jpg: 384x640 6 cars, 16.5ms\n",
            "Speed: 1.8ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be52b29f-61846699.jpg: 384x640 7 cars, 1 truck, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4942/10000 [02:38<02:55, 28.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be52b29f-aa3b290b.jpg: 384x640 1 car, 1 traffic light, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be52b29f-de33251f.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be535920-9cc2e6aa.jpg: 384x640 5 cars, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be554fed-4ac78405.jpg: 384x640 1 person, 8 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  49%|████▉     | 4946/10000 [02:38<02:47, 30.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be554fed-a4c92888.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be554fed-b1ed30d1.jpg: 384x640 13 cars, 13.8ms\n",
            "Speed: 6.6ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be554fed-d4a627d0.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be554fed-f627824e.jpg: 384x640 1 car, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4950/10000 [02:38<02:43, 30.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5559e0-15ecaa2b.jpg: 384x640 12 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be56ab92-96e20e29.jpg: 384x640 1 person, 6 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be56ab92-da00e516.jpg: 384x640 3 persons, 11 cars, 1 bus, 2 trucks, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5b8df4-72b40d4c.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4954/10000 [02:38<02:41, 31.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5b8df4-784c9d84.jpg: 384x640 5 cars, 1 bus, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5b8df4-c5ac6782.jpg: 384x640 1 car, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5b8df4-c69d8fa1.jpg: 384x640 5 cars, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5b8df4-f47db0e2.jpg: 384x640 3 cars, 3 traffic lights, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5c5aae-206ccb9c.jpg: 384x640 1 person, 5 cars, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4959/10000 [02:38<02:30, 33.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5c5aae-50668a30.jpg: 384x640 1 car, 1 traffic light, 10.3ms\n",
            "Speed: 5.6ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5c5aae-67fd8380.jpg: 384x640 1 car, 3 trucks, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5c5aae-d31145ff.jpg: 384x640 1 person, 3 cars, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5ca08c-52c0860e.jpg: 384x640 2 traffic lights, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4963/10000 [02:39<02:24, 34.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5ca360-3585455f.jpg: 384x640 4 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5ca360-afcedc9e.jpg: 384x640 3 cars, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be5ec90e-8f48d12d.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be60191c-2dea5114.jpg: 384x640 2 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4967/10000 [02:39<02:20, 35.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be60191c-813aa925.jpg: 384x640 8 cars, 1 bus, 1 truck, 2 traffic lights, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be60191c-cade58a2.jpg: 384x640 1 car, 9 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be614466-2e58f448.jpg: 384x640 6 cars, 1 bus, 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be62c9ed-524c83e8.jpg: 384x640 2 persons, 15 cars, 1 traffic light, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4971/10000 [02:39<02:25, 34.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be62c9ed-cfe00d7a.jpg: 384x640 2 persons, 2 cars, 5 traffic lights, 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be64f818-053b36ba.jpg: 384x640 1 car, 1 suitcase, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-02659bee.jpg: 384x640 11 cars, 1 truck, 1 traffic light, 1 tv, 16.8ms\n",
            "Speed: 2.4ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-08fcb61f.jpg: 384x640 5 cars, 16.5ms\n",
            "Speed: 1.9ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4975/10000 [02:39<02:39, 31.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-21253da1.jpg: 384x640 3 persons, 2 cars, 1 truck, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-2feb0be6.jpg: 384x640 7 cars, 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-4b80b1c3.jpg: 384x640 1 car, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-5e0e949d.jpg: 384x640 2 cars, 17.3ms\n",
            "Speed: 1.8ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4979/10000 [02:39<02:41, 31.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-5ee1f563.jpg: 384x640 1 person, 6 cars, 11.4ms\n",
            "Speed: 3.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-779cf7ef.jpg: 384x640 4 cars, 1 tv, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-90da2dc5.jpg: 384x640 2 cars, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-a7e2074e.jpg: 384x640 6 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4983/10000 [02:39<02:37, 31.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-bc7ce2fe.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-bdd56721.jpg: 384x640 2 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-c3407554.jpg: 384x640 1 person, 2 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ed5-eceae7bc.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4987/10000 [02:39<02:29, 33.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ffd-0bc74ac7.jpg: 384x640 2 persons, 8 cars, 2 motorcycles, 1 truck, 1 umbrella, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be651ffd-cf17daaf.jpg: 384x640 6 cars, 1 bus, 1 truck, 2 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be66a004-91dbe123.jpg: 384x640 4 cars, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be67f423-8aec9ba5.jpg: 384x640 13 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4991/10000 [02:39<02:27, 34.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be689d93-672d54ff.jpg: 384x640 4 cars, 1 train, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6b4502-b150e016.jpg: 384x640 2 cars, 2 trains, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6b4502-e0c95034.jpg: 384x640 6 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6ed1f7-853489ce.jpg: 384x640 1 person, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4995/10000 [02:39<02:21, 35.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6ed1f7-dd0e252b.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6fd6ac-158f717e.jpg: 384x640 1 car, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6fd6ac-35af61fd.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6fd6ac-624b4634.jpg: 384x640 6 cars, 1 truck, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|████▉     | 4999/10000 [02:40<02:20, 35.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6fd6ac-a0cc8633.jpg: 384x640 1 person, 5 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be6feca9-888ffd4c.jpg: 384x640 3 cars, 1 bus, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be724abb-9a2a625c.jpg: 384x640 3 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be731030-7593da2a.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5003/10000 [02:40<02:16, 36.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be731030-82d58159.jpg: 384x640 7 cars, 2 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be731030-c29affd6.jpg: 384x640 5 cars, 1 truck, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be73806a-cd8633af.jpg: 384x640 2 cars, 1 bus, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be769e9f-abea5fd9.jpg: 384x640 11 cars, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5007/10000 [02:40<02:21, 35.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be769e9f-ed37df2b.jpg: 384x640 9 cars, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be76ea62-78b2c8f8.jpg: 384x640 1 traffic light, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be776742-fe6599b2.jpg: 384x640 15 cars, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be777044-7db298a4.jpg: 384x640 1 person, 14 cars, 14.7ms\n",
            "Speed: 6.1ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5011/10000 [02:40<02:31, 32.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be777044-db29e596.jpg: 384x640 9 cars, 1 truck, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be7783b0-b44ff154.jpg: 384x640 2 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be791a81-a6b53fef.jpg: 384x640 2 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be7b856e-d1ece683.jpg: 384x640 2 traffic lights, 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5015/10000 [02:40<02:37, 31.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be7c5bf9-f31d60c1.jpg: 384x640 4 cars, 1 bus, 1 truck, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be80a253-75e6f6aa.jpg: 384x640 5 cars, 2 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be819732-9cff62ba.jpg: 384x640 7 cars, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be832d0b-0ed20122.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5019/10000 [02:40<02:28, 33.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be832d0b-2384fe4c.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be83776d-e07b8fdc.jpg: 384x640 1 person, 4 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be839b4c-fba3ea45.jpg: 384x640 3 persons, 16 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be83fbfa-53a6b842.jpg: 384x640 4 cars, 3 trucks, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5023/10000 [02:40<02:25, 34.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be85292c-a3fbba40.jpg: 384x640 12 cars, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be852dd5-29511af0.jpg: 384x640 1 person, 5 cars, 1 truck, 2 traffic lights, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be854092-492e5e65.jpg: 384x640 11 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be85665c-4fe33b5c.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5027/10000 [02:40<02:24, 34.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8590fa-52948d8f.jpg: 384x640 3 cars, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8590fa-9ab10ced.jpg: 384x640 1 person, 8 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be85bd88-4aad89d7.jpg: 384x640 7 cars, 3 traffic lights, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be85bd88-d849c034.jpg: 384x640 2 cars, 2 buss, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5031/10000 [02:41<02:26, 33.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be860305-899a96c3.jpg: 384x640 7 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8663d6-e9cbeb2e.jpg: 384x640 2 persons, 1 bicycle, 7 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8962cd-17e6f610.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8962cd-2f4d528e.jpg: 384x640 5 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5035/10000 [02:41<02:23, 34.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8b3ab2-26370e88.jpg: 384x640 11 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8b8284-01e2400c.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8b8284-18138380.jpg: 384x640 (no detections), 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8bceff-efda56f8.jpg: 384x640 3 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8cb554-6f4255f3.jpg: 384x640 2 cars, 17.2ms\n",
            "Speed: 3.8ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5040/10000 [02:41<02:18, 35.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8d7ea3-4b798531.jpg: 384x640 5 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8d7ea3-a6236da4.jpg: 384x640 3 cars, 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8d7ea3-f860b6f5.jpg: 384x640 1 traffic light, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be8dc474-faef6d09.jpg: 384x640 1 person, 1 car, 17.1ms\n",
            "Speed: 1.8ms preprocess, 17.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5044/10000 [02:41<02:25, 34.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be926190-5293afb9.jpg: 384x640 13 cars, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be93769c-354d1d72.jpg: 384x640 2 persons, 10 cars, 1 truck, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9496ad-3d23e714.jpg: 384x640 4 cars, 2 traffic lights, 19.9ms\n",
            "Speed: 1.8ms preprocess, 19.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be94c28f-7128d4c4.jpg: 384x640 4 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  50%|█████     | 5048/10000 [02:41<02:36, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be94c28f-9526bf9a.jpg: 384x640 1 car, 1 stop sign, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be94df25-464ac4f8.jpg: 384x640 4 cars, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be95af9a-dee1fc2d.jpg: 384x640 6 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be96d002-8742b0e0.jpg: 384x640 (no detections), 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5052/10000 [02:41<02:33, 32.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be96d002-f987edab.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be97ef40-3cdcb388.jpg: 384x640 2 persons, 8 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be986afd-012d020c.jpg: 384x640 3 cars, 1 sheep, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be986afd-b86569ff.jpg: 384x640 13 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5056/10000 [02:41<02:27, 33.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be986afd-f734d33e.jpg: 384x640 5 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9a438d-fec060b0.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9b088f-3fc248ee.jpg: 384x640 2 persons, 9 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9b088f-c2a29c43.jpg: 384x640 6 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5060/10000 [02:41<02:23, 34.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9c5bdd-02782f34.jpg: 384x640 3 cars, 1 truck, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9c5bdd-7714057c.jpg: 384x640 (no detections), 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9ce27e-304f0df0.jpg: 384x640 8 cars, 1 motorcycle, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9ce27e-65ec1c4e.jpg: 384x640 4 cars, 1 bus, 1 truck, 9.8ms\n",
            "Speed: 4.1ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5064/10000 [02:41<02:17, 35.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9ce27e-b78ea956.jpg: 384x640 10 cars, 3 trucks, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9e39ad-cc4bc43f.jpg: 384x640 6 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/be9f9a44-8d9b651e.jpg: 384x640 3 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea02fed-85841fe4.jpg: 384x640 10 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5068/10000 [02:42<02:19, 35.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea02fed-c120c91d.jpg: 384x640 2 persons, 4 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea02fed-c803e656.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea02fed-e64fced9.jpg: 384x640 1 person, 2 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea3ece7-e73287ff.jpg: 384x640 1 car, 1 traffic light, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5072/10000 [02:42<02:15, 36.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea4a94e-119bd9e7.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea4ac92-340863d9.jpg: 384x640 1 fire hydrant, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea4ac92-f9e0f736.jpg: 384x640 4 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea55e98-2769bb0f.jpg: 384x640 1 person, 8 cars, 1 truck, 1 traffic light, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5076/10000 [02:42<02:18, 35.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea64506-3ce23cff.jpg: 384x640 1 person, 10 cars, 1 potted plant, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea64506-48ef84e0.jpg: 384x640 2 persons, 1 bicycle, 5 cars, 1 truck, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea64506-a82db0f9.jpg: 384x640 12 persons, 1 bicycle, 7 cars, 1 traffic light, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea64506-c04d4b12.jpg: 384x640 1 person, 4 cars, 1 traffic light, 1 clock, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5080/10000 [02:42<02:27, 33.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea6dbeb-3292525a.jpg: 384x640 4 persons, 9 cars, 2 traffic lights, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea6dbeb-f1056997.jpg: 384x640 5 cars, 15.0ms\n",
            "Speed: 2.3ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea74140-801c009e.jpg: 384x640 9 persons, 1 car, 2 traffic lights, 3 umbrellas, 1 handbag, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea78bf6-01be38ee.jpg: 384x640 4 cars, 1 truck, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5084/10000 [02:42<02:39, 30.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bea82122-66fc59a4.jpg: 384x640 1 person, 9 cars, 1 truck, 2 traffic lights, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beaa00a7-25aba714.jpg: 384x640 9 cars, 1 truck, 3 traffic lights, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beaa0c22-77f57e18.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beaa0c22-9f7d6767.jpg: 384x640 1 person, 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5088/10000 [02:42<02:45, 29.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beaa0c22-e5e3c48f.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beaa8787-b07dfe8e.jpg: 384x640 1 person, 3 cars, 3 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beaae4eb-e874663f.jpg: 384x640 1 person, 5 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beaae4eb-f6975a4f.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5092/10000 [02:42<02:33, 31.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb12388-2a415a61.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb12388-c1f4f3b1.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb12388-c681fd3d.jpg: 384x640 3 cars, 1 bus, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb2aa47-4c96d667.jpg: 384x640 6 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5096/10000 [02:42<02:25, 33.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb2d175-69dae2f2.jpg: 384x640 6 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb2d175-72de2f87.jpg: 384x640 1 person, 8 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb3d6ea-272401a6.jpg: 384x640 6 cars, 1 truck, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb3d6ea-3a661077.jpg: 384x640 6 cars, 1 traffic light, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5100/10000 [02:43<02:21, 34.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb3d6ea-3b5b9e2e.jpg: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb3d6ea-d2584fc7.jpg: 384x640 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb41a39-89ceabe8.jpg: 384x640 5 cars, 2 trucks, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb41a39-be4bfe96.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb53c44-1aa54ed7.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5105/10000 [02:43<02:14, 36.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb53c44-3b9231ca.jpg: 384x640 17 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb53c44-6af8d3b4.jpg: 384x640 11 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb53c44-f3619124.jpg: 384x640 1 car, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb712cc-6594b626.jpg: 384x640 8 cars, 1 bus, 2 trucks, 1 traffic light, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5109/10000 [02:43<02:20, 34.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb712cc-ee31a67b.jpg: 384x640 9 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb80a43-c3b9107e.jpg: 384x640 4 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beb87fd7-6120b637.jpg: 384x640 5 cars, 1 bus, 1 truck, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bebb5b76-68384a7d.jpg: 384x640 9 cars, 10.7ms\n",
            "Speed: 5.1ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5113/10000 [02:43<02:25, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bebbf02d-dc8f1e04.jpg: 384x640 9 cars, 3 trucks, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bebc2a98-23f14ef2.jpg: 384x640 1 person, 7 cars, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bebc2a98-728ce6e0.jpg: 384x640 12 cars, 1 truck, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bebc6162-bf494364.jpg: 384x640 3 persons, 1 bus, 2 traffic lights, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5117/10000 [02:43<02:36, 31.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bebd2415-30a87543.jpg: 384x640 4 cars, 17.7ms\n",
            "Speed: 1.8ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bebd9c47-9d51ac58.jpg: 384x640 2 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec0d815-f71f4f7b.jpg: 384x640 6 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec165a2-cc4b47ed.jpg: 384x640 4 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████     | 5121/10000 [02:43<02:32, 32.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec19328-e01f5679.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec5aa0b-27aa89d9.jpg: 384x640 2 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec5aa0b-fdc30a1e.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec66c97-a8a831f3.jpg: 384x640 6 cars, 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec6904e-816bf499.jpg: 384x640 6 persons, 4 cars, 1 train, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████▏    | 5126/10000 [02:43<02:21, 34.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-177923dd.jpg: 384x640 3 persons, 5 cars, 2 trucks, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-1bbf2379.jpg: 384x640 2 cars, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-36069512.jpg: 384x640 3 persons, 1 car, 2 trucks, 2 traffic lights, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-43e0242a.jpg: 384x640 7 cars, 1 truck, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-492e391a.jpg: 384x640 1 car, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████▏    | 5131/10000 [02:43<02:14, 36.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-5cf322d9.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-5d9ee937.jpg: 384x640 7 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-6bf5ac85.jpg: 384x640 10 cars, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-ca19e1e3.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████▏    | 5135/10000 [02:44<02:15, 35.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-db214db2.jpg: 384x640 5 persons, 1 car, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-e365257b.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec7b5c0-f928ccf5.jpg: 384x640 1 person, 2 cars, 1 truck, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bec94d5a-e7effd81.jpg: 384x640 3 cars, 2 trucks, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████▏    | 5139/10000 [02:44<02:17, 35.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/becccb13-74e09a25.jpg: 384x640 1 car, 1 motorcycle, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beccfad4-d24a29c5.jpg: 384x640 1 car, 1 train, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/becd26b2-c02db1e6.jpg: 384x640 5 cars, 1 bus, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bece8f9e-2c905717.jpg: 384x640 1 car, 17.7ms\n",
            "Speed: 1.8ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████▏    | 5143/10000 [02:44<02:24, 33.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beced1e4-8d82da4e.jpg: 384x640 1 car, 1 truck, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beced1e4-e2532a6e.jpg: 384x640 11 cars, 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/becfc708-145da944.jpg: 384x640 2 cars, 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/becfc708-24488979.jpg: 384x640 1 car, 15.7ms\n",
            "Speed: 3.3ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  51%|█████▏    | 5147/10000 [02:44<02:36, 31.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/becfc708-b7f59377.jpg: 384x640 1 car, 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/becfc708-eaf36a96.jpg: 384x640 8 cars, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed001a8-2339fb95.jpg: 384x640 7 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed001a8-6cd3d8be.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5151/10000 [02:44<02:34, 31.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed07392-75beda90.jpg: 384x640 2 trains, 1 traffic light, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed3a784-c17f9bcb.jpg: 384x640 3 cars, 1 bus, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed3bee0-0aa5d83d.jpg: 384x640 9 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed3bee0-a9817eee.jpg: 384x640 5 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5155/10000 [02:44<02:32, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed3db3f-f0ce3c29.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed4ed94-526eb41d.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed4ed94-7b8c51c7.jpg: 384x640 3 persons, 3 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed782a6-b511b4b6.jpg: 384x640 20 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5159/10000 [02:44<02:27, 32.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed7aad9-554b58df.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed8e0d6-615b8f5e.jpg: 384x640 8 cars, 2 trucks, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bed8e0d6-d5645404.jpg: 384x640 4 cars, 1 traffic light, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedb6dc2-777e4568.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedb9474-8dd30e6f.jpg: 384x640 2 persons, 13 cars, 2 trucks, 2 traffic lights, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5164/10000 [02:44<02:21, 34.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedbeb83-cfb5b8eb.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedbeb83-fe19f8c6.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedcfa26-332689fc.jpg: 384x640 8 cars, 3 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedcfa26-e2d45cac.jpg: 384x640 7 cars, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5168/10000 [02:45<02:16, 35.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedd1376-090caeff.jpg: 384x640 (no detections), 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedd1376-60cdb96b.jpg: 384x640 7 cars, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bedd1376-f4b27761.jpg: 384x640 8 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee05c71-de853116.jpg: 384x640 3 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5172/10000 [02:45<02:18, 34.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee09035-01100c39.jpg: 384x640 4 cars, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee1374f-cceb9a68.jpg: 384x640 1 person, 3 cars, 1 traffic light, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee1b799-cfe60aff.jpg: 384x640 1 person, 5 cars, 1 truck, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee1f0a4-22dbabcd.jpg: 384x640 1 truck, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5176/10000 [02:45<02:24, 33.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee41f4c-27a63e4b.jpg: 384x640 1 person, 3 cars, 1 traffic light, 11.4ms\n",
            "Speed: 4.3ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee41f4c-ff91e224.jpg: 384x640 4 cars, 1 traffic light, 17.7ms\n",
            "Speed: 2.0ms preprocess, 17.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee5ec8b-493be8dd.jpg: 384x640 2 cars, 2 trucks, 16.5ms\n",
            "Speed: 3.7ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee67716-066d25dc.jpg: 384x640 2 cars, 1 bus, 15.6ms\n",
            "Speed: 2.4ms preprocess, 15.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5180/10000 [02:45<02:29, 32.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee67716-2a04a827.jpg: 384x640 6 persons, 1 bicycle, 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 16.3ms\n",
            "Speed: 2.0ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee679f2-dd1ee975.jpg: 384x640 1 car, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee6e5eb-3269dda9.jpg: 384x640 2 cars, 1 traffic light, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee6e5eb-ee57b54a.jpg: 384x640 2 cars, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5184/10000 [02:45<02:33, 31.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee6f1ed-04d4eed4.jpg: 384x640 4 cars, 1 traffic light, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee6f1ed-1a33ed88.jpg: 384x640 8 cars, 3 traffic lights, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee6f1ed-5f8eec63.jpg: 384x640 2 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee6f1ed-d591156d.jpg: 384x640 2 persons, 1 car, 2 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5188/10000 [02:45<02:30, 32.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bee6f1ed-d8ef19e6.jpg: 384x640 3 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beea0870-130c4849.jpg: 384x640 1 traffic light, 15.6ms\n",
            "Speed: 1.8ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beea0870-e7fed5d8.jpg: 384x640 2 cars, 1 traffic light, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beea0e03-031a65e7.jpg: 384x640 5 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5192/10000 [02:45<02:29, 32.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beea0e03-fa22a607.jpg: 384x640 5 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beeaded5-7cb91618.jpg: 384x640 2 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beeaded5-8b3f6201.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beeaded5-9bb26175.jpg: 384x640 5 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beeaded5-ab8d8f4b.jpg: 384x640 1 car, 2 traffic lights, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5197/10000 [02:45<02:21, 33.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beebb876-a43fa1b4.jpg: 384x640 10 cars, 1 truck, 8.5ms\n",
            "Speed: 3.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beebb876-fec7bfc6.jpg: 384x640 5 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beec1825-ec4450ad.jpg: 384x640 1 car, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beeed9e7-d279d8ee.jpg: 384x640 2 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5201/10000 [02:46<02:16, 35.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beef90ca-dd806a38.jpg: 384x640 5 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef016fa-761bfbc6.jpg: 384x640 4 cars, 1 train, 1 traffic light, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef09238-c1e87e2d.jpg: 384x640 4 cars, 12.0ms\n",
            "Speed: 1.7ms preprocess, 12.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef1fe5a-2384bb3d.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5205/10000 [02:46<02:13, 35.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef1fe5a-64664ad2.jpg: 384x640 8 cars, 3 trucks, 4 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef271e3-99f9020e.jpg: 384x640 4 cars, 2 traffic lights, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef3c0bd-5e448793.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef60eb6-80419967.jpg: 384x640 5 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5209/10000 [02:46<02:16, 35.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef60eb6-b92e9131.jpg: 384x640 5 cars, 1 train, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef703f9-1b27304e.jpg: 384x640 3 persons, 11 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef766cb-e61b2168.jpg: 384x640 12 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef766cb-f36b2dca.jpg: 384x640 8 cars, 1 truck, 3 traffic lights, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5213/10000 [02:46<02:19, 34.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef77538-a89b1dfa.jpg: 384x640 6 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef7c739-8821d482.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef7c739-c71a55d9.jpg: 384x640 4 cars, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef7fb14-970e2929.jpg: 384x640 3 cars, 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5217/10000 [02:46<02:22, 33.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef8ae8b-17ae6029.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 2.1ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef906fc-2f834e3d.jpg: 384x640 5 cars, 1 truck, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef906fc-4922c33f.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef906fc-b88eb3a5.jpg: 384x640 1 car, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5221/10000 [02:46<02:21, 33.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bef9fe55-0bba41cb.jpg: 384x640 10 cars, 2 traffic lights, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befa588e-80b3c62a.jpg: 384x640 8 cars, 1 truck, 3 traffic lights, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befbd710-6bf61d20.jpg: 384x640 1 bus, 1 train, 17.6ms\n",
            "Speed: 1.8ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befbf2cc-bec128ef.jpg: 384x640 1 traffic light, 16.7ms\n",
            "Speed: 6.1ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5225/10000 [02:46<02:42, 29.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befce81b-f743c561.jpg: 384x640 5 persons, 9 cars, 1 traffic light, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befd675c-ead3969d.jpg: 384x640 1 truck, 8.4ms\n",
            "Speed: 5.0ms preprocess, 8.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befd706d-2e1fe6e1.jpg: 384x640 12 cars, 1 parking meter, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befd706d-40c8471f.jpg: 384x640 1 person, 6 cars, 11.4ms\n",
            "Speed: 6.7ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5229/10000 [02:47<02:44, 28.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befe15d9-e3db8d6b.jpg: 384x640 1 person, 12 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befee345-01dae796.jpg: 384x640 2 persons, 4 cars, 3 traffic lights, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befee345-19b86489.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/befee345-1efe9c0a.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5233/10000 [02:47<02:33, 31.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beff1d1c-567ec742.jpg: 384x640 3 cars, 1 truck, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beff1d1c-61ba43ef.jpg: 384x640 1 person, 4 cars, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beff1d1c-7c47d369.jpg: 384x640 17 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beff1d1c-c6d92f51.jpg: 384x640 2 cars, 1 traffic light, 15.0ms\n",
            "Speed: 1.7ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5237/10000 [02:47<02:33, 31.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beff1d1c-cd927d17.jpg: 384x640 2 cars, 2 traffic lights, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beff1d1c-f80d0deb.jpg: 384x640 1 person, 1 traffic light, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beff1d1c-faff23dd.jpg: 384x640 9 cars, 1 traffic light, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/beffe676-8c0d1028.jpg: 384x640 9 cars, 1 truck, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5241/10000 [02:47<02:38, 30.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0038bc-5446bb48.jpg: 384x640 3 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0038bc-5512f257.jpg: 384x640 3 cars, 1 traffic light, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf02cf02-6168f0d6.jpg: 384x640 9 cars, 1 bus, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf037fa1-01adcdac.jpg: 384x640 2 persons, 6 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▏    | 5245/10000 [02:47<02:32, 31.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf03e478-3ead0cb8.jpg: 384x640 6 cars, 1 truck, 1 stop sign, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf03faea-d6b6f567.jpg: 384x640 (no detections), 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf041cc0-35f5357e.jpg: 384x640 3 cars, 2 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf04b038-341ec0e5.jpg: 384x640 7 cars, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf052c3b-5c1b4e94.jpg: 384x640 1 car, 1 traffic light, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  52%|█████▎    | 5250/10000 [02:47<02:19, 34.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf052c3b-a0f32e60.jpg: 384x640 6 cars, 1 traffic light, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf054de4-025bb1c3.jpg: 384x640 3 cars, 2 trucks, 3 traffic lights, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf05a6c1-e2ce238f.jpg: 384x640 3 persons, 7 cars, 4 traffic lights, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf05e3be-6a2103bc.jpg: 384x640 2 cars, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5254/10000 [02:47<02:14, 35.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf05e3be-96b558db.jpg: 384x640 4 cars, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0b285b-46b928cd.jpg: 384x640 6 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0b285b-afa81125.jpg: 384x640 1 person, 7 cars, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0b4238-302c2ca1.jpg: 384x640 1 person, 4 cars, 1 traffic light, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0e0d24-5b11b412.jpg: 384x640 8 cars, 1 bus, 1 truck, 1 traffic light, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5259/10000 [02:47<02:11, 35.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0e0d24-ab9a3039.jpg: 384x640 2 persons, 2 bicycles, 7 cars, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0e0d24-b48c6201.jpg: 384x640 20 cars, 1 truck, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0e0d24-c2c09c60.jpg: 384x640 8 cars, 1 bus, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0eda09-d1773b85.jpg: 384x640 2 cars, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5263/10000 [02:47<02:19, 33.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0fa6b5-1388ed76.jpg: 384x640 3 cars, 1 truck, 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0fa6b5-d2d998ed.jpg: 384x640 4 cars, 1 truck, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf0fd4de-7db956ab.jpg: 384x640 1 car, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf10e8c4-9122dd20.jpg: 384x640 1 person, 9 cars, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5267/10000 [02:48<02:25, 32.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf12003f-2a0d3f5f.jpg: 384x640 5 cars, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf144b6a-99b46408.jpg: 384x640 1 car, 1 train, 2 trucks, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf144b6a-c204b7ad.jpg: 384x640 7 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf15b5bf-01ddf8ac.jpg: 384x640 1 person, 4 cars, 3 trucks, 1 traffic light, 12.8ms\n",
            "Speed: 3.9ms preprocess, 12.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5271/10000 [02:48<02:31, 31.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf15b5bf-1416d166.jpg: 384x640 8 cars, 1 bus, 1 truck, 15.9ms\n",
            "Speed: 1.7ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf15c7b5-99d19019.jpg: 384x640 6 cars, 15.3ms\n",
            "Speed: 4.6ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf165ce1-a936b909.jpg: 384x640 6 cars, 18.4ms\n",
            "Speed: 2.0ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1787f3-3073f6c0.jpg: 384x640 2 cars, 2 traffic lights, 19.1ms\n",
            "Speed: 2.0ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5275/10000 [02:48<02:48, 27.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf183e49-9965b6a6.jpg: 384x640 3 cars, 1 truck, 17.0ms\n",
            "Speed: 3.9ms preprocess, 17.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf183e49-ba9bf999.jpg: 384x640 7 cars, 2 trucks, 1 traffic light, 21.3ms\n",
            "Speed: 2.5ms preprocess, 21.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf196891-1bf4eedc.jpg: 384x640 12 cars, 1 traffic light, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5278/10000 [02:48<02:59, 26.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1a30f8-29c812b9.jpg: 384x640 2 cars, 19.4ms\n",
            "Speed: 1.9ms preprocess, 19.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1a30f8-59a115d8.jpg: 384x640 (no detections), 19.3ms\n",
            "Speed: 1.8ms preprocess, 19.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1a30f8-9e0a449f.jpg: 384x640 1 car, 11.7ms\n",
            "Speed: 5.9ms preprocess, 11.7ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5281/10000 [02:48<03:00, 26.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1af4ce-dcf62242.jpg: 384x640 1 person, 4 cars, 1 traffic light, 19.4ms\n",
            "Speed: 1.8ms preprocess, 19.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1af616-188d7e2a.jpg: 384x640 5 cars, 1 traffic light, 12.9ms\n",
            "Speed: 6.9ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1af616-5a57545f.jpg: 384x640 10 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5284/10000 [02:48<02:59, 26.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1af616-e750e7dd.jpg: 384x640 11 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1bae75-f13a1d02.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1e5669-0beb1b4a.jpg: 384x640 2 persons, 5 cars, 1 bus, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1e5669-69f07222.jpg: 384x640 1 person, 9 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5288/10000 [02:48<02:42, 29.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1e5669-860f46d0.jpg: 384x640 4 cars, 1 truck, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1e5669-bbaafa89.jpg: 384x640 7 cars, 1 truck, 13.7ms\n",
            "Speed: 1.7ms preprocess, 13.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1e5669-e6da49f2.jpg: 384x640 5 cars, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5291/10000 [02:49<02:41, 29.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1f4d74-22e5dedf.jpg: 384x640 4 cars, 1 traffic light, 9.5ms\n",
            "Speed: 3.4ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1f6e6e-3e47c0f7.jpg: 384x640 4 cars, 1 traffic light, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf1f6e6e-56f03a2b.jpg: 384x640 1 car, 2 traffic lights, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf213ac1-1665b81a.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5295/10000 [02:49<02:31, 31.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf213ac1-62a8536b.jpg: 384x640 6 cars, 2 trucks, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf213ac1-760849cf.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf214d1e-0e86ca1f.jpg: 384x640 5 cars, 1 traffic light, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf214d1e-13344ae4.jpg: 384x640 2 persons, 6 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5299/10000 [02:49<02:22, 32.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf214d1e-2c30bc7d.jpg: 384x640 6 persons, 7 cars, 1 bus, 14.0ms\n",
            "Speed: 1.7ms preprocess, 14.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf234dae-307f8179.jpg: 384x640 3 cars, 1 traffic light, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf234dae-5e550365.jpg: 384x640 4 cars, 3 traffic lights, 13.5ms\n",
            "Speed: 3.9ms preprocess, 13.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf234dae-f65aaae7.jpg: 384x640 1 car, 1 bus, 1 truck, 1 traffic light, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5303/10000 [02:49<02:38, 29.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf24495d-0926df8b.jpg: 384x640 2 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf24495d-c9787981.jpg: 384x640 2 persons, 8 cars, 7.8ms\n",
            "Speed: 3.8ms preprocess, 7.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf245ae0-5e89fbec.jpg: 384x640 5 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf245ae0-7630688e.jpg: 384x640 1 person, 3 cars, 1 traffic light, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5307/10000 [02:49<02:36, 30.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf253792-58f60cfd.jpg: 384x640 5 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf253792-ee5c325c.jpg: 384x640 5 cars, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf261d80-f339c048.jpg: 384x640 4 cars, 1 truck, 9.7ms\n",
            "Speed: 5.0ms preprocess, 9.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf293835-27fe9270.jpg: 384x640 7 cars, 6 traffic lights, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5311/10000 [02:49<02:37, 29.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf29e65c-53d90f54.jpg: 384x640 10 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2a6720-a23c2b5e.jpg: 384x640 20 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2c174a-547a550a.jpg: 384x640 1 person, 11 cars, 14.3ms\n",
            "Speed: 4.1ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2cc385-11d88c56.jpg: 384x640 9 cars, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5315/10000 [02:49<02:44, 28.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2e0bca-0e06c1e6.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2e0bca-37a0f62f.jpg: 384x640 1 traffic light, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2e0bca-9689bbb7.jpg: 384x640 3 traffic lights, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2f4d22-2ce6a77f.jpg: 384x640 3 cars, 3 trucks, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5319/10000 [02:49<02:32, 30.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2fa820-e9e1f3a9.jpg: 384x640 3 cars, 1 traffic light, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2fa820-f92b9073.jpg: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.7ms preprocess, 12.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2fac72-133aa7bd.jpg: 384x640 10 cars, 1 bus, 1 truck, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf2fac72-c72dea3b.jpg: 384x640 1 car, 13.3ms\n",
            "Speed: 4.5ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5323/10000 [02:50<02:29, 31.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf31a320-4f8a93b3.jpg: 384x640 3 cars, 1 truck, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf343a92-8db05f89.jpg: 384x640 2 cars, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf35c34e-a6721934.jpg: 384x640 1 truck, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf35cb3d-af58fa54.jpg: 384x640 9 cars, 1 bus, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5327/10000 [02:50<02:33, 30.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf383078-27a885cb.jpg: 384x640 6 cars, 1 truck, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf3ce441-1f58c6c7.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf3ce441-9a0953bb.jpg: 384x640 4 persons, 12 cars, 1 traffic light, 14.1ms\n",
            "Speed: 6.3ms preprocess, 14.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf3d49bf-b543e245.jpg: 384x640 3 cars, 18.6ms\n",
            "Speed: 2.0ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5331/10000 [02:50<02:43, 28.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf3f6680-1b77d211.jpg: 384x640 4 traffic lights, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf42f468-f2b3301f.jpg: 384x640 4 persons, 3 cars, 1 bus, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf44f0b6-7e6ad409.jpg: 384x640 3 cars, 1 traffic light, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5334/10000 [02:50<02:48, 27.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf44f0b6-9339bf70.jpg: 384x640 2 traffic lights, 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf44f0b6-9e06f79f.jpg: 384x640 1 car, 1 truck, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf44f0b6-b0ca7b49.jpg: 384x640 2 cars, 18.9ms\n",
            "Speed: 1.9ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5337/10000 [02:50<02:45, 28.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf44f0b6-f574a2e3.jpg: 384x640 4 cars, 13.7ms\n",
            "Speed: 4.1ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf474631-7bf7833c.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf474631-c3a76c7d.jpg: 384x640 6 cars, 1 stop sign, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf476255-3d67b267.jpg: 384x640 12 cars, 3 trucks, 8 traffic lights, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5341/10000 [02:50<02:36, 29.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf4784eb-172d9e7a.jpg: 384x640 6 cars, 14.4ms\n",
            "Speed: 4.8ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf480c09-1ca4a92f.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf482378-7f39ea1d.jpg: 384x640 4 cars, 1 traffic light, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf482378-d236a3a7.jpg: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5345/10000 [02:50<02:28, 31.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf482378-efc17f31.jpg: 384x640 1 car, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf4906e0-73ed04de.jpg: 384x640 13 cars, 1 truck, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf4af26f-12121f1d.jpg: 384x640 9 cars, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf4af26f-3304199e.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  53%|█████▎    | 5349/10000 [02:50<02:28, 31.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf4af26f-44beba25.jpg: 384x640 1 person, 8 cars, 1 bus, 1 traffic light, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf4b0c94-a416bc37.jpg: 384x640 5 cars, 2 traffic lights, 14.3ms\n",
            "Speed: 5.1ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf527384-71f7e998.jpg: 384x640 1 car, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf527384-894c88c6.jpg: 384x640 1 person, 3 cars, 1 traffic light, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▎    | 5353/10000 [02:51<02:31, 30.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf538a51-8782f04d.jpg: 384x640 9 cars, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf53cf41-5f1eb5f7.jpg: 384x640 6 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf54973d-ad129b06.jpg: 384x640 11 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf54973d-fa144605.jpg: 384x640 1 person, 2 cars, 2 trucks, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▎    | 5357/10000 [02:51<02:37, 29.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf568d39-2bac1d09.jpg: 384x640 5 persons, 1 car, 2 traffic lights, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf57ea07-3e2c4a5c.jpg: 384x640 5 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf585795-7312cfb9.jpg: 384x640 9 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▎    | 5360/10000 [02:51<02:38, 29.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf593f19-ebbb7e5d.jpg: 384x640 3 persons, 16 cars, 1 traffic light, 18.2ms\n",
            "Speed: 2.0ms preprocess, 18.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5ae456-be2897e1.jpg: 384x640 8 cars, 1 truck, 14.9ms\n",
            "Speed: 2.0ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5b423c-955dc71e.jpg: 384x640 3 cars, 7 traffic lights, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▎    | 5363/10000 [02:51<02:49, 27.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5b423c-eb2447d8.jpg: 384x640 3 cars, 1 truck, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5b7ee3-18a07bcb.jpg: 384x640 1 person, 8 cars, 1 truck, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5b7ee3-c2fbdc46.jpg: 384x640 13 cars, 1 traffic light, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5c77a9-13452168.jpg: 384x640 5 cars, 1 truck, 14.3ms\n",
            "Speed: 1.8ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▎    | 5367/10000 [02:51<02:40, 28.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5cbf56-68ea71b1.jpg: 384x640 11 cars, 1 truck, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5d49a3-e2779858.jpg: 384x640 2 cars, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5e662c-0c0afa60.jpg: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▎    | 5370/10000 [02:51<02:43, 28.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5e662c-dba716fd.jpg: 384x640 2 persons, 2 cars, 1 traffic light, 1 bench, 9.5ms\n",
            "Speed: 6.5ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5ea8d2-108ab9c6.jpg: 384x640 3 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf5ea8d2-94c28266.jpg: 384x640 18 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▎    | 5373/10000 [02:51<02:41, 28.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf601884-354b9229.jpg: 384x640 6 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf601884-af1b43e3.jpg: 384x640 7 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf601f23-a680411c.jpg: 384x640 8 cars, 1 stop sign, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf60c0eb-310cd7ca.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5377/10000 [02:51<02:30, 30.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf61730d-6e8eedcc.jpg: 384x640 6 cars, 1 truck, 10.8ms\n",
            "Speed: 1.7ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf61730d-ee3b8d16.jpg: 384x640 3 cars, 1 train, 1 traffic light, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf622d4e-cfdc02ae.jpg: 384x640 1 person, 6 cars, 1 truck, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6250de-7cb7cbea.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5381/10000 [02:52<02:24, 31.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf62df05-4bf9402e.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf62df05-874604fe.jpg: 384x640 6 cars, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf62df05-98d03652.jpg: 384x640 1 car, 3 traffic lights, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf62e180-b6240b12.jpg: 384x640 5 cars, 1 bus, 1 truck, 1 stop sign, 13.0ms\n",
            "Speed: 5.1ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5385/10000 [02:52<02:25, 31.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf62fab5-912af759.jpg: 384x640 6 cars, 2 traffic lights, 10.6ms\n",
            "Speed: 4.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf62fab5-bb2d9b65.jpg: 384x640 10 cars, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6315ee-a77e1bb2.jpg: 384x640 1 bicycle, 6 cars, 2 traffic lights, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6315ee-ab762696.jpg: 384x640 1 traffic light, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5389/10000 [02:52<02:34, 29.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf65bf11-942ce158.jpg: 384x640 16 cars, 1 traffic light, 12.7ms\n",
            "Speed: 5.7ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf668f9e-a12cb035.jpg: 384x640 2 cars, 2 buss, 1 truck, 1 traffic light, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf66b0b2-63bcf4a9.jpg: 384x640 1 car, 12.9ms\n",
            "Speed: 2.6ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6711ef-76e408aa.jpg: 384x640 3 cars, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5393/10000 [02:52<02:39, 28.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf671862-75861ff3.jpg: 384x640 3 persons, 10 cars, 1 bus, 1 truck, 3 traffic lights, 22.2ms\n",
            "Speed: 1.9ms preprocess, 22.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6789ed-4089397b.jpg: 384x640 4 cars, 1 truck, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf688d4d-54210a91.jpg: 384x640 1 car, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5396/10000 [02:52<02:44, 27.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf688d4d-e96a15d5.jpg: 384x640 1 car, 1 traffic light, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6b680e-c959640f.jpg: 384x640 1 person, 2 cars, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6b680e-fe68c5f5.jpg: 384x640 (no detections), 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6e127b-7d039d6b.jpg: 384x640 1 person, 3 cars, 1 train, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5400/10000 [02:52<02:38, 28.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6e127b-cc8a310b.jpg: 384x640 1 car, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf6fda4e-0a49960f.jpg: 384x640 1 car, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf70a9e2-55b26931.jpg: 384x640 2 cars, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf70d850-0abbeea2.jpg: 384x640 1 car, 17.8ms\n",
            "Speed: 2.3ms preprocess, 17.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5404/10000 [02:52<02:33, 29.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf721457-715b4856.jpg: 384x640 7 cars, 19.9ms\n",
            "Speed: 1.9ms preprocess, 19.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf7355b8-f5de162f.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 2.3ms preprocess, 15.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf761516-f03a434a.jpg: 384x640 3 cars, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf76fa8e-889c317d.jpg: 384x640 1 truck, 16.6ms\n",
            "Speed: 2.0ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5408/10000 [02:52<02:34, 29.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf77e9b1-33a1b81e.jpg: 384x640 8 cars, 16.1ms\n",
            "Speed: 1.8ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf77e9b1-717cbd2c.jpg: 384x640 (no detections), 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf77e9b1-b7b5025b.jpg: 384x640 7 cars, 2 traffic lights, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5411/10000 [02:53<02:35, 29.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf77e9b1-b862e178.jpg: 384x640 5 cars, 1 traffic light, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf77e9b1-cd3a731c.jpg: 384x640 3 cars, 1 traffic light, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf77e9b1-ebc57a82.jpg: 384x640 (no detections), 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf77e9b1-f693c2f5.jpg: 384x640 3 cars, 1 bus, 1 truck, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5415/10000 [02:53<02:33, 29.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf78f601-1003f3da.jpg: 384x640 6 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf7b93b6-de7552a6.jpg: 384x640 7 cars, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf7cb2a4-685faa7f.jpg: 384x640 6 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf7e1159-054559d2.jpg: 384x640 6 cars, 5 traffic lights, 19.7ms\n",
            "Speed: 2.1ms preprocess, 19.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5419/10000 [02:53<02:33, 29.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf7e1159-d2bcc563.jpg: 384x640 6 cars, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf7f097a-2fcff02a.jpg: 384x640 13 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf7f98e7-026008d3.jpg: 384x640 11 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf7f98e7-ca70ee34.jpg: 384x640 5 cars, 1 train, 4 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5423/10000 [02:53<02:32, 30.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf80599d-c04f3cbb.jpg: 384x640 1 person, 4 cars, 1 truck, 2 traffic lights, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf80a27d-159d64f6.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf80a27d-2933a89a.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf80a27d-38c70fee.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8220b9-086e9e29.jpg: 384x640 1 person, 4 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5428/10000 [02:53<02:16, 33.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8332bd-2f11c278.jpg: 384x640 5 persons, 11 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf838e9d-08f6fb44.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf838e9d-d8d5be4d.jpg: 384x640 5 cars, 1 truck, 7 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf83a7d7-d4c69012.jpg: 384x640 9 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5432/10000 [02:53<02:20, 32.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf83fca6-1742f6e6.jpg: 384x640 13 cars, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8463c9-7f1810d4.jpg: 384x640 4 cars, 1 bus, 2 trucks, 6 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf86bb70-2699b8b6.jpg: 384x640 6 cars, 1 truck, 6 traffic lights, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf879071-533b979e.jpg: 384x640 4 persons, 6 cars, 1 bus, 1 truck, 1 traffic light, 9.3ms\n",
            "Speed: 4.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5436/10000 [02:53<02:27, 30.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8982ce-1369162c.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8982ce-1ae20c0f.jpg: 384x640 6 persons, 6 cars, 1 backpack, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8982ce-a4dd6736.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8ec5b7-66439a9c.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5440/10000 [02:53<02:19, 32.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8ec5b7-72e1f37c.jpg: 384x640 10 cars, 2 trucks, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8feaf5-cf2b6195.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8ff5f5-1133a840.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8ff5f5-877edaa0.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 2.6ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5444/10000 [02:54<02:21, 32.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8ff5f5-916b50d0.jpg: 384x640 6 persons, 3 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf8ff5f5-9ae0cea2.jpg: 384x640 4 cars, 1 bus, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf90176a-c0b94917.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf928096-25eb02e7.jpg: 384x640 2 cars, 1 traffic light, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  54%|█████▍    | 5448/10000 [02:54<02:16, 33.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf928096-34a8405b.jpg: 384x640 7 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf928096-9b96d95f.jpg: 384x640 3 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9460c0-65fea53a.jpg: 384x640 1 person, 2 cars, 2 buss, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf96ae83-7705add3.jpg: 384x640 6 cars, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5452/10000 [02:54<02:16, 33.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf96f64f-283c7376.jpg: 384x640 1 car, 1 traffic light, 14.8ms\n",
            "Speed: 2.0ms preprocess, 14.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf97082f-6527ff5e.jpg: 384x640 12 cars, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf97082f-7b5ec66c.jpg: 384x640 7 cars, 1 truck, 1 keyboard, 13.6ms\n",
            "Speed: 4.4ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf971590-0308762e.jpg: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5456/10000 [02:54<02:24, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf972758-7ae264e7.jpg: 384x640 2 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf972758-b963f153.jpg: 384x640 4 cars, 18.8ms\n",
            "Speed: 3.8ms preprocess, 18.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9881e4-9f1bb471.jpg: 384x640 7 cars, 1 traffic light, 16.7ms\n",
            "Speed: 1.9ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9881e4-ade54a94.jpg: 384x640 6 persons, 1 backpack, 1 handbag, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5460/10000 [02:54<02:31, 29.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9a1430-3640a531.jpg: 384x640 9 cars, 11.6ms\n",
            "Speed: 6.7ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9a1430-d4650520.jpg: 384x640 3 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9aa573-01b4b4f8.jpg: 384x640 2 cars, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9b895d-47e834dc.jpg: 384x640 7 cars, 1 traffic light, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5464/10000 [02:54<02:36, 29.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9ba5a3-22398dcc.jpg: 384x640 4 cars, 15.5ms\n",
            "Speed: 2.9ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9cab66-816b6d5f.jpg: 384x640 4 cars, 1 traffic light, 15.1ms\n",
            "Speed: 3.2ms preprocess, 15.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9d1ca5-2ff62aeb.jpg: 384x640 2 cars, 1 bus, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5467/10000 [02:54<02:45, 27.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9e2172-8a10c663.jpg: 384x640 11 cars, 2 trucks, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9e2172-8feb4817.jpg: 384x640 3 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9e3b67-2d5736bc.jpg: 384x640 9 cars, 1 bus, 9.2ms\n",
            "Speed: 6.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5470/10000 [02:54<02:48, 26.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9e3b67-49c1ef1c.jpg: 384x640 5 persons, 5 cars, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9e3b67-7c3ff8f9.jpg: 384x640 1 person, 4 cars, 2 trucks, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bf9e5f64-da8a4c40.jpg: 384x640 10 cars, 3 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa05832-d5061cc3.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5474/10000 [02:55<02:33, 29.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa087f5-1913ced9.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa23f26-588ee4a8.jpg: 384x640 5 cars, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa5fc6e-d45ac06d.jpg: 384x640 11 cars, 2 trucks, 5 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa5fc6e-d9573dba.jpg: 384x640 2 persons, 1 bottle, 11.9ms\n",
            "Speed: 1.7ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5478/10000 [02:55<02:26, 30.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa5fc6e-e4c87cf7.jpg: 384x640 12 cars, 1 truck, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa89962-310ad204.jpg: 384x640 4 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa89962-637b5ce3.jpg: 384x640 1 person, 2 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa89962-9698bc68.jpg: 384x640 8 cars, 1 traffic light, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5482/10000 [02:55<02:21, 31.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa89962-a4546438.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa8c531-7831c864.jpg: 384x640 1 car, 1 truck, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa8c531-e3fed04f.jpg: 384x640 1 person, 5 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa92b30-41f9894f.jpg: 384x640 (no detections), 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5486/10000 [02:55<02:16, 33.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfa92b30-f12f3535.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa2229-ae426591.jpg: 384x640 3 cars, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa2229-c1b190bb.jpg: 384x640 4 cars, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa6e54-07a6b37f.jpg: 384x640 3 persons, 9 cars, 1 fire hydrant, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5490/10000 [02:55<02:11, 34.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa6e54-0aeb77a6.jpg: 384x640 2 cars, 1 truck, 1 bench, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa6e54-147a080d.jpg: 384x640 2 cars, 1 truck, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa6e54-7749c750.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa6e54-86f831bf.jpg: 384x640 3 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5494/10000 [02:55<02:06, 35.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa6e54-d6a20a93.jpg: 384x640 4 cars, 1 traffic light, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa6e54-f82c8c56.jpg: 384x640 5 cars, 1 bus, 1 truck, 2 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaa6e54-fafa90f6.jpg: 384x640 1 person, 1 car, 4 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaca2bb-22fbe726.jpg: 384x640 5 cars, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▍    | 5498/10000 [02:55<02:07, 35.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaca2bb-30af2110.jpg: 384x640 4 persons, 1 car, 1 bus, 1 train, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaca2bb-98dfee43.jpg: 384x640 7 cars, 1 truck, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaca2bb-b5223147.jpg: 384x640 3 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfaca2bb-f1c305a8.jpg: 384x640 8 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5502/10000 [02:55<02:03, 36.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfacd805-eb6140c4.jpg: 384x640 7 persons, 5 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfae2833-616084f1.jpg: 384x640 2 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb0e8d5-bd35f625.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb11474-87040800.jpg: 384x640 3 cars, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5506/10000 [02:55<02:02, 36.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb23820-94babfba.jpg: 384x640 2 persons, 10 cars, 1 truck, 3 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb2803b-16154aab.jpg: 384x640 10 cars, 1 truck, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb37269-2df1685d.jpg: 384x640 2 persons, 5 cars, 1 bus, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb3cabc-90e4418a.jpg: 384x640 16 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5510/10000 [02:56<02:08, 34.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb3e0e3-6767a552.jpg: 384x640 10 cars, 1 truck, 1 traffic light, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb3e0e3-9844c8ca.jpg: 384x640 11 cars, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb41e9f-48952c95.jpg: 384x640 6 cars, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb41e9f-e4f81437.jpg: 384x640 12 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5514/10000 [02:56<02:11, 34.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb4dfcd-2f987f2b.jpg: 384x640 9 cars, 2 trucks, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb5e668-6cddf5eb.jpg: 384x640 8 cars, 2 traffic lights, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb5e668-73628b9f.jpg: 384x640 5 persons, 14 cars, 14.7ms\n",
            "Speed: 2.6ms preprocess, 14.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb60a50-6a338fe9.jpg: 384x640 (no detections), 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5518/10000 [02:56<02:23, 31.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb6d7c1-d607f837.jpg: 384x640 1 person, 1 car, 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb72242-2b84934e.jpg: 384x640 2 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb72242-c9cffb08.jpg: 384x640 2 persons, 4 cars, 2 traffic lights, 16.4ms\n",
            "Speed: 2.0ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb97ec2-23a5c362.jpg: 384x640 9 cars, 18.8ms\n",
            "Speed: 1.9ms preprocess, 18.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5522/10000 [02:56<02:31, 29.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfb9cf70-29fd574e.jpg: 384x640 3 persons, 6 cars, 1 bus, 4 traffic lights, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfba9eb5-3f0a9a5b.jpg: 384x640 2 cars, 1 traffic light, 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfba9eb5-64a87010.jpg: 384x640 1 person, 7 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfba9eb5-efe572ee.jpg: 384x640 5 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5526/10000 [02:56<02:28, 30.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbaca55-12ec55cc.jpg: 384x640 12 cars, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbaca55-9e368f0e.jpg: 384x640 1 car, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbaca55-cb5e8edb.jpg: 384x640 4 cars, 1 bus, 15.5ms\n",
            "Speed: 3.0ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbc2f14-6fb10366.jpg: 384x640 6 cars, 1 bus, 1 truck, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5530/10000 [02:56<02:34, 29.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbe2ad2-03a46467.jpg: 384x640 3 cars, 1 motorcycle, 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbe2ad2-303c3576.jpg: 384x640 3 cars, 2 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbe2ad2-a1ac1610.jpg: 384x640 6 cars, 1 bus, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbe2ad2-eaedd133.jpg: 384x640 11 cars, 1 bus, 2 traffic lights, 13.9ms\n",
            "Speed: 6.4ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5534/10000 [02:56<02:34, 28.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfbe2ad2-ec5dea9d.jpg: 384x640 4 cars, 17.6ms\n",
            "Speed: 3.3ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc0402e-23a0568c.jpg: 384x640 5 cars, 2 traffic lights, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc06497-fc2b4581.jpg: 384x640 3 persons, 3 cars, 1 traffic light, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc3a09f-117ab7b9.jpg: 384x640 2 persons, 9 cars, 1 truck, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5538/10000 [02:57<02:30, 29.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc43556-5db6add1.jpg: 384x640 2 persons, 12 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc5dbe7-792c876f.jpg: 384x640 4 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc62f16-5ecb9627.jpg: 384x640 1 person, 9 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc62f16-845d051b.jpg: 384x640 6 cars, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5542/10000 [02:57<02:27, 30.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc62f16-f0cc96d9.jpg: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc62f16-f4f6adfa.jpg: 384x640 4 cars, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc62f16-f88f822c.jpg: 384x640 6 cars, 1 bus, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc62f16-fabea717.jpg: 384x640 9 cars, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5546/10000 [02:57<02:33, 28.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc8dd24-b7264c9d.jpg: 384x640 15 cars, 1 truck, 11.5ms\n",
            "Speed: 2.7ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc8dd24-e8506ffa.jpg: 384x640 1 person, 8 cars, 1 stop sign, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfc99518-547e6e69.jpg: 384x640 4 cars, 1 traffic light, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  55%|█████▌    | 5549/10000 [02:57<02:34, 28.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfcd1873-fbd35796.jpg: 384x640 1 person, 8 cars, 9.5ms\n",
            "Speed: 3.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfcd4491-8f55e55d.jpg: 384x640 (no detections), 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd08f2c-b67851d1.jpg: 384x640 5 persons, 1 bicycle, 10 cars, 1 motorcycle, 1 traffic light, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5552/10000 [02:57<02:36, 28.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd29575-767314a3.jpg: 384x640 6 cars, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd32194-f4ea20e9.jpg: 384x640 1 person, 4 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd64d5f-172c9bb5.jpg: 384x640 1 person, 2 cars, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd64d5f-a12327b4.jpg: 384x640 16 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5556/10000 [02:57<02:27, 30.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd64d5f-d141be33.jpg: 384x640 7 persons, 10 cars, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd64d5f-ec05de8b.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd64d5f-f98204af.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfd74a4a-94602dce.jpg: 384x640 7 cars, 1 traffic light, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5560/10000 [02:57<02:25, 30.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfdb9d69-9beabbd2.jpg: 384x640 2 cars, 2 trucks, 1 traffic light, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfdd9ffd-3943106e.jpg: 384x640 7 cars, 4 trucks, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfdd9ffd-82f78be7.jpg: 384x640 10 cars, 1 bus, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe0801e-20388316.jpg: 384x640 8 cars, 1 truck, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5564/10000 [02:57<02:23, 30.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe133fb-db319b45.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe1fd3b-01f8671b.jpg: 384x640 1 person, 6 cars, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe2b817-505676ef.jpg: 384x640 17 cars, 1 fire hydrant, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe2b817-628f0621.jpg: 384x640 5 cars, 1 bus, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5568/10000 [02:58<02:22, 31.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe2b817-8501bdbe.jpg: 384x640 5 cars, 2 trucks, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe2b817-f79474a3.jpg: 384x640 9 cars, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe52f47-395aca52.jpg: 384x640 5 cars, 1 bus, 1 truck, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe52f47-a09aa689.jpg: 384x640 3 persons, 5 cars, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5572/10000 [02:58<02:21, 31.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe587eb-11d07974.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe587eb-6335f4b3.jpg: 384x640 1 car, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe587eb-9394a16a.jpg: 384x640 4 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe587eb-d21baba4.jpg: 384x640 5 persons, 5 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5576/10000 [02:58<02:20, 31.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe75427-6cd46203.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 5.8ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe7b25a-08e67541.jpg: 384x640 4 cars, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe8b400-4d8c8141.jpg: 384x640 4 cars, 17.0ms\n",
            "Speed: 2.1ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe8b400-4f8084c2.jpg: 384x640 1 person, 10 cars, 1 bus, 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5580/10000 [02:58<02:29, 29.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe8b400-befb1a30.jpg: 384x640 1 car, 17.9ms\n",
            "Speed: 2.6ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe976fd-62a13503.jpg: 384x640 12 cars, 2 traffic lights, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe98b68-6e23d74e.jpg: 384x640 5 cars, 17.1ms\n",
            "Speed: 2.4ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5583/10000 [02:58<02:41, 27.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe98b68-afa168ac.jpg: 384x640 2 cars, 22.3ms\n",
            "Speed: 2.0ms preprocess, 22.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfe98b68-b1125889.jpg: 384x640 1 car, 1 truck, 17.2ms\n",
            "Speed: 2.1ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfea6630-09edb925.jpg: 384x640 9 cars, 18.6ms\n",
            "Speed: 1.9ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5586/10000 [02:58<02:46, 26.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfea6630-1ddff719.jpg: 384x640 8 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfea6630-3fa3b8fb.jpg: 384x640 5 persons, 5 cars, 5 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfea6630-64c40790.jpg: 384x640 5 cars, 2 trucks, 7 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfea6630-8072c98b.jpg: 384x640 3 cars, 2 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5590/10000 [02:58<02:33, 28.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfea6630-a872fd0d.jpg: 384x640 7 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfee349b-7f157350.jpg: 384x640 5 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfee82ef-f5aad313.jpg: 384x640 3 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfef4a55-005ca254.jpg: 384x640 6 persons, 3 cars, 1 truck, 2 traffic lights, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5594/10000 [02:58<02:28, 29.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfef4a55-0c354241.jpg: 384x640 1 person, 4 cars, 1 bus, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfef4a55-a91bccc2.jpg: 384x640 4 persons, 6 cars, 1 umbrella, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfef4a55-c2edf3fa.jpg: 384x640 1 person, 4 cars, 3 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bfef4a55-cb6a5afa.jpg: 384x640 1 truck, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5598/10000 [02:59<02:19, 31.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff1a1d0-56aa4453.jpg: 384x640 1 truck, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff1a1d0-5a57063a.jpg: 384x640 3 cars, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff2ee41-90d20c1a.jpg: 384x640 8 persons, 1 bicycle, 1 motorcycle, 2 trucks, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff35990-58723dd3.jpg: 384x640 1 car, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5602/10000 [02:59<02:21, 31.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff4b8c8-1713b132.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff4bb8b-08eee3f5.jpg: 384x640 11 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff4bb8b-152c6105.jpg: 384x640 7 cars, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff4bb8b-8a96fd04.jpg: 384x640 7 cars, 17.2ms\n",
            "Speed: 1.8ms preprocess, 17.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5606/10000 [02:59<02:21, 31.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff7091d-346e6f58.jpg: 384x640 1 bus, 1 potted plant, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff7091d-4ea5eb2a.jpg: 384x640 12 cars, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff76a29-d83cd75e.jpg: 384x640 7 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff7ed18-00774a1e.jpg: 384x640 1 car, 1 traffic light, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5610/10000 [02:59<02:24, 30.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff7ed18-63d4857d.jpg: 384x640 3 cars, 16.0ms\n",
            "Speed: 2.5ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bff7ed18-b5f7d2e1.jpg: 384x640 4 cars, 1 truck, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffa2c3f-5f909b3f.jpg: 384x640 2 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffa2c3f-ac75497e.jpg: 384x640 1 car, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5614/10000 [02:59<02:24, 30.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffa2c3f-b28b13ed.jpg: 384x640 3 cars, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffa98fc-bfb566ff.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffbaf67-67882851.jpg: 384x640 8 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffc4ac6-08b91b4d.jpg: 384x640 4 cars, 1 train, 10.0ms\n",
            "Speed: 4.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5618/10000 [02:59<02:20, 31.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffc4ac6-436c938b.jpg: 384x640 11 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffc4ac6-583caa9e.jpg: 384x640 2 cars, 3 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffd135f-e011f9b8.jpg: 384x640 2 persons, 4 cars, 1 bus, 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffd135f-e90ce8f8.jpg: 384x640 14 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▌    | 5622/10000 [02:59<02:17, 31.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffe6c38-2cd2565f.jpg: 384x640 7 cars, 1 bus, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffe6c38-d48f5ee5.jpg: 384x640 9 cars, 4 traffic lights, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffe8c14-18cf493f.jpg: 384x640 1 person, 11 cars, 2 traffic lights, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffe8c14-48544350.jpg: 384x640 8 persons, 1 bicycle, 4 cars, 1 truck, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▋    | 5626/10000 [02:59<02:20, 31.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffe8c14-b44a7634.jpg: 384x640 1 person, 9 cars, 2 buss, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/bffe8c14-cb8d9a20.jpg: 384x640 6 cars, 2 trucks, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c000dedd-0352a12a.jpg: 384x640 2 cars, 1 truck, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c000dedd-db6c37a3.jpg: 384x640 1 car, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▋    | 5630/10000 [03:00<02:13, 32.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c001770a-2aac41a8.jpg: 384x640 12 cars, 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c001c58f-86eaaa56.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0020346-d539abe5.jpg: 384x640 6 cars, 1 bus, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c002c544-26fdb4d1.jpg: 384x640 4 cars, 1 traffic light, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▋    | 5634/10000 [03:00<02:09, 33.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c002e4d7-fd635384.jpg: 384x640 4 cars, 3 buss, 1 truck, 11.8ms\n",
            "Speed: 2.9ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0035eda-6e1b34d6.jpg: 384x640 5 cars, 1 truck, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c003e0c6-ed98cc51.jpg: 384x640 2 cars, 1 truck, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0071cbb-02fb08c6.jpg: 384x640 1 person, 1 car, 1 truck, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▋    | 5638/10000 [03:00<02:17, 31.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c007ae4f-1529fac2.jpg: 384x640 5 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c007dc97-377cfd8a.jpg: 384x640 1 person, 1 car, 17.8ms\n",
            "Speed: 1.8ms preprocess, 17.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0082590-683d229f.jpg: 384x640 1 person, 4 cars, 1 truck, 11.1ms\n",
            "Speed: 5.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0082590-c1533b81.jpg: 384x640 8 cars, 17.5ms\n",
            "Speed: 3.1ms preprocess, 17.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▋    | 5642/10000 [03:00<02:29, 29.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0082590-e325cff4.jpg: 384x640 7 persons, 4 cars, 3 traffic lights, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c009571d-dec7e775.jpg: 384x640 5 cars, 2 traffic lights, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c009fbf7-93fa77b1.jpg: 384x640 5 cars, 1 train, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▋    | 5645/10000 [03:00<02:29, 29.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00a8f2a-d84a9895.jpg: 384x640 3 persons, 3 cars, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00c9631-ae7bd0ad.jpg: 384x640 1 person, 12 cars, 1 motorcycle, 1 truck, 2 traffic lights, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00cc83c-a6a9ce44.jpg: 384x640 7 persons, 9 cars, 2 trucks, 2 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  56%|█████▋    | 5648/10000 [03:00<02:31, 28.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00d02a5-01e36f95.jpg: 384x640 9 cars, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00d02a5-6d49812c.jpg: 384x640 1 person, 6 cars, 2 traffic lights, 15.9ms\n",
            "Speed: 1.9ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00d0859-8e02615e.jpg: 384x640 2 bicycles, 7 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5651/10000 [03:00<02:33, 28.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00dd69e-cee6e38e.jpg: 384x640 10 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00ec632-8bf1e59e.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00f8f83-5c4bc3eb.jpg: 384x640 8 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00f8f83-bdd9f783.jpg: 384x640 1 person, 3 cars, 1 bus, 2 traffic lights, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5655/10000 [03:00<02:24, 30.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c00fffc0-bd41df0c.jpg: 384x640 1 car, 1 traffic light, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c011d5e2-d4732967.jpg: 384x640 1 person, 4 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c012c422-cfa24c39.jpg: 384x640 2 cars, 2 motorcycles, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c013472b-6f3cec0b.jpg: 384x640 1 car, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5659/10000 [03:01<02:13, 32.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c013a15f-06edbffd.jpg: 384x640 1 person, 9 cars, 4 traffic lights, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c019c1f1-883ea964.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01c313b-e0b15fa2.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01c4d85-3381ebcd.jpg: 384x640 2 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5663/10000 [03:01<02:09, 33.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01c4d85-36b417ee.jpg: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01c4d85-745a5a22.jpg: 384x640 7 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01c4d85-a68b0ac8.jpg: 384x640 1 person, 4 cars, 2 traffic lights, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01c4d85-e0e6780a.jpg: 384x640 8 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5667/10000 [03:01<02:09, 33.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01cec8c-897f1dfc.jpg: 384x640 3 cars, 3 trucks, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01e4610-de557db8.jpg: 384x640 13 persons, 4 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01eddca-7c14637e.jpg: 384x640 3 cars, 1 truck, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01feca6-4fe11029.jpg: 384x640 4 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5671/10000 [03:01<02:11, 32.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c01feca6-512daace.jpg: 384x640 13 cars, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0200910-8ac0f85d.jpg: 384x640 3 cars, 1 traffic light, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0200910-93adc390.jpg: 384x640 7 cars, 1 traffic light, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0200910-e470c541.jpg: 384x640 2 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5675/10000 [03:01<02:14, 32.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0208527-089e044f.jpg: 384x640 1 car, 1 bus, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0209255-980acc6a.jpg: 384x640 8 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0217f91-3ec314e4.jpg: 384x640 10 cars, 3 trucks, 2 traffic lights, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02184c3-43f2bd7d.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5679/10000 [03:01<02:15, 32.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c022e075-40907eff.jpg: 384x640 2 cars, 2 trucks, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c022e075-de13593a.jpg: 384x640 1 truck, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c022f361-3ffdbe53.jpg: 384x640 2 persons, 6 cars, 2 traffic lights, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c024c31c-9ec7869f.jpg: 384x640 6 persons, 4 cars, 2 traffic lights, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5683/10000 [03:01<02:13, 32.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c025f721-84478bc5.jpg: 384x640 1 person, 8 cars, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0276bce-0683c19d.jpg: 384x640 4 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02cb208-81964a07.jpg: 384x640 6 cars, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02d0ae3-bce5af86.jpg: 384x640 3 cars, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5687/10000 [03:01<02:12, 32.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02d18db-023c1955.jpg: 384x640 12 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02d18db-f5278de0.jpg: 384x640 11 cars, 1 bus, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02d414a-44e52614.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02d414a-7176a61e.jpg: 384x640 4 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5691/10000 [03:02<02:11, 32.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02d91b8-8b1bdadc.jpg: 384x640 18 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02eb4ca-1f560719.jpg: 384x640 2 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02eb4ca-b352643a.jpg: 384x640 7 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02ee64a-3178b7fa.jpg: 384x640 2 persons, 8 cars, 2 trucks, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5695/10000 [03:02<02:10, 32.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02ee64a-64c0a49a.jpg: 384x640 2 persons, 8 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02ee64a-ec68fa8e.jpg: 384x640 6 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c02fb811-03f28b56.jpg: 384x640 2 cars, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0309dda-23a5c949.jpg: 384x640 18 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5699/10000 [03:02<02:11, 32.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c030d423-3c82226c.jpg: 384x640 3 cars, 2 trucks, 14.6ms\n",
            "Speed: 7.0ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c030d423-7f21731a.jpg: 384x640 3 cars, 1 traffic light, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c030d423-d10bec89.jpg: 384x640 1 car, 1 tv, 11.1ms\n",
            "Speed: 3.8ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c030d423-f3c1f768.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5703/10000 [03:02<02:13, 32.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c030d423-f82b1a39.jpg: 384x640 2 cars, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0336a86-50bbf914.jpg: 384x640 2 cars, 1 train, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0350481-340b9ea4.jpg: 384x640 8 cars, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c036f281-0fcdc2ee.jpg: 384x640 2 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5707/10000 [03:02<02:08, 33.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c036f281-1d7ac9df.jpg: 384x640 2 persons, 7 cars, 2 traffic lights, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c036f281-831b21ba.jpg: 384x640 3 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c036f281-a0c90e9a.jpg: 384x640 8 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c038cdca-4df5e979.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5711/10000 [03:02<02:06, 33.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c038f7df-82eb7666.jpg: 384x640 5 persons, 1 car, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c03936ec-8a87395f.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c03d48c2-869f09b4.jpg: 384x640 4 cars, 1 bus, 1 truck, 13.5ms\n",
            "Speed: 1.7ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c03d7f81-5f0aafb9.jpg: 384x640 1 person, 6 cars, 1 traffic light, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5715/10000 [03:02<02:06, 34.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c03f8f84-a2f668ce.jpg: 384x640 5 cars, 1 truck, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c04192a3-8f5b4646.jpg: 384x640 7 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c041ef14-a9bb6a98.jpg: 384x640 1 car, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c041f204-6b0c3778.jpg: 384x640 1 person, 5 cars, 1 bus, 1 truck, 2 traffic lights, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5719/10000 [03:02<02:04, 34.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c04246b7-5386e803.jpg: 384x640 3 cars, 1 traffic light, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c04246b7-d3f8084d.jpg: 384x640 1 car, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0458999-18bb1ce3.jpg: 384x640 4 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c046b4c6-420f75ad.jpg: 384x640 2 persons, 8 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5723/10000 [03:02<02:01, 35.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c047f07b-d0d11ec9.jpg: 384x640 6 cars, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c04ad8f3-05b8c75c.jpg: 384x640 2 persons, 5 cars, 2 buss, 1 truck, 1 traffic light, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c04eb80c-520a8f79.jpg: 384x640 3 traffic lights, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c050a325-3fbdf46f.jpg: 384x640 5 persons, 4 cars, 1 traffic light, 1 fire hydrant, 1 backpack, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5727/10000 [03:03<02:02, 34.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c050a325-b9aa9e5f.jpg: 384x640 2 persons, 6 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c050ecbc-968adb56.jpg: 384x640 6 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c051661b-c3b862eb.jpg: 384x640 3 persons, 3 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c051bcee-e5c6ad9f.jpg: 384x640 3 cars, 2 trucks, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5731/10000 [03:03<01:57, 36.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c054d340-311be93f.jpg: 384x640 2 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c055cef2-01665d65.jpg: 384x640 2 cars, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c055ff34-c10a74d4.jpg: 384x640 1 person, 3 cars, 17.8ms\n",
            "Speed: 2.0ms preprocess, 17.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0568203-456be7fe.jpg: 384x640 2 cars, 17.1ms\n",
            "Speed: 4.0ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5735/10000 [03:03<02:06, 33.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05703f8-d4391e9d.jpg: 384x640 5 cars, 1 truck, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0572d8a-a52b43eb.jpg: 384x640 1 person, 7 cars, 2 traffic lights, 21.0ms\n",
            "Speed: 1.9ms preprocess, 21.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0576688-a5a81042.jpg: 384x640 6 cars, 11.2ms\n",
            "Speed: 4.5ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05767da-e6197c97.jpg: 384x640 2 persons, 1 bicycle, 9 cars, 1 truck, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5739/10000 [03:03<02:21, 30.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05767da-e6e016b5.jpg: 384x640 7 cars, 1 truck, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c057f689-dde1e141.jpg: 384x640 6 cars, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0591ae4-6214d10f.jpg: 384x640 1 person, 13 cars, 3 traffic lights, 16.9ms\n",
            "Speed: 2.4ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05df6d2-9959222a.jpg: 384x640 5 cars, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5743/10000 [03:03<02:25, 29.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05e4d3b-3edaadc6.jpg: 384x640 7 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05e4d3b-4512f1aa.jpg: 384x640 7 cars, 1 traffic light, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05ef84a-2a2e27b2.jpg: 384x640 8 cars, 16.2ms\n",
            "Speed: 2.0ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05f2610-0d3df457.jpg: 384x640 4 persons, 6 cars, 1 truck, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  57%|█████▋    | 5747/10000 [03:03<02:21, 30.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05f27be-54bd73f1.jpg: 384x640 7 persons, 4 cars, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c05f6683-01c5215b.jpg: 384x640 6 cars, 1 truck, 12.5ms\n",
            "Speed: 4.1ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c060ea1f-12965687.jpg: 384x640 9 cars, 2 trucks, 15.4ms\n",
            "Speed: 2.1ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c060ea1f-da217407.jpg: 384x640 1 person, 7 cars, 1 bus, 1 truck, 1 fire hydrant, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5751/10000 [03:03<02:28, 28.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0625a26-2d4fc27d.jpg: 384x640 14 cars, 13.4ms\n",
            "Speed: 4.3ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0625a26-8bacfe16.jpg: 384x640 12 cars, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0625a26-bbc13047.jpg: 384x640 2 cars, 2 traffic lights, 14.4ms\n",
            "Speed: 6.0ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5754/10000 [03:04<02:36, 27.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0625a26-cd00b6b6.jpg: 384x640 3 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0625a26-cefa81e9.jpg: 384x640 12 cars, 1 truck, 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0625a26-ef2bcca4.jpg: 384x640 (no detections), 18.6ms\n",
            "Speed: 1.9ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5757/10000 [03:04<02:33, 27.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0625a26-fc1f04b9.jpg: 384x640 10 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0625a26-fd1b7885.jpg: 384x640 10 cars, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0639f50-9ecb84f1.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c063c188-26f08957.jpg: 384x640 12 cars, 2 traffic lights, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5761/10000 [03:04<02:31, 27.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c064e44f-6f76921d.jpg: 384x640 (no detections), 18.0ms\n",
            "Speed: 3.1ms preprocess, 18.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c064e44f-ccbd9a2f.jpg: 384x640 3 cars, 3 traffic lights, 14.0ms\n",
            "Speed: 3.1ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06733f8-1fe942b9.jpg: 384x640 7 cars, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5764/10000 [03:04<02:33, 27.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-16b35549.jpg: 384x640 3 cars, 1 truck, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-39c6f234.jpg: 384x640 7 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-55a2f724.jpg: 384x640 4 cars, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-613b4f10.jpg: 384x640 11 cars, 1 truck, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5768/10000 [03:04<02:29, 28.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-69842abb.jpg: 384x640 2 persons, 9 cars, 1 traffic light, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-6bffc56f.jpg: 384x640 2 persons, 2 cars, 1 truck, 16.4ms\n",
            "Speed: 1.8ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-8371743a.jpg: 384x640 10 cars, 1 traffic light, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5771/10000 [03:04<02:30, 28.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-89d37846.jpg: 384x640 11 cars, 9.0ms\n",
            "Speed: 3.8ms preprocess, 9.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-b0154931.jpg: 384x640 3 cars, 3 trucks, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-b6a1bcdd.jpg: 384x640 5 cars, 1 traffic light, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-c094cd72.jpg: 384x640 11 cars, 1 truck, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5775/10000 [03:04<02:23, 29.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-c63c7c95.jpg: 384x640 8 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0677163-cccbd1cf.jpg: 384x640 1 car, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c068a67b-03b6e200.jpg: 384x640 1 person, 13 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0697e71-428e14b1.jpg: 384x640 3 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5779/10000 [03:04<02:14, 31.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0697e71-84867efa.jpg: 384x640 3 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0697e71-b05bc4b3.jpg: 384x640 9 cars, 4 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0697e71-ba9f6c4f.jpg: 384x640 1 person, 13 cars, 1 handbag, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06aa107-6d6d0938.jpg: 384x640 5 persons, 2 cars, 15.6ms\n",
            "Speed: 1.8ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5783/10000 [03:05<02:17, 30.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06b00b3-b8b5c0d7.jpg: 384x640 4 persons, 1 car, 1 truck, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06be53b-be47b965.jpg: 384x640 8 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06d23aa-28bc6026.jpg: 384x640 6 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06d23aa-8a03f2c0.jpg: 384x640 6 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5787/10000 [03:05<02:14, 31.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06d23aa-c38fa368.jpg: 384x640 1 person, 8 cars, 3 traffic lights, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06d23aa-cb9ae751.jpg: 384x640 3 cars, 1 stop sign, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06defbe-c0034220.jpg: 384x640 2 cars, 1 traffic light, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06defbe-d63aaecb.jpg: 384x640 1 traffic light, 14.8ms\n",
            "Speed: 3.1ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5791/10000 [03:05<02:14, 31.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06defbe-fff19cfc.jpg: 384x640 6 cars, 1 traffic light, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06e75f0-de0335ed.jpg: 384x640 1 person, 3 cars, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c06fd7ca-420dd696.jpg: 384x640 3 persons, 5 cars, 3 traffic lights, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0703477-78356915.jpg: 384x640 6 cars, 1 truck, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5795/10000 [03:05<02:15, 31.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0703477-b5138d5d.jpg: 384x640 1 person, 6 cars, 1 traffic light, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c070f253-79cd771d.jpg: 384x640 1 person, 15 cars, 15.7ms\n",
            "Speed: 1.9ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0711468-991a6038.jpg: 384x640 3 cars, 21.9ms\n",
            "Speed: 2.0ms preprocess, 21.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0717263-495fc5b6.jpg: 384x640 11 cars, 3 traffic lights, 16.4ms\n",
            "Speed: 2.1ms preprocess, 16.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5799/10000 [03:05<02:28, 28.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0717263-73ccb048.jpg: 384x640 1 person, 7 cars, 13.7ms\n",
            "Speed: 7.0ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0726425-0b2f4892.jpg: 384x640 8 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07365da-fe6ea473.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0750fe1-50a37a79.jpg: 384x640 8 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5803/10000 [03:05<02:25, 28.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0750fe1-95210aca.jpg: 384x640 7 cars, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0756468-c4fd9382.jpg: 384x640 5 cars, 1 bus, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0771fb7-818e1025.jpg: 384x640 3 cars, 1 bus, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0771fb7-d03aa33e.jpg: 384x640 1 person, 5 cars, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5807/10000 [03:05<02:13, 31.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07733d0-6b75a5ee.jpg: 384x640 2 cars, 2 trucks, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07733d0-7525eae7.jpg: 384x640 9 cars, 1 train, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07733d0-79ec92e9.jpg: 384x640 11 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07733d0-8445e6b8.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5811/10000 [03:05<02:04, 33.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07733d0-9738eec9.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07733d0-974d1334.jpg: 384x640 4 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07733d0-aebb8786.jpg: 384x640 7 cars, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0773447-b9d4a2fc.jpg: 384x640 2 cars, 18.5ms\n",
            "Speed: 2.3ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5815/10000 [03:06<02:06, 33.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0773447-c1d1508b.jpg: 384x640 4 cars, 6 traffic lights, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0775b6f-d6afcd0e.jpg: 384x640 7 cars, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0775b6f-de6addd1.jpg: 384x640 5 cars, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0792259-e4b3dbbe.jpg: 384x640 6 cars, 17.4ms\n",
            "Speed: 6.9ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5819/10000 [03:06<02:18, 30.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07a05be-b5b2a3a4.jpg: 384x640 1 person, 1 car, 1 tv, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07ceafc-344c73cd.jpg: 384x640 6 cars, 2 trucks, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07ceafc-6060ff3e.jpg: 384x640 1 person, 1 bicycle, 5 cars, 1 truck, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07e5e33-06443391.jpg: 384x640 1 person, 5 cars, 1 truck, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5823/10000 [03:06<02:14, 31.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07e5e33-68d7a2fe.jpg: 384x640 9 cars, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07e5e33-7aeda19c.jpg: 384x640 4 cars, 1 truck, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07e5e33-b70291b0.jpg: 384x640 4 cars, 16.0ms\n",
            "Speed: 6.2ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c07e5e33-e6e74657.jpg: 384x640 2 persons, 6 cars, 2 trucks, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5827/10000 [03:06<02:30, 27.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c080a244-0233bdce.jpg: 384x640 8 cars, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c080a244-0d9e0842.jpg: 384x640 3 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c080a244-30c4cf38.jpg: 384x640 1 car, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c080a244-66dd9e1f.jpg: 384x640 6 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5831/10000 [03:06<02:24, 28.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c080a244-73db7e97.jpg: 384x640 4 persons, 4 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c080a244-e915a4c2.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c080d56f-53b1cfaf.jpg: 384x640 14 cars, 1 bus, 1 truck, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0848dc2-3958b05d.jpg: 384x640 14 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5835/10000 [03:06<02:16, 30.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08493f0-0afee671.jpg: 384x640 10 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08493f0-7e15983d.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c084d6cb-18c509b4.jpg: 384x640 11 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c084d6cb-9113f4ba.jpg: 384x640 (no detections), 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5839/10000 [03:06<02:06, 32.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0863b71-8c4ce9be.jpg: 384x640 3 persons, 4 cars, 2 traffic lights, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0882fd0-cb7eb3dc.jpg: 384x640 5 persons, 1 car, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0885032-0317987c.jpg: 384x640 3 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0885032-2ec2353d.jpg: 384x640 4 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5843/10000 [03:06<02:02, 33.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c088650e-f71b7011.jpg: 384x640 8 cars, 1 stop sign, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0892575-b842e6c9.jpg: 384x640 1 person, 1 car, 1 traffic light, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c089e474-b795bcdc.jpg: 384x640 5 cars, 1 bus, 14.2ms\n",
            "Speed: 6.9ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08ac802-a61149ad.jpg: 384x640 10 cars, 3 traffic lights, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  58%|█████▊    | 5847/10000 [03:07<02:05, 33.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08ac802-ada02f31.jpg: 384x640 2 cars, 1 traffic light, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08b49d7-164707bb.jpg: 384x640 5 cars, 2 traffic lights, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08b49d7-6d6c4ad7.jpg: 384x640 2 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08b49d7-712e16b7.jpg: 384x640 3 cars, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▊    | 5851/10000 [03:07<02:02, 33.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08b49d7-83415596.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08b49d7-b1cea927.jpg: 384x640 1 bicycle, 2 cars, 2 traffic lights, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08b49d7-bc52cd66.jpg: 384x640 2 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08bf392-3d39a1bc.jpg: 384x640 1 person, 5 cars, 2 buss, 2 traffic lights, 15.4ms\n",
            "Speed: 5.8ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▊    | 5855/10000 [03:07<02:07, 32.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08bf392-b9a3eeb5.jpg: 384x640 9 persons, 2 cars, 1 bus, 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08c6940-0248e76d.jpg: 384x640 1 person, 7 cars, 1 truck, 17.2ms\n",
            "Speed: 4.2ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08d18c6-6d211ae8.jpg: 384x640 1 person, 15 cars, 2 trucks, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08eacf9-8054501c.jpg: 384x640 1 car, 19.6ms\n",
            "Speed: 4.0ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▊    | 5859/10000 [03:07<02:27, 28.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c08eacf9-a819d218.jpg: 384x640 1 person, 4 cars, 1 traffic light, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0905216-425f59d3.jpg: 384x640 1 car, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c090895d-02949f2b.jpg: 384x640 1 car, 1 truck, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0924681-14dd2682.jpg: 384x640 11 cars, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▊    | 5863/10000 [03:07<02:17, 30.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c092eed0-3b36e79d.jpg: 384x640 13 cars, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c093cec2-178d0616.jpg: 384x640 (no detections), 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c093f8be-262822a7.jpg: 384x640 2 persons, 5 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c093f8be-45274361.jpg: 384x640 1 person, 5 cars, 3 traffic lights, 1 handbag, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▊    | 5867/10000 [03:07<02:15, 30.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c093f8be-b478e611.jpg: 384x640 9 cars, 1 bus, 1 truck, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c093f8be-ca74d5ff.jpg: 384x640 1 person, 3 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c093f8be-f17f116a.jpg: 384x640 1 car, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c094413f-30199e1f.jpg: 384x640 2 persons, 10 cars, 1 bus, 2 trucks, 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▊    | 5871/10000 [03:07<02:18, 29.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0945c0c-e16c694a.jpg: 384x640 4 persons, 1 bicycle, 3 cars, 1 truck, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0945c0c-e78590d4.jpg: 384x640 14 cars, 9.5ms\n",
            "Speed: 2.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0945c0c-f1d60d48.jpg: 384x640 3 persons, 4 cars, 1 bus, 1 truck, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c096103a-23e302b8.jpg: 384x640 1 person, 7 cars, 1 bus, 1 truck, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5875/10000 [03:08<02:22, 28.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c096103a-665e307e.jpg: 384x640 10 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c09af0c6-3c0b82a7.jpg: 384x640 2 cars, 1 truck, 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c09af0c6-61c87b58.jpg: 384x640 13 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5878/10000 [03:08<02:23, 28.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c09af0c6-d87bbf00.jpg: 384x640 2 cars, 1 truck, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c09b6e1f-e23f6359.jpg: 384x640 3 persons, 7 cars, 1 truck, 1 traffic light, 1 handbag, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c09dfe6c-f23991eb.jpg: 384x640 6 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5881/10000 [03:08<02:28, 27.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c09f3c10-25c675f4.jpg: 384x640 1 car, 15.9ms\n",
            "Speed: 1.9ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c09ffc61-d494d8f0.jpg: 384x640 7 cars, 17.4ms\n",
            "Speed: 1.9ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a3b5cc-b6d07aae.jpg: 384x640 4 cars, 1 traffic light, 18.8ms\n",
            "Speed: 3.9ms preprocess, 18.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5884/10000 [03:08<02:34, 26.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a66d6a-607213d1.jpg: 384x640 2 persons, 5 cars, 3 buss, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a66d6a-9542b722.jpg: 384x640 4 cars, 1 bus, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a66d6a-b7cc47d8.jpg: 384x640 12 cars, 2 trucks, 12.5ms\n",
            "Speed: 4.2ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5887/10000 [03:08<02:38, 25.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a6cfd6-0c600d1f.jpg: 384x640 7 cars, 1 traffic light, 18.9ms\n",
            "Speed: 1.9ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a6cfd6-3b25543a.jpg: 384x640 15 cars, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a6cfd6-a2f01374.jpg: 384x640 5 cars, 19.7ms\n",
            "Speed: 1.8ms preprocess, 19.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5890/10000 [03:08<02:45, 24.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a6cfd6-c22af944.jpg: 384x640 8 cars, 15.9ms\n",
            "Speed: 1.8ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a6cfd6-e96fd466.jpg: 384x640 8 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a6cfd6-fa4e3a71.jpg: 384x640 17 cars, 3 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5893/10000 [03:08<02:41, 25.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a6cfd6-fe9a5c77.jpg: 384x640 6 cars, 3 trucks, 4 traffic lights, 12.0ms\n",
            "Speed: 5.8ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a71f47-14439a44.jpg: 384x640 5 cars, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a71f47-5e5948c3.jpg: 384x640 3 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5896/10000 [03:08<02:35, 26.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a7a9dc-458aa118.jpg: 384x640 2 persons, 7 cars, 17.1ms\n",
            "Speed: 1.8ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a7a9dc-497459f0.jpg: 384x640 14 cars, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a7a9dc-4f00d11c.jpg: 384x640 1 car, 13.7ms\n",
            "Speed: 3.9ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5899/10000 [03:08<02:35, 26.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a7a9dc-60feea97.jpg: 384x640 1 person, 11 cars, 17.4ms\n",
            "Speed: 3.8ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a7a9dc-7762bc0e.jpg: 384x640 4 persons, 11 cars, 1 truck, 1 traffic light, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a7a9dc-d43be893.jpg: 384x640 1 person, 2 cars, 1 bus, 4 traffic lights, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5902/10000 [03:09<02:36, 26.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a7fac6-3b412647.jpg: 384x640 7 persons, 4 cars, 1 truck, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a8843f-878c626c.jpg: 384x640 2 persons, 2 bicycles, 7 cars, 1 truck, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0a8843f-b467b5b5.jpg: 384x640 7 cars, 1 truck, 16.1ms\n",
            "Speed: 1.8ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0aa83ea-5e7cbb16.jpg: 384x640 7 cars, 1 traffic light, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5906/10000 [03:09<02:27, 27.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0aa979d-dd5c54d1.jpg: 384x640 9 cars, 1 truck, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b14bde-89e03259.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b279b6-134749d1.jpg: 384x640 9 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b30dae-548c5972.jpg: 384x640 2 persons, 3 cars, 1 truck, 16.4ms\n",
            "Speed: 2.1ms preprocess, 16.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5910/10000 [03:09<02:20, 29.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b358a3-fef47f1e.jpg: 384x640 3 cars, 18.9ms\n",
            "Speed: 1.9ms preprocess, 18.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b45bc6-df6c6ee7.jpg: 384x640 2 cars, 1 train, 19.6ms\n",
            "Speed: 7.0ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b4f0df-586ab062.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 14.9ms\n",
            "Speed: 3.9ms preprocess, 14.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5913/10000 [03:09<02:32, 26.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b7212e-40f23e1e.jpg: 384x640 1 person, 5 cars, 2 traffic lights, 19.6ms\n",
            "Speed: 1.9ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b731b5-01375e2e.jpg: 384x640 4 cars, 1 truck, 13.1ms\n",
            "Speed: 7.0ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b731b5-5f8f2b02.jpg: 384x640 3 cars, 3 traffic lights, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5916/10000 [03:09<02:39, 25.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b98a97-c7609d09.jpg: 384x640 1 car, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0b9d756-7e259c4d.jpg: 384x640 5 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0ba2a86-363aebd6.jpg: 384x640 1 person, 2 traffic lights, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0ba2a86-f44beec8.jpg: 384x640 3 cars, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5920/10000 [03:09<02:21, 28.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0bbcd5e-d9c5d41e.jpg: 384x640 1 car, 1 traffic light, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0bbcd5e-e207560d.jpg: 384x640 3 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0bbcd5e-f57df892.jpg: 384x640 1 person, 5 traffic lights, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0bdac3c-56f7aff3.jpg: 384x640 1 traffic light, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5924/10000 [03:09<02:12, 30.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0bdd2df-c6e1aa24.jpg: 384x640 4 cars, 1 truck, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0be0e03-063c7cf7.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0be0e03-0663efcf.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 1.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0be0e03-3ab88509.jpg: 384x640 13 cars, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5928/10000 [03:09<02:09, 31.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0be0e03-459a6d3c.jpg: 384x640 13 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c183ff-1b24f541.jpg: 384x640 16 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c23a94-d914f7ec.jpg: 384x640 6 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c23a94-f2f15c15.jpg: 384x640 9 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5932/10000 [03:10<02:06, 32.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c26539-f8761bd1.jpg: 384x640 2 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c27443-bf546b1f.jpg: 384x640 2 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c283d7-06fc47f0.jpg: 384x640 1 bus, 1 truck, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c33c60-63c65011.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c33c60-bb2f7822.jpg: 384x640 1 car, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5937/10000 [03:10<01:55, 35.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c3d5f5-f17f878d.jpg: 384x640 9 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c51509-cb8d3298.jpg: 384x640 2 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c63f02-77b9b06d.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c64a18-eed54540.jpg: 384x640 1 car, 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5941/10000 [03:10<01:53, 35.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c6e74f-8f9f8ceb.jpg: 384x640 11 cars, 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c821a8-361cc57e.jpg: 384x640 5 cars, 15.7ms\n",
            "Speed: 5.9ms preprocess, 15.7ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c8ee02-431b9781.jpg: 384x640 1 person, 3 cars, 1 bus, 16.5ms\n",
            "Speed: 1.8ms preprocess, 16.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c8efe2-2efe6ba7.jpg: 384x640 1 person, 10 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5945/10000 [03:10<02:13, 30.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c8efe2-cb74e696.jpg: 384x640 1 person, 1 bicycle, 22 cars, 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c954a7-0c7fa0bb.jpg: 384x640 6 cars, 17.2ms\n",
            "Speed: 2.0ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c9ec9a-ce2ae421.jpg: 384x640 2 cars, 16.0ms\n",
            "Speed: 1.8ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c9ec9a-d3638a82.jpg: 384x640 1 car, 1 truck, 2 traffic lights, 18.9ms\n",
            "Speed: 1.8ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  59%|█████▉    | 5949/10000 [03:10<02:24, 28.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0c9ec9a-dad1653f.jpg: 384x640 1 car, 1 traffic light, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0ca0e6f-4236bfe6.jpg: 384x640 1 car, 2 traffic lights, 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0ca172c-5f15e9fb.jpg: 384x640 1 person, 3 cars, 1 bus, 1 truck, 13.7ms\n",
            "Speed: 5.1ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5952/10000 [03:10<02:25, 27.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0cb2de6-501299c6.jpg: 384x640 10 cars, 15.8ms\n",
            "Speed: 4.7ms preprocess, 15.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0cca954-2890db9b.jpg: 384x640 1 person, 2 cars, 1 truck, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0cce290-f5382dbd.jpg: 384x640 3 cars, 15.7ms\n",
            "Speed: 1.9ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5955/10000 [03:10<02:30, 26.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0cf4efc-65b9d672.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d12f7f-1e033ebf.jpg: 384x640 3 cars, 1 truck, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d12f7f-b672c821.jpg: 384x640 2 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d1a6d9-54ae850d.jpg: 384x640 7 cars, 1 traffic light, 14.6ms\n",
            "Speed: 1.7ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5959/10000 [03:10<02:27, 27.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d3128e-7887e513.jpg: 384x640 4 cars, 1 truck, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d3128e-8adf0493.jpg: 384x640 4 cars, 13.0ms\n",
            "Speed: 3.8ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d61d2b-a15012f3.jpg: 384x640 2 cars, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5962/10000 [03:11<02:25, 27.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d678b8-de457e55.jpg: 384x640 5 cars, 1 bus, 1 train, 19.3ms\n",
            "Speed: 1.8ms preprocess, 19.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d85a76-8187c669.jpg: 384x640 1 person, 6 cars, 1 train, 1 truck, 1 traffic light, 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d85a76-c68c9ff0.jpg: 384x640 4 cars, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5965/10000 [03:11<02:25, 27.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d85a76-efa45769.jpg: 384x640 4 cars, 1 traffic light, 21.6ms\n",
            "Speed: 1.8ms preprocess, 21.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0d8d6d0-f2152200.jpg: 384x640 1 person, 4 cars, 1 bus, 1 traffic light, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0da08cc-444b48f0.jpg: 384x640 1 car, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5968/10000 [03:11<02:26, 27.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0da08cc-adbbb7b3.jpg: 384x640 5 cars, 14.7ms\n",
            "Speed: 1.8ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0da399b-afffb28c.jpg: 384x640 4 persons, 6 cars, 1 bus, 1 truck, 1 traffic light, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0db3bd8-17587381.jpg: 384x640 1 car, 1 truck, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5971/10000 [03:11<02:27, 27.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0db3bd8-9bb194d2.jpg: 384x640 1 person, 6 cars, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dbd924-da3f8c08.jpg: 384x640 5 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 5.8ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dc123c-25946136.jpg: 384x640 8 cars, 3 traffic lights, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5974/10000 [03:11<02:30, 26.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dc5a95-26ea2d7d.jpg: 384x640 1 car, 11.4ms\n",
            "Speed: 6.4ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dc5a95-27a7b607.jpg: 384x640 4 cars, 1 truck, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dc5a95-b4bfcb2c.jpg: 384x640 2 cars, 1 fire hydrant, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dc9cd3-ff30805f.jpg: 384x640 1 person, 4 cars, 1 truck, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5978/10000 [03:11<02:20, 28.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dcabad-155ca5ee.jpg: 384x640 5 persons, 1 car, 1 truck, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dcabad-418c9ebf.jpg: 384x640 3 cars, 1 bus, 1 train, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0ddb55a-d705f3c3.jpg: 384x640 10 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0ddc0e1-c0c70d00.jpg: 384x640 18 cars, 1 truck, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5982/10000 [03:11<02:11, 30.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0de0a97-69386814.jpg: 384x640 1 car, 1 traffic light, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0de5178-547765fc.jpg: 384x640 3 persons, 4 cars, 6 traffic lights, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0de5178-dd9fe4fb.jpg: 384x640 4 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0de9100-1b2704ac.jpg: 384x640 6 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5986/10000 [03:11<02:03, 32.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0de9100-dba9e79d.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0dee1a9-19b5d7a5.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0deebc1-16cfa791.jpg: 384x640 3 persons, 2 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0deebc1-ff77802c.jpg: 384x640 11 cars, 1 traffic light, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5990/10000 [03:11<02:01, 33.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0df59b4-a549ef6e.jpg: 384x640 1 car, 1 stop sign, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e05e70-6431cfed.jpg: 384x640 2 cars, 1 truck, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e13807-ca0635f0.jpg: 384x640 1 person, 7 cars, 1 truck, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e17fa8-a378411a.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5994/10000 [03:12<01:56, 34.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e1fd2a-45156dec.jpg: 384x640 4 cars, 8.5ms\n",
            "Speed: 2.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e24bac-16ba0eb9.jpg: 384x640 1 person, 4 cars, 9.6ms\n",
            "Speed: 5.3ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e24bac-261d32aa.jpg: 384x640 12 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e24bac-d541b20d.jpg: 384x640 3 cars, 1 train, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|█████▉    | 5998/10000 [03:12<01:57, 34.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e24bac-f07076d1.jpg: 384x640 2 persons, 4 cars, 1 motorcycle, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e3df1a-5ab511a6.jpg: 384x640 8 cars, 1 truck, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e3df1a-5cb39f7c.jpg: 384x640 2 persons, 4 cars, 1 truck, 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e5695d-8f784313.jpg: 384x640 1 car, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6002/10000 [03:12<02:06, 31.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e631f4-cf85b543.jpg: 384x640 12 cars, 1 stop sign, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e6d0ec-17a4eb38.jpg: 384x640 8 cars, 2 traffic lights, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e6d0ec-254d2aac.jpg: 384x640 7 cars, 2 traffic lights, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e6d0ec-71f98edb.jpg: 384x640 2 persons, 1 bicycle, 5 cars, 2 trucks, 14.3ms\n",
            "Speed: 1.8ms preprocess, 14.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6006/10000 [03:12<02:08, 31.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e6d0ec-ec23e2d2.jpg: 384x640 1 person, 3 cars, 1 traffic light, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e701ee-42f7323e.jpg: 384x640 1 traffic light, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e701ee-58d60493.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e7271a-a3c8d55f.jpg: 384x640 2 cars, 1 truck, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6010/10000 [03:12<02:08, 30.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e74e90-15e1888e.jpg: 384x640 4 cars, 1 truck, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e74e90-91053849.jpg: 384x640 7 cars, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e74e90-9684bfc2.jpg: 384x640 5 cars, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e834fd-74036e84.jpg: 384x640 13 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6014/10000 [03:12<02:06, 31.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e834fd-b666a542.jpg: 384x640 1 car, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e8b725-a6daa3a3.jpg: 384x640 1 person, 7 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e8fdda-cc0a57e4.jpg: 384x640 1 car, 2 trucks, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e90884-ab3e26af.jpg: 384x640 6 cars, 1 stop sign, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6018/10000 [03:12<02:03, 32.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0e9b7c4-cd8b7249.jpg: 384x640 7 cars, 13.1ms\n",
            "Speed: 4.8ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0eab4d0-010273fa.jpg: 384x640 1 person, 6 cars, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0eab4d0-f30a0b42.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0eb4a02-3b40262b.jpg: 384x640 5 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6022/10000 [03:13<02:04, 31.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0eba0ba-c73e128d.jpg: 384x640 1 car, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0eba0ba-db5d7deb.jpg: 384x640 3 persons, 2 cars, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0ec0d98-63733eb9.jpg: 384x640 3 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0ed2c49-e0d49ca5.jpg: 384x640 9 cars, 1 traffic light, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6026/10000 [03:13<02:01, 32.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0edf06a-74008e93.jpg: 384x640 9 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0efbe92-2ee3e529.jpg: 384x640 4 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0efbe92-541cb3fa.jpg: 384x640 5 cars, 1 bus, 2 trucks, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0efbe92-d5be8958.jpg: 384x640 13 cars, 2 trucks, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6030/10000 [03:13<02:00, 32.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f1a2f9-0e16bcb7.jpg: 384x640 6 cars, 1 truck, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f1a2f9-1476c2ee.jpg: 384x640 6 cars, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f1a2f9-6b09c60a.jpg: 384x640 5 cars, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f1a2f9-8928361a.jpg: 384x640 6 cars, 1 bus, 1 truck, 1 stop sign, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6034/10000 [03:13<02:06, 31.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f1a2f9-d0b67ce6.jpg: 384x640 4 cars, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f1a2f9-df251b35.jpg: 384x640 6 cars, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f35000-9401b8f3.jpg: 384x640 3 persons, 5 cars, 2 trucks, 3 traffic lights, 1 handbag, 1 suitcase, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f4e96b-3fa1961a.jpg: 384x640 3 cars, 1 truck, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6038/10000 [03:13<02:11, 30.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f5b0d0-17e0110c.jpg: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f5b0d0-6e438a33.jpg: 384x640 3 persons, 1 car, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f5b0d0-d088d6c1.jpg: 384x640 5 cars, 12.1ms\n",
            "Speed: 1.7ms preprocess, 12.1ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f5b0d0-d0dcf28e.jpg: 384x640 15 persons, 4 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6042/10000 [03:13<02:09, 30.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f5b0d0-f7860ad8.jpg: 384x640 3 persons, 5 cars, 1 bus, 1 traffic light, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f6ac18-37ce6bd5.jpg: 384x640 3 cars, 1 traffic light, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f739d8-6ff93525.jpg: 384x640 10 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f7c2d3-1abf98ec.jpg: 384x640 1 car, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6046/10000 [03:13<02:10, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f89882-542093a7.jpg: 384x640 3 cars, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f89882-8961b4ed.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f978fa-0651fdd0.jpg: 384x640 1 car, 1 bus, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f978fa-425cdcd6.jpg: 384x640 7 cars, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  60%|██████    | 6050/10000 [03:13<02:04, 31.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0f978fa-9b4e623f.jpg: 384x640 1 person, 11 cars, 1 traffic light, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0faa237-5724019d.jpg: 384x640 1 person, 5 cars, 1 truck, 1 traffic light, 1 skateboard, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0faf05b-b3cba171.jpg: 384x640 3 cars, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0fb59eb-895d806d.jpg: 384x640 8 persons, 8 cars, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6054/10000 [03:14<02:08, 30.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0fc4716-6f3d5d3d.jpg: 384x640 1 person, 2 cars, 1 traffic light, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0fc4716-ee97c5a0.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c0fce69f-42d06912.jpg: 384x640 8 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1006024-9713b693.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6058/10000 [03:14<02:01, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c100db13-6de74f3b.jpg: 384x640 11 cars, 1 truck, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c100db13-71b423e5.jpg: 384x640 9 cars, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c100db13-878b2e5f.jpg: 384x640 4 cars, 1 truck, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c100db13-8af08790.jpg: 384x640 5 cars, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6062/10000 [03:14<02:02, 32.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c10163bb-7ad315ce.jpg: 384x640 10 cars, 2 trucks, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1025fcf-69509758.jpg: 384x640 5 persons, 2 cars, 2 traffic lights, 20.4ms\n",
            "Speed: 1.8ms preprocess, 20.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c10472c3-9c569d4f.jpg: 384x640 6 cars, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1059f09-10ccdbd4.jpg: 384x640 2 cars, 1 bus, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6066/10000 [03:14<02:08, 30.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c107c2f1-b2b8fff0.jpg: 384x640 7 cars, 1 truck, 14.0ms\n",
            "Speed: 7.0ms preprocess, 14.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c107ca7b-e60766f2.jpg: 384x640 3 cars, 1 bus, 1 truck, 18.0ms\n",
            "Speed: 3.4ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c10838df-720662b5.jpg: 384x640 7 cars, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c10aed37-ad2cda9b.jpg: 384x640 2 cars, 1 traffic light, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6070/10000 [03:14<02:15, 29.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c10c78a2-583a8467.jpg: 384x640 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c10e92bd-f6241f08.jpg: 384x640 8 cars, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c10f0578-c613c144.jpg: 384x640 1 person, 4 cars, 1 bus, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c111bb7d-c3aa5b7a.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6074/10000 [03:14<02:07, 30.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c112ff03-1c0d5484.jpg: 384x640 1 person, 7 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c119a2ea-f59c8486.jpg: 384x640 7 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11a0015-fa2086af.jpg: 384x640 12 cars, 16.1ms\n",
            "Speed: 1.7ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11a0015-fc7c0b35.jpg: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6078/10000 [03:14<02:04, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11add12-bb59c2a1.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11bcaaf-2213faec.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11c833f-3673eff3.jpg: 384x640 3 cars, 1 traffic light, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11c833f-e77889aa.jpg: 384x640 6 cars, 1 truck, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6082/10000 [03:14<02:00, 32.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11f4171-18d042d3.jpg: 384x640 1 person, 1 car, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11f4171-a712ce1d.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11f4171-fe3bf475.jpg: 384x640 1 car, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11f9ba5-11a0dd0f.jpg: 384x640 1 bus, 3 traffic lights, 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6086/10000 [03:15<01:56, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11fb0c4-16ba72ea.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c11fb0c4-afc93e36.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1207647-f966579a.jpg: 384x640 2 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 1.7ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1211833-1ba939db.jpg: 384x640 7 cars, 1 truck, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6090/10000 [03:15<01:54, 34.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1211833-db271204.jpg: 384x640 7 cars, 1 truck, 1 traffic light, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c121b93f-93807706.jpg: 384x640 13 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c121b93f-b2ee73d4.jpg: 384x640 13 cars, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c121f402-2e25ddb9.jpg: 384x640 2 cars, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6094/10000 [03:15<01:57, 33.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c122a91d-7ac64c77.jpg: 384x640 1 person, 5 cars, 3 trucks, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c122b0dd-6aea2ae9.jpg: 384x640 3 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c122b0dd-9c06c62c.jpg: 384x640 4 cars, 1 truck, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12378e1-e9b8f175.jpg: 384x640 3 cars, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6098/10000 [03:15<01:56, 33.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1239aa1-10b91116.jpg: 384x640 1 car, 1 bus, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1243d2d-1a754959.jpg: 384x640 1 car, 12.3ms\n",
            "Speed: 5.7ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1243d2d-ea0d84a3.jpg: 384x640 8 cars, 1 traffic light, 14.7ms\n",
            "Speed: 1.8ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c124e51c-31bb804d.jpg: 384x640 11 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6102/10000 [03:15<02:03, 31.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c124e51c-52e077cb.jpg: 384x640 1 person, 5 cars, 2 buss, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c124e51c-b3b1db34.jpg: 384x640 16 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1252547-1492d53d.jpg: 384x640 5 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1252e1f-a88318f0.jpg: 384x640 10 cars, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6106/10000 [03:15<02:03, 31.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1252e1f-c0640ea4.jpg: 384x640 1 person, 5 cars, 1 truck, 1 traffic light, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1252e1f-f45bb339.jpg: 384x640 7 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c126dfe1-2a1c0ea8.jpg: 384x640 10 cars, 2 trucks, 2 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c126dfe1-4bdd6502.jpg: 384x640 13 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6110/10000 [03:15<02:06, 30.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12b8a48-168db729.jpg: 384x640 9 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12bfd38-4fe7afb2.jpg: 384x640 7 cars, 1 bus, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12c6524-ee3ce336.jpg: 384x640 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12ce21f-6f6ecfa7.jpg: 384x640 9 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6114/10000 [03:15<01:58, 32.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12dc478-0d43272d.jpg: 384x640 2 cars, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12dc478-40a1a306.jpg: 384x640 8 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12e6924-5860d30a.jpg: 384x640 2 persons, 1 bicycle, 6 cars, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12e6924-6d6ef77c.jpg: 384x640 7 persons, 4 cars, 1 bus, 1 truck, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6118/10000 [03:16<01:55, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12ea027-1f29fc11.jpg: 384x640 25 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12ea027-2919c581.jpg: 384x640 3 persons, 5 cars, 1 bus, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c12ea027-76835823.jpg: 384x640 1 person, 7 cars, 1 bus, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c132df41-509fc403.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████    | 6122/10000 [03:16<01:55, 33.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c132df41-a4dbc930.jpg: 384x640 7 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c132ff8a-831eadbd.jpg: 384x640 10 cars, 1 truck, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1356a63-e9e5a5f2.jpg: 384x640 3 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-1bdcf8a1.jpg: 384x640 1 person, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████▏   | 6126/10000 [03:16<01:52, 34.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-3bafc956.jpg: 384x640 1 car, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-42a66cea.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-5aa8acd1.jpg: 384x640 2 cars, 1 traffic light, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-654db2c3.jpg: 384x640 8 cars, 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████▏   | 6130/10000 [03:16<01:51, 34.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-6abdd8c2.jpg: 384x640 5 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-93d3e230.jpg: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-9538421f.jpg: 384x640 5 cars, 2 buss, 1 traffic light, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-bc544663.jpg: 384x640 2 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████▏   | 6134/10000 [03:16<01:50, 34.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1362f73-ddc9206a.jpg: 384x640 6 cars, 2 traffic lights, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13829a7-37c9959d.jpg: 384x640 4 cars, 2 buss, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13829a7-6447cab7.jpg: 384x640 1 person, 10 cars, 2 trucks, 3 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13829a7-761a16ef.jpg: 384x640 1 person, 5 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████▏   | 6138/10000 [03:16<01:51, 34.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1384653-b2644b7e.jpg: 384x640 2 persons, 2 cars, 1 train, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1384653-f155dde5.jpg: 384x640 3 cars, 1 bus, 1 truck, 2 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c138a567-6a2dd99d.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c138a567-c79aac4f.jpg: 384x640 1 person, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1392188-10227871.jpg: 384x640 3 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████▏   | 6143/10000 [03:16<01:45, 36.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1394b3c-a48bc983.jpg: 384x640 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13ab9cd-88c99ae5.jpg: 384x640 7 cars, 1 bus, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b26a2-95a8d142.jpg: 384x640 4 cars, 1 traffic light, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b9590-492e626a.jpg: 384x640 5 cars, 1 truck, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b9590-500de09d.jpg: 384x640 5 cars, 1 truck, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  61%|██████▏   | 6148/10000 [03:16<01:41, 37.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b9590-5105f7ad.jpg: 384x640 3 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b9590-54527388.jpg: 384x640 9 cars, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b9590-7e14e55c.jpg: 384x640 6 cars, 10.3ms\n",
            "Speed: 1.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b9590-a875ea73.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6152/10000 [03:16<01:43, 37.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b9590-d6db1a86.jpg: 384x640 2 cars, 2 trucks, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13b9590-fbc531ea.jpg: 384x640 7 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13c0d1f-00dfd075.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13e6a36-6bb92c09.jpg: 384x640 1 car, 1 truck, 2 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6156/10000 [03:17<01:43, 37.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13ecaa8-69459760.jpg: 384x640 2 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c13ef0e9-9cc08bb3.jpg: 384x640 5 cars, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1404de9-4f70883d.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1404de9-ca7c53e4.jpg: 384x640 2 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1428d85-1e1afff5.jpg: 384x640 1 train, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6161/10000 [03:17<01:39, 38.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c143af06-2e9cba65.jpg: 384x640 6 persons, 6 cars, 3 traffic lights, 1 skateboard, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c143af06-b1635ba6.jpg: 384x640 4 persons, 7 cars, 3 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c143af06-f2b0a9d6.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 1 stop sign, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14425b1-5fa20993.jpg: 384x640 10 cars, 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6165/10000 [03:17<01:45, 36.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c146708c-9119a8a3.jpg: 384x640 4 cars, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c146d100-4ee36f35.jpg: 384x640 13 cars, 4 buss, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c146d100-64e024d1.jpg: 384x640 5 persons, 3 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c146d100-917008e9.jpg: 384x640 2 persons, 1 bicycle, 7 cars, 1 bus, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6169/10000 [03:17<01:51, 34.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c146d100-92fd1b9f.jpg: 384x640 3 cars, 2 traffic lights, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c146d100-c0e4da58.jpg: 384x640 1 car, 1 bus, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c146d100-cb76d05b.jpg: 384x640 2 cars, 2 cows, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c147e8f1-42dac06d.jpg: 384x640 5 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6173/10000 [03:17<01:51, 34.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c147e8f1-d78d168a.jpg: 384x640 1 person, 2 cars, 1 traffic light, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c147ecf8-7f7e7c9e.jpg: 384x640 6 persons, 2 cars, 1 handbag, 1 suitcase, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c149583d-ba5e16cb.jpg: 384x640 9 cars, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1496e0d-45fb4823.jpg: 384x640 1 person, 6 cars, 1 traffic light, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6177/10000 [03:17<01:55, 33.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1496e0d-bb0887f7.jpg: 384x640 6 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14a28d6-1623e98d.jpg: 384x640 (no detections), 18.8ms\n",
            "Speed: 1.8ms preprocess, 18.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14a83f1-16a14a16.jpg: 384x640 5 cars, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14a83f1-89a60357.jpg: 384x640 6 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6181/10000 [03:17<01:57, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14c42e1-a83bad41.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14c42e1-bbb66a0a.jpg: 384x640 1 person, 2 skateboards, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14ccf5b-41faebd2.jpg: 384x640 2 persons, 7 cars, 1 truck, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14d8658-f91e67b2.jpg: 384x640 5 cars, 1 traffic light, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6185/10000 [03:17<01:59, 31.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14dc226-1d699f84.jpg: 384x640 2 cars, 1 traffic light, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14e8180-1445eb0a.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14e8180-1968200f.jpg: 384x640 1 bus, 1 truck, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c14e8180-ec624140.jpg: 384x640 1 person, 1 car, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6189/10000 [03:18<01:54, 33.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c150197f-1cf078f2.jpg: 384x640 6 persons, 2 cars, 2 trucks, 1 handbag, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c150197f-3dbfce3c.jpg: 384x640 3 persons, 4 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c150197f-96adff4d.jpg: 384x640 1 person, 2 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c150197f-f934a129.jpg: 384x640 7 cars, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6193/10000 [03:18<01:50, 34.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1504278-565f9d8f.jpg: 384x640 12 cars, 3 traffic lights, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c150584d-0c5c8f75.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c150584d-67716d8e.jpg: 384x640 9 cars, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c152d738-646ba59f.jpg: 384x640 5 cars, 1 truck, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6197/10000 [03:18<01:54, 33.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c153a7d6-902f591d.jpg: 384x640 10 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c154b889-24d4f272.jpg: 384x640 8 cars, 2 trucks, 8 traffic lights, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c154b889-31f9ae3e.jpg: 384x640 1 person, 4 cars, 1 bus, 1 truck, 1 traffic light, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c154b889-9f8ad734.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6201/10000 [03:18<01:56, 32.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1557ff7-0103f652.jpg: 384x640 8 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155b6d9-3f10e2e8.jpg: 384x640 8 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155b6d9-8938e3d3.jpg: 384x640 5 cars, 1 truck, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155b6d9-a803a8d9.jpg: 384x640 8 cars, 1 truck, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6205/10000 [03:18<01:56, 32.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155b6d9-cfa6c733.jpg: 384x640 8 cars, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155d65b-01ae7aac.jpg: 384x640 1 car, 1 truck, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155d65b-2d961d55.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155d65b-50f96017.jpg: 384x640 4 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6209/10000 [03:18<01:52, 33.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155d65b-ae8038a6.jpg: 384x640 1 person, 1 car, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c155d65b-bf020dcb.jpg: 384x640 1 person, 1 car, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1562416-05f50759.jpg: 384x640 3 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1583ab8-1c0feef0.jpg: 384x640 8 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1589305-200e315b.jpg: 384x640 10 cars, 1 bus, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6214/10000 [03:18<01:46, 35.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c159a842-58ec61d9.jpg: 384x640 (no detections), 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c159a842-67c83740.jpg: 384x640 1 car, 6 traffic lights, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c159a842-7a45f3d9.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c159a842-7fa65680.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c159a842-b245f317.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6219/10000 [03:18<01:41, 37.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c159a842-cdc7a8cd.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-184070ba.jpg: 384x640 4 persons, 4 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-3a80f3b2.jpg: 384x640 11 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-47a16c75.jpg: 384x640 7 persons, 4 cars, 1 bus, 4 traffic lights, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6223/10000 [03:19<01:45, 35.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-5be4dad3.jpg: 384x640 (no detections), 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-6881956e.jpg: 384x640 1 person, 1 car, 1 bus, 2 trucks, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-74788f46.jpg: 384x640 16 cars, 1 truck, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-9af1055d.jpg: 384x640 2 persons, 5 cars, 1 truck, 3 traffic lights, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6227/10000 [03:19<01:49, 34.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-b3da941e.jpg: 384x640 10 cars, 1 bus, 3 trucks, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-eb30cb60.jpg: 384x640 1 person, 10 cars, 2 buss, 2 trucks, 4 traffic lights, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15c29a5-f475b344.jpg: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15defff-3d0670f9.jpg: 384x640 3 persons, 3 cars, 1 traffic light, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6231/10000 [03:19<01:57, 32.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15e64e5-f459ff4d.jpg: 384x640 4 persons, 17 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c15e9dd6-955a897b.jpg: 384x640 2 cars, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1617c3b-c295ec43.jpg: 384x640 1 car, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1627cd8-d8c10968.jpg: 384x640 5 cars, 1 traffic light, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6235/10000 [03:19<01:58, 31.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c16613ce-b065ed48.jpg: 384x640 6 cars, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1675e95-6e450bc4.jpg: 384x640 3 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c16766b6-205384e6.jpg: 384x640 4 cars, 1 traffic light, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c167c2a8-3a6f62c1.jpg: 384x640 8 cars, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6239/10000 [03:19<01:56, 32.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c168558d-9a3f4c8c.jpg: 384x640 5 cars, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c16a24ab-c8c540e1.jpg: 384x640 11 cars, 2 traffic lights, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c16c2f49-366525d8.jpg: 384x640 3 persons, 10 cars, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c16d1626-a3df1547.jpg: 384x640 2 cars, 1 fire hydrant, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6243/10000 [03:19<02:09, 29.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c16d3fdb-a3a8c912.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 4.8ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c16e5581-1b1317e2.jpg: 384x640 10 cars, 1 traffic light, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c16e5581-3e798354.jpg: 384x640 1 truck, 1 potted plant, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1707ab9-102247cf.jpg: 384x640 3 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  62%|██████▏   | 6247/10000 [03:19<02:04, 30.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1707ab9-9321801c.jpg: 384x640 1 car, 1 bus, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1715aef-9c4e4c40.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c172eb28-aaf233b7.jpg: 384x640 3 persons, 8 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c172eb28-fbd07793.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c173438f-01b0b013.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6252/10000 [03:19<01:52, 33.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c174a2be-b32a8285.jpg: 384x640 5 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c174b1bd-2a882560.jpg: 384x640 4 cars, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c174b1bd-4b33c65a.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c174b1bd-62c7b473.jpg: 384x640 9 cars, 1 fire hydrant, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6256/10000 [03:20<01:47, 34.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c174b1bd-6d940899.jpg: 384x640 10 cars, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c174b1bd-e90c56a2.jpg: 384x640 (no detections), 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c174b1bd-ff23da83.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c174c108-7bf5b863.jpg: 384x640 1 car, 2 traffic lights, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6260/10000 [03:20<01:46, 34.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1757757-140fa8b6.jpg: 384x640 7 persons, 3 cars, 2 buss, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1757757-601402ff.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1757757-8208000e.jpg: 384x640 16 cars, 1 bus, 2 trucks, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1757757-9879fd39.jpg: 384x640 3 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6264/10000 [03:20<01:46, 35.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17752b1-1949c442.jpg: 384x640 2 cars, 3 traffic lights, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c177a543-86fc2f32.jpg: 384x640 7 cars, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c178a6d6-0f03f247.jpg: 384x640 1 car, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17935d5-3978abec.jpg: 384x640 1 car, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6268/10000 [03:20<01:45, 35.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17935d5-6da1bc64.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1797ffb-1f4c2bc1.jpg: 384x640 1 car, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1797ffb-4afdb9c9.jpg: 384x640 6 cars, 1 truck, 2 traffic lights, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1797ffb-50a40199.jpg: 384x640 1 car, 3 traffic lights, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6272/10000 [03:20<01:43, 36.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1797ffb-633a7ed8.jpg: 384x640 2 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1797ffb-df92d709.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1797ffb-e25c45e4.jpg: 384x640 9 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c179d309-0e034578.jpg: 384x640 9 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6276/10000 [03:20<01:41, 36.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c179d309-59d431e7.jpg: 384x640 11 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c179d309-8939ab37.jpg: 384x640 4 traffic lights, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c179d309-b446fda3.jpg: 384x640 13 cars, 1 truck, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c179d309-bbf612b9.jpg: 384x640 6 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6280/10000 [03:20<01:43, 36.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17a1579-23256ea7.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17a1579-37f5c36f.jpg: 384x640 1 traffic light, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17a1579-afd4745a.jpg: 384x640 1 person, 2 cars, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17a1579-d4af565a.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17a1579-edf3958f.jpg: 384x640 6 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6285/10000 [03:20<01:36, 38.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17aa6cb-4966e0c9.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17aa6cb-b8dbbf71.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17ac26d-a03ed133.jpg: 384x640 7 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17b1192-94d768db.jpg: 384x640 5 cars, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6289/10000 [03:20<01:35, 38.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17b2387-acbe59ce.jpg: 384x640 1 person, 3 cars, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17b2387-b53d9933.jpg: 384x640 2 persons, 1 car, 2 traffic lights, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17b2387-d6a59eed.jpg: 384x640 2 traffic lights, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c17fd4de-d4f40b90.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1807c66-2813073f.jpg: 384x640 3 cars, 2 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6294/10000 [03:21<01:33, 39.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c181581e-2cb8bbad.jpg: 384x640 2 persons, 2 cars, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c181581e-515d3b4a.jpg: 384x640 5 persons, 5 cars, 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c181581e-d2c1c633.jpg: 384x640 2 cars, 1 truck, 11.2ms\n",
            "Speed: 3.5ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c182828e-8ee6c4f8.jpg: 384x640 3 cars, 1 train, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6298/10000 [03:21<01:36, 38.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c186075f-85cc92e4.jpg: 384x640 3 cars, 3 trucks, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1862df8-21ee7c12.jpg: 384x640 5 cars, 1 truck, 6 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1862df8-a1c9702a.jpg: 384x640 13 cars, 1 traffic light, 1 fire hydrant, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c187431f-7b6ad6d6.jpg: 384x640 4 cars, 16.1ms\n",
            "Speed: 2.5ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6302/10000 [03:21<01:44, 35.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c187a3b2-30716126.jpg: 384x640 2 cars, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c189f62f-7cbbe028.jpg: 384x640 1 person, 2 clocks, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18b5a00-f7a987d8.jpg: 384x640 16 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18c0928-a28a4f94.jpg: 384x640 2 persons, 7 cars, 1 traffic light, 13.2ms\n",
            "Speed: 5.7ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6306/10000 [03:21<01:50, 33.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18c2720-3900ffa7.jpg: 384x640 1 person, 15 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18c4ccb-c32c02c7.jpg: 384x640 13 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18c9fe9-a30aa4ca.jpg: 384x640 2 cars, 1 bus, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18cdb0e-c6d8672a.jpg: 384x640 (no detections), 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6310/10000 [03:21<01:52, 32.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18d3ffa-2e847265.jpg: 384x640 15 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18d3ffa-befc072e.jpg: 384x640 12 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18df454-acb6d4fa.jpg: 384x640 3 cars, 1 traffic light, 12.4ms\n",
            "Speed: 3.8ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18e4ce3-2a594c39.jpg: 384x640 5 cars, 1 bus, 1 truck, 12.0ms\n",
            "Speed: 1.7ms preprocess, 12.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6314/10000 [03:21<01:51, 33.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c18feebb-3e10acea.jpg: 384x640 5 cars, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1923ac1-242516f9.jpg: 384x640 9 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1923ac1-5a311813.jpg: 384x640 7 cars, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1924b4e-09f3abc2.jpg: 384x640 (no detections), 21.5ms\n",
            "Speed: 1.9ms preprocess, 21.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6318/10000 [03:21<01:51, 32.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1924b4e-cec324a7.jpg: 384x640 (no detections), 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1924b4e-d9f9aca2.jpg: 384x640 11 cars, 3 traffic lights, 15.8ms\n",
            "Speed: 1.7ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c192dc69-59bbb54c.jpg: 384x640 4 cars, 1 truck, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1947e09-4ec75b70.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6322/10000 [03:21<01:53, 32.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c194891d-b4b5d072.jpg: 384x640 2 cars, 1 truck, 11.2ms\n",
            "Speed: 4.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c19681f6-26f7aa52.jpg: 384x640 5 cars, 1 truck, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c19681f6-c6258473.jpg: 384x640 8 cars, 2 traffic lights, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1978334-40dc8bd3.jpg: 384x640 2 cars, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6326/10000 [03:22<01:55, 31.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1978334-ee0b01df.jpg: 384x640 (no detections), 7.6ms\n",
            "Speed: 2.1ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c197a2a7-20f63536.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c197a2a7-5b960a7f.jpg: 384x640 1 person, 10 cars, 1 truck, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c197a2a7-ea0bf42c.jpg: 384x640 2 persons, 6 cars, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6330/10000 [03:22<01:50, 33.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c198d362-608f78ff.jpg: 384x640 5 cars, 1 bus, 1 truck, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c19aa2da-25679033.jpg: 384x640 2 persons, 2 cars, 1 traffic light, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c19c6ce3-c8682f81.jpg: 384x640 1 person, 5 cars, 15.9ms\n",
            "Speed: 3.6ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c19d66b8-46ba1ad6.jpg: 384x640 13 cars, 17.0ms\n",
            "Speed: 3.8ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6334/10000 [03:22<02:00, 30.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c19d7224-503472e5.jpg: 384x640 4 cars, 2 trucks, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c19e69b1-c22bb482.jpg: 384x640 5 cars, 17.4ms\n",
            "Speed: 3.4ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c19e69b1-d725a651.jpg: 384x640 3 cars, 15.5ms\n",
            "Speed: 2.2ms preprocess, 15.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a026fd-4cce52f5.jpg: 384x640 5 cars, 1 traffic light, 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6338/10000 [03:22<02:01, 30.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a026fd-6c19a089.jpg: 384x640 5 cars, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a026fd-769c0a00.jpg: 384x640 4 cars, 12.6ms\n",
            "Speed: 5.4ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a026fd-7b8320ca.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a026fd-7fa757fd.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6342/10000 [03:22<02:00, 30.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a026fd-88317021.jpg: 384x640 2 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a026fd-9f4909aa.jpg: 384x640 1 car, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a026fd-f78b8860.jpg: 384x640 2 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a06160-7046d0fc.jpg: 384x640 5 cars, 1 truck, 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  63%|██████▎   | 6346/10000 [03:22<01:54, 31.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a06160-8c102212.jpg: 384x640 1 person, 1 train, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a06160-fdbec44f.jpg: 384x640 8 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a07cae-0aaf3a16.jpg: 384x640 8 persons, 4 cars, 1 bus, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a07cae-269e1f30.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▎   | 6350/10000 [03:22<01:47, 33.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a07cae-67a51c91.jpg: 384x640 10 cars, 1 truck, 12.1ms\n",
            "Speed: 7.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a07cae-73529cf4.jpg: 384x640 4 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a07cae-fc54c9dc.jpg: 384x640 3 cars, 2 trucks, 17.8ms\n",
            "Speed: 1.8ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a1e343-52fde736.jpg: 384x640 1 car, 2 trucks, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▎   | 6354/10000 [03:22<01:56, 31.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a1e343-92f68005.jpg: 384x640 2 cars, 1 train, 2 trucks, 1 traffic light, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a1e343-a2aed5dc.jpg: 384x640 1 car, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a2ae3c-19fc5138.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a2ae3c-2040a6cf.jpg: 384x640 (no detections), 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▎   | 6358/10000 [03:23<01:53, 32.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a2ae3c-2325d797.jpg: 384x640 (no detections), 13.5ms\n",
            "Speed: 1.7ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a2f331-c407620f.jpg: 384x640 2 persons, 10 cars, 17.3ms\n",
            "Speed: 1.8ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a42d25-f69459ca.jpg: 384x640 3 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a479d9-0d218cf2.jpg: 384x640 5 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▎   | 6362/10000 [03:23<01:55, 31.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a479d9-0f8f9f4f.jpg: 384x640 1 person, 3 cars, 1 truck, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a479d9-e8ee7bae.jpg: 384x640 1 car, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-0ea22b59.jpg: 384x640 2 cars, 1 bus, 1 truck, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-16222044.jpg: 384x640 6 cars, 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▎   | 6366/10000 [03:23<01:58, 30.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-29536004.jpg: 384x640 4 cars, 16.3ms\n",
            "Speed: 3.3ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-4aa34c73.jpg: 384x640 1 person, 5 cars, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-4e25e6ef.jpg: 384x640 2 cars, 1 truck, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-7b895437.jpg: 384x640 2 persons, 2 cars, 2 buss, 1 truck, 1 traffic light, 1 parking meter, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▎   | 6370/10000 [03:23<01:55, 31.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-83d22fb5.jpg: 384x640 1 person, 3 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-b8528fc1.jpg: 384x640 1 truck, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-c2afbdde.jpg: 384x640 6 cars, 2 traffic lights, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-f41039d1.jpg: 384x640 1 person, 2 cars, 2 trucks, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▎   | 6374/10000 [03:23<01:51, 32.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a5825c-f4d4e625.jpg: 384x640 8 cars, 20.1ms\n",
            "Speed: 2.1ms preprocess, 20.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a61e43-1fe7e02e.jpg: 384x640 6 cars, 1 traffic light, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a8c10a-2c737293.jpg: 384x640 5 cars, 1 traffic light, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a8c10a-85b7b1d9.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6378/10000 [03:23<01:51, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a99e5b-03814753.jpg: 384x640 7 cars, 1 fire hydrant, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a99e5b-9ff89172.jpg: 384x640 15 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a99e5b-c709000a.jpg: 384x640 9 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1a99e5b-fc88d6a2.jpg: 384x640 14 cars, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6382/10000 [03:23<01:47, 33.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1aa3aff-7dab2121.jpg: 384x640 2 persons, 3 cars, 1 bus, 2 trucks, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ae330e-0543c8dc.jpg: 384x640 13 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1aed008-b74dbb7e.jpg: 384x640 9 persons, 3 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1af705e-dfb1664f.jpg: 384x640 1 person, 6 cars, 6 traffic lights, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6386/10000 [03:23<01:44, 34.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1aff52d-0b07b8ae.jpg: 384x640 8 cars, 1 truck, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1aff52d-48e2c3f7.jpg: 384x640 6 persons, 5 cars, 2 traffic lights, 3 parking meters, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b16eee-24ccb54b.jpg: 384x640 1 boat, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b16eee-4d40da01.jpg: 384x640 (no detections), 13.7ms\n",
            "Speed: 1.7ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6390/10000 [03:24<01:43, 34.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b16eee-61bd970b.jpg: 384x640 2 persons, 7 cars, 3 traffic lights, 2 umbrellas, 18.7ms\n",
            "Speed: 1.8ms preprocess, 18.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b16eee-7773662a.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b16eee-d45c1777.jpg: 384x640 1 car, 1 traffic light, 1 bench, 7.8ms\n",
            "Speed: 6.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b173ec-7c9f4aba.jpg: 384x640 9 cars, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6394/10000 [03:24<01:47, 33.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b26cc4-7a7cf86b.jpg: 384x640 14 cars, 10.6ms\n",
            "Speed: 1.7ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b3582d-31ed042c.jpg: 384x640 8 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b3582d-3eb61cdc.jpg: 384x640 1 person, 5 cars, 2 traffic lights, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b3582d-7a6b9124.jpg: 384x640 15 cars, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6398/10000 [03:24<01:55, 31.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b3582d-b9c87c82.jpg: 384x640 1 person, 3 cars, 2 trucks, 1 traffic light, 19.1ms\n",
            "Speed: 1.9ms preprocess, 19.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b4cd01-249d0c21.jpg: 384x640 9 cars, 1 truck, 19.7ms\n",
            "Speed: 3.3ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b5a91c-9e402e78.jpg: 384x640 11 cars, 17.1ms\n",
            "Speed: 4.1ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b5aaf7-f184ef82.jpg: 384x640 1 person, 5 cars, 11.9ms\n",
            "Speed: 2.5ms preprocess, 11.9ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6402/10000 [03:24<02:12, 27.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b64469-18575cd6.jpg: 384x640 7 cars, 1 bus, 1 truck, 18.3ms\n",
            "Speed: 1.8ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b7f449-2e7ddbce.jpg: 384x640 12 cars, 1 truck, 19.0ms\n",
            "Speed: 1.8ms preprocess, 19.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b8863d-5c238b87.jpg: 384x640 13 cars, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6405/10000 [03:24<02:17, 26.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b89289-81b3242f.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b93aa0-3f3c05a3.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1b93aa0-cba79a5f.jpg: 384x640 1 bus, 3 traffic lights, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ba5ee6-1a00a269.jpg: 384x640 5 cars, 1 truck, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6409/10000 [03:24<02:02, 29.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ba5ee6-1ac54091.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ba5ee6-81459f71.jpg: 384x640 9 cars, 2 trucks, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ba5ee6-a7916d65.jpg: 384x640 8 persons, 5 cars, 2 trucks, 1 traffic light, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ba5ee6-b2cb1e51.jpg: 384x640 1 person, 6 cars, 2 trucks, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6413/10000 [03:24<02:03, 28.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ba5ee6-c2c5967a.jpg: 384x640 7 cars, 2 trucks, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ba5ee6-d5c419d3.jpg: 384x640 1 person, 2 cars, 1 truck, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ba5ee6-d7c173ea.jpg: 384x640 7 cars, 2 trucks, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bb60fd-24b6cf0b.jpg: 384x640 3 cars, 2 buss, 2 trucks, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6417/10000 [03:24<01:53, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bbc01a-42a391bd.jpg: 384x640 6 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bbc01a-be613683.jpg: 384x640 8 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bbc01a-cd5108c4.jpg: 384x640 1 car, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bc8490-bf1a47be.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6421/10000 [03:25<01:46, 33.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bd17fc-fc404eba.jpg: 384x640 5 cars, 1 traffic light, 9.8ms\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bd4140-1f2bd79e.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bd4140-645c2847.jpg: 384x640 2 persons, 2 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bd4140-690572f8.jpg: 384x640 1 person, 11 cars, 4 traffic lights, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6425/10000 [03:25<01:46, 33.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bd9a5f-8706ae26.jpg: 384x640 1 car, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1be4f15-060de5f9.jpg: 384x640 2 cars, 1 traffic light, 12.3ms\n",
            "Speed: 4.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1bf3315-d2d3b34f.jpg: 384x640 4 persons, 1 car, 12.3ms\n",
            "Speed: 3.8ms preprocess, 12.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c2aba5-5d0757aa.jpg: 384x640 6 cars, 1 truck, 1 traffic light, 18.3ms\n",
            "Speed: 3.9ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6429/10000 [03:25<01:51, 32.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c6903c-922c5fce.jpg: 384x640 5 cars, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c70561-e47b6c58.jpg: 384x640 7 cars, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c778df-c9e106ab.jpg: 384x640 1 car, 20.7ms\n",
            "Speed: 1.9ms preprocess, 20.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c7a738-75bb5332.jpg: 384x640 6 cars, 2 trucks, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6433/10000 [03:25<02:00, 29.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c811a6-523b402f.jpg: 384x640 2 cars, 2 trucks, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c865f7-23381910.jpg: 384x640 5 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c8b782-bd19a1f1.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c8b782-bece3215.jpg: 384x640 4 cars, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6437/10000 [03:25<01:54, 31.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c8cf02-3ada98f8.jpg: 384x640 5 cars, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1c91c87-beecba09.jpg: 384x640 10 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ca33ef-2b3cedac.jpg: 384x640 6 cars, 1 truck, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ca33ef-b36cc11b.jpg: 384x640 5 persons, 12 cars, 1 traffic light, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6441/10000 [03:25<01:57, 30.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1cc53e4-301ce7f6.jpg: 384x640 1 person, 7 cars, 1 fire hydrant, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d28a8a-6ce21619.jpg: 384x640 3 cars, 1 truck, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d2a1ff-3fe5e395.jpg: 384x640 4 cars, 1 bus, 1 truck, 2 traffic lights, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d4499d-c5dd6747.jpg: 384x640 2 persons, 4 cars, 1 truck, 1 traffic light, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6445/10000 [03:25<01:56, 30.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d49e85-c8f5e1a5.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d4e142-4fedae95.jpg: 384x640 1 car, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d63428-737aac1d.jpg: 384x640 2 persons, 4 cars, 1 bus, 1 truck, 2 traffic lights, 1 stop sign, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d7db26-99ee3075.jpg: 384x640 1 car, 3 traffic lights, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  64%|██████▍   | 6449/10000 [03:25<01:53, 31.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d9b74d-19748e56.jpg: 384x640 3 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d9b74d-56311612.jpg: 384x640 3 cars, 1 bus, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d9b74d-57a10465.jpg: 384x640 1 truck, 10.3ms\n",
            "Speed: 4.7ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d9b74d-d3c2b059.jpg: 384x640 2 persons, 3 cars, 2 trucks, 1 traffic light, 1 parking meter, 12.5ms\n",
            "Speed: 6.0ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6453/10000 [03:26<01:53, 31.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d9b74d-f9ebe548.jpg: 384x640 7 cars, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1d9edc8-8986da55.jpg: 384x640 3 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1da4b69-9de1ea25.jpg: 384x640 3 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1db01c0-566146b4.jpg: 384x640 3 persons, 8 cars, 1 stop sign, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6457/10000 [03:26<01:52, 31.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1dbf9f7-0090d73a.jpg: 384x640 2 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1dc04b3-0279aa42.jpg: 384x640 4 cars, 1 truck, 15.4ms\n",
            "Speed: 5.1ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1dc5cd2-0fd8be03.jpg: 384x640 4 cars, 3 traffic lights, 17.9ms\n",
            "Speed: 3.8ms preprocess, 17.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1dcd827-e36b0fd0.jpg: 384x640 2 cars, 17.2ms\n",
            "Speed: 4.0ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6461/10000 [03:26<02:02, 28.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1de2ece-05370fe3.jpg: 384x640 1 car, 2 traffic lights, 16.6ms\n",
            "Speed: 3.6ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1de2ece-26433e37.jpg: 384x640 5 cars, 14.4ms\n",
            "Speed: 3.9ms preprocess, 14.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1de2ece-5e60449c.jpg: 384x640 3 cars, 16.5ms\n",
            "Speed: 5.9ms preprocess, 16.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6464/10000 [03:26<02:08, 27.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1de2ece-fae99097.jpg: 384x640 4 cars, 5 traffic lights, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ded192-65c5836c.jpg: 384x640 2 cars, 13.3ms\n",
            "Speed: 4.5ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e10ddc-10a024c6.jpg: 384x640 4 cars, 1 truck, 2 stop signs, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6467/10000 [03:26<02:08, 27.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e10ddc-9aaafa4c.jpg: 384x640 1 person, 9 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e1ae56-7ac1bd33.jpg: 384x640 (no detections), 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e1f0cb-ffa477f3.jpg: 384x640 2 persons, 6 cars, 3 buss, 2 trucks, 2 traffic lights, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6470/10000 [03:26<02:06, 27.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e1f7c0-9bbd3146.jpg: 384x640 2 persons, 4 cars, 11.6ms\n",
            "Speed: 5.7ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e1f7c0-b6466fae.jpg: 384x640 12 cars, 1 traffic light, 1 stop sign, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e404d7-4a3eedc5.jpg: 384x640 2 persons, 11 cars, 1 truck, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6473/10000 [03:26<02:06, 27.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e52d50-200c259b.jpg: 384x640 2 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e52d50-62ec817f.jpg: 384x640 2 cars, 2 trucks, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e6340e-084ce27d.jpg: 384x640 1 car, 1 bus, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e662cf-67b73cdc.jpg: 384x640 4 persons, 6 cars, 1 truck, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6477/10000 [03:26<01:56, 30.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1e9212e-dd32de40.jpg: 384x640 3 cars, 14.5ms\n",
            "Speed: 5.0ms preprocess, 14.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ec4d78-1b59adc6.jpg: 384x640 2 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ed2bc1-13f7b91b.jpg: 384x640 1 person, 9 cars, 1 traffic light, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ed2bc1-3d9c0425.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6481/10000 [03:27<01:54, 30.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ed2bc1-6a2e61c4.jpg: 384x640 4 persons, 4 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1ed2bc1-883eb236.jpg: 384x640 2 persons, 2 cars, 1 traffic light, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1eec0f9-986b3a7c.jpg: 384x640 8 cars, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f1b5b7-9bc64925.jpg: 384x640 3 persons, 3 cars, 1 truck, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6485/10000 [03:27<01:53, 30.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f279ae-5a52d338.jpg: 384x640 8 cars, 3 traffic lights, 19.5ms\n",
            "Speed: 1.8ms preprocess, 19.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f279ae-67dfd217.jpg: 384x640 5 cars, 2 traffic lights, 15.9ms\n",
            "Speed: 4.9ms preprocess, 15.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f2bf8e-0364535d.jpg: 384x640 5 cars, 1 truck, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f2bf8e-7b0e284d.jpg: 384x640 2 cars, 1 truck, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6489/10000 [03:27<02:04, 28.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-1bf0a037.jpg: 384x640 3 cars, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-3c5f84a8.jpg: 384x640 4 cars, 3 traffic lights, 14.1ms\n",
            "Speed: 3.9ms preprocess, 14.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-3c7d204b.jpg: 384x640 3 cars, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6492/10000 [03:27<02:09, 27.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-419afa5e.jpg: 384x640 6 cars, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-546dd038.jpg: 384x640 1 car, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-96ab408e.jpg: 384x640 1 car, 15.1ms\n",
            "Speed: 1.8ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6495/10000 [03:27<02:08, 27.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-a26ccd71.jpg: 384x640 (no detections), 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-b529c043.jpg: 384x640 10 cars, 15.2ms\n",
            "Speed: 1.7ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-b78de93e.jpg: 384x640 1 car, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-bfad084b.jpg: 384x640 (no detections), 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▍   | 6499/10000 [03:27<02:00, 28.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f35f18-cc6a82e9.jpg: 384x640 2 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-077f75ad.jpg: 384x640 11 cars, 1 bus, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-4b7f4d35.jpg: 384x640 1 bus, 1 truck, 3 traffic lights, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-59878ba6.jpg: 384x640 1 person, 8 cars, 3 traffic lights, 15.5ms\n",
            "Speed: 4.1ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6503/10000 [03:27<02:01, 28.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-5ae83750.jpg: 384x640 3 persons, 6 cars, 1 bus, 1 truck, 18.5ms\n",
            "Speed: 1.9ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-6e74022e.jpg: 384x640 3 cars, 1 bus, 2 trucks, 1 traffic light, 12.0ms\n",
            "Speed: 5.0ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-717857b3.jpg: 384x640 2 persons, 1 bicycle, 4 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6506/10000 [03:27<02:00, 28.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-7fc50bd1.jpg: 384x640 8 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-9942e4f7.jpg: 384x640 18 cars, 14.9ms\n",
            "Speed: 7.8ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f39934-d26d7dd2.jpg: 384x640 11 cars, 1 truck, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6509/10000 [03:28<02:08, 27.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f47a2c-6ff02223.jpg: 384x640 1 car, 1 traffic light, 9.4ms\n",
            "Speed: 4.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f4b883-84444018.jpg: 384x640 1 person, 6 cars, 2 buss, 1 truck, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f4b883-97d48a35.jpg: 384x640 10 cars, 9.9ms\n",
            "Speed: 3.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f5ccf1-3db75c28.jpg: 384x640 6 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6513/10000 [03:28<02:01, 28.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f65250-4bf4a042.jpg: 384x640 1 car, 2 trucks, 3 traffic lights, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f65250-7a0e931b.jpg: 384x640 1 car, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f7104e-b64ae3b2.jpg: 384x640 4 persons, 1 bicycle, 4 cars, 16.7ms\n",
            "Speed: 1.9ms preprocess, 16.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6516/10000 [03:28<02:01, 28.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f74dbc-21fc10db.jpg: 384x640 5 cars, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f74dbc-457b1a3a.jpg: 384x640 4 cars, 16.6ms\n",
            "Speed: 4.2ms preprocess, 16.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f74dbc-af3b1aa4.jpg: 384x640 4 cars, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6519/10000 [03:28<02:06, 27.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f74dbc-c774031f.jpg: 384x640 (no detections), 17.3ms\n",
            "Speed: 1.8ms preprocess, 17.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f7cec6-549a06ac.jpg: 384x640 1 person, 9 cars, 1 truck, 14.6ms\n",
            "Speed: 5.8ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-06b1c09d.jpg: 384x640 2 cars, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6522/10000 [03:28<02:07, 27.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-08345938.jpg: 384x640 (no detections), 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-2b52f21e.jpg: 384x640 3 cars, 16.4ms\n",
            "Speed: 1.8ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-343f4798.jpg: 384x640 3 cars, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-438f46c3.jpg: 384x640 3 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6526/10000 [03:28<02:00, 28.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-55f5ae24.jpg: 384x640 1 car, 2 traffic lights, 1 bench, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-683c824f.jpg: 384x640 (no detections), 18.5ms\n",
            "Speed: 1.8ms preprocess, 18.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-7cb2d56b.jpg: 384x640 2 cars, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-81ee1c2d.jpg: 384x640 8 cars, 2 traffic lights, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6530/10000 [03:28<01:58, 29.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-c550f84e.jpg: 384x640 1 car, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-c6dae792.jpg: 384x640 1 person, 1 car, 1 bench, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f8d9b3-e7a69cc0.jpg: 384x640 1 person, 4 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f917f7-49fe8032.jpg: 384x640 4 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6534/10000 [03:28<01:55, 29.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f917f7-c3b86ce0.jpg: 384x640 11 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f9740a-41816cad.jpg: 384x640 3 cars, 3 traffic lights, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f9f357-0ea2a4a9.jpg: 384x640 4 cars, 1 bus, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6537/10000 [03:29<01:58, 29.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1f9f357-ab0da339.jpg: 384x640 4 cars, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fa7950-56a78519.jpg: 384x640 3 cars, 1 bus, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fa7950-fbc6ec93.jpg: 384x640 5 cars, 1 fire hydrant, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fa81f4-43a87286.jpg: 384x640 2 persons, 1 car, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6541/10000 [03:29<01:52, 30.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fa81f4-f26197b3.jpg: 384x640 1 car, 12.1ms\n",
            "Speed: 4.8ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fb9b6e-39387962.jpg: 384x640 2 cars, 17.9ms\n",
            "Speed: 1.8ms preprocess, 17.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fbed4d-18be096c.jpg: 384x640 4 cars, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fcbbba-82bed253.jpg: 384x640 5 cars, 1 truck, 20.9ms\n",
            "Speed: 2.8ms preprocess, 20.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6545/10000 [03:29<01:59, 28.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fcdfd1-b34ce63c.jpg: 384x640 1 person, 22 cars, 1 traffic light, 15.0ms\n",
            "Speed: 2.1ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fd3aad-0fdb8c7c.jpg: 384x640 8 cars, 2 traffic lights, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fd3aad-e12c3c56.jpg: 384x640 12 cars, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  65%|██████▌   | 6548/10000 [03:29<02:06, 27.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fdbab3-9f0f7dfd.jpg: 384x640 2 cars, 1 traffic light, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fdd182-0431866d.jpg: 384x640 4 cars, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fdd182-1d547f9b.jpg: 384x640 11 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fdd182-28e0d6aa.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6552/10000 [03:29<01:58, 29.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fdd182-89c4beb5.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fdd182-c46e6435.jpg: 384x640 1 person, 6 cars, 1 motorcycle, 1 truck, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c1fdd182-ee635148.jpg: 384x640 1 person, 7 cars, 1 traffic light, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2021c8c-474a8eda.jpg: 384x640 8 cars, 1 bus, 4 trucks, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6556/10000 [03:29<01:55, 29.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2021f20-421a5da4.jpg: 384x640 7 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2021f20-46a5823b.jpg: 384x640 4 persons, 2 cars, 1 motorcycle, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2021f20-5b9772ba.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2021f20-6c78f954.jpg: 384x640 1 car, 1 truck, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6560/10000 [03:29<01:46, 32.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2021f20-db3a51d7.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c202b384-5783e17c.jpg: 384x640 8 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c202c860-fbf85ab9.jpg: 384x640 3 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2032247-86ea336e.jpg: 384x640 1 person, 10 cars, 1 truck, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6564/10000 [03:29<01:41, 33.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2044e67-b5d63528.jpg: 384x640 4 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2046c97-1d2d5571.jpg: 384x640 4 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2050b3c-55dd8c44.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2054961-03b26a4f.jpg: 384x640 11 cars, 1 truck, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6568/10000 [03:30<01:39, 34.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20562f2-5524d6c5.jpg: 384x640 12 cars, 1 motorcycle, 1 umbrella, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20685c6-10269c46.jpg: 384x640 8 cars, 1 bus, 2 trucks, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2074a7c-7905ced0.jpg: 384x640 1 person, 1 car, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20aa83a-0646a7d3.jpg: 384x640 1 car, 1 stop sign, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6572/10000 [03:30<01:39, 34.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-0e43133b.jpg: 384x640 1 car, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-197a71ae.jpg: 384x640 2 cars, 4 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-1c40dc28.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-3fee400d.jpg: 384x640 1 car, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6576/10000 [03:30<01:37, 35.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-8d54d4cb.jpg: 384x640 2 cars, 1 traffic light, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-a8207705.jpg: 384x640 2 traffic lights, 16.1ms\n",
            "Speed: 2.9ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-b0b530cf.jpg: 384x640 2 cars, 4 traffic lights, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-bc706ea7.jpg: 384x640 1 car, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6580/10000 [03:30<01:41, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-f5107b2c.jpg: 384x640 3 persons, 2 cars, 1 bus, 1 stop sign, 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20ae70f-fb4f0da6.jpg: 384x640 1 car, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20b3a6a-c51292e2.jpg: 384x640 2 cars, 1 traffic light, 19.5ms\n",
            "Speed: 3.4ms preprocess, 19.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20db6e7-6613883a.jpg: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6584/10000 [03:30<01:47, 31.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c20e5778-cfbaabbf.jpg: 384x640 7 cars, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c210f326-88ad92d0.jpg: 384x640 7 cars, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21334d5-57aa0da4.jpg: 384x640 3 cars, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21334d5-c0e77c4e.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6588/10000 [03:30<01:50, 30.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c213a6ff-1ee61516.jpg: 384x640 1 traffic light, 18.9ms\n",
            "Speed: 3.0ms preprocess, 18.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c213a6ff-386e0c8e.jpg: 384x640 1 car, 3 traffic lights, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c213a6ff-9de3bb98.jpg: 384x640 2 cars, 4 traffic lights, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2148d05-9f10097f.jpg: 384x640 4 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6592/10000 [03:30<01:53, 30.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2148d05-b52ebea0.jpg: 384x640 9 cars, 1 truck, 3 traffic lights, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c214be24-661d4b88.jpg: 384x640 1 truck, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c214c96d-579ff000.jpg: 384x640 10 cars, 1 traffic light, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2179f35-d4666c72.jpg: 384x640 5 cars, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6596/10000 [03:30<01:51, 30.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2186a76-5444a563.jpg: 384x640 15 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2186a76-6757a4be.jpg: 384x640 3 cars, 1 traffic light, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2186a76-86491ba7.jpg: 384x640 10 cars, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c219e30c-1f1796a7.jpg: 384x640 9 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6600/10000 [03:31<01:49, 31.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c219f321-d15ce31b.jpg: 384x640 2 cars, 2 fire hydrants, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21bf66e-42fff314.jpg: 384x640 12 cars, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21d47dc-fd0bdc45.jpg: 384x640 1 person, 1 bicycle, 1 traffic light, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21defc7-61b5e22a.jpg: 384x640 1 person, 6 cars, 1 motorcycle, 3 trucks, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6604/10000 [03:31<01:44, 32.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21e328e-0d19a282.jpg: 384x640 6 cars, 3 trucks, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21ef8aa-0c751223.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21ef8aa-cabc5b7a.jpg: 384x640 4 persons, 3 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21f174e-57fbb4a3.jpg: 384x640 1 car, 1 horse, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6608/10000 [03:31<01:43, 32.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21f174e-63f35244.jpg: 384x640 9 persons, 5 cars, 2 benchs, 24.3ms\n",
            "Speed: 2.8ms preprocess, 24.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21f174e-c4bbb429.jpg: 384x640 3 cars, 1 traffic light, 18.1ms\n",
            "Speed: 4.3ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21fba09-38039a43.jpg: 384x640 1 car, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21fba09-53381e9a.jpg: 384x640 3 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6612/10000 [03:31<01:51, 30.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21fba09-8236eb51.jpg: 384x640 1 train, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21fba09-f3c37fc9.jpg: 384x640 1 car, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c21fba09-f4501c68.jpg: 384x640 3 cars, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2201fab-5d3df1a5.jpg: 384x640 8 cars, 3 traffic lights, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6616/10000 [03:31<01:45, 32.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2201fab-cbe7ff17.jpg: 384x640 7 persons, 3 cars, 10.3ms\n",
            "Speed: 5.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2201fab-f8248caa.jpg: 384x640 5 cars, 1 traffic light, 17.9ms\n",
            "Speed: 1.8ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2216e26-f9faa96a.jpg: 384x640 3 cars, 2 traffic lights, 12.5ms\n",
            "Speed: 6.7ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c223e6d7-9cc59b6b.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 6.5ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6620/10000 [03:31<01:52, 30.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c223e6d7-e1a9bb5a.jpg: 384x640 2 cars, 1 truck, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2244286-08a1eebf.jpg: 384x640 2 cars, 1 bus, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2260f2c-787c095d.jpg: 384x640 (no detections), 9.8ms\n",
            "Speed: 4.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c22b4f17-7befe1a1.jpg: 384x640 2 cars, 2 trucks, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▌   | 6624/10000 [03:31<01:45, 31.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c22b4f17-afdf71f2.jpg: 384x640 1 car, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c22c0422-2de1b215.jpg: 384x640 4 cars, 1 truck, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c22f5c49-f16b772b.jpg: 384x640 1 car, 3 traffic lights, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c22feff4-14505161.jpg: 384x640 9 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▋   | 6628/10000 [03:31<01:43, 32.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2302f7c-85b15ee2.jpg: 384x640 11 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2313d3a-69748e1a.jpg: 384x640 1 car, 1 traffic light, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c231647c-229d2cac.jpg: 384x640 2 persons, 9 cars, 1 truck, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c233073e-4295b189.jpg: 384x640 5 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▋   | 6632/10000 [03:32<01:42, 32.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2341eec-16d212b8.jpg: 384x640 2 persons, 5 cars, 1 bus, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2341eec-293df47b.jpg: 384x640 7 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c23551ce-34508f75.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c23551ce-6007b75e.jpg: 384x640 3 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▋   | 6636/10000 [03:32<01:40, 33.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2364a53-a22c73f2.jpg: 384x640 2 persons, 2 bicycles, 16 cars, 1 fire hydrant, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c23746ed-28a94ca8.jpg: 384x640 8 cars, 1 bus, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c23770f3-1b29a7b7.jpg: 384x640 9 cars, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c237ce66-cf2860b7.jpg: 384x640 1 traffic light, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▋   | 6640/10000 [03:32<01:41, 33.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2381a27-bf6306b9.jpg: 384x640 1 truck, 13.5ms\n",
            "Speed: 3.2ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c239ab3d-61c3912f.jpg: 384x640 6 persons, 5 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c239dcd2-0868f0e1.jpg: 384x640 1 person, 8 cars, 3 trucks, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c239dcd2-bbd38c33.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▋   | 6644/10000 [03:32<01:45, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c239f9d5-92e82ab6.jpg: 384x640 3 persons, 5 cars, 1 traffic light, 1 stop sign, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c239f9d5-a5ccfdec.jpg: 384x640 2 persons, 3 cars, 20.9ms\n",
            "Speed: 1.7ms preprocess, 20.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c239f9d5-ba69ae6a.jpg: 384x640 7 persons, 3 cars, 2 motorcycles, 16.9ms\n",
            "Speed: 3.1ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2425dd9-c679e796.jpg: 384x640 1 car, 1 traffic light, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  66%|██████▋   | 6648/10000 [03:32<01:50, 30.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2425dd9-ca97c25b.jpg: 384x640 6 cars, 1 bus, 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c242b4b8-0dab228f.jpg: 384x640 3 cars, 1 truck, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c242b4b8-6757e7b6.jpg: 384x640 1 person, 9 cars, 2 traffic lights, 19.5ms\n",
            "Speed: 1.8ms preprocess, 19.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c242b4b8-7d73aa05.jpg: 384x640 1 person, 7 cars, 1 truck, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6652/10000 [03:32<02:03, 27.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c242b4b8-f07bddfe.jpg: 384x640 3 persons, 4 cars, 1 bus, 1 handbag, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2437a91-3c23aba9.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2461a5a-936bf379.jpg: 384x640 7 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2461a5a-c6094472.jpg: 384x640 1 person, 5 cars, 1 tv, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6656/10000 [03:32<01:55, 28.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24838fd-064f7c3f.jpg: 384x640 1 person, 11 cars, 1 bus, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24838fd-2747849c.jpg: 384x640 6 cars, 1 truck, 5 traffic lights, 12.4ms\n",
            "Speed: 1.7ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24838fd-971abd46.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24838fd-ad7ca437.jpg: 384x640 8 persons, 3 cars, 11.1ms\n",
            "Speed: 3.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6660/10000 [03:32<01:52, 29.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24838fd-e3eae166.jpg: 384x640 1 person, 6 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24838fd-e77a2501.jpg: 384x640 13 persons, 4 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c249fd49-2b590a59.jpg: 384x640 1 person, 5 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24a4e92-fe4e161a.jpg: 384x640 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6664/10000 [03:33<01:46, 31.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24ab4b6-3f1b1b45.jpg: 384x640 7 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24aece5-9554f636.jpg: 384x640 6 cars, 1 truck, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24bae34-454a0416.jpg: 384x640 4 persons, 7 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24bae34-ecd0abe5.jpg: 384x640 11 cars, 2 potted plants, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6668/10000 [03:33<01:43, 32.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24bfc75-858cdb28.jpg: 384x640 1 car, 3 traffic lights, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24da7c7-21c58e17.jpg: 384x640 1 car, 20.0ms\n",
            "Speed: 2.0ms preprocess, 20.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e1c23-c639fa40.jpg: 384x640 2 cars, 18.0ms\n",
            "Speed: 1.7ms preprocess, 18.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e5f86-035733db.jpg: 384x640 1 truck, 16.9ms\n",
            "Speed: 1.8ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6672/10000 [03:33<01:45, 31.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e5f86-182d7a32.jpg: 384x640 2 cars, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e5f86-317d18d5.jpg: 384x640 2 cars, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e5f86-c7ad4eac.jpg: 384x640 (no detections), 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e7c72-2aefe7f1.jpg: 384x640 1 person, 8 cars, 1 traffic light, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6676/10000 [03:33<01:44, 31.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e7c72-3f74481c.jpg: 384x640 10 cars, 16.9ms\n",
            "Speed: 3.3ms preprocess, 16.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e7c72-be9fff6f.jpg: 384x640 1 person, 1 bicycle, 6 cars, 1 traffic light, 1 fire hydrant, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e7c72-c2ea97f0.jpg: 384x640 4 cars, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e7c72-ec7528ea.jpg: 384x640 1 person, 3 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6680/10000 [03:33<01:48, 30.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c24e7c72-f53291ea.jpg: 384x640 1 car, 1 bus, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2509294-e36cd975.jpg: 384x640 4 cars, 1 motorcycle, 1 truck, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2509294-f6bd70dc.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2511583-9b7d39a0.jpg: 384x640 2 cars, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6684/10000 [03:33<01:40, 32.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c253aa39-477c3d0a.jpg: 384x640 1 car, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c253f19a-40117192.jpg: 384x640 6 cars, 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2592033-48254ed4.jpg: 384x640 5 cars, 3 buss, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2592033-8052ef77.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6688/10000 [03:33<01:41, 32.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2592033-97240486.jpg: 384x640 7 cars, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c25956aa-0dba6cc7.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c25a8eea-5c0d75f6.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c25d979a-020521ba.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6692/10000 [03:33<01:37, 33.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c25d979a-8467d479.jpg: 384x640 1 person, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c25f97e6-1827a77f.jpg: 384x640 5 persons, 8 cars, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c25f97e6-2007b36c.jpg: 384x640 1 person, 2 cars, 1 bus, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c25f97e6-3fe484e6.jpg: 384x640 1 person, 5 cars, 2 trucks, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6696/10000 [03:34<01:35, 34.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c25f97e6-6a4c4ca2.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c261a365-e321c618.jpg: 384x640 3 cars, 1 truck, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c262c510-15478ba1.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c264943c-5e493c9f.jpg: 384x640 10 cars, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6700/10000 [03:34<01:35, 34.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c265ca04-fe330cbb.jpg: 384x640 11 cars, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26620df-69c25d46.jpg: 384x640 1 car, 2 trucks, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c267da7f-006f108f.jpg: 384x640 8 cars, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c267da7f-b62da311.jpg: 384x640 1 person, 1 car, 1 truck, 1 traffic light, 1 potted plant, 14.0ms\n",
            "Speed: 2.6ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6704/10000 [03:34<01:41, 32.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c267da7f-d242db6c.jpg: 384x640 3 cars, 2 buss, 1 traffic light, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2680d40-90d19d17.jpg: 384x640 9 cars, 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26abe13-497f3abf.jpg: 384x640 15 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26b2918-1cb13443.jpg: 384x640 6 cars, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6708/10000 [03:34<01:46, 30.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26b9b25-a8bbf0b5.jpg: 384x640 4 cars, 18.3ms\n",
            "Speed: 2.5ms preprocess, 18.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26c1352-5e1c2fe2.jpg: 384x640 2 persons, 3 traffic lights, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26c1883-9c563aa8.jpg: 384x640 6 cars, 1 traffic light, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26f2635-1d311675.jpg: 384x640 1 person, 3 cars, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6712/10000 [03:34<01:52, 29.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26f2635-26462f90.jpg: 384x640 2 cars, 17.6ms\n",
            "Speed: 4.0ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c26f2635-f33e1d9f.jpg: 384x640 2 persons, 7 cars, 1 truck, 1 traffic light, 17.6ms\n",
            "Speed: 3.5ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c27353a6-2b3a186d.jpg: 384x640 6 cars, 9.5ms\n",
            "Speed: 6.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6715/10000 [03:34<01:55, 28.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c273b0cc-4286333b.jpg: 384x640 5 cars, 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c273e0e3-050cf9b4.jpg: 384x640 6 cars, 1 truck, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c273e0e3-27a4413f.jpg: 384x640 10 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c273e0e3-524fae66.jpg: 384x640 6 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6719/10000 [03:34<01:51, 29.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c274ce4e-e2f8d81b.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2753ce8-bef4b9d4.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2775fbb-12089565.jpg: 384x640 4 cars, 3 traffic lights, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2775fbb-7b8764dc.jpg: 384x640 1 person, 1 car, 3 traffic lights, 9.4ms\n",
            "Speed: 4.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6723/10000 [03:34<01:47, 30.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c279d4e7-97fb3340.jpg: 384x640 4 persons, 2 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c27e2a5d-3fb04be8.jpg: 384x640 2 persons, 6 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c27e2a5d-93699ec3.jpg: 384x640 7 persons, 11 cars, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c27e5a2b-ecd48437.jpg: 384x640 1 bus, 1 truck, 1 stop sign, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6727/10000 [03:35<01:48, 30.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c281c4a6-21278370.jpg: 384x640 9 cars, 1 traffic light, 1 stop sign, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c281c4a6-27abfe08.jpg: 384x640 1 person, 10 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c281c4a6-310425cb.jpg: 384x640 8 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c281c4a6-40432e1d.jpg: 384x640 1 person, 7 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6731/10000 [03:35<01:44, 31.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c281c4a6-c90826d4.jpg: 384x640 15 cars, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2841851-644a8cfe.jpg: 384x640 6 cars, 1 truck, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2853fd5-304c554e.jpg: 384x640 10 cars, 2 traffic lights, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c288c7a7-347f9b29.jpg: 384x640 1 car, 2 traffic lights, 15.5ms\n",
            "Speed: 3.1ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6735/10000 [03:35<01:51, 29.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c288c7a7-785cdad5.jpg: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c28982c9-343d3ab5.jpg: 384x640 3 persons, 11 cars, 1 truck, 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c28b1cad-827d300e.jpg: 384x640 4 cars, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6738/10000 [03:35<01:56, 28.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c28b60fb-a5e9b955.jpg: 384x640 19 cars, 17.3ms\n",
            "Speed: 6.0ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c28cecbb-11796cf6.jpg: 384x640 7 cars, 12.0ms\n",
            "Speed: 5.1ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c291c9ab-a9ccb89d.jpg: 384x640 2 cars, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6741/10000 [03:35<02:06, 25.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c292800e-4290dbb9.jpg: 384x640 4 persons, 6 cars, 3 motorcycles, 1 bus, 1 traffic light, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c292800e-fd3697ee.jpg: 384x640 5 cars, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2937a02-5e3132bb.jpg: 384x640 1 person, 6 cars, 1 bus, 1 truck, 3 traffic lights, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6744/10000 [03:35<02:07, 25.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2937a02-db177509.jpg: 384x640 12 cars, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c294e58f-9310c6be.jpg: 384x640 11 cars, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29829cf-9790141e.jpg: 384x640 8 cars, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  67%|██████▋   | 6747/10000 [03:35<02:03, 26.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29829cf-a9e05937.jpg: 384x640 13 cars, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2987e05-9c59c386.jpg: 384x640 8 cars, 10.3ms\n",
            "Speed: 2.6ms preprocess, 10.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2987e05-cb9bfcee.jpg: 384x640 8 cars, 15.0ms\n",
            "Speed: 4.2ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6750/10000 [03:35<02:07, 25.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29976d5-c811d4fc.jpg: 384x640 3 cars, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29d13ba-67447c50.jpg: 384x640 1 person, 5 cars, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29d13ba-ad7aee3f.jpg: 384x640 1 person, 7 cars, 1 truck, 3 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29d444d-06b31782.jpg: 384x640 13 persons, 4 cars, 1 truck, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6754/10000 [03:36<01:59, 27.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29d692d-ed6435ba.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29e8060-71ad061c.jpg: 384x640 (no detections), 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c29eff38-fcac5247.jpg: 384x640 1 car, 3 traffic lights, 1 cup, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a0e52f-013aa867.jpg: 384x640 1 person, 1 bus, 2 traffic lights, 2 suitcases, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a0e52f-024a2af0.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6759/10000 [03:36<01:43, 31.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a0e52f-bed5a09e.jpg: 384x640 2 cars, 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a26f9b-634ed98f.jpg: 384x640 1 car, 1 truck, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a26f9b-f5f43bb4.jpg: 384x640 1 car, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a42061-fc4af0cd.jpg: 384x640 7 cars, 1 bench, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6763/10000 [03:36<01:43, 31.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a4a88f-1a60e4a6.jpg: 384x640 4 cars, 1 truck, 4 traffic lights, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a5efc2-5db1bfef.jpg: 384x640 2 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a6a273-553fcc3e.jpg: 384x640 1 person, 1 car, 1 truck, 1 traffic light, 15.4ms\n",
            "Speed: 2.4ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a6b1c9-c45dc6e2.jpg: 384x640 8 cars, 4 traffic lights, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6767/10000 [03:36<01:47, 29.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a6b1c9-ce009635.jpg: 384x640 14 cars, 1 bus, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a6b1c9-dd645325.jpg: 384x640 10 cars, 1 traffic light, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a76d08-8d6ecf47.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a76d08-bba28d34.jpg: 384x640 (no detections), 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6771/10000 [03:36<01:45, 30.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a861df-c568afdf.jpg: 384x640 6 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a97407-8de8d65d.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2a9ed1d-3468f926.jpg: 384x640 8 cars, 4 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ab5734-0f552875.jpg: 384x640 1 person, 1 stop sign, 1 potted plant, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6775/10000 [03:36<01:40, 32.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ac826b-a3056d98.jpg: 384x640 7 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ad6f21-713c330a.jpg: 384x640 8 cars, 1 truck, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b0aeff-8116fb32.jpg: 384x640 5 cars, 1 bus, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b457e5-1779ee7a.jpg: 384x640 1 person, 6 cars, 15.0ms\n",
            "Speed: 1.7ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6779/10000 [03:36<01:42, 31.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b457e5-36e3ecee.jpg: 384x640 1 person, 3 cars, 1 motorcycle, 2 traffic lights, 8.6ms\n",
            "Speed: 2.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b4e787-cb1903e2.jpg: 384x640 1 person, 13 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b665b0-204f2f52.jpg: 384x640 9 cars, 1 motorcycle, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b673e4-93811ad0.jpg: 384x640 (no detections), 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6783/10000 [03:37<01:40, 32.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b6ba94-2700b429.jpg: 384x640 3 cars, 1 bus, 1 truck, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b6d359-e8c54604.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b760c8-952a9da4.jpg: 384x640 12 cars, 2 trucks, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2b79a27-6c31cf15.jpg: 384x640 1 car, 1 traffic light, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6787/10000 [03:37<01:38, 32.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bc5a4c-69603eab.jpg: 384x640 5 persons, 1 car, 2 trucks, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bc5a4c-714081e9.jpg: 384x640 2 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bc5a4c-b2bc828b.jpg: 384x640 3 cars, 1 bus, 2 trucks, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bc5a4c-c4864ac1.jpg: 384x640 7 cars, 1 bus, 1 truck, 1 traffic light, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6791/10000 [03:37<01:37, 32.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bcd344-ee1fa1cf.jpg: 384x640 1 person, 4 cars, 2 buss, 1 truck, 11.2ms\n",
            "Speed: 4.4ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bd6e37-f28f3332.jpg: 384x640 4 cars, 16.5ms\n",
            "Speed: 2.5ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bd70f5-009e856e.jpg: 384x640 8 cars, 13.2ms\n",
            "Speed: 3.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bd70f5-b518c14f.jpg: 384x640 6 cars, 2 trucks, 16.9ms\n",
            "Speed: 1.9ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6795/10000 [03:37<01:44, 30.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2bd70f5-d811bd56.jpg: 384x640 9 cars, 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c2b345-0bd03595.jpg: 384x640 1 car, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c32a23-8636a7e4.jpg: 384x640 2 cars, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c32a23-b356a99b.jpg: 384x640 5 cars, 17.7ms\n",
            "Speed: 2.6ms preprocess, 17.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6799/10000 [03:37<01:47, 29.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c38d09-ac9ea6ea.jpg: 384x640 1 car, 1 traffic light, 17.0ms\n",
            "Speed: 3.1ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c46944-e4ca174b.jpg: 384x640 14 cars, 1 bus, 1 truck, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c5ac9a-fc00e41a.jpg: 384x640 13 cars, 1 traffic light, 1 fire hydrant, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c5fee5-a8360924.jpg: 384x640 1 person, 3 bicycles, 3 cars, 1 truck, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6803/10000 [03:37<01:53, 28.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c5fee5-da368df3.jpg: 384x640 2 persons, 4 bicycles, 2 cars, 1 truck, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c5fee5-f8ce1342.jpg: 384x640 3 cars, 1 bus, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c6e56c-253eb798.jpg: 384x640 1 car, 2 trucks, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c78435-b075e841.jpg: 384x640 13 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6807/10000 [03:37<01:47, 29.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c78435-e0e98f96.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c8b275-6341d9ae.jpg: 384x640 15 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c8b275-a29bbc9b.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c8b275-bd783d7f.jpg: 384x640 1 car, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6811/10000 [03:37<01:40, 31.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c8b275-cd37b639.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c8b275-ce362dfc.jpg: 384x640 7 cars, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2c8b275-e923a396.jpg: 384x640 2 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ca5977-11073d54.jpg: 384x640 9 cars, 1 bus, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6815/10000 [03:38<01:35, 33.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ca6fc5-20262bf2.jpg: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ccc2a6-300804e4.jpg: 384x640 10 cars, 1 bus, 1 stop sign, 15.3ms\n",
            "Speed: 1.8ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ccc2a6-81d75278.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ccdd66-06c44d2f.jpg: 384x640 4 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6819/10000 [03:38<01:31, 34.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ccdd66-3ad4767a.jpg: 384x640 3 persons, 6 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ccdd66-47e6d7cd.jpg: 384x640 2 cars, 1 traffic light, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ccdd66-66b6b14f.jpg: 384x640 3 cars, 4 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ccdd66-8cf38323.jpg: 384x640 2 cars, 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6823/10000 [03:38<01:34, 33.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ccdd66-f578a841.jpg: 384x640 10 cars, 17.8ms\n",
            "Speed: 2.9ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2cce0a4-9e2fccd0.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2cf05b9-112623fd.jpg: 384x640 1 person, 6 cars, 1 truck, 2 traffic lights, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2cf05b9-a796747a.jpg: 384x640 16 cars, 1 truck, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6827/10000 [03:38<01:40, 31.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d051a0-007fa10e.jpg: 384x640 5 cars, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d051a0-31c90f75.jpg: 384x640 1 person, 6 cars, 1 truck, 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d051a0-33d3efce.jpg: 384x640 8 cars, 1 bus, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d051a0-a1590f05.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6831/10000 [03:38<01:40, 31.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d07fa1-f6cebd10.jpg: 384x640 2 persons, 8 cars, 12.2ms\n",
            "Speed: 1.7ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d33423-0f14ffaa.jpg: 384x640 9 cars, 1 bus, 3 traffic lights, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d33423-8f1d3d05.jpg: 384x640 2 persons, 9 cars, 1 traffic light, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d5a01a-a0821dcd.jpg: 384x640 5 cars, 3 traffic lights, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6835/10000 [03:38<01:43, 30.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d5a01a-c58b92d1.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d5a01a-e636934d.jpg: 384x640 1 car, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d84b6d-36aacbc8.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d84b6d-5b9fc9f6.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d921c8-2d2a2c9b.jpg: 384x640 2 persons, 3 cars, 1 bench, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6840/10000 [03:38<01:33, 33.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2d921c8-6d91821a.jpg: 384x640 10 cars, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2dba16e-9ead0a99.jpg: 384x640 13 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e04d81-cb5871d8.jpg: 384x640 14 cars, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e068f4-1ba33b01.jpg: 384x640 3 cars, 1 truck, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6844/10000 [03:38<01:33, 33.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e0f386-2f25f1fd.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e294a9-07a2a060.jpg: 384x640 3 persons, 2 cars, 1 bus, 2 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e294a9-8b108774.jpg: 384x640 19 cars, 16.5ms\n",
            "Speed: 5.4ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e294a9-93e364f0.jpg: 384x640 2 persons, 10 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  68%|██████▊   | 6848/10000 [03:39<01:36, 32.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e294a9-cd5c3b02.jpg: 384x640 16 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e3cd3c-27871334.jpg: 384x640 4 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e3cd3c-d9fd1bfd.jpg: 384x640 7 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e3cd3c-fc972e2e.jpg: 384x640 1 person, 9 cars, 1 traffic light, 1 clock, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▊   | 6852/10000 [03:39<01:40, 31.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e3fe05-6c12de55.jpg: 384x640 2 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e3fe05-7a8ce431.jpg: 384x640 2 persons, 4 cars, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e3fe05-fa312f4d.jpg: 384x640 1 car, 2 trucks, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e4e91e-cf165083.jpg: 384x640 6 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▊   | 6856/10000 [03:39<01:41, 31.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e50057-06f8a09f.jpg: 384x640 3 cars, 19.3ms\n",
            "Speed: 3.5ms preprocess, 19.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e50057-24acc02d.jpg: 384x640 3 cars, 18.2ms\n",
            "Speed: 3.2ms preprocess, 18.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e64366-81f14610.jpg: 384x640 4 cars, 1 truck, 13.5ms\n",
            "Speed: 4.8ms preprocess, 13.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e64366-e1c00685.jpg: 384x640 3 persons, 3 cars, 2 trucks, 15.1ms\n",
            "Speed: 4.1ms preprocess, 15.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▊   | 6860/10000 [03:39<01:53, 27.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e9a1b8-c9299c7a.jpg: 384x640 1 traffic light, 18.0ms\n",
            "Speed: 3.0ms preprocess, 18.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2e9a1b8-e631ecd9.jpg: 384x640 (no detections), 16.6ms\n",
            "Speed: 5.3ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2eb1910-39269c22.jpg: 384x640 5 cars, 1 traffic light, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▊   | 6863/10000 [03:39<01:56, 27.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2eb2ca4-fc64114e.jpg: 384x640 5 cars, 16.6ms\n",
            "Speed: 1.8ms preprocess, 16.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ecefdc-3722313c.jpg: 384x640 9 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ecefdc-899cd0ca.jpg: 384x640 1 person, 3 cars, 1 bus, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▊   | 6866/10000 [03:39<01:59, 26.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ecf02b-bc9b4eb7.jpg: 384x640 5 cars, 3 traffic lights, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2edec5a-66ae2e42.jpg: 384x640 1 car, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2edec5a-cb5f109b.jpg: 384x640 1 car, 1 traffic light, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▊   | 6869/10000 [03:39<01:56, 26.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2edfde8-ed5a96ad.jpg: 384x640 1 car, 1 truck, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ee74ff-63374b3e.jpg: 384x640 1 person, 3 cars, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ee74ff-9e493288.jpg: 384x640 12 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2ef33b3-561067be.jpg: 384x640 3 persons, 5 cars, 2 traffic lights, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▊   | 6873/10000 [03:39<01:52, 27.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f06deb-e3f1630a.jpg: 384x640 10 cars, 1 truck, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f0c529-238574c7.jpg: 384x640 4 cars, 1 truck, 4 traffic lights, 18.7ms\n",
            "Speed: 1.8ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f0d1f5-0fe37fc4.jpg: 384x640 3 cars, 1 truck, 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6876/10000 [03:40<01:53, 27.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f149f0-1074361e.jpg: 384x640 2 bicycles, 5 cars, 1 traffic light, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f16364-2fbd9f8d.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 12.7ms\n",
            "Speed: 2.9ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f25682-16a2fc3f.jpg: 384x640 2 persons, 1 bicycle, 9 cars, 1 truck, 3 traffic lights, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6879/10000 [03:40<01:51, 28.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f25682-59bb9423.jpg: 384x640 2 cars, 1 truck, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f25682-d1334b0c.jpg: 384x640 3 persons, 7 cars, 1 bus, 1 truck, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f2f742-59d1b7ac.jpg: 384x640 5 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6882/10000 [03:40<01:49, 28.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f2f742-e24a5d3d.jpg: 384x640 1 person, 4 cars, 2 trucks, 19.0ms\n",
            "Speed: 3.5ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f3e924-031246d8.jpg: 384x640 11 cars, 1 bus, 1 truck, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f57401-4dbd1948.jpg: 384x640 4 cars, 19.8ms\n",
            "Speed: 1.9ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6885/10000 [03:40<01:58, 26.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f5e5c4-35640746.jpg: 384x640 4 cars, 1 truck, 1 fire hydrant, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f5e5c4-7e0e3665.jpg: 384x640 11 cars, 17.8ms\n",
            "Speed: 2.1ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f7d6e4-2e5ac55c.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6888/10000 [03:40<01:59, 25.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f88368-4292c1a0.jpg: 384x640 6 cars, 18.7ms\n",
            "Speed: 1.8ms preprocess, 18.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f8b141-5ef7d661.jpg: 384x640 6 cars, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2f92f94-43481d10.jpg: 384x640 3 cars, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6891/10000 [03:40<01:57, 26.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2fb790e-4cd5a630.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2fb790e-a8d3b8eb.jpg: 384x640 6 cars, 1 bus, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2fd4d4f-220a401d.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c2fd4d4f-3bb5c0cc.jpg: 384x640 7 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6895/10000 [03:40<01:46, 29.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3009124-01540ddb.jpg: 384x640 3 persons, 10 cars, 1 bus, 1 truck, 1 handbag, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3009124-6a11b9b0.jpg: 384x640 3 cars, 1 boat, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3009124-b8d0d1ea.jpg: 384x640 4 cars, 1 truck, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3009124-d4c47e39.jpg: 384x640 4 cars, 1 truck, 4 traffic lights, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6899/10000 [03:40<01:39, 31.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c300fd4b-8ff92c2d.jpg: 384x640 9 cars, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c301c86c-1acdbecb.jpg: 384x640 14 cars, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c30226a9-f882478c.jpg: 384x640 5 cars, 1 truck, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3026ac7-8105e9a9.jpg: 384x640 8 cars, 1 truck, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6903/10000 [03:40<01:36, 32.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3061560-56ac649f.jpg: 384x640 3 cars, 2 traffic lights, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3061560-cb940839.jpg: 384x640 3 cars, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3061560-df40e898.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3061560-e5d3971d.jpg: 384x640 3 cars, 1 bus, 1 traffic light, 1 bottle, 1 chair, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c306625b-dfc8a05f.jpg: 384x640 1 person, 1 car, 2 buss, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6908/10000 [03:41<01:28, 35.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c306771b-67b9007f.jpg: 384x640 1 person, 5 cars, 2 traffic lights, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c308561a-0b199e0a.jpg: 384x640 13 persons, 5 cars, 2 traffic lights, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c308561a-1b698bb4.jpg: 384x640 4 cars, 1 bus, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c308561a-448168db.jpg: 384x640 4 cars, 1 truck, 17.0ms\n",
            "Speed: 2.2ms preprocess, 17.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6912/10000 [03:41<01:36, 31.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c308561a-7b825f0b.jpg: 384x640 2 persons, 3 cars, 1 truck, 2 traffic lights, 17.9ms\n",
            "Speed: 2.0ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c308724a-56daf08b.jpg: 384x640 1 car, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c30be28e-bc8fd997.jpg: 384x640 2 cars, 1 traffic light, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c30db884-c85d8fee.jpg: 384x640 1 car, 15.1ms\n",
            "Speed: 2.0ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6916/10000 [03:41<01:39, 30.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c30f013a-9e9fe3ce.jpg: 384x640 4 persons, 7 cars, 18.6ms\n",
            "Speed: 2.0ms preprocess, 18.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c30f013a-a0802298.jpg: 384x640 3 cars, 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c30f959a-bd87aa16.jpg: 384x640 2 cars, 2 traffic lights, 14.1ms\n",
            "Speed: 6.6ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3127fc5-0411259f.jpg: 384x640 9 cars, 1 truck, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6920/10000 [03:41<01:47, 28.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3130621-11b84f78.jpg: 384x640 3 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3130621-97d57961.jpg: 384x640 9 cars, 1 bus, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3148906-5b3db383.jpg: 384x640 9 cars, 2 trucks, 8 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6923/10000 [03:41<01:46, 28.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3148906-a35c7571.jpg: 384x640 11 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c315b14e-429b1108.jpg: 384x640 4 cars, 10.3ms\n",
            "Speed: 5.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31625c9-4cf16add.jpg: 384x640 1 person, 5 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31625c9-9e5a7d0c.jpg: 384x640 8 persons, 5 cars, 2 buss, 1 truck, 1 traffic light, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6927/10000 [03:41<01:48, 28.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c317c38b-ce5550bb.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31a04de-1c417568.jpg: 384x640 3 cars, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31a04de-a3a5bc29.jpg: 384x640 1 person, 2 cars, 1 bus, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31a04de-b269b568.jpg: 384x640 1 person, 12 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6931/10000 [03:41<01:40, 30.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31a04de-d4cc31fb.jpg: 384x640 4 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa396-beb4f81b.jpg: 384x640 8 persons, 1 bus, 5 traffic lights, 1 handbag, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-1f6cbf7f.jpg: 384x640 2 cars, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-3e3a215c.jpg: 384x640 6 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6935/10000 [03:42<01:36, 31.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-7da84341.jpg: 384x640 1 car, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-9a2a8c52.jpg: 384x640 10 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-9cd15ede.jpg: 384x640 8 cars, 1 traffic light, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-cb2fb9ce.jpg: 384x640 2 cars, 1 traffic light, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6939/10000 [03:42<01:31, 33.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-cfd19d38.jpg: 384x640 1 person, 2 cars, 1 traffic light, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-d99ef9fc.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-dd64b3b7.jpg: 384x640 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31aa969-fb62cfc9.jpg: 384x640 1 car, 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31c9630-33e93909.jpg: 384x640 5 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6944/10000 [03:42<01:26, 35.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31c9630-34495985.jpg: 384x640 3 cars, 13.8ms\n",
            "Speed: 4.2ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31c9630-58e757e5.jpg: 384x640 2 persons, 5 cars, 17.1ms\n",
            "Speed: 2.0ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31c9630-bb223690.jpg: 384x640 4 cars, 19.1ms\n",
            "Speed: 1.9ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31cd426-0a38fe18.jpg: 384x640 12 cars, 1 truck, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  69%|██████▉   | 6948/10000 [03:42<01:44, 29.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31d9531-694298f0.jpg: 384x640 3 cars, 2 trucks, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31e94f0-25b5a72f.jpg: 384x640 7 cars, 1 traffic light, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c31edac1-218458ed.jpg: 384x640 12 cars, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c321a98d-e1a9c503.jpg: 384x640 1 car, 19.8ms\n",
            "Speed: 1.8ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6952/10000 [03:42<01:51, 27.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c321a98d-e3d79f4f.jpg: 384x640 5 cars, 2 traffic lights, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c321b69d-0043bcac.jpg: 384x640 6 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c321c219-54340460.jpg: 384x640 9 persons, 10 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c321c219-a3547f2a.jpg: 384x640 4 cars, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6956/10000 [03:42<01:42, 29.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32246a5-79a01821.jpg: 384x640 4 cars, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32278e7-af964526.jpg: 384x640 12 cars, 1 truck, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c323201c-9bcf7cf8.jpg: 384x640 11 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c323201c-b96be3cd.jpg: 384x640 11 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6960/10000 [03:42<01:36, 31.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c323201c-cf5e33b5.jpg: 384x640 9 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3248121-1ef2b38c.jpg: 384x640 8 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3248121-96de25d5.jpg: 384x640 7 cars, 1 bus, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c324a11d-b8793e25.jpg: 384x640 9 cars, 1 truck, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6964/10000 [03:42<01:33, 32.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c324a11d-eaaeb859.jpg: 384x640 12 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c324e953-ad402fa6.jpg: 384x640 6 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3259da7-7e61cbb1.jpg: 384x640 1 person, 10 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c327ace4-9dfe6490.jpg: 384x640 4 cars, 1 bus, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6968/10000 [03:43<01:32, 32.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c327ace4-f06a47fc.jpg: 384x640 8 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3283326-494b49b0.jpg: 384x640 5 cars, 1 traffic light, 1 tv, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3283326-74d7ae20.jpg: 384x640 5 cars, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3287e28-f6bcc9ef.jpg: 384x640 5 cars, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6972/10000 [03:43<01:28, 34.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c328b7ab-7a893ba0.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c328b7ab-8bb33358.jpg: 384x640 2 cars, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32a6d73-bda5c6ed.jpg: 384x640 3 cars, 1 truck, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32aa914-b99e4d62.jpg: 384x640 (no detections), 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6976/10000 [03:43<01:27, 34.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32be69b-f02d6229.jpg: 384x640 4 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32da93f-1463bf89.jpg: 384x640 14 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32dbcaf-480ffc17.jpg: 384x640 2 cars, 16.3ms\n",
            "Speed: 2.0ms preprocess, 16.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32dbcaf-4947ca34.jpg: 384x640 (no detections), 18.8ms\n",
            "Speed: 4.0ms preprocess, 18.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6980/10000 [03:43<01:37, 31.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32dbcaf-50f0a281.jpg: 384x640 2 cars, 1 truck, 14.5ms\n",
            "Speed: 5.9ms preprocess, 14.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c32ed490-87271dee.jpg: 384x640 1 bus, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-0f40c0b6.jpg: 384x640 7 cars, 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-1e2b9b50.jpg: 384x640 5 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6984/10000 [03:43<01:41, 29.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-1e974795.jpg: 384x640 1 truck, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-368eb638.jpg: 384x640 5 cars, 1 truck, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-3952d9a9.jpg: 384x640 2 persons, 3 cars, 1 bus, 1 traffic light, 1 dog, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-8aa08cbf.jpg: 384x640 (no detections), 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6988/10000 [03:43<01:35, 31.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-aa838610.jpg: 384x640 5 persons, 6 cars, 1 truck, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-ac4f1ff5.jpg: 384x640 7 cars, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c330c787-ae1c841a.jpg: 384x640 3 cars, 1 truck, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3318e73-7060e2ce.jpg: 384x640 6 cars, 1 truck, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6992/10000 [03:43<01:32, 32.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3321660-e6b60390.jpg: 384x640 1 car, 1 train, 1 truck, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33251a6-16b72b39.jpg: 384x640 4 cars, 1 bus, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33251a6-812a0ea8.jpg: 384x640 1 car, 2 buss, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33251a6-e75f8824.jpg: 384x640 3 cars, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33251a6-fa2a8810.jpg: 384x640 2 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|██████▉   | 6997/10000 [03:43<01:27, 34.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c332a2f5-ee258489.jpg: 384x640 1 person, 3 cars, 1 traffic light, 19.1ms\n",
            "Speed: 1.8ms preprocess, 19.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3346363-41b4ddf6.jpg: 384x640 10 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3348435-58a3fba0.jpg: 384x640 8 cars, 1 bus, 15.3ms\n",
            "Speed: 3.8ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3348435-d86c8ed9.jpg: 384x640 12 cars, 1 bus, 1 traffic light, 10.7ms\n",
            "Speed: 4.3ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7001/10000 [03:44<01:32, 32.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c334fad5-145809d5.jpg: 384x640 5 cars, 1 traffic light, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3364b6e-7b10cac7.jpg: 384x640 6 cars, 1 truck, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3364b6e-cb703061.jpg: 384x640 14 cars, 1 truck, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3367099-841c2fba.jpg: 384x640 1 person, 10 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7005/10000 [03:44<01:35, 31.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33700f7-08262a44.jpg: 384x640 13 cars, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33700f7-db0d8271.jpg: 384x640 1 person, 11 cars, 1 truck, 14.3ms\n",
            "Speed: 3.9ms preprocess, 14.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c338bae4-6f7b7153.jpg: 384x640 12 cars, 12.6ms\n",
            "Speed: 3.8ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c338bae4-b6f47a90.jpg: 384x640 18 cars, 1 truck, 18.8ms\n",
            "Speed: 4.1ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7009/10000 [03:44<01:47, 27.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c339e4bd-e3d99d50.jpg: 384x640 2 cars, 12.9ms\n",
            "Speed: 4.5ms preprocess, 12.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33a646b-70d40dc3.jpg: 384x640 5 cars, 17.4ms\n",
            "Speed: 3.5ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33b61b6-47d0f8ba.jpg: 384x640 5 cars, 3 trucks, 2 traffic lights, 14.5ms\n",
            "Speed: 3.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7012/10000 [03:44<01:51, 26.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33df08a-5c6bad4a.jpg: 384x640 9 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33ec7c6-ab13ff1b.jpg: 384x640 6 cars, 1 bus, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33fbbba-de07905f.jpg: 384x640 7 cars, 2 trucks, 16.7ms\n",
            "Speed: 3.0ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7015/10000 [03:44<01:53, 26.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33fd06b-7beab8d7.jpg: 384x640 2 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33ff185-6648dfa9.jpg: 384x640 10 cars, 2 trucks, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c33ff185-93a0dd91.jpg: 384x640 1 car, 1 bus, 1 truck, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7018/10000 [03:44<01:51, 26.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c34058b8-2790784b.jpg: 384x640 1 person, 4 cars, 2 trucks, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c342b42d-09b85192.jpg: 384x640 2 persons, 4 cars, 2 traffic lights, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3436372-070af78a.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3436372-eb18934d.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7022/10000 [03:44<01:42, 29.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c343e9dc-ce6e03ef.jpg: 384x640 6 cars, 13.4ms\n",
            "Speed: 4.4ms preprocess, 13.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c343e9dc-f2dcbc21.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c345715a-b532f7a9.jpg: 384x640 1 car, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c346c42b-748697b5.jpg: 384x640 2 cars, 4 traffic lights, 21.3ms\n",
            "Speed: 1.8ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7026/10000 [03:45<01:41, 29.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c34d1beb-7e2ce15b.jpg: 384x640 5 cars, 18.1ms\n",
            "Speed: 1.8ms preprocess, 18.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c34d7b7c-90f9af54.jpg: 384x640 7 cars, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c350632d-75a312d1.jpg: 384x640 10 cars, 1 truck, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7029/10000 [03:45<01:44, 28.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3529718-252e80fb.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c352d9c5-d0019b8b.jpg: 384x640 5 persons, 3 cars, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c353f0b4-c62600fa.jpg: 384x640 4 persons, 8 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35418da-e9e8e7dc.jpg: 384x640 5 cars, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7033/10000 [03:45<01:36, 30.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35531fb-c1bd532b.jpg: 384x640 1 person, 18 cars, 16.9ms\n",
            "Speed: 2.1ms preprocess, 16.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c356bbec-0c1293f7.jpg: 384x640 10 cars, 3 traffic lights, 18.9ms\n",
            "Speed: 4.1ms preprocess, 18.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c356bbec-10171932.jpg: 384x640 1 car, 1 truck, 1 banana, 14.8ms\n",
            "Speed: 7.4ms preprocess, 14.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c357f7fe-3f94d6aa.jpg: 384x640 1 car, 1 traffic light, 11.8ms\n",
            "Speed: 3.7ms preprocess, 11.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7037/10000 [03:45<01:50, 26.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c358bbb8-b458b22b.jpg: 384x640 2 cars, 13.8ms\n",
            "Speed: 4.6ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3593016-1adba20d.jpg: 384x640 6 cars, 2 buss, 3 traffic lights, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3593016-3f75ba4e.jpg: 384x640 1 person, 8 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7040/10000 [03:45<01:48, 27.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3593016-43a3f33f.jpg: 384x640 8 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3593016-ac7c536a.jpg: 384x640 10 cars, 2 trucks, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3593016-c20441ce.jpg: 384x640 8 cars, 2 trucks, 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7043/10000 [03:45<01:49, 27.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3593016-c4528d9d.jpg: 384x640 2 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c359556b-77ced0e9.jpg: 384x640 4 cars, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c359e7b1-5b68aea4.jpg: 384x640 5 cars, 1 bus, 1 truck, 10.5ms\n",
            "Speed: 6.7ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c359f52e-d1916e72.jpg: 384x640 4 cars, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  70%|███████   | 7047/10000 [03:45<01:43, 28.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35a0c1c-33884693.jpg: 384x640 6 cars, 2 trucks, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35c16ba-83fcb452.jpg: 384x640 6 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35c16ba-b65a3906.jpg: 384x640 2 cars, 1 traffic light, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35e0eea-7596f0bd.jpg: 384x640 1 person, 1 car, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7051/10000 [03:45<01:35, 30.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35e0eea-8161d596.jpg: 384x640 5 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35f5984-a2763387.jpg: 384x640 3 cars, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35f86eb-86dc57eb.jpg: 384x640 2 persons, 8 cars, 14.3ms\n",
            "Speed: 1.7ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c35f86eb-e0657fa3.jpg: 384x640 7 cars, 11.5ms\n",
            "Speed: 6.8ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7055/10000 [03:46<01:34, 31.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c360ca4b-7a8ec6e6.jpg: 384x640 4 cars, 1 truck, 1 fire hydrant, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c361f0b8-d5940918.jpg: 384x640 4 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c361ff02-d7492340.jpg: 384x640 2 cars, 1 truck, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3639d96-271bbe4c.jpg: 384x640 3 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7059/10000 [03:46<01:32, 31.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3639d96-b9928b16.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 3.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3639d96-d284eda4.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3668a3d-22233f64.jpg: 384x640 1 person, 6 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c366973d-c03525b0.jpg: 384x640 1 person, 1 car, 5 traffic lights, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7063/10000 [03:46<01:26, 33.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c366973d-f5ec8394.jpg: 384x640 1 car, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c367562a-54687761.jpg: 384x640 12 cars, 1 truck, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3686339-5832705e.jpg: 384x640 5 cars, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3698cec-2231cb86.jpg: 384x640 9 cars, 1 truck, 3 traffic lights, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7067/10000 [03:46<01:36, 30.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3698cec-77311999.jpg: 384x640 6 cars, 1 traffic light, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c36a8dac-908de757.jpg: 384x640 1 person, 5 cars, 1 truck, 15.2ms\n",
            "Speed: 4.8ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c36c60e8-ad8ad874.jpg: 384x640 3 persons, 1 car, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c36d561d-157eefbb.jpg: 384x640 11 cars, 18.7ms\n",
            "Speed: 1.8ms preprocess, 18.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7071/10000 [03:46<01:42, 28.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c36ded7c-4736f84e.jpg: 384x640 8 cars, 17.0ms\n",
            "Speed: 2.8ms preprocess, 17.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c36ded7c-a435e454.jpg: 384x640 1 car, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3714b40-1610471f.jpg: 384x640 10 cars, 3 trucks, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3719317-3ea7c35e.jpg: 384x640 4 persons, 2 cars, 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7075/10000 [03:46<01:41, 28.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3719317-4da29e4a.jpg: 384x640 1 car, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3719317-5605c5af.jpg: 384x640 2 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c372b0f2-81abd5d1.jpg: 384x640 6 cars, 2 buss, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37360b7-35a6b33c.jpg: 384x640 1 car, 1 surfboard, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7079/10000 [03:46<01:36, 30.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37360b7-70c0e672.jpg: 384x640 4 cars, 1 truck, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37360b7-718f9bba.jpg: 384x640 3 persons, 7 cars, 1 traffic light, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37360b7-7dab5705.jpg: 384x640 1 car, 1 traffic light, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37382d8-010bbe82.jpg: 384x640 5 cars, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7083/10000 [03:46<01:32, 31.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37388ef-99765627.jpg: 384x640 7 persons, 4 cars, 1 bus, 1 traffic light, 11.2ms\n",
            "Speed: 3.8ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37388ef-cb776f63.jpg: 384x640 1 truck, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c373cc4e-59108d25.jpg: 384x640 6 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c376fce7-54f5721d.jpg: 384x640 8 cars, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7087/10000 [03:47<01:32, 31.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3783c84-e38a9213.jpg: 384x640 9 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3784403-0c68fd6c.jpg: 384x640 4 cars, 1 bus, 4 traffic lights, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3784403-212cfb2e.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3784403-4532f110.jpg: 384x640 6 cars, 3 trucks, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7091/10000 [03:47<01:33, 31.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3787c5e-8a246457.jpg: 384x640 21 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37884fa-ef0b1d8e.jpg: 384x640 10 persons, 6 cars, 1 truck, 1 traffic light, 17.5ms\n",
            "Speed: 4.0ms preprocess, 17.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c379bc53-4e2c5dee.jpg: 384x640 1 person, 1 car, 3 buss, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c379f9c4-079ee461.jpg: 384x640 11 cars, 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7095/10000 [03:47<01:39, 29.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c379f9c4-9e689b20.jpg: 384x640 4 cars, 1 truck, 17.8ms\n",
            "Speed: 1.9ms preprocess, 17.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c379f9c4-f41ab256.jpg: 384x640 7 cars, 13.5ms\n",
            "Speed: 6.3ms preprocess, 13.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37ae4d0-27e020b9.jpg: 384x640 13 cars, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7098/10000 [03:47<01:45, 27.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b517d-477f8143.jpg: 384x640 1 person, 5 cars, 3 trains, 20.7ms\n",
            "Speed: 2.5ms preprocess, 20.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b8378-9c23f3b3.jpg: 384x640 11 cars, 2 trucks, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b9726-29dfad76.jpg: 384x640 2 persons, 3 cars, 1 bus, 3 trucks, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7101/10000 [03:47<01:51, 26.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b9726-5056fc28.jpg: 384x640 7 cars, 1 bus, 2 traffic lights, 13.3ms\n",
            "Speed: 1.7ms preprocess, 13.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b9726-6e562435.jpg: 384x640 1 person, 7 cars, 13.1ms\n",
            "Speed: 8.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b9726-a567227e.jpg: 384x640 11 persons, 5 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7104/10000 [03:47<01:52, 25.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b9726-c2532aba.jpg: 384x640 9 persons, 4 cars, 4 traffic lights, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b9726-caffaa65.jpg: 384x640 3 persons, 6 cars, 3 buss, 1 truck, 1 traffic light, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37b9f20-e161a563.jpg: 384x640 7 cars, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7107/10000 [03:47<01:51, 26.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37bffe3-a98ee42d.jpg: 384x640 8 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37c2977-45e57cc0.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37c2977-dfcf5b8a.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37c2977-f11fb4a5.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7111/10000 [03:47<01:38, 29.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37cf84f-18aa50f6.jpg: 384x640 1 car, 2 trains, 3 trucks, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37d47c0-05bf99e0.jpg: 384x640 6 cars, 1 truck, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37d47c0-c830ec1c.jpg: 384x640 2 cars, 19.3ms\n",
            "Speed: 1.8ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7114/10000 [03:48<01:38, 29.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37fdf68-03ba744c.jpg: 384x640 4 cars, 14.6ms\n",
            "Speed: 5.5ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c37fdf68-18b4792a.jpg: 384x640 1 car, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3804a06-26cf84ff.jpg: 384x640 3 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c380e9e2-30ee7832.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7118/10000 [03:48<01:33, 30.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c380e9e2-6d8a84be.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3812229-47c8e5f2.jpg: 384x640 5 cars, 4 traffic lights, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3812229-954a41bd.jpg: 384x640 7 cars, 1 train, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3822b6a-0ef41057.jpg: 384x640 1 car, 16.6ms\n",
            "Speed: 3.1ms preprocess, 16.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████   | 7122/10000 [03:48<01:30, 31.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c384667d-73536fcb.jpg: 384x640 3 persons, 5 cars, 1 bus, 1 traffic light, 14.4ms\n",
            "Speed: 2.6ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c385a199-0bb19524.jpg: 384x640 2 cars, 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3870915-a0d8f653.jpg: 384x640 3 cars, 13.7ms\n",
            "Speed: 2.9ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3884826-226b69e7.jpg: 384x640 11 cars, 1 traffic light, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████▏  | 7126/10000 [03:48<01:35, 30.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3884826-d8789adb.jpg: 384x640 8 cars, 2 buss, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3884826-f2da6bd2.jpg: 384x640 3 cars, 1 bus, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c389631f-34a8e513.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c389631f-a4b2d909.jpg: 384x640 (no detections), 17.0ms\n",
            "Speed: 4.8ms preprocess, 17.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████▏  | 7130/10000 [03:48<01:35, 30.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c389631f-b7bb20cb.jpg: 384x640 2 cars, 14.1ms\n",
            "Speed: 3.9ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38a5b1a-67951cd4.jpg: 384x640 1 car, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38bdba6-181f8cfa.jpg: 384x640 1 person, 5 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38bdba6-2abed256.jpg: 384x640 7 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████▏  | 7134/10000 [03:48<01:30, 31.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38bdba6-9a4af57f.jpg: 384x640 1 traffic light, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38bdba6-bc70b28c.jpg: 384x640 8 cars, 1 bus, 1 truck, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38bdba6-cb18e83a.jpg: 384x640 1 person, 9 cars, 1 traffic light, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38cd3f6-2aba9218.jpg: 384x640 7 cars, 1 truck, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████▏  | 7138/10000 [03:48<01:29, 32.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38cd3f6-bd22367b.jpg: 384x640 1 person, 10 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38cd3f6-c74ca48b.jpg: 384x640 3 persons, 5 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c38e77f6-edc3c34b.jpg: 384x640 3 cars, 1 motorcycle, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3906a23-5c373f34.jpg: 384x640 3 cars, 1 stop sign, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████▏  | 7142/10000 [03:48<01:28, 32.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c390eca8-8beac58f.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3926b26-2b8702c9.jpg: 384x640 6 cars, 8.5ms\n",
            "Speed: 4.4ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39375fb-153bf02b.jpg: 384x640 9 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39375fb-4de2d085.jpg: 384x640 9 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  71%|███████▏  | 7146/10000 [03:49<01:26, 33.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39375fb-ecf20028.jpg: 384x640 2 cars, 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39375fb-fd57ccd3.jpg: 384x640 3 cars, 2 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3949a9e-7ee214aa.jpg: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3968de8-18e45feb.jpg: 384x640 2 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7150/10000 [03:49<01:22, 34.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3968de8-21d6c364.jpg: 384x640 1 car, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3968de8-ba91cf82.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3968de8-bd6747f5.jpg: 384x640 2 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3968de8-fe9ac544.jpg: 384x640 3 cars, 1 traffic light, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7154/10000 [03:49<01:22, 34.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c396b7c0-cf46a981.jpg: 384x640 4 cars, 16.2ms\n",
            "Speed: 3.4ms preprocess, 16.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c396e833-890b7ddb.jpg: 384x640 19 cars, 19.6ms\n",
            "Speed: 3.1ms preprocess, 19.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c396e833-a3876e00.jpg: 384x640 7 cars, 1 traffic light, 15.5ms\n",
            "Speed: 2.4ms preprocess, 15.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c396e833-ba935f99.jpg: 384x640 7 cars, 1 truck, 6 traffic lights, 11.3ms\n",
            "Speed: 5.1ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7158/10000 [03:49<01:39, 28.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c397cd5e-ad9369e9.jpg: 384x640 13 cars, 11.9ms\n",
            "Speed: 3.4ms preprocess, 11.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39807d2-936e95ae.jpg: 384x640 6 cars, 1 truck, 1 traffic light, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39807d2-dd8710a0.jpg: 384x640 8 cars, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3981cf1-6e95c296.jpg: 384x640 6 cars, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7162/10000 [03:49<01:43, 27.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3981cf1-a949f363.jpg: 384x640 4 cars, 14.9ms\n",
            "Speed: 4.1ms preprocess, 14.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3981cf1-fb7c634e.jpg: 384x640 (no detections), 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3993f07-cc084164.jpg: 384x640 2 persons, 3 cars, 2 traffic lights, 15.7ms\n",
            "Speed: 2.9ms preprocess, 15.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7165/10000 [03:49<01:45, 26.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3997bc7-ae6fd2e3.jpg: 384x640 4 cars, 1 bus, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3999837-32005ed6.jpg: 384x640 3 persons, 7 cars, 1 bus, 3 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c399b1cb-0b569b85.jpg: 384x640 5 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39a0a67-dcf8ab72.jpg: 384x640 7 cars, 10.8ms\n",
            "Speed: 1.7ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7169/10000 [03:49<01:39, 28.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39a2422-2c66916b.jpg: 384x640 1 person, 2 cars, 1 traffic light, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39ad1d8-0993aef9.jpg: 384x640 3 cars, 17.4ms\n",
            "Speed: 1.8ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39b357e-5a90a6b6.jpg: 384x640 7 cars, 1 traffic light, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7172/10000 [03:49<01:38, 28.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39d3334-9c866b4c.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39dc2ff-4399acc0.jpg: 384x640 3 persons, 1 car, 1 train, 1 traffic light, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39dc2ff-6976d19d.jpg: 384x640 3 persons, 6 cars, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39ddb2c-740d920d.jpg: 384x640 9 cars, 1 traffic light, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7176/10000 [03:50<01:34, 29.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39ddb2c-db949106.jpg: 384x640 15 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c39f04ad-07b3e09f.jpg: 384x640 5 cars, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a015d4-2779708e.jpg: 384x640 14 cars, 1 motorcycle, 1 truck, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a048fb-9adc169f.jpg: 384x640 9 cars, 2 trucks, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7180/10000 [03:50<01:37, 28.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a048fb-c45a1e4c.jpg: 384x640 4 persons, 2 cars, 1 bus, 1 truck, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a048fb-ed02cd5a.jpg: 384x640 1 car, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a0a1c9-90f0081e.jpg: 384x640 12 cars, 2 trucks, 14.1ms\n",
            "Speed: 5.4ms preprocess, 14.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7183/10000 [03:50<01:38, 28.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a18207-109c0500.jpg: 384x640 1 car, 2 trucks, 16.1ms\n",
            "Speed: 1.8ms preprocess, 16.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a18207-504667c7.jpg: 384x640 2 cars, 1 bus, 16.5ms\n",
            "Speed: 1.9ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a1baa1-763e77d7.jpg: 384x640 5 cars, 2 traffic lights, 14.5ms\n",
            "Speed: 2.5ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7186/10000 [03:50<01:41, 27.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a20d02-09c1ff17.jpg: 384x640 1 car, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a26429-19fefafb.jpg: 384x640 14 cars, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a26429-70b45205.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a26429-e8f01a18.jpg: 384x640 9 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7190/10000 [03:50<01:34, 29.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a3265f-d6562e9f.jpg: 384x640 1 person, 2 cars, 1 traffic light, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a5542d-132f75f3.jpg: 384x640 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a94f80-27e0d36a.jpg: 384x640 3 cars, 3 trucks, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3a94f80-a80f1f94.jpg: 384x640 12 cars, 1 truck, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7194/10000 [03:50<01:28, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ac34e8-2701e034.jpg: 384x640 1 car, 2 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ac34e8-a07ac73e.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3aca55d-61d72a19.jpg: 384x640 6 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3acc6a5-00d3dc8d.jpg: 384x640 3 cars, 1 traffic light, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7198/10000 [03:50<01:23, 33.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3acda34-73acb8f3.jpg: 384x640 5 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ad67db-0e969ba8.jpg: 384x640 1 car, 2 trucks, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ae39d6-f5f25d64.jpg: 384x640 1 person, 1 bicycle, 3 cars, 3 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ae9216-3d694ff1.jpg: 384x640 4 cars, 1 truck, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7202/10000 [03:50<01:21, 34.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ae9216-b9dab4a9.jpg: 384x640 10 cars, 9.5ms\n",
            "Speed: 5.4ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b1694b-79c97ac2.jpg: 384x640 5 cars, 1 truck, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b1694b-fadd8eba.jpg: 384x640 6 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b31662-4e576035.jpg: 384x640 1 car, 1 bus, 1 traffic light, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7206/10000 [03:50<01:21, 34.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b31662-7aa8bae6.jpg: 384x640 5 cars, 1 truck, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b31662-8eae58f3.jpg: 384x640 18 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b60e81-b28ef868.jpg: 384x640 4 cars, 1 bus, 2 traffic lights, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b8f4e4-10cf3a2b.jpg: 384x640 2 cars, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7210/10000 [03:51<01:21, 34.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b940ca-5e220748.jpg: 384x640 1 person, 4 cars, 1 stop sign, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3b9feeb-8362c56c.jpg: 384x640 4 cars, 1 truck, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ba4a87-4d02b5ab.jpg: 384x640 1 car, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3bb4925-a3b4c1ed.jpg: 384x640 8 cars, 1 bus, 1 truck, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7214/10000 [03:51<01:18, 35.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3bb4925-f78e285a.jpg: 384x640 11 cars, 1 truck, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3bf9233-8462deb1.jpg: 384x640 6 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3bf9cd8-4c3187c7.jpg: 384x640 2 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3bf9cd8-5a2df929.jpg: 384x640 4 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7218/10000 [03:51<01:20, 34.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3bf9cd8-81cb03ad.jpg: 384x640 (no detections), 13.9ms\n",
            "Speed: 4.1ms preprocess, 13.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3bfdcda-bfdd5fdb.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3bfdcda-e1e6bd15.jpg: 384x640 5 cars, 1 truck, 2 traffic lights, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c021ef-9f0c8741.jpg: 384x640 7 cars, 1 traffic light, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7222/10000 [03:51<01:23, 33.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-1e1b1003.jpg: 384x640 7 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-3d4e0313.jpg: 384x640 7 cars, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-5cee9e20.jpg: 384x640 7 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-7f004614.jpg: 384x640 6 cars, 1 traffic light, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7226/10000 [03:51<01:21, 33.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-8210803f.jpg: 384x640 2 persons, 3 cars, 1 truck, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-936bc208.jpg: 384x640 7 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-ac19bef3.jpg: 384x640 1 person, 6 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-cccf82b7.jpg: 384x640 6 cars, 1 truck, 1 parking meter, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7230/10000 [03:51<01:21, 34.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-e11941f3.jpg: 384x640 8 cars, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c0f47b-f5a22431.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c10c0c-45eec8a3.jpg: 384x640 4 persons, 5 cars, 4 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c10c0c-4adfd99c.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7234/10000 [03:51<01:20, 34.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c2748d-b3291d20.jpg: 384x640 2 persons, 3 cars, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c28990-04db5664.jpg: 384x640 9 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c2eb65-3af33302.jpg: 384x640 5 persons, 3 cars, 1 bus, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c2eb65-bd875ecb.jpg: 384x640 6 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7238/10000 [03:51<01:18, 34.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c43f15-1afc9745.jpg: 384x640 1 person, 5 cars, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c43f15-b0ed775c.jpg: 384x640 7 cars, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c4afe7-b9a0a895.jpg: 384x640 1 car, 1 fire hydrant, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c4bbae-eff92ddd.jpg: 384x640 5 cars, 1 truck, 5 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7242/10000 [03:52<01:22, 33.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c5785b-a71e4bf7.jpg: 384x640 1 car, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3c78ded-3747f1c4.jpg: 384x640 1 car, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cae07c-b1c025cf.jpg: 384x640 1 person, 8 cars, 1 bus, 1 truck, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cae07c-ceeefd3f.jpg: 384x640 3 persons, 5 cars, 1 truck, 1 traffic light, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▏  | 7246/10000 [03:52<01:23, 32.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cb6d3b-bd44323e.jpg: 384x640 2 persons, 6 cars, 1 motorcycle, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cc01c7-306b42b3.jpg: 384x640 1 person, 5 cars, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cc12e9-d96fb013.jpg: 384x640 4 cars, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cd662f-228cba06.jpg: 384x640 4 cars, 1 truck, 2 traffic lights, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  72%|███████▎  | 7250/10000 [03:52<01:25, 32.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cd662f-4d6d3e82.jpg: 384x640 4 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cd6c82-21bd6ca4.jpg: 384x640 5 cars, 1 truck, 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cd6c82-b5d52beb.jpg: 384x640 9 cars, 15.7ms\n",
            "Speed: 4.3ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ce46d8-9ca61ff7.jpg: 384x640 1 car, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7254/10000 [03:52<01:27, 31.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3cf722d-07e2250c.jpg: 384x640 8 cars, 11.8ms\n",
            "Speed: 2.9ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3d0cee9-9d113ffd.jpg: 384x640 5 cars, 14.0ms\n",
            "Speed: 5.0ms preprocess, 14.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3d1640a-b89d2de8.jpg: 384x640 1 person, 8 cars, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3d39d44-4ee18d50.jpg: 384x640 6 cars, 3 trucks, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7258/10000 [03:52<01:35, 28.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3d70e8e-64b02c51.jpg: 384x640 14 cars, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3d714d5-9b0e71c1.jpg: 384x640 6 cars, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3d81c03-185c3684.jpg: 384x640 4 cars, 1 bus, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3da13a9-31363949.jpg: 384x640 10 cars, 1 bus, 1 traffic light, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7262/10000 [03:52<01:33, 29.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3da90b0-cfd1d6b9.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3db3042-11a5ab24.jpg: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3dc6d37-450bc114.jpg: 384x640 1 car, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3dc6d37-60d68540.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7266/10000 [03:52<01:26, 31.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3dd2df5-262ecc08.jpg: 384x640 9 cars, 16.0ms\n",
            "Speed: 1.7ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3dd2df5-e805df01.jpg: 384x640 1 person, 8 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3dde797-7bb8b56c.jpg: 384x640 13 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3dde797-aea46f02.jpg: 384x640 4 persons, 3 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7270/10000 [03:52<01:28, 30.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3dde797-d3a9bf00.jpg: 384x640 6 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3dde797-f180bf54.jpg: 384x640 5 cars, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3de5a74-899efae7.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3decde7-31339506.jpg: 384x640 6 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7274/10000 [03:53<01:22, 32.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3def78d-b3fa5b93.jpg: 384x640 1 car, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3df2c24-3449c92b.jpg: 384x640 2 persons, 10 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3df354d-407d442c.jpg: 384x640 4 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3df354d-bec42887.jpg: 384x640 6 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7278/10000 [03:53<01:20, 33.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e067a4-535a9b93.jpg: 384x640 2 persons, 3 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e363a2-505e84d5.jpg: 384x640 16 cars, 1 truck, 1 traffic light, 17.4ms\n",
            "Speed: 3.3ms preprocess, 17.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e4deae-a76258ee.jpg: 384x640 2 persons, 3 cars, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e7bd65-aff9c706.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7282/10000 [03:53<01:26, 31.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e7f8b2-92a1ce9e.jpg: 384x640 9 cars, 16.8ms\n",
            "Speed: 2.7ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e87419-5b9ddce0.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 14.0ms\n",
            "Speed: 7.9ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e87419-dd6f2321.jpg: 384x640 5 cars, 17.6ms\n",
            "Speed: 1.9ms preprocess, 17.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e986e8-1d7a6ddc.jpg: 384x640 6 cars, 16.4ms\n",
            "Speed: 1.8ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7286/10000 [03:53<01:30, 30.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e986e8-47958da8.jpg: 384x640 4 cars, 14.7ms\n",
            "Speed: 3.1ms preprocess, 14.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3e986e8-99f2d744.jpg: 384x640 6 cars, 1 traffic light, 17.2ms\n",
            "Speed: 2.7ms preprocess, 17.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3eae174-c44b69cb.jpg: 384x640 1 tv, 1 cell phone, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ecb3cb-5fb43d29.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7290/10000 [03:53<01:30, 29.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3edf653-bb92b354.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ee4b9b-1929ab81.jpg: 384x640 3 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ee4b9b-b8786bce.jpg: 384x640 3 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ee5975-02ea08d9.jpg: 384x640 3 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ee5975-0eb73316.jpg: 384x640 1 car, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7295/10000 [03:53<01:21, 33.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3ee5975-59bec570.jpg: 384x640 4 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f1aefa-b66cbd5d.jpg: 384x640 12 cars, 1 bus, 1 traffic light, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f3b7a2-6d6f679a.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f3dd92-23328dbb.jpg: 384x640 3 cars, 8.5ms\n",
            "Speed: 2.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7299/10000 [03:53<01:21, 33.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f50821-74cff39b.jpg: 384x640 7 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f50821-9998804f.jpg: 384x640 11 cars, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f50821-a7ea98ab.jpg: 384x640 2 persons, 5 cars, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f50821-f74d05ed.jpg: 384x640 1 person, 1 car, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7303/10000 [03:53<01:20, 33.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f50821-ff9823a2.jpg: 384x640 6 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f5620f-9311677e.jpg: 384x640 6 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3f8a4ce-2090da6b.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3fcfa68-43c4f28f.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7307/10000 [03:54<01:22, 32.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3fd58b6-04bcbef3.jpg: 384x640 6 cars, 1 traffic light, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3fd9aad-7e464a06.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3fdd07a-6a106ecd.jpg: 384x640 7 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c3fdd07a-70b28379.jpg: 384x640 1 person, 9 cars, 1 truck, 1 fire hydrant, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7311/10000 [03:54<01:22, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c400a0e1-c137168b.jpg: 384x640 7 cars, 18.8ms\n",
            "Speed: 1.8ms preprocess, 18.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4016527-4a26d292.jpg: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4031040-488a6ce0.jpg: 384x640 10 cars, 1 traffic light, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4031040-73e296bc.jpg: 384x640 4 traffic lights, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7315/10000 [03:54<01:26, 30.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4031040-ec530889.jpg: 384x640 10 cars, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c403ebf2-97af9f88.jpg: 384x640 13 cars, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c404818a-ac56c4e1.jpg: 384x640 4 cars, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4057c0c-000a6aaf.jpg: 384x640 9 cars, 1 stop sign, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7319/10000 [03:54<01:28, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4057c0c-a47d8dba.jpg: 384x640 8 cars, 1 traffic light, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c405a5e6-c5687e69.jpg: 384x640 4 cars, 2 trucks, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4097a21-ed514c08.jpg: 384x640 1 car, 1 truck, 1 stop sign, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c40a2c98-3709f786.jpg: 384x640 9 cars, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7323/10000 [03:54<01:26, 30.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c40de985-fb2512f0.jpg: 384x640 4 cars, 1 truck, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c410bbba-9460f6c1.jpg: 384x640 6 cars, 2 trucks, 1 stop sign, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c411687d-24c5fb83.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 1 parking meter, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c411687d-73471431.jpg: 384x640 13 cars, 1 truck, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7327/10000 [03:54<01:23, 32.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c411687d-830f8ddf.jpg: 384x640 1 person, 2 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41203a6-e4b059c0.jpg: 384x640 1 person, 7 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41203a6-f2bee3f0.jpg: 384x640 6 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4130097-887da34f.jpg: 384x640 3 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7331/10000 [03:54<01:19, 33.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41358e5-e74b4a5b.jpg: 384x640 8 cars, 2 trucks, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c413a89b-fb60c163.jpg: 384x640 2 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c414ea72-128822b2.jpg: 384x640 7 cars, 3 buss, 3 trucks, 1 traffic light, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4155f73-01f813b2.jpg: 384x640 10 cars, 1 truck, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7335/10000 [03:54<01:19, 33.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41585dc-6fe06ca1.jpg: 384x640 3 cars, 1 bus, 1 truck, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c415a08c-50060410.jpg: 384x640 4 persons, 1 car, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c415a08c-a6cb455e.jpg: 384x640 9 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c415a08c-d4f4488e.jpg: 384x640 9 cars, 3 traffic lights, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7339/10000 [03:55<01:18, 34.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4160d08-c506293d.jpg: 384x640 7 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4160d08-d9c52d7b.jpg: 384x640 10 cars, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4171655-424bc10e.jpg: 384x640 2 cars, 1 truck, 4 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c417a291-6a4ed4c9.jpg: 384x640 16 cars, 1 bird, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7343/10000 [03:55<01:20, 33.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c417a291-7802692d.jpg: 384x640 1 person, 12 cars, 2 trucks, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c417a291-7ea03054.jpg: 384x640 12 cars, 1 bus, 2 trucks, 15.5ms\n",
            "Speed: 2.0ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c417a291-b8079637.jpg: 384x640 15 cars, 15.3ms\n",
            "Speed: 3.5ms preprocess, 15.3ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41826e3-9e581f79.jpg: 384x640 2 persons, 10 cars, 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  73%|███████▎  | 7347/10000 [03:55<01:34, 28.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4192610-f46ed7cc.jpg: 384x640 1 car, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41ae6bb-8973ad18.jpg: 384x640 2 persons, 12 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41b6f56-ac54b332.jpg: 384x640 2 cars, 1 traffic light, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41b6f56-cf6480a5.jpg: 384x640 9 cars, 11.1ms\n",
            "Speed: 4.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▎  | 7351/10000 [03:55<01:32, 28.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41c4557-ca6aea38.jpg: 384x640 5 cars, 1 truck, 1 fire hydrant, 16.3ms\n",
            "Speed: 5.1ms preprocess, 16.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41c4557-f9e2022e.jpg: 384x640 7 cars, 17.2ms\n",
            "Speed: 2.6ms preprocess, 17.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c41d22bb-080065ca.jpg: 384x640 7 cars, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▎  | 7354/10000 [03:55<01:35, 27.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c420873f-28164388.jpg: 384x640 2 cars, 1 truck, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c420873f-c5ec4d87.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c420e95a-f7f8eacd.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4223cc0-7053ae09.jpg: 384x640 10 cars, 1 traffic light, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▎  | 7358/10000 [03:55<01:27, 30.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4223cc0-82c4be3e.jpg: 384x640 2 persons, 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c422771c-1619481d.jpg: 384x640 2 cars, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c422771c-ecd74810.jpg: 384x640 1 person, 6 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c425e76b-198b3cc5.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▎  | 7362/10000 [03:55<01:23, 31.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c425e76b-ef2256e0.jpg: 384x640 13 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c426d85e-62e3c585.jpg: 384x640 1 traffic light, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c426ec74-d878b23e.jpg: 384x640 4 persons, 6 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c427410f-07d5dfe7.jpg: 384x640 1 bicycle, 2 cars, 1 traffic light, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▎  | 7366/10000 [03:56<01:21, 32.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c427410f-3ddc8e2f.jpg: 384x640 2 persons, 5 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c427410f-aec7f6a9.jpg: 384x640 1 person, 12 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c428ad7c-f3bbc3a0.jpg: 384x640 3 persons, 3 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c428e890-674ecc9d.jpg: 384x640 1 car, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▎  | 7370/10000 [03:56<01:20, 32.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c429f0de-01d10230.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c42adf2b-718ec79e.jpg: 384x640 9 cars, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c42cd95d-d4b78e2d.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c42dd876-5f8d76fd.jpg: 384x640 11 cars, 1 truck, 10.4ms\n",
            "Speed: 4.3ms preprocess, 10.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▎  | 7374/10000 [03:56<01:23, 31.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c42e0040-72f94280.jpg: 384x640 2 cars, 13.6ms\n",
            "Speed: 6.4ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43052f6-662bb3a2.jpg: 384x640 3 cars, 16.9ms\n",
            "Speed: 2.0ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43052f6-d337ba62.jpg: 384x640 1 train, 16.5ms\n",
            "Speed: 3.5ms preprocess, 16.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43052f6-d90711e9.jpg: 384x640 14 cars, 1 truck, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7378/10000 [03:56<01:29, 29.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43077c9-470f06f9.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43254a8-9aa667dc.jpg: 384x640 9 cars, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4327604-039da856.jpg: 384x640 (no detections), 11.9ms\n",
            "Speed: 6.5ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7381/10000 [03:56<01:30, 28.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4327604-12a96366.jpg: 384x640 5 cars, 1 traffic light, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4327604-30fa8196.jpg: 384x640 8 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c433e2aa-5ddac4bd.jpg: 384x640 6 cars, 1 traffic light, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c433e2aa-77bf9219.jpg: 384x640 5 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7385/10000 [03:56<01:27, 30.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c433e2aa-a0c604de.jpg: 384x640 10 cars, 1 bus, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c434f595-753bae5b.jpg: 384x640 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4353b9c-08eedac2.jpg: 384x640 2 persons, 4 cars, 7 traffic lights, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4353b9c-9d50cbe9.jpg: 384x640 10 persons, 4 cars, 1 traffic light, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7389/10000 [03:56<01:24, 30.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4353b9c-b50ff0d9.jpg: 384x640 9 cars, 1 truck, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4353b9c-f8f56adc.jpg: 384x640 2 cars, 1 train, 2 trucks, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43778b1-56af0542.jpg: 384x640 1 person, 8 cars, 1 motorcycle, 2 traffic lights, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4396376-b6de614b.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7393/10000 [03:56<01:21, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c439e607-c03383c7.jpg: 384x640 5 cars, 1 truck, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43a3013-05a252d3.jpg: 384x640 1 car, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43a3013-c727b023.jpg: 384x640 6 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43c290b-61f94939.jpg: 384x640 6 cars, 1 truck, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7397/10000 [03:57<01:18, 33.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43daa45-612283ce.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43df889-173cde62.jpg: 384x640 2 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43df889-350225a5.jpg: 384x640 4 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43df889-410e2643.jpg: 384x640 8 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7401/10000 [03:57<01:16, 34.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43eaa20-61c1ec04.jpg: 384x640 2 cars, 1 truck, 3 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43eaa20-8450cd59.jpg: 384x640 1 car, 1 bus, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43eaa20-a3a0a7e8.jpg: 384x640 1 person, 2 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43eaa20-ee66c295.jpg: 384x640 1 car, 15.0ms\n",
            "Speed: 2.9ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7405/10000 [03:57<01:15, 34.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43fb080-64852108.jpg: 384x640 2 cars, 1 truck, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43fe5b8-165b2904.jpg: 384x640 4 cars, 1 bus, 2 trucks, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43fe5b8-3d3608ce.jpg: 384x640 12 cars, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c43fe5b8-45b12c52.jpg: 384x640 2 cars, 1 truck, 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7409/10000 [03:57<01:21, 31.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4402b90-b65a2393.jpg: 384x640 1 car, 1 traffic light, 1 stop sign, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4406d9a-1864ada7.jpg: 384x640 1 car, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4430cb6-f86d46e6.jpg: 384x640 1 person, 12 cars, 1 truck, 2 traffic lights, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4436054-23e266f5.jpg: 384x640 6 cars, 1 bus, 2 trucks, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7413/10000 [03:57<01:22, 31.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4436054-434051b8.jpg: 384x640 10 cars, 1 motorcycle, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4436054-c0d83d61.jpg: 384x640 20 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4436054-d3c3dccf.jpg: 384x640 18 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c447f74e-64671040.jpg: 384x640 1 person, 14 cars, 1 traffic light, 14.4ms\n",
            "Speed: 3.6ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7417/10000 [03:57<01:29, 28.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c447f74e-98ec82f5.jpg: 384x640 9 cars, 1 bus, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c447f74e-c458f6c5.jpg: 384x640 6 cars, 1 truck, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c447f74e-f67bf173.jpg: 384x640 6 traffic lights, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7420/10000 [03:57<01:30, 28.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4480d4b-e0efbbca.jpg: 384x640 2 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4494f87-59e5c703.jpg: 384x640 4 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44980af-2f8d90c4.jpg: 384x640 2 cars, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44a2ecf-b5b2f533.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 16.3ms\n",
            "Speed: 4.5ms preprocess, 16.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7424/10000 [03:57<01:30, 28.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44a5b51-6bfcec78.jpg: 384x640 5 cars, 1 truck, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44b8617-3100c413.jpg: 384x640 1 car, 1 bus, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44bf71d-c073c94e.jpg: 384x640 1 car, 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7427/10000 [03:58<01:33, 27.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44c7f5c-9bef0aea.jpg: 384x640 12 cars, 1 truck, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44d8c58-1e08c667.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44d8c58-cca1e1a3.jpg: 384x640 8 cars, 1 truck, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7430/10000 [03:58<01:32, 27.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44da9b8-5cded201.jpg: 384x640 1 person, 4 cars, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44da9b8-ecd04bdd.jpg: 384x640 (no detections), 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44e7068-5dafd017.jpg: 384x640 2 persons, 11 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44e7068-cc04270e.jpg: 384x640 1 person, 7 cars, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7434/10000 [03:58<01:31, 27.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44f673a-599eb3e3.jpg: 384x640 1 car, 16.4ms\n",
            "Speed: 3.9ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44f673a-95ffa424.jpg: 384x640 10 cars, 17.4ms\n",
            "Speed: 4.0ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44f673a-a7429e84.jpg: 384x640 10 cars, 22.3ms\n",
            "Speed: 2.0ms preprocess, 22.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7437/10000 [03:58<01:40, 25.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c44f673a-b4b48b84.jpg: 384x640 9 cars, 1 traffic light, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4528c24-144b8340.jpg: 384x640 8 cars, 3 traffic lights, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c452e38d-db51883f.jpg: 384x640 10 cars, 20.4ms\n",
            "Speed: 1.9ms preprocess, 20.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7440/10000 [03:58<01:43, 24.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4542f68-d3221fd3.jpg: 384x640 5 cars, 1 traffic light, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4552519-f5897060.jpg: 384x640 1 person, 2 cars, 4 trucks, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c455b31c-12fbb7a9.jpg: 384x640 6 cars, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7443/10000 [03:58<01:39, 25.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c456e9c3-8a255f8c.jpg: 384x640 4 cars, 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c456e9c3-fa69d872.jpg: 384x640 17 cars, 1 traffic light, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c456ed56-adbb1839.jpg: 384x640 3 persons, 5 cars, 1 bus, 3 trucks, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7446/10000 [03:58<01:35, 26.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45734da-de0f5c25.jpg: 384x640 3 persons, 4 cars, 1 bus, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c457bb30-990d6395.jpg: 384x640 2 cars, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c457d18a-610011a8.jpg: 384x640 6 cars, 1 traffic light, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  74%|███████▍  | 7449/10000 [03:58<01:33, 27.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4590261-d7081dfa.jpg: 384x640 7 cars, 1 truck, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c459408e-3dd887d7.jpg: 384x640 8 persons, 9 cars, 15.3ms\n",
            "Speed: 4.6ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45b2e04-5689b375.jpg: 384x640 5 cars, 1 truck, 5 traffic lights, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7452/10000 [03:58<01:36, 26.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45b2e04-fb920e89.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45c7487-c44e6bab.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 3.9ms preprocess, 8.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45cf21f-c11847dd.jpg: 384x640 6 cars, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45cf21f-d6bc94ba.jpg: 384x640 7 cars, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7456/10000 [03:59<01:28, 28.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45d3e0a-75c44167.jpg: 384x640 1 person, 9 cars, 1 train, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45d3e0a-93a52b80.jpg: 384x640 1 person, 1 bicycle, 4 cars, 2 trucks, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45d3e0a-b26d5167.jpg: 384x640 3 persons, 1 bicycle, 3 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45e3dc0-3517e269.jpg: 384x640 4 cars, 1 bus, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7460/10000 [03:59<01:20, 31.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45e9809-f95fd1e2.jpg: 384x640 6 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45fbe22-2c182907.jpg: 384x640 7 cars, 1 fire hydrant, 16.6ms\n",
            "Speed: 2.0ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45fbe22-61885df3.jpg: 384x640 9 cars, 1 truck, 16.5ms\n",
            "Speed: 1.7ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45fbe22-66a2e8da.jpg: 384x640 13 cars, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7464/10000 [03:59<01:27, 29.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45fbe22-8bcb4ef4.jpg: 384x640 2 persons, 3 cars, 17.1ms\n",
            "Speed: 2.1ms preprocess, 17.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c45fce16-113938a6.jpg: 384x640 22 cars, 18.5ms\n",
            "Speed: 3.9ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4605841-affd9541.jpg: 384x640 6 cars, 1 bus, 1 truck, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7467/10000 [03:59<01:34, 26.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4613fc7-919152c4.jpg: 384x640 1 car, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c463025d-87dab187.jpg: 384x640 2 persons, 2 cars, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c464c963-0279dcc0.jpg: 384x640 1 person, 15 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c464c963-5ac10424.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7471/10000 [03:59<01:28, 28.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c464c963-6fa9416d.jpg: 384x640 8 persons, 1 bus, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c464c963-74458fbb.jpg: 384x640 14 cars, 2 trucks, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c464c963-a377ab36.jpg: 384x640 5 cars, 1 traffic light, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c464c963-fbf300ba.jpg: 384x640 5 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7475/10000 [03:59<01:23, 30.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46ab79d-5e0c7623.jpg: 384x640 7 persons, 5 cars, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46ae02f-e7635cbf.jpg: 384x640 1 person, 10 cars, 1 truck, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46b6439-379167c1.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46b71ac-2c83a68e.jpg: 384x640 1 car, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7479/10000 [03:59<01:21, 30.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46c8375-20bbe925.jpg: 384x640 2 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46c8375-44338121.jpg: 384x640 1 person, 5 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46c8375-e5fa2581.jpg: 384x640 4 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46c8896-0d981461.jpg: 384x640 6 cars, 1 bus, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7483/10000 [03:59<01:18, 32.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46cdbf7-7e30902e.jpg: 384x640 7 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c46f4c8a-c6c995c1.jpg: 384x640 4 cars, 2 trucks, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4725a9d-9d57ea61.jpg: 384x640 1 car, 13.0ms\n",
            "Speed: 5.8ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-04ad682a.jpg: 384x640 5 cars, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7487/10000 [04:00<01:17, 32.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-1afc30eb.jpg: 384x640 6 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-204ffa13.jpg: 384x640 4 cars, 2 trains, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-2311398c.jpg: 384x640 8 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-38974bfd.jpg: 384x640 6 persons, 3 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7491/10000 [04:00<01:15, 33.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-539e74f4.jpg: 384x640 4 cars, 1 traffic light, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-5af296e0.jpg: 384x640 5 persons, 1 bicycle, 1 car, 1 bus, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-5be69e5b.jpg: 384x640 5 persons, 2 cars, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-81aa45ae.jpg: 384x640 1 person, 9 cars, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7495/10000 [04:00<01:19, 31.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-8900110c.jpg: 384x640 8 cars, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-a38a2d85.jpg: 384x640 3 cars, 1 traffic light, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-c0e2297d.jpg: 384x640 1 person, 1 car, 19.5ms\n",
            "Speed: 4.2ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-d24c4260.jpg: 384x640 1 car, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▍  | 7499/10000 [04:00<01:26, 28.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4742900-d3fdcb6c.jpg: 384x640 6 cars, 17.7ms\n",
            "Speed: 1.8ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4756fa2-027007f8.jpg: 384x640 1 person, 2 cars, 17.8ms\n",
            "Speed: 3.5ms preprocess, 17.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4770a97-1393ce84.jpg: 384x640 7 cars, 16.9ms\n",
            "Speed: 1.7ms preprocess, 16.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7502/10000 [04:00<01:32, 27.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4770a97-d8a26f8c.jpg: 384x640 6 cars, 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4770a97-fb46c2d8.jpg: 384x640 6 cars, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c477c67b-6eb95776.jpg: 384x640 6 cars, 1 bus, 1 traffic light, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7505/10000 [04:00<01:32, 27.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c477c67b-89221134.jpg: 384x640 1 car, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c479fb68-0060cade.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c479fb68-c67705cd.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c47ac0cd-42edbc96.jpg: 384x640 7 persons, 4 cars, 2 buss, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7509/10000 [04:00<01:23, 29.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c47ac0cd-7e14e3f2.jpg: 384x640 8 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c47d2355-85330657.jpg: 384x640 2 cars, 3 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c47d2355-e6ac67d5.jpg: 384x640 1 car, 1 train, 1 traffic light, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c47d8d11-30ed3058.jpg: 384x640 10 cars, 1 motorcycle, 1 truck, 1 fire hydrant, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7513/10000 [04:01<01:22, 30.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c47f172b-42e86c73.jpg: 384x640 1 person, 5 cars, 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c47f850b-97816a73.jpg: 384x640 1 person, 16 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c47fb4ff-92db68d6.jpg: 384x640 5 cars, 1 truck, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4816131-7251b67e.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7517/10000 [04:01<01:18, 31.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c482a775-8e9c09c8.jpg: 384x640 9 cars, 1 bus, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48569ef-c99d8f9e.jpg: 384x640 15 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4857d94-0f462d91.jpg: 384x640 1 car, 12.5ms\n",
            "Speed: 3.9ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48593bf-ca97d93d.jpg: 384x640 6 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7521/10000 [04:01<01:17, 32.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c485d97d-e833c4a1.jpg: 384x640 4 persons, 1 truck, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c486bf3b-6bcde09a.jpg: 384x640 5 cars, 15.6ms\n",
            "Speed: 2.3ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c487edf6-0cbf1727.jpg: 384x640 9 cars, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c488f6a3-cffdf85a.jpg: 384x640 8 cars, 1 truck, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7525/10000 [04:01<01:19, 31.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4891df0-24371ae1.jpg: 384x640 1 car, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48ba79f-920445ac.jpg: 384x640 5 cars, 21.1ms\n",
            "Speed: 1.8ms preprocess, 21.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48ba79f-a2bf2dcf.jpg: 384x640 8 cars, 1 traffic light, 20.5ms\n",
            "Speed: 1.8ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48ba79f-d11f6d9b.jpg: 384x640 2 cars, 17.8ms\n",
            "Speed: 1.8ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7529/10000 [04:01<01:23, 29.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48ba79f-d8e0bf32.jpg: 384x640 2 cars, 1 truck, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48bcc55-8b6f35e1.jpg: 384x640 12 cars, 1 truck, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48bcc55-9fc09810.jpg: 384x640 14 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7532/10000 [04:01<01:23, 29.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48bcc55-fb68d6b7.jpg: 384x640 5 cars, 1 traffic light, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48cfadb-09901ed4.jpg: 384x640 5 cars, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48cfadb-fcbdaa65.jpg: 384x640 3 cars, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48db695-5c28a6a5.jpg: 384x640 3 cars, 2 traffic lights, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7536/10000 [04:01<01:21, 30.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48e9b2e-0edd0832.jpg: 384x640 1 person, 8 cars, 3 traffic lights, 9.9ms\n",
            "Speed: 3.6ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48f5464-2b6fcad2.jpg: 384x640 1 person, 7 cars, 1 fire hydrant, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48f5464-73d132a1.jpg: 384x640 14 cars, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48f5464-ebc458bf.jpg: 384x640 1 person, 2 cars, 6 trucks, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7540/10000 [04:01<01:19, 30.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c48f5464-fde5983e.jpg: 384x640 1 person, 12 cars, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4910419-e8cf2965.jpg: 384x640 3 cars, 1 truck, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c491ce8e-58b8a379.jpg: 384x640 8 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c492bb89-922226bb.jpg: 384x640 2 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7544/10000 [04:01<01:17, 31.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c492bb89-abf09ef4.jpg: 384x640 10 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c492c534-2d7821c2.jpg: 384x640 10 cars, 3 trucks, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4933980-04482b56.jpg: 384x640 2 cars, 1 horse, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c494f267-66097731.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  75%|███████▌  | 7548/10000 [04:02<01:17, 31.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c1308-4ef95803.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c1308-71384f70.jpg: 384x640 6 cars, 1 truck, 2 traffic lights, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c1308-fa377b09.jpg: 384x640 8 cars, 1 bus, 1 truck, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-30d3e9f2.jpg: 384x640 7 cars, 1 cell phone, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7552/10000 [04:02<01:19, 30.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-4adf80d2.jpg: 384x640 1 car, 1 traffic light, 1 tv, 18.6ms\n",
            "Speed: 1.9ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-6d4b36f5.jpg: 384x640 1 car, 18.4ms\n",
            "Speed: 1.9ms preprocess, 18.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-71549f83.jpg: 384x640 3 cars, 1 suitcase, 13.8ms\n",
            "Speed: 3.9ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-82bc1d4d.jpg: 384x640 1 traffic light, 1 cell phone, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7556/10000 [04:02<01:23, 29.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-859a1bd7.jpg: 384x640 1 person, 9 cars, 18.0ms\n",
            "Speed: 2.3ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-85ca8693.jpg: 384x640 1 laptop, 1 cell phone, 17.9ms\n",
            "Speed: 1.8ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-8a2e64e2.jpg: 384x640 5 cars, 1 traffic light, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7559/10000 [04:02<01:25, 28.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-e4d8763a.jpg: 384x640 1 chair, 1 laptop, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-ec5d3b29.jpg: 384x640 1 laptop, 9.6ms\n",
            "Speed: 3.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-f56b7e30.jpg: 384x640 3 cars, 1 truck, 1 chair, 1 laptop, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49c8353-fe2f3304.jpg: 384x640 1 car, 1 chair, 1 laptop, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7563/10000 [04:02<01:23, 29.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49d39a3-738d6240.jpg: 384x640 (no detections), 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49d39a3-9064a5ae.jpg: 384x640 2 cars, 12.2ms\n",
            "Speed: 4.2ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49e96b9-24ec6193.jpg: 384x640 1 person, 8 cars, 1 truck, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7566/10000 [04:02<01:23, 29.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49f9073-3657ccaf.jpg: 384x640 5 cars, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c49fdce8-68545005.jpg: 384x640 1 car, 18.1ms\n",
            "Speed: 2.0ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a06183-4a42e1b9.jpg: 384x640 1 car, 16.2ms\n",
            "Speed: 3.9ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7569/10000 [04:02<01:23, 29.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a06183-898ad98d.jpg: 384x640 7 cars, 1 bus, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a078bd-8e5b3732.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a1065b-ec1e76ba.jpg: 384x640 7 cars, 15.0ms\n",
            "Speed: 2.1ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7572/10000 [04:02<01:25, 28.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a19ba6-0d09788f.jpg: 384x640 2 persons, 5 cars, 4 trucks, 1 fire hydrant, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a19ba6-872ab53e.jpg: 384x640 4 persons, 4 cars, 17.0ms\n",
            "Speed: 2.0ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a19ba6-e17be5d5.jpg: 384x640 4 cars, 1 truck, 10.4ms\n",
            "Speed: 2.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7575/10000 [04:03<01:28, 27.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a19ba6-e706bdc2.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a19ba6-fa93d45f.jpg: 384x640 3 persons, 3 cars, 2 buss, 2 trucks, 2 traffic lights, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a2accd-bd3e878a.jpg: 384x640 4 persons, 7 cars, 1 traffic light, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7578/10000 [04:03<01:26, 27.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a4ccdc-9c4aeeeb.jpg: 384x640 8 cars, 3 trucks, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a6774c-144a01d6.jpg: 384x640 13 cars, 7 traffic lights, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a6774c-753a089b.jpg: 384x640 6 persons, 1 bicycle, 4 cars, 1 bus, 20.4ms\n",
            "Speed: 2.0ms preprocess, 20.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7581/10000 [04:03<01:35, 25.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a6774c-ffc10e46.jpg: 384x640 9 cars, 1 truck, 18.6ms\n",
            "Speed: 1.9ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a6cc43-f689c9f1.jpg: 384x640 9 cars, 1 bus, 18.6ms\n",
            "Speed: 2.7ms preprocess, 18.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a6feae-63c06b39.jpg: 384x640 8 cars, 1 truck, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7584/10000 [04:03<01:34, 25.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a90af7-02583942.jpg: 384x640 2 persons, 3 cars, 17.6ms\n",
            "Speed: 2.0ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a9c191-20e1a3c3.jpg: 384x640 4 cars, 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4a9c6f0-f18e20e1.jpg: 384x640 6 cars, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4aa9a10-9e10483d.jpg: 384x640 3 trucks, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7588/10000 [04:03<01:28, 27.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4aac9d9-47b01027.jpg: 384x640 4 persons, 13 cars, 1 traffic light, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ab81ac-4bd1c081.jpg: 384x640 11 cars, 1 truck, 16.1ms\n",
            "Speed: 2.0ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ab81ac-d0b2d9d3.jpg: 384x640 7 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7591/10000 [04:03<01:30, 26.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4accb9c-58311122.jpg: 384x640 8 cars, 14.3ms\n",
            "Speed: 6.6ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ad8036-ee20aaf7.jpg: 384x640 2 cars, 1 boat, 4 traffic lights, 12.1ms\n",
            "Speed: 3.6ms preprocess, 12.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4adecb8-62235513.jpg: 384x640 4 persons, 6 cars, 1 truck, 1 potted plant, 14.3ms\n",
            "Speed: 3.8ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7594/10000 [04:03<01:30, 26.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4af195c-45288c26.jpg: 384x640 3 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4af4030-d3b1831d.jpg: 384x640 1 person, 3 cars, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b0ddd7-e8973c8f.jpg: 384x640 8 cars, 2 traffic lights, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7597/10000 [04:03<01:27, 27.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b21612-fa6c1df7.jpg: 384x640 2 persons, 5 cars, 1 truck, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b3ab99-a4a09eeb.jpg: 384x640 4 cars, 1 bus, 3 trucks, 13.8ms\n",
            "Speed: 7.7ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b3ce3d-077bb161.jpg: 384x640 4 cars, 19.1ms\n",
            "Speed: 1.9ms preprocess, 19.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7600/10000 [04:04<01:30, 26.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b3ce3d-2e77b39d.jpg: 384x640 7 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b3ce3d-42ddd6a3.jpg: 384x640 16 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b3ce3d-6e999bfc.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b3ce3d-8b344a2f.jpg: 384x640 2 cars, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7604/10000 [04:04<01:21, 29.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b3ce3d-cdc056ce.jpg: 384x640 4 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b3ce3d-ef12b7eb.jpg: 384x640 7 cars, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b610ae-4b915923.jpg: 384x640 8 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b610ae-bc6dc0c9.jpg: 384x640 3 cars, 1 traffic light, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7608/10000 [04:04<01:15, 31.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b610ae-f75d91a9.jpg: 384x640 1 car, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b75335-81d7421a.jpg: 384x640 9 cars, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b77809-63fd577c.jpg: 384x640 5 cars, 1 truck, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b8340c-51d3f82b.jpg: 384x640 5 persons, 6 cars, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7612/10000 [04:04<01:16, 31.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b8d344-dcbbc041.jpg: 384x640 1 car, 1 truck, 1 traffic light, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4b90e82-0a023704.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4bc3dee-58920c9c.jpg: 384x640 15 cars, 1 traffic light, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4bfc4c7-98ed20f8.jpg: 384x640 7 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7616/10000 [04:04<01:16, 31.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c35028-acf2331c.jpg: 384x640 3 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c4b88a-d1a38d2f.jpg: 384x640 10 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c4db55-82c87232.jpg: 384x640 3 cars, 1 truck, 13.6ms\n",
            "Speed: 3.3ms preprocess, 13.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c5ba90-bb1f87c2.jpg: 384x640 2 cars, 17.1ms\n",
            "Speed: 1.9ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7620/10000 [04:04<01:17, 30.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c5f66a-a1df8079.jpg: 384x640 4 cars, 2 traffic lights, 11.3ms\n",
            "Speed: 2.8ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c60257-a432f6b0.jpg: 384x640 3 cars, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c62162-f5b851c8.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c62e31-64421eb6.jpg: 384x640 4 cars, 1 fire hydrant, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▌  | 7624/10000 [04:04<01:15, 31.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c7fdec-4f505413.jpg: 384x640 2 cars, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4c7fdec-ec322a67.jpg: 384x640 6 cars, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4cb6f64-283904da.jpg: 384x640 2 cars, 1 traffic light, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4cb8333-dcda097b.jpg: 384x640 1 person, 1 bicycle, 4 cars, 2 potted plants, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▋  | 7628/10000 [04:04<01:15, 31.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4cc2bbd-a4913bdf.jpg: 384x640 5 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ccd765-48590402.jpg: 384x640 2 cars, 1 traffic light, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ccffb1-e4215665.jpg: 384x640 4 cars, 1 traffic light, 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ccffb1-e53dc8ca.jpg: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▋  | 7632/10000 [04:05<01:13, 32.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4cd1f3d-ff8db980.jpg: 384x640 7 cars, 2 trucks, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ceb792-87e9c3b2.jpg: 384x640 10 cars, 1 bench, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4cebcf0-c8c73eb8.jpg: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4cf4c32-e9845a14.jpg: 384x640 10 cars, 1 bus, 3 trucks, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▋  | 7636/10000 [04:05<01:14, 31.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4cf6bff-d98bdd3c.jpg: 384x640 9 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d023f4-27b83fe1.jpg: 384x640 (no detections), 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d1be5c-f868e120.jpg: 384x640 2 persons, 4 cars, 1 traffic light, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d25f00-158d0757.jpg: 384x640 7 cars, 1 truck, 14.5ms\n",
            "Speed: 3.1ms preprocess, 14.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▋  | 7640/10000 [04:05<01:14, 31.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d25f00-3b1d8669.jpg: 384x640 2 cars, 1 traffic light, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d25f00-b6658057.jpg: 384x640 7 cars, 1 truck, 15.5ms\n",
            "Speed: 2.9ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d2b46a-4fef7a35.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d58b70-d6d1bc1b.jpg: 384x640 1 person, 4 cars, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▋  | 7644/10000 [04:05<01:16, 30.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d631ce-55e4d4e9.jpg: 384x640 1 person, 5 cars, 1 bus, 3 traffic lights, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d6708e-850d258c.jpg: 384x640 10 cars, 18.0ms\n",
            "Speed: 3.7ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d7185b-6c141918.jpg: 384x640 (no detections), 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d83625-8af1c66e.jpg: 384x640 10 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  76%|███████▋  | 7648/10000 [04:05<01:18, 30.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4d8d2c5-4b12f422.jpg: 384x640 15 cars, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4da6b04-56ce6c06.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4dab4e2-6c4805a2.jpg: 384x640 (no detections), 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4db746c-5428658b.jpg: 384x640 1 car, 3 traffic lights, 12.8ms\n",
            "Speed: 3.7ms preprocess, 12.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7652/10000 [04:05<01:17, 30.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4dbd719-1d98586e.jpg: 384x640 16 cars, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4dbd719-26df8369.jpg: 384x640 2 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4dbd719-db521513.jpg: 384x640 8 cars, 4 traffic lights, 1 bowl, 1 sink, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4dcbfde-47aff5b9.jpg: 384x640 11 cars, 1 truck, 1 traffic light, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7656/10000 [04:05<01:19, 29.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4de6fe5-90dc8799.jpg: 384x640 12 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e00603-9f2734d0.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e2eba0-02c66276.jpg: 384x640 (no detections), 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e2eba0-1f3761a9.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e2eba0-f32cc5b6.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7661/10000 [04:05<01:10, 33.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e3cf95-4f803484.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 3.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e3cf95-ceb5651a.jpg: 384x640 5 cars, 1 truck, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e55051-2f5623da.jpg: 384x640 5 cars, 1 bus, 1 truck, 4 traffic lights, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e55051-bda84aa3.jpg: 384x640 11 cars, 1 traffic light, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7665/10000 [04:06<01:12, 32.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e5de4b-35f6a1b1.jpg: 384x640 2 cars, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e8705f-39bf4a26.jpg: 384x640 5 cars, 1 truck, 12.9ms\n",
            "Speed: 1.7ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e92086-d5d22167.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e92086-e0ea5438.jpg: 384x640 8 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7669/10000 [04:06<01:11, 32.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e92086-e1b8324f.jpg: 384x640 8 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e926af-43c5f8d3.jpg: 384x640 6 cars, 3 traffic lights, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e926af-54c0d842.jpg: 384x640 3 cars, 2 trucks, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e926af-bb5132fd.jpg: 384x640 12 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7673/10000 [04:06<01:12, 32.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e96efa-73bd2e38.jpg: 384x640 3 cars, 2 buss, 2 trucks, 2 traffic lights, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e96efa-94aad2be.jpg: 384x640 4 cars, 1 bus, 1 truck, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e96efa-cbe1be6a.jpg: 384x640 1 person, 9 cars, 3 traffic lights, 17.3ms\n",
            "Speed: 2.7ms preprocess, 17.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e96efa-ea5f524b.jpg: 384x640 3 cars, 3 buss, 17.1ms\n",
            "Speed: 2.5ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7677/10000 [04:06<01:21, 28.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4e97226-7be7eef5.jpg: 384x640 6 cars, 1 truck, 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb5462-184dced9.jpg: 384x640 10 persons, 3 cars, 2 traffic lights, 1 handbag, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb5462-4d947240.jpg: 384x640 17 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7680/10000 [04:06<01:21, 28.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb5462-657f5921.jpg: 384x640 3 persons, 4 cars, 1 bus, 1 truck, 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb5462-c917fefd.jpg: 384x640 1 person, 4 traffic lights, 1 fire hydrant, 1 stop sign, 1 horse, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb5462-ebd248b7.jpg: 384x640 6 cars, 1 truck, 11.8ms\n",
            "Speed: 1.7ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb5462-f87b7afc.jpg: 384x640 9 cars, 1 truck, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7684/10000 [04:06<01:20, 28.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb680f-4fdac155.jpg: 384x640 4 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb680f-5b3f5675.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4eb96a1-92fb9d6f.jpg: 384x640 3 persons, 7 cars, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ee0cc4-b7af9602.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7688/10000 [04:06<01:14, 30.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4ef83b2-696779d1.jpg: 384x640 9 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f19b5d-63528c25.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f4718b-5356b324.jpg: 384x640 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f4718b-7a18cd62.jpg: 384x640 2 cars, 1 bench, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7692/10000 [04:06<01:10, 32.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f4718b-f6e8ce43.jpg: 384x640 1 car, 1 train, 1 traffic light, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f59bdd-00356764.jpg: 384x640 3 cars, 1 bus, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f59bdd-11bad1c6.jpg: 384x640 1 person, 2 cars, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f62823-9d3f8519.jpg: 384x640 1 person, 6 cars, 1 truck, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7696/10000 [04:07<01:10, 32.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f65761-4cdc3348.jpg: 384x640 3 cars, 1 bus, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f65761-92ca62d4.jpg: 384x640 3 cars, 1 truck, 4 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f723f1-5ba8f7ee.jpg: 384x640 1 traffic light, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f723f1-a0aab25c.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7700/10000 [04:07<01:08, 33.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f723f1-babfc6fe.jpg: 384x640 (no detections), 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f79b31-594adb6b.jpg: 384x640 19 cars, 1 traffic light, 16.6ms\n",
            "Speed: 1.8ms preprocess, 16.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f8633c-a33316a8.jpg: 384x640 1 car, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f993bf-3eee07b1.jpg: 384x640 6 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7704/10000 [04:07<01:11, 32.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4f993bf-e6edd387.jpg: 384x640 3 cars, 1 bus, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4fa3b0a-29b96446.jpg: 384x640 6 cars, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4fb5145-f7056d01.jpg: 384x640 5 persons, 5 cars, 1 motorcycle, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4fb6443-4d900d7f.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7708/10000 [04:07<01:09, 32.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4fb6443-babb6e4c.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4fb8930-2ff82458.jpg: 384x640 1 person, 2 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c4fd6567-49ef2209.jpg: 384x640 12 cars, 1 bus, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50193e1-630410dc.jpg: 384x640 (no detections), 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7712/10000 [04:07<01:09, 33.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5030241-68561ce7.jpg: 384x640 2 persons, 5 cars, 2 trucks, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c503e333-c84c1f79.jpg: 384x640 9 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c503f2e8-1780553c.jpg: 384x640 5 persons, 7 cars, 1 bus, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c503f2e8-55cc08bf.jpg: 384x640 3 persons, 6 cars, 2 trucks, 3 traffic lights, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7716/10000 [04:07<01:07, 33.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50410a9-da5e3b8d.jpg: 384x640 9 cars, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c504ed5c-0f63b8cb.jpg: 384x640 4 cars, 1 truck, 4 traffic lights, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50ac48c-417a806b.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50b63be-01088e58.jpg: 384x640 13 cars, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7720/10000 [04:07<01:07, 33.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50b63be-93930ff0.jpg: 384x640 3 cars, 2 buss, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50b63be-e0aa64b3.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50c20fc-39f5336c.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50c20fc-7941d80e.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50c20fc-9b816732.jpg: 384x640 9 cars, 1 bus, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7725/10000 [04:07<01:03, 35.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50d0b3f-3a8df0bf.jpg: 384x640 23 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50d0b3f-96a483e0.jpg: 384x640 3 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50e6ae2-b9b2e863.jpg: 384x640 10 cars, 1 truck, 1 traffic light, 1 fire hydrant, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50faaad-75284f27.jpg: 384x640 12 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7729/10000 [04:08<01:03, 35.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50faaad-a8463d3d.jpg: 384x640 6 cars, 3 traffic lights, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50faaad-d383bf66.jpg: 384x640 1 person, 4 cars, 1 motorcycle, 1 truck, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c50faaad-d84b2856.jpg: 384x640 1 car, 2 stop signs, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5118204-23d7a171.jpg: 384x640 7 cars, 1 traffic light, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7733/10000 [04:08<01:07, 33.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5121aec-f19f3e8d.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 4.8ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5125543-1bb695f3.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5125543-c78ee13f.jpg: 384x640 1 car, 2 traffic lights, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c513195c-6ff34daf.jpg: 384x640 14 cars, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7737/10000 [04:08<01:06, 34.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51321e5-033ac799.jpg: 384x640 5 persons, 3 cars, 2 trucks, 4 traffic lights, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5134065-dce97cfb.jpg: 384x640 3 cars, 1 truck, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5179971-6c0bbf66.jpg: 384x640 4 cars, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c517c182-52118b0a.jpg: 384x640 7 cars, 1 traffic light, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7741/10000 [04:08<01:07, 33.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c517c182-a162a7f9.jpg: 384x640 2 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c517c182-d75f08e3.jpg: 384x640 3 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c517c182-db33a55a.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51a2815-5d5e6d1a.jpg: 384x640 2 cars, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7745/10000 [04:08<01:07, 33.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51c4c12-3ccdcd61.jpg: 384x640 13 cars, 1 bus, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51c4c12-e9006511.jpg: 384x640 2 cars, 2 trucks, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51d0636-2b91b311.jpg: 384x640 6 cars, 2 traffic lights, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51d0636-7e3c91ea.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  77%|███████▋  | 7749/10000 [04:08<01:06, 33.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51d0636-89b6a9d9.jpg: 384x640 6 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51d0636-df16876f.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51de804-7b18411f.jpg: 384x640 13 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51ec845-16754dac.jpg: 384x640 5 persons, 6 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7753/10000 [04:08<01:03, 35.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51ec845-67e41e84.jpg: 384x640 1 person, 9 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51ec845-75af36d3.jpg: 384x640 6 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51ec845-9096d93a.jpg: 384x640 10 cars, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51ec845-99c75a49.jpg: 384x640 3 persons, 3 cars, 1 bus, 2 traffic lights, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7757/10000 [04:08<01:04, 34.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c51ee110-ea464eff.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52170ea-5346382f.jpg: 384x640 8 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5218d47-c938bca6.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c524ecb5-74c5e510.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7761/10000 [04:08<01:01, 36.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c524ecb5-d58d39ee.jpg: 384x640 5 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52a5080-19a9e0a7.jpg: 384x640 2 cars, 2 trucks, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52a5080-7f1eba3f.jpg: 384x640 2 cars, 2 trucks, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52a5080-e5a538ae.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52a5080-f9be7559.jpg: 384x640 11 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7766/10000 [04:09<01:00, 37.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52b6d8b-defd3a03.jpg: 384x640 13 cars, 2 buss, 1 truck, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52f53f8-1df973bb.jpg: 384x640 4 cars, 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52f53f8-70ad0125.jpg: 384x640 6 cars, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52f53f8-83f49a86.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7770/10000 [04:09<01:04, 34.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52f53f8-8e4cd9a5.jpg: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52f53f8-ca29420e.jpg: 384x640 1 person, 1 train, 1 traffic light, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c52f53f8-f2c94064.jpg: 384x640 1 person, 2 cars, 2 trucks, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5302a80-100fc260.jpg: 384x640 4 cars, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7774/10000 [04:09<01:04, 34.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c532201e-8531945e.jpg: 384x640 5 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53221aa-4ef98335.jpg: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53385ee-1fe07e21.jpg: 384x640 8 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5339d15-f0812440.jpg: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7778/10000 [04:09<01:03, 35.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5343589-b82a2d0b.jpg: 384x640 (no detections), 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5343589-f0a9e124.jpg: 384x640 2 cars, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53478c5-0565e28b.jpg: 384x640 1 person, 1 car, 1 traffic light, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53478c5-79d0affb.jpg: 384x640 5 cars, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7782/10000 [04:09<01:04, 34.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c536c7e6-f9b2808f.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c536d061-03d98dde.jpg: 384x640 1 person, 4 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c536d061-694537c9.jpg: 384x640 4 persons, 1 car, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53941d4-889b2e48.jpg: 384x640 12 cars, 2 trucks, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7786/10000 [04:09<01:03, 35.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53986c1-311f3693.jpg: 384x640 8 cars, 1 truck, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53986c1-9107e7a9.jpg: 384x640 1 car, 1 truck, 1 traffic light, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53986c1-925eafc4.jpg: 384x640 1 person, 5 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53986c1-a827a10a.jpg: 384x640 7 cars, 1 truck, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7790/10000 [04:09<01:02, 35.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53986c1-c00f0bdc.jpg: 384x640 1 person, 2 cars, 1 bus, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53986c1-c1e5c59d.jpg: 384x640 1 person, 6 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53986c1-e01903a1.jpg: 384x640 6 cars, 1 bus, 1 truck, 1 traffic light, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53986c1-ead41bbf.jpg: 384x640 3 cars, 2 traffic lights, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7794/10000 [04:09<01:02, 35.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53a24f2-545aa062.jpg: 384x640 10 cars, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53a24f2-5e6c5cbd.jpg: 384x640 7 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53a24f2-a94dfb53.jpg: 384x640 1 person, 9 cars, 1 fire hydrant, 8.8ms\n",
            "Speed: 4.2ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53a24f2-dd27caa2.jpg: 384x640 5 cars, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7798/10000 [04:10<01:02, 35.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53a24f2-e7ccbacd.jpg: 384x640 6 cars, 3 traffic lights, 1 potted plant, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53bb16d-509a7840.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53c8bba-e8fa6bc6.jpg: 384x640 16 cars, 2 trucks, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53c9807-1eadf674.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7802/10000 [04:10<01:03, 34.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c53cad0a-e31c0406.jpg: 384x640 1 person, 3 cars, 2 trucks, 1 traffic light, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c540a708-48091e56.jpg: 384x640 2 cars, 1 traffic light, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c540a708-71fd04e3.jpg: 384x640 7 cars, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c540a708-e1a4ff73.jpg: 384x640 10 cars, 2 trucks, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7806/10000 [04:10<01:08, 31.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c540a708-e532e378.jpg: 384x640 1 car, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c540a708-f9601c77.jpg: 384x640 (no detections), 13.4ms\n",
            "Speed: 6.9ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c540d300-35f80d81.jpg: 384x640 1 car, 16.7ms\n",
            "Speed: 6.9ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c540d300-d60d1a91.jpg: 384x640 4 cars, 11.1ms\n",
            "Speed: 5.3ms preprocess, 11.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7810/10000 [04:10<01:12, 30.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5430bf3-07e67721.jpg: 384x640 3 cars, 1 traffic light, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5434464-5dcb3bd7.jpg: 384x640 1 person, 7 cars, 2 traffic lights, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c54441e6-400c221e.jpg: 384x640 8 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c546c109-92e1a97e.jpg: 384x640 10 cars, 1 bus, 3 traffic lights, 15.7ms\n",
            "Speed: 1.9ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7814/10000 [04:10<01:14, 29.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5490183-eb00ff57.jpg: 384x640 11 cars, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c54925a2-af3b6166.jpg: 384x640 7 persons, 3 cars, 3 traffic lights, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c54a2f90-4762b269.jpg: 384x640 11 cars, 1 truck, 1 fire hydrant, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7817/10000 [04:10<01:17, 28.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c54abf2f-cd3f73dc.jpg: 384x640 4 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c54c4e66-d4b3ef01.jpg: 384x640 (no detections), 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c54e3b28-168e2176.jpg: 384x640 2 cars, 1 traffic light, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c54ec43c-1aa7875b.jpg: 384x640 5 cars, 1 traffic light, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7821/10000 [04:10<01:14, 29.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5530340-6ca6f8bc.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55332bb-cdf3fe55.jpg: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c553c602-a2d33a0c.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55554e1-b61fd176.jpg: 384x640 4 cars, 5 traffic lights, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7825/10000 [04:10<01:11, 30.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c555922f-58564fdc.jpg: 384x640 12 cars, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c555922f-e8bc7d91.jpg: 384x640 7 cars, 1 truck, 1 traffic light, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5568343-7dfa0efd.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5568343-87284a3a.jpg: 384x640 1 train, 2 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7829/10000 [04:11<01:10, 30.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c556b94f-70bb8f52.jpg: 384x640 2 cars, 1 traffic light, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5578df5-1318c8a5.jpg: 384x640 1 person, 10 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5584f14-7fcc4797.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5584f14-cba77967.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7833/10000 [04:11<01:05, 32.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5588233-76a1ecf3.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5588233-b03622f3.jpg: 384x640 9 cars, 1 truck, 22.8ms\n",
            "Speed: 1.8ms preprocess, 22.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c558e42a-f172181e.jpg: 384x640 1 traffic light, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c558f74c-8874b6c0.jpg: 384x640 5 cars, 1 traffic light, 14.8ms\n",
            "Speed: 2.0ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7837/10000 [04:11<01:11, 30.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c558f74c-8d36158e.jpg: 384x640 2 cars, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c559b4de-a039e833.jpg: 384x640 1 person, 2 cars, 1 bus, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55a3ec9-9aa6b23e.jpg: 384x640 24 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55ab634-34faa48e.jpg: 384x640 3 cars, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7841/10000 [04:11<01:12, 29.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55ab634-b93da9ef.jpg: 384x640 10 cars, 16.1ms\n",
            "Speed: 1.8ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55b474f-f39c51a8.jpg: 384x640 1 person, 6 cars, 1 truck, 1 traffic light, 17.8ms\n",
            "Speed: 1.8ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55b79ad-fff7df7b.jpg: 384x640 12 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55c4242-e70337b4.jpg: 384x640 3 persons, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7845/10000 [04:11<01:14, 28.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55c6b72-d4bb26f3.jpg: 384x640 9 cars, 1 truck, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55d0615-f1eb15ca.jpg: 384x640 2 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55da7df-537c27fd.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55da7df-facccafc.jpg: 384x640 4 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  78%|███████▊  | 7849/10000 [04:11<01:09, 30.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55dc887-58fc27e7.jpg: 384x640 2 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55dde26-9a4d91e4.jpg: 384x640 8 cars, 1 truck, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55f5f07-0e2857f2.jpg: 384x640 9 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55f5f07-1d069cfd.jpg: 384x640 7 cars, 1 motorcycle, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▊  | 7853/10000 [04:11<01:07, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c55fef10-97ed70d9.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c560e52d-71c73e43.jpg: 384x640 1 traffic light, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c560e8b4-ac764600.jpg: 384x640 3 persons, 11 cars, 1 traffic light, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5617574-cca98859.jpg: 384x640 1 car, 1 bus, 1 truck, 13.8ms\n",
            "Speed: 3.1ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▊  | 7857/10000 [04:11<01:07, 31.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c561cb9a-6b311a1c.jpg: 384x640 11 cars, 1 truck, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c561cb9a-7ee655d2.jpg: 384x640 15 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c561cb9a-aafc0bad.jpg: 384x640 10 cars, 1 bus, 1 truck, 2 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5623327-f089f3ee.jpg: 384x640 5 cars, 1 bus, 1 traffic light, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▊  | 7861/10000 [04:12<01:09, 30.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c563b8a0-c21b10e8.jpg: 384x640 11 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c564c92b-2f727c05.jpg: 384x640 6 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c564c92b-dec2638b.jpg: 384x640 1 person, 6 cars, 4 trucks, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56569c3-449c1da2.jpg: 384x640 1 car, 1 traffic light, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▊  | 7865/10000 [04:12<01:09, 30.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c566026b-2879276d.jpg: 384x640 1 person, 9 cars, 1 truck, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c566026b-3127f5d8.jpg: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c566026b-36fc6e3c.jpg: 384x640 4 cars, 1 bus, 1 truck, 18.2ms\n",
            "Speed: 2.4ms preprocess, 18.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c566026b-ea7cc2ea.jpg: 384x640 5 cars, 1 traffic light, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▊  | 7869/10000 [04:12<01:13, 29.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c566a4d9-0504c08b.jpg: 384x640 1 car, 1 traffic light, 14.8ms\n",
            "Speed: 2.5ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c566a4d9-3b84e88d.jpg: 384x640 1 car, 17.9ms\n",
            "Speed: 1.8ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5673b5f-6c5e63bc.jpg: 384x640 6 cars, 1 traffic light, 12.8ms\n",
            "Speed: 4.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▊  | 7872/10000 [04:12<01:14, 28.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5683128-8fa894d4.jpg: 384x640 4 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56915dc-1eb8abe1.jpg: 384x640 2 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56915dc-8d1f7b7a.jpg: 384x640 1 person, 5 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5694077-e345e2a8.jpg: 384x640 1 person, 1 bicycle, 6 cars, 1 truck, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7876/10000 [04:12<01:10, 30.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569a073-b6125b79.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-0738a573.jpg: 384x640 2 persons, 10 cars, 4 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-13855f70.jpg: 384x640 7 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-16b6f263.jpg: 384x640 17 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7880/10000 [04:12<01:10, 29.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-3845bd46.jpg: 384x640 13 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-411184c2.jpg: 384x640 4 cars, 2 buss, 4 trucks, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-695c432c.jpg: 384x640 3 cars, 1 truck, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-8a583641.jpg: 384x640 10 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7884/10000 [04:12<01:07, 31.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-a065134a.jpg: 384x640 1 person, 11 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-cc941b80.jpg: 384x640 2 persons, 10 cars, 2 trucks, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-e9e2071f.jpg: 384x640 11 cars, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c569c251-ee16dcb1.jpg: 384x640 2 persons, 5 cars, 1 bus, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7888/10000 [04:12<01:05, 32.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-35537de6.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-40a9f774.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-5ee26a21.jpg: 384x640 6 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-6707dbb4.jpg: 384x640 3 cars, 3 traffic lights, 1 parking meter, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7892/10000 [04:13<01:02, 33.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-6a32ee17.jpg: 384x640 4 cars, 5 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-8744e902.jpg: 384x640 2 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-8b473204.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-9e626450.jpg: 384x640 8 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7896/10000 [04:13<01:00, 34.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-c7ecc589.jpg: 384x640 7 cars, 12.8ms\n",
            "Speed: 3.6ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-ce17a387.jpg: 384x640 2 persons, 2 cars, 16.5ms\n",
            "Speed: 2.6ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-ef30489c.jpg: 384x640 8 cars, 1 traffic light, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-fca9c961.jpg: 384x640 6 cars, 1 bus, 1 stop sign, 14.9ms\n",
            "Speed: 2.7ms preprocess, 14.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7900/10000 [04:13<01:07, 31.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56ad92a-ff0ebcb2.jpg: 384x640 (no detections), 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56c7249-f70c6c33.jpg: 384x640 7 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56c951e-07a935da.jpg: 384x640 2 cars, 14.2ms\n",
            "Speed: 1.7ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56c951e-9eadf2b7.jpg: 384x640 6 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7904/10000 [04:13<01:10, 29.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56cdb77-68cd6d79.jpg: 384x640 4 cars, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56cdb77-b69228d3.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56cdb77-d0e10fbb.jpg: 384x640 2 cars, 1 traffic light, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56d9ab9-fd988840.jpg: 384x640 6 cars, 1 traffic light, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7908/10000 [04:13<01:09, 30.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c56f2163-005261fc.jpg: 384x640 15 cars, 1 truck, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5718931-d5862304.jpg: 384x640 8 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c571c186-33a17c72.jpg: 384x640 1 car, 2 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c571c186-39041336.jpg: 384x640 6 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7912/10000 [04:13<01:05, 31.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c571c186-d0b3877c.jpg: 384x640 10 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57363a5-1237e193.jpg: 384x640 13 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c573ac02-6c5f037e.jpg: 384x640 2 persons, 1 bicycle, 8 cars, 1 truck, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c573d709-4a0dbd2a.jpg: 384x640 3 persons, 8 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7916/10000 [04:13<01:07, 31.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c576ccff-0a51ae4b.jpg: 384x640 1 car, 1 train, 1 truck, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5789b5b-89d36fa8.jpg: 384x640 1 person, 5 cars, 1 truck, 5 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57906c2-0f8c5acb.jpg: 384x640 1 person, 11 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57906c2-4fd67f12.jpg: 384x640 2 cars, 1 traffic light, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7920/10000 [04:14<01:06, 31.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57906c2-9696bf52.jpg: 384x640 4 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5792511-7e5cec42.jpg: 384x640 3 cars, 3 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5796880-a7005e6e.jpg: 384x640 2 bicycles, 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c579ded4-2bdbcd45.jpg: 384x640 5 cars, 3 trucks, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7924/10000 [04:14<01:02, 33.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57a44ff-1a53cea4.jpg: 384x640 3 persons, 7 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57a44ff-50e4b77f.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57a44ff-5cf5202c.jpg: 384x640 2 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57a44ff-6cf39d9a.jpg: 384x640 2 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57a466b-876d29df.jpg: 384x640 2 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7929/10000 [04:14<00:59, 35.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57a8745-d78279a8.jpg: 384x640 6 cars, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57c1efb-3033d1ff.jpg: 384x640 3 cars, 2 traffic lights, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57c1efb-660f4ec3.jpg: 384x640 2 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57c1efb-d906271a.jpg: 384x640 2 cars, 15.9ms\n",
            "Speed: 2.0ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7933/10000 [04:14<01:00, 34.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57caddc-26ab6ed5.jpg: 384x640 2 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57cda5b-7783c7cb.jpg: 384x640 4 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57cda5b-7ca48687.jpg: 384x640 1 car, 1 bus, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57cda5b-92fa0083.jpg: 384x640 5 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7937/10000 [04:14<00:59, 34.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57cda5b-e43a49aa.jpg: 384x640 7 cars, 1 bus, 1 truck, 13.5ms\n",
            "Speed: 5.8ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57ec379-3d606dec.jpg: 384x640 3 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57ec379-6b2b4a1b.jpg: 384x640 3 cars, 2 traffic lights, 14.7ms\n",
            "Speed: 1.8ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c57ec379-7827cbab.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7941/10000 [04:14<01:01, 33.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58428cf-2398dd36.jpg: 384x640 3 persons, 4 cars, 1 traffic light, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5843165-79210a52.jpg: 384x640 9 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58446da-3863db47.jpg: 384x640 6 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c584f2c3-83912b35.jpg: 384x640 10 cars, 3 traffic lights, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  79%|███████▉  | 7945/10000 [04:14<00:59, 34.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5853065-e066b724.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c585c0c4-f0596352.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c586b898-17285cc9.jpg: 384x640 1 person, 4 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c586b898-260e642f.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c586b898-4247945c.jpg: 384x640 1 car, 1 bus, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7950/10000 [04:14<00:55, 37.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c586b898-99a46642.jpg: 384x640 1 person, 2 cars, 1 bus, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c586b898-d44df97d.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5879538-6312ddd1.jpg: 384x640 6 persons, 2 cars, 2 trucks, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c587d65a-90cbad97.jpg: 384x640 1 car, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c587df13-09f601eb.jpg: 384x640 1 person, 2 cars, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7955/10000 [04:14<00:53, 38.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5882339-1ee18f0d.jpg: 384x640 5 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5882339-42bfd7a8.jpg: 384x640 1 person, 8 cars, 1 traffic light, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5882339-dff241de.jpg: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c588eb5e-dfd59d8e.jpg: 384x640 10 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7959/10000 [04:15<00:54, 37.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c588f35b-79bd69fe.jpg: 384x640 2 persons, 3 cars, 2 buss, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5891130-4bfd998d.jpg: 384x640 11 cars, 2 buss, 1 truck, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5895bc5-f14bcbec.jpg: 384x640 (no detections), 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c589f726-1a6459e8.jpg: 384x640 5 cars, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7963/10000 [04:15<00:54, 37.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58a9085-abc0c295.jpg: 384x640 15 cars, 1 truck, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58ace84-1b30e5a5.jpg: 384x640 3 persons, 1 car, 2 buss, 2 trucks, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58afc12-d228f86b.jpg: 384x640 5 cars, 1 traffic light, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58ba000-928da283.jpg: 384x640 7 cars, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7967/10000 [04:15<00:56, 35.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58bb853-256a6c3e.jpg: 384x640 1 person, 5 cars, 2 trucks, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58bb853-c9421648.jpg: 384x640 3 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58d52cb-63d66bf4.jpg: 384x640 7 cars, 1 traffic light, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58e720e-771b366f.jpg: 384x640 3 cars, 1 truck, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7971/10000 [04:15<00:58, 34.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58eb8da-9871eb53.jpg: 384x640 2 persons, 8 cars, 1 motorcycle, 13.2ms\n",
            "Speed: 3.0ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c58f17ae-e811d801.jpg: 384x640 2 persons, 5 cars, 1 truck, 3 traffic lights, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c591f68a-75fddc3a.jpg: 384x640 11 cars, 1 bus, 3 traffic lights, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c593756a-4d6ae1d1.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7975/10000 [04:15<01:02, 32.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c593b804-4c08d1a1.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59500f0-130d7415.jpg: 384x640 8 cars, 1 truck, 11.8ms\n",
            "Speed: 5.6ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59500f0-1e9d31c1.jpg: 384x640 2 cars, 1 traffic light, 11.8ms\n",
            "Speed: 4.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59500f0-602e9446.jpg: 384x640 10 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7979/10000 [04:15<01:03, 31.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59500f0-6304fda1.jpg: 384x640 13 cars, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59500f0-64edb242.jpg: 384x640 1 person, 11 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59500f0-d3272eb4.jpg: 384x640 5 persons, 6 cars, 1 motorcycle, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59500f0-f26be735.jpg: 384x640 10 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7983/10000 [04:15<01:05, 30.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c595cb01-89718083.jpg: 384x640 1 car, 1 truck, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c595de6c-1fe5d3df.jpg: 384x640 14 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c599480d-15223a32.jpg: 384x640 2 persons, 5 cars, 1 bus, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59af260-1bec72c5.jpg: 384x640 5 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7987/10000 [04:15<01:07, 29.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59af260-aa52b5d0.jpg: 384x640 7 cars, 1 traffic light, 14.5ms\n",
            "Speed: 4.5ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59c31f2-cdac8cc8.jpg: 384x640 7 persons, 3 bicycles, 3 cars, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c59e4f05-5ebe763a.jpg: 384x640 2 persons, 5 cars, 1 truck, 5 traffic lights, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a0ad25-32da84bb.jpg: 384x640 10 cars, 1 bus, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7991/10000 [04:16<01:08, 29.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a0ad25-ce65688e.jpg: 384x640 3 persons, 10 cars, 2 trucks, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a0d993-3505c5ce.jpg: 384x640 11 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a0d993-a86563c1.jpg: 384x640 2 cars, 1 truck, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7994/10000 [04:16<01:08, 29.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a11aec-af855969.jpg: 384x640 5 cars, 2 buss, 2 trucks, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a170ce-85355a1b.jpg: 384x640 2 cars, 1 truck, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a170ce-f820f869.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a178bf-5a656bed.jpg: 384x640 2 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|███████▉  | 7998/10000 [04:16<01:06, 30.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a178bf-637d1750.jpg: 384x640 1 car, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a178bf-af5c99dd.jpg: 384x640 2 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a178bf-ed8f9807.jpg: 384x640 6 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a32922-3909caf2.jpg: 384x640 3 cars, 1 traffic light, 18.3ms\n",
            "Speed: 1.8ms preprocess, 18.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8002/10000 [04:16<01:03, 31.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a42fb0-f73381b8.jpg: 384x640 4 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a4ccc0-2119ddb9.jpg: 384x640 2 cars, 13.2ms\n",
            "Speed: 4.1ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a4ccc0-2bc61efc.jpg: 384x640 6 cars, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a4ccc0-87c6df6e.jpg: 384x640 4 cars, 3 trucks, 4 traffic lights, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8006/10000 [04:16<01:04, 30.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a4ccc0-b786fbb2.jpg: 384x640 2 cars, 1 truck, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a805c8-318bd605.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5a84acc-baf6323a.jpg: 384x640 1 person, 8 cars, 1 bus, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5aa59aa-4ce7e750.jpg: 384x640 7 cars, 10.9ms\n",
            "Speed: 4.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8010/10000 [04:16<01:03, 31.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ab4d79-c244d950.jpg: 384x640 2 cars, 1 truck, 16.3ms\n",
            "Speed: 1.8ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ae33f9-a2c4f208.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ae7bf8-25901c98.jpg: 384x640 6 cars, 2 trucks, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b166fd-3156e611.jpg: 384x640 7 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8014/10000 [04:16<01:00, 32.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b166fd-443c316f.jpg: 384x640 10 cars, 1 truck, 1 traffic light, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b166fd-cb88868f.jpg: 384x640 1 person, 13 cars, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b166fd-cbe303b7.jpg: 384x640 7 cars, 15.9ms\n",
            "Speed: 1.8ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b166fd-df77bb5d.jpg: 384x640 15 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8018/10000 [04:16<01:00, 32.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b1e3f5-479118b6.jpg: 384x640 2 persons, 3 cars, 6 traffic lights, 1 bench, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-07e406a6.jpg: 384x640 5 cars, 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-1241a008.jpg: 384x640 2 persons, 3 cars, 1 truck, 1 traffic light, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-1c31cee3.jpg: 384x640 10 persons, 6 cars, 1 suitcase, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8022/10000 [04:17<01:01, 32.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-6e15c4c3.jpg: 384x640 1 person, 9 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-7e987d44.jpg: 384x640 2 cars, 2 trucks, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-9121123c.jpg: 384x640 5 persons, 6 cars, 2 traffic lights, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-a03619f7.jpg: 384x640 1 person, 5 cars, 1 bus, 3 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8026/10000 [04:17<00:59, 33.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-aa9e5484.jpg: 384x640 2 persons, 6 cars, 2 trucks, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-b5774e49.jpg: 384x640 3 persons, 6 cars, 1 bus, 1 truck, 2 traffic lights, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b2506d-d7479cbb.jpg: 384x640 1 car, 1 bus, 1 traffic light, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b29044-75af49f0.jpg: 384x640 3 cars, 1 bus, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8030/10000 [04:17<00:59, 32.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b59090-05bcd505.jpg: 384x640 1 car, 1 stop sign, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b64f27-53710b20.jpg: 384x640 1 person, 6 cars, 1 bus, 1 train, 2 trucks, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b64f27-b5bd4388.jpg: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b64f27-fc829e64.jpg: 384x640 2 cars, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8034/10000 [04:17<00:57, 34.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b6c311-962e60b4.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b6c311-9841604a.jpg: 384x640 7 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b6c311-af650f3b.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b6c311-c7351dcf.jpg: 384x640 4 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8038/10000 [04:17<00:57, 34.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b76793-172c4594.jpg: 384x640 7 cars, 2 traffic lights, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b76793-56c6c886.jpg: 384x640 2 persons, 2 cars, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b76b45-6a9e676b.jpg: 384x640 5 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b7b466-4adbd41c.jpg: 384x640 10 cars, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8042/10000 [04:17<00:55, 35.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b7b466-c3bd479a.jpg: 384x640 1 person, 1 bus, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b7b466-eac86195.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b7b466-f6066e36.jpg: 384x640 4 cars, 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b7db86-88bceca0.jpg: 384x640 2 persons, 7 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b7db86-b62a7a3f.jpg: 384x640 5 cars, 2 trucks, 13.1ms\n",
            "Speed: 5.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  80%|████████  | 8047/10000 [04:17<00:54, 35.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b80ec1-6efedb0e.jpg: 384x640 1 car, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b80ec1-7fc5097c.jpg: 384x640 5 cars, 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5b80ec1-bb9fd172.jpg: 384x640 3 cars, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ba135d-32240f6d.jpg: 384x640 2 persons, 4 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8051/10000 [04:17<00:56, 34.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5bb525f-be098cfb.jpg: 384x640 (no detections), 12.4ms\n",
            "Speed: 2.6ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5bbf929-8c3d6c80.jpg: 384x640 1 person, 10 cars, 1 truck, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5bbf929-e89aac92.jpg: 384x640 3 cars, 1 truck, 13.0ms\n",
            "Speed: 7.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5bc3aa9-0d55c4f9.jpg: 384x640 1 person, 4 cars, 3 buss, 2 traffic lights, 17.8ms\n",
            "Speed: 1.9ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8055/10000 [04:18<00:59, 32.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5bc3aa9-8be77f9c.jpg: 384x640 2 cars, 1 bus, 2 trucks, 1 traffic light, 12.7ms\n",
            "Speed: 5.6ms preprocess, 12.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5bc3aa9-d268a0aa.jpg: 384x640 1 car, 1 traffic light, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5bd516c-decd0287.jpg: 384x640 3 cars, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5bf095c-f18a6c47.jpg: 384x640 3 persons, 5 cars, 3 traffic lights, 16.0ms\n",
            "Speed: 1.9ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8059/10000 [04:18<01:01, 31.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c1956a-f18fba95.jpg: 384x640 8 cars, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c3116a-52333439.jpg: 384x640 2 cars, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c3116a-8bcf604c.jpg: 384x640 14 cars, 13.6ms\n",
            "Speed: 3.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c352c8-2b9624d5.jpg: 384x640 4 cars, 1 truck, 17.3ms\n",
            "Speed: 3.6ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8063/10000 [04:18<01:03, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c352c8-c97b0943.jpg: 384x640 7 cars, 1 truck, 1 traffic light, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c37cfe-a885a8d2.jpg: 384x640 11 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c3b858-bc1ffd47.jpg: 384x640 1 person, 4 cars, 1 bus, 1 bench, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c43551-472281ea.jpg: 384x640 7 cars, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8067/10000 [04:18<01:03, 30.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c43551-916bcae8.jpg: 384x640 19 cars, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c48d80-4204c6c7.jpg: 384x640 1 person, 3 cars, 2 traffic lights, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c48d80-d0a65d93.jpg: 384x640 3 cars, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c6fd07-9a05cafd.jpg: 384x640 (no detections), 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8071/10000 [04:18<01:01, 31.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c7c186-2f98e734.jpg: 384x640 1 person, 1 bicycle, 4 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c7c186-9381f4a2.jpg: 384x640 5 cars, 2 trucks, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c86b04-083cb3fd.jpg: 384x640 1 car, 19.6ms\n",
            "Speed: 1.9ms preprocess, 19.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c8a92c-49d1ba7c.jpg: 384x640 20 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8075/10000 [04:18<01:01, 31.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c8a92c-ed6160d8.jpg: 384x640 7 cars, 3 traffic lights, 17.6ms\n",
            "Speed: 1.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c910c6-c7aa96f1.jpg: 384x640 10 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c9d88b-71b49b27.jpg: 384x640 (no detections), 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c9d88b-cd7f4b25.jpg: 384x640 1 person, 8 cars, 1 suitcase, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8079/10000 [04:18<01:02, 30.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5c9ead6-dab2dae6.jpg: 384x640 3 cars, 1 kite, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ca1272-3f672c39.jpg: 384x640 3 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ca1272-a926594c.jpg: 384x640 3 persons, 2 cars, 1 traffic light, 1 umbrella, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ca1272-c0d0ab9a.jpg: 384x640 1 person, 4 cars, 1 train, 2 traffic lights, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8083/10000 [04:18<01:01, 31.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ca1272-df2c0491.jpg: 384x640 5 persons, 3 cars, 1 train, 2 traffic lights, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5caf169-3010206a.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5caf169-f75db8a9.jpg: 384x640 (no detections), 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5cbe746-95cc81dc.jpg: 384x640 3 cars, 1 truck, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8087/10000 [04:19<00:59, 32.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5cc1219-49036234.jpg: 384x640 4 cars, 1 truck, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5cdbe94-689ed201.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ce458d-da546f8a.jpg: 384x640 7 cars, 16.3ms\n",
            "Speed: 1.7ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ce9781-b8db3bfa.jpg: 384x640 4 cars, 2 fire hydrants, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8091/10000 [04:19<00:58, 32.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d13cf9-038d680e.jpg: 384x640 7 cars, 12.9ms\n",
            "Speed: 4.8ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d13cf9-8840eb07.jpg: 384x640 5 cars, 1 truck, 13.2ms\n",
            "Speed: 3.7ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d26790-b391812d.jpg: 384x640 7 cars, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d2daaf-bee29c76.jpg: 384x640 5 cars, 1 truck, 20.5ms\n",
            "Speed: 1.8ms preprocess, 20.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8095/10000 [04:19<01:02, 30.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d43861-1e463c29.jpg: 384x640 1 person, 4 cars, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d79098-0b67a544.jpg: 384x640 11 cars, 1 truck, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d79098-e6587dc0.jpg: 384x640 6 cars, 2 traffic lights, 13.4ms\n",
            "Speed: 3.5ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d7ce8d-55f07ede.jpg: 384x640 6 cars, 1 truck, 18.4ms\n",
            "Speed: 2.7ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8099/10000 [04:19<01:08, 27.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-1b3f0232.jpg: 384x640 1 person, 8 cars, 12.6ms\n",
            "Speed: 4.0ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-20290c25.jpg: 384x640 8 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-34365f4f.jpg: 384x640 1 person, 6 cars, 1 traffic light, 1 umbrella, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-3b452090.jpg: 384x640 3 cars, 2 buss, 1 truck, 3 traffic lights, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8103/10000 [04:19<01:05, 28.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-46e3de37.jpg: 384x640 11 cars, 1 bus, 2 trucks, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-8e525d48.jpg: 384x640 6 cars, 1 truck, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-a008f891.jpg: 384x640 6 cars, 2 trucks, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-a4e15b55.jpg: 384x640 1 person, 6 cars, 1 bus, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8107/10000 [04:19<01:04, 29.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-b0b2380b.jpg: 384x640 7 persons, 8 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-b3fffe5d.jpg: 384x640 7 persons, 2 cars, 1 bus, 1 train, 4 umbrellas, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5d864fa-dec84644.jpg: 384x640 10 cars, 1 bus, 1 truck, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5dd12e7-e1f925bf.jpg: 384x640 4 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8111/10000 [04:19<01:01, 30.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5dd7a2a-bab83a60.jpg: 384x640 3 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5dd7de4-53608747.jpg: 384x640 3 cars, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5dee1e2-e17da4f5.jpg: 384x640 7 cars, 1 truck, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5def92b-7c703f2f.jpg: 384x640 (no detections), 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8115/10000 [04:20<01:00, 31.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5def92b-a0699b4e.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5def92b-af08d4b8.jpg: 384x640 1 car, 5 trucks, 1 traffic light, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e29bbb-9d7569ec.jpg: 384x640 4 cars, 3 traffic lights, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e29bbb-d09c83c8.jpg: 384x640 4 cars, 1 truck, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8119/10000 [04:20<00:56, 33.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e32cf6-7d2e04b4.jpg: 384x640 21 cars, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e32cf6-89b8fb88.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e32cf6-cd1cec66.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e41dc2-3efd50c3.jpg: 384x640 4 cars, 1 truck, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████  | 8123/10000 [04:20<00:55, 33.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e41dc2-4be2c885.jpg: 384x640 3 cars, 3 traffic lights, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e41dc2-537a34c6.jpg: 384x640 8 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e41dc2-b8afddfc.jpg: 384x640 4 cars, 13.9ms\n",
            "Speed: 3.9ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e41dc2-c5eb4569.jpg: 384x640 8 cars, 17.4ms\n",
            "Speed: 1.9ms preprocess, 17.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████▏ | 8127/10000 [04:20<01:00, 31.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e8457e-381c8a85.jpg: 384x640 5 persons, 1 car, 1 motorcycle, 1 bus, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e8ab3b-6e92761c.jpg: 384x640 4 cars, 1 truck, 21.0ms\n",
            "Speed: 1.9ms preprocess, 21.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5e8cd7e-2fc99e96.jpg: 384x640 2 persons, 1 stop sign, 19.9ms\n",
            "Speed: 5.0ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ea1566-5388419a.jpg: 384x640 4 cars, 12.2ms\n",
            "Speed: 4.9ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████▏ | 8131/10000 [04:20<01:08, 27.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ea1566-561af343.jpg: 384x640 15 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5eb7f02-2eeb75ed.jpg: 384x640 1 person, 4 cars, 1 bus, 1 traffic light, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5eb7f02-4de68c54.jpg: 384x640 5 cars, 1 traffic light, 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████▏ | 8134/10000 [04:20<01:09, 27.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5eb7f02-6ddd1f4e.jpg: 384x640 3 cars, 2 traffic lights, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5eb7f02-80a6bb1c.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5eb7f02-c4f67fb1.jpg: 384x640 3 persons, 3 cars, 2 buss, 1 truck, 17.0ms\n",
            "Speed: 3.0ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████▏ | 8137/10000 [04:20<01:07, 27.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ec1247-80a84ca0.jpg: 384x640 4 cars, 1 bus, 1 truck, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ec5261-567ff509.jpg: 384x640 3 cars, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ed5d69-f2a3b0ed.jpg: 384x640 1 traffic light, 20.1ms\n",
            "Speed: 1.9ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████▏ | 8140/10000 [04:20<01:08, 27.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5eebbf5-1450247a.jpg: 384x640 5 cars, 1 bus, 1 truck, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f0cacd-26e83cd1.jpg: 384x640 1 person, 1 traffic light, 1 backpack, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f0cacd-3c4333b4.jpg: 384x640 5 cars, 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f27105-45b3e276.jpg: 384x640 7 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████▏ | 8144/10000 [04:21<01:06, 27.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f2e071-fcf05969.jpg: 384x640 10 cars, 1 bus, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f31e54-2e91ccbd.jpg: 384x640 8 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f31e54-76b8c52c.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f4350d-1f7632ea.jpg: 384x640 5 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  81%|████████▏ | 8148/10000 [04:21<01:02, 29.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f4350d-de142038.jpg: 384x640 4 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f4b6d4-0a740188.jpg: 384x640 3 persons, 8 cars, 1 truck, 17.8ms\n",
            "Speed: 1.8ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f4b6d4-92bcf575.jpg: 384x640 6 persons, 3 cars, 13.0ms\n",
            "Speed: 4.2ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8151/10000 [04:21<01:04, 28.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f4b6d4-eb1f94b7.jpg: 384x640 1 person, 10 cars, 18.4ms\n",
            "Speed: 1.8ms preprocess, 18.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f523f3-b5a9057e.jpg: 384x640 3 cars, 14.8ms\n",
            "Speed: 4.9ms preprocess, 14.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f87655-a6b5b5ff.jpg: 384x640 8 cars, 17.2ms\n",
            "Speed: 3.9ms preprocess, 17.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8154/10000 [04:21<01:09, 26.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f8a1ae-0d55fc7a.jpg: 384x640 1 person, 6 cars, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5f99fea-d9ccc213.jpg: 384x640 3 cars, 16.2ms\n",
            "Speed: 1.9ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5fa2573-a33e9b84.jpg: 384x640 1 person, 4 cars, 17.8ms\n",
            "Speed: 1.9ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8157/10000 [04:21<01:12, 25.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5fac5ad-8854736e.jpg: 384x640 1 person, 11 cars, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5fb6c66-c243092c.jpg: 384x640 1 person, 4 cars, 2 trucks, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5fcf26b-c3f9aa67.jpg: 384x640 1 car, 1 truck, 13.5ms\n",
            "Speed: 2.0ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8160/10000 [04:21<01:10, 26.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5fd03fa-70ea30f9.jpg: 384x640 9 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5fe7f8b-38ce05b2.jpg: 384x640 8 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5fe7f8b-522055d5.jpg: 384x640 2 persons, 5 cars, 1 truck, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5feca03-0f32ddcf.jpg: 384x640 9 cars, 12.6ms\n",
            "Speed: 4.1ms preprocess, 12.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8164/10000 [04:21<01:05, 28.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ffb92c-67f32de8.jpg: 384x640 6 cars, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c5ffb92c-772cfc9c.jpg: 384x640 2 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6013f78-376051fb.jpg: 384x640 6 cars, 1 bus, 12.2ms\n",
            "Speed: 3.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60144b6-3d65950d.jpg: 384x640 4 cars, 3 traffic lights, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8168/10000 [04:21<01:02, 29.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60144b6-62841efb.jpg: 384x640 2 persons, 4 cars, 1 traffic light, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60144b6-74583c0d.jpg: 384x640 8 persons, 2 cars, 2 traffic lights, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60144b6-76df711e.jpg: 384x640 7 cars, 15.9ms\n",
            "Speed: 1.9ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8171/10000 [04:22<01:04, 28.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60144b6-ddad5125.jpg: 384x640 2 persons, 4 cars, 2 traffic lights, 9.7ms\n",
            "Speed: 7.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c602b3c5-0bba271b.jpg: 384x640 1 car, 1 bus, 1 traffic light, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c602b3c5-8f9a3aef.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8174/10000 [04:22<01:05, 27.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60327b4-f096274e.jpg: 384x640 8 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6033a7e-3c3211ec.jpg: 384x640 6 cars, 2 traffic lights, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60535ee-007fd6dd.jpg: 384x640 5 cars, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8177/10000 [04:22<01:03, 28.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c605bc6e-78064ec8.jpg: 384x640 2 persons, 4 cars, 2 traffic lights, 17.6ms\n",
            "Speed: 2.5ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c605bc6e-a4a48e5c.jpg: 384x640 2 cars, 18.9ms\n",
            "Speed: 2.0ms preprocess, 18.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c605bc6e-b329a5c1.jpg: 384x640 8 cars, 3 traffic lights, 16.0ms\n",
            "Speed: 2.5ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8180/10000 [04:22<01:05, 27.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c606dc56-2a64e82c.jpg: 384x640 (no detections), 18.4ms\n",
            "Speed: 2.0ms preprocess, 18.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6079e86-f5203076.jpg: 384x640 4 cars, 3 trucks, 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6083af3-97345ce2.jpg: 384x640 2 trucks, 17.5ms\n",
            "Speed: 5.4ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8183/10000 [04:22<01:09, 26.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6085e74-b63938e2.jpg: 384x640 7 cars, 1 truck, 2 traffic lights, 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6089c97-fb6682fb.jpg: 384x640 3 cars, 1 truck, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60b2910-c3ce88e1.jpg: 384x640 1 car, 1 traffic light, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8186/10000 [04:22<01:10, 25.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60b2910-e0fb459f.jpg: 384x640 2 persons, 14 cars, 7 traffic lights, 11.6ms\n",
            "Speed: 4.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60b2910-eb72d5a2.jpg: 384x640 5 cars, 2 trucks, 17.2ms\n",
            "Speed: 2.1ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60b6c7a-3bc6fa12.jpg: 384x640 3 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8189/10000 [04:22<01:15, 23.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60c04c3-10c3f122.jpg: 384x640 15 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60c04c3-b48a4e84.jpg: 384x640 12 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60d6c5c-11adb0a5.jpg: 384x640 1 person, 7 cars, 1 bus, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8192/10000 [04:22<01:11, 25.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60d6c5c-689d8921.jpg: 384x640 1 person, 3 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60db1dc-73c1e986.jpg: 384x640 8 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60db1dc-f8f24f9f.jpg: 384x640 9 cars, 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60dc8c4-3c29b3e3.jpg: 384x640 3 persons, 5 cars, 1 truck, 12.1ms\n",
            "Speed: 1.7ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8196/10000 [04:22<01:06, 26.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60dc8c4-c8c80749.jpg: 384x640 9 cars, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60deb3c-d8219cc9.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60e27d7-0c92e2f2.jpg: 384x640 2 cars, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60f0eb4-bb0d650b.jpg: 384x640 12 cars, 10.6ms\n",
            "Speed: 4.3ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8200/10000 [04:23<01:03, 28.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c60ffc99-13f7f8e0.jpg: 384x640 7 cars, 1 truck, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c614250f-060df27c.jpg: 384x640 (no detections), 11.5ms\n",
            "Speed: 4.3ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c614250f-612cd1b1.jpg: 384x640 3 persons, 3 cars, 1 tv, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c614250f-8197deb8.jpg: 384x640 2 cars, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8204/10000 [04:23<01:00, 29.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6148dad-03eb1951.jpg: 384x640 3 cars, 20.5ms\n",
            "Speed: 1.8ms preprocess, 20.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6148dad-32f6f2b2.jpg: 384x640 6 cars, 1 truck, 17.6ms\n",
            "Speed: 4.7ms preprocess, 17.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6148dad-b073324c.jpg: 384x640 14 cars, 22.3ms\n",
            "Speed: 1.9ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8207/10000 [04:23<01:05, 27.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c614be17-f1d896e0.jpg: 384x640 1 person, 4 cars, 1 traffic light, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c617d219-c5bb6104.jpg: 384x640 4 cars, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6180886-aaf908a0.jpg: 384x640 5 cars, 1 bus, 2 trucks, 17.1ms\n",
            "Speed: 3.0ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8210/10000 [04:23<01:09, 25.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61820fc-ba8d6a48.jpg: 384x640 3 cars, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6193869-d2f9aed1.jpg: 384x640 1 person, 6 cars, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61af85d-0570a2a9.jpg: 384x640 7 cars, 1 truck, 15.5ms\n",
            "Speed: 4.0ms preprocess, 15.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8213/10000 [04:23<01:11, 24.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61c91ec-1c678f63.jpg: 384x640 1 person, 7 cars, 3 trucks, 1 traffic light, 15.5ms\n",
            "Speed: 3.1ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61cc09d-620a73cb.jpg: 384x640 1 car, 18.7ms\n",
            "Speed: 1.8ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61cc09d-7ba22a23.jpg: 384x640 5 cars, 1 truck, 18.1ms\n",
            "Speed: 1.8ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8216/10000 [04:23<01:12, 24.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61e0f0d-188e2618.jpg: 384x640 9 cars, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61e0f0d-96124634.jpg: 384x640 (no detections), 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61e36b0-4e14731e.jpg: 384x640 (no detections), 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c61e7344-d27499c3.jpg: 384x640 10 cars, 1 stop sign, 11.8ms\n",
            "Speed: 1.7ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8220/10000 [04:23<01:05, 27.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62073d1-3d9adad7.jpg: 384x640 2 cars, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c620ac7c-124d4be5.jpg: 384x640 (no detections), 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c620ac7c-3bbb50e2.jpg: 384x640 5 cars, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c620ac7c-f3d4e50c.jpg: 384x640 4 persons, 4 cars, 3 traffic lights, 12.5ms\n",
            "Speed: 1.7ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8224/10000 [04:23<01:00, 29.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6215f72-266bf801.jpg: 384x640 5 cars, 2 traffic lights, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6265010-8caa470f.jpg: 384x640 7 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62664f1-b6fec7e5.jpg: 384x640 4 persons, 4 cars, 2 buss, 1 truck, 18.2ms\n",
            "Speed: 1.8ms preprocess, 18.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8227/10000 [04:24<01:03, 27.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62664f1-e2a87cef.jpg: 384x640 10 cars, 2 traffic lights, 19.8ms\n",
            "Speed: 1.9ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c629768e-7da2d4f0.jpg: 384x640 5 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62ba5b8-0efc4385.jpg: 384x640 2 persons, 2 cars, 2 trucks, 13.6ms\n",
            "Speed: 2.6ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8230/10000 [04:24<01:04, 27.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62ba5b8-9119eae7.jpg: 384x640 2 persons, 6 cars, 1 traffic light, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62ba5b8-bfa3fbad.jpg: 384x640 12 cars, 1 truck, 1 traffic light, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62cf532-b431541d.jpg: 384x640 2 persons, 3 cars, 21.5ms\n",
            "Speed: 1.9ms preprocess, 21.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8233/10000 [04:24<01:08, 25.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62dc284-683bf6e9.jpg: 384x640 1 train, 14.3ms\n",
            "Speed: 5.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62dc284-926392bf.jpg: 384x640 9 cars, 1 truck, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62dc284-faca580e.jpg: 384x640 1 person, 2 cars, 15.6ms\n",
            "Speed: 2.4ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8236/10000 [04:24<01:07, 25.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62efadc-a4255fc1.jpg: 384x640 (no detections), 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c62efadc-d5d01fc2.jpg: 384x640 6 cars, 1 truck, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6301763-2abac61a.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 3.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c630c103-34a53b18.jpg: 384x640 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8240/10000 [04:24<01:01, 28.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6313a48-d945108a.jpg: 384x640 11 cars, 1 truck, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6320aee-c3faffdc.jpg: 384x640 6 cars, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6338e17-c0df8fbe.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c633cafb-496ee40f.jpg: 384x640 11 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8244/10000 [04:24<00:55, 31.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c633cafb-9ff0a3a2.jpg: 384x640 7 cars, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63428f4-7e084bea.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c634f845-8fdb6a3e.jpg: 384x640 5 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6352da9-dbb06c04.jpg: 384x640 3 cars, 3 traffic lights, 11.6ms\n",
            "Speed: 1.7ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  82%|████████▏ | 8248/10000 [04:24<00:52, 33.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6367bde-a28b0ad2.jpg: 384x640 8 cars, 1 bus, 2 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63800c9-ebf059d1.jpg: 384x640 1 person, 6 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63864a9-35e14676.jpg: 384x640 1 person, 1 car, 1 traffic light, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6387d9e-26028281.jpg: 384x640 5 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8252/10000 [04:24<00:50, 34.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6387d9e-b30064de.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c639e1c0-2eb71da1.jpg: 384x640 4 persons, 5 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63bf933-0514a263.jpg: 384x640 5 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63c27a4-6c1b3f4e.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8256/10000 [04:25<00:48, 35.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63da3b1-bb66bf72.jpg: 384x640 7 cars, 2 trucks, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63da678-d3f535e3.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63df65f-acb7276e.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63f6bb5-e23a253e.jpg: 384x640 1 person, 5 cars, 3 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8260/10000 [04:25<00:47, 36.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c63f6bb5-f2449af8.jpg: 384x640 4 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6406d76-4b7872d2.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6406d76-b7b64e81.jpg: 384x640 2 cars, 1 truck, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6406d76-bbf7229f.jpg: 384x640 1 person, 13 cars, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8264/10000 [04:25<00:46, 37.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c640ffda-035e5b98.jpg: 384x640 3 cars, 1 truck, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6424a42-1e0e0f7c.jpg: 384x640 1 person, 12 cars, 15.3ms\n",
            "Speed: 3.3ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6424a42-272aa782.jpg: 384x640 2 persons, 9 cars, 1 traffic light, 13.9ms\n",
            "Speed: 5.4ms preprocess, 13.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c643f246-e29733b4.jpg: 384x640 1 car, 17.2ms\n",
            "Speed: 1.9ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8268/10000 [04:25<00:53, 32.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c644bce5-310a172f.jpg: 384x640 7 cars, 3 traffic lights, 10.4ms\n",
            "Speed: 5.8ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c644bce5-b6465290.jpg: 384x640 2 persons, 6 cars, 3 traffic lights, 14.7ms\n",
            "Speed: 2.6ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c644e81b-53cbf3b6.jpg: 384x640 6 cars, 1 truck, 2 stop signs, 15.8ms\n",
            "Speed: 2.6ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c644e81b-d8e6dcc0.jpg: 384x640 1 truck, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8272/10000 [04:25<00:58, 29.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6459d6c-2a477f42.jpg: 384x640 2 cars, 14.3ms\n",
            "Speed: 4.9ms preprocess, 14.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6459d6c-e50530d0.jpg: 384x640 5 cars, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6468284-3d60a86b.jpg: 384x640 10 cars, 3 trucks, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c647174d-4f64af93.jpg: 384x640 4 cars, 1 train, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8276/10000 [04:25<01:00, 28.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c64d4efa-0a2488a5.jpg: 384x640 6 cars, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c64d742b-1ecf1b4b.jpg: 384x640 4 cars, 12.7ms\n",
            "Speed: 6.0ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c64d742b-b58c8bc3.jpg: 384x640 1 car, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c64dd3d9-3981f6e3.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8280/10000 [04:25<00:57, 30.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c64dd3d9-51adbe1e.jpg: 384x640 3 cars, 3 trucks, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c64dd3d9-afe20215.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c64dd3d9-ed092171.jpg: 384x640 5 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c650b257-a545cebf.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8284/10000 [04:25<00:52, 32.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-21436fe0.jpg: 384x640 1 person, 7 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-35d928df.jpg: 384x640 1 car, 1 traffic light, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-4832b39e.jpg: 384x640 5 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-525a2429.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-57169b63.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8289/10000 [04:26<00:48, 34.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-58a407e4.jpg: 384x640 5 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-6d2e9309.jpg: 384x640 3 persons, 3 cars, 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-9fe4c6f6.jpg: 384x640 1 car, 1 traffic light, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-b2454b41.jpg: 384x640 2 cars, 1 train, 2 traffic lights, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6549c4a-d3fc68f7.jpg: 384x640 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8294/10000 [04:26<00:46, 36.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65628b7-0a11aa60.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65628b7-27006fb6.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65628b7-6c13c99d.jpg: 384x640 1 car, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65628b7-78e929a2.jpg: 384x640 3 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65628b7-8260b5b1.jpg: 384x640 4 cars, 1 traffic light, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8299/10000 [04:26<00:46, 36.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65628b7-82c1aa6f.jpg: 384x640 2 cars, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65628b7-b1f37776.jpg: 384x640 3 cars, 3 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65628b7-d705638d.jpg: 384x640 2 persons, 2 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c656f999-970e284f.jpg: 384x640 5 cars, 1 traffic light, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8303/10000 [04:26<00:49, 33.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65715c7-47338a24.jpg: 384x640 1 car, 15.6ms\n",
            "Speed: 1.9ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6580b8a-368c5647.jpg: 384x640 1 person, 4 cars, 1 bus, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6580b8a-7a0bd033.jpg: 384x640 2 persons, 1 bicycle, 3 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c658c9ae-0a49e06c.jpg: 384x640 7 cars, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8307/10000 [04:26<00:49, 33.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c659e062-f6e9aeab.jpg: 384x640 7 cars, 8.9ms\n",
            "Speed: 4.5ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65b8cb4-e2aa6d2f.jpg: 384x640 6 cars, 1 traffic light, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65c2462-96e8ae92.jpg: 384x640 2 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65c2462-ccc20dff.jpg: 384x640 9 cars, 1 truck, 1 traffic light, 10.8ms\n",
            "Speed: 3.7ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8311/10000 [04:26<00:48, 34.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-0992c93a.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-11a2512b.jpg: 384x640 7 cars, 2 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-2d317fb3.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-5b33d44d.jpg: 384x640 (no detections), 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-626aeec8.jpg: 384x640 4 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8316/10000 [04:26<00:46, 36.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-92b77f49.jpg: 384x640 1 car, 2 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-be0f479e.jpg: 384x640 1 car, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-dd2e932b.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65d48bf-e65698bd.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65eb5d6-e90e41da.jpg: 384x640 2 cars, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8321/10000 [04:26<00:43, 38.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65f7702-979ab570.jpg: 384x640 9 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65fad1e-08c796e4.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c65fad1e-d790b8ce.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c661115f-f6d1c64b.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66202a8-69baf495.jpg: 384x640 5 persons, 7 cars, 1 bus, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8326/10000 [04:27<00:43, 38.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c663ebc6-21dbeb77.jpg: 384x640 3 persons, 7 cars, 1 traffic light, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c663ebc6-46365c70.jpg: 384x640 7 persons, 4 cars, 3 traffic lights, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c664605e-3e933e30.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c664605e-44460227.jpg: 384x640 12 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8330/10000 [04:27<00:44, 37.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c664605e-abd72a76.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6648ad5-91058550.jpg: 384x640 3 cars, 1 traffic light, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c665137e-6fffaf45.jpg: 384x640 11 cars, 2 trucks, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c665137e-a9471287.jpg: 384x640 6 cars, 1 truck, 14.8ms\n",
            "Speed: 3.1ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8334/10000 [04:27<00:47, 35.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c665137e-c5ba935a.jpg: 384x640 3 cars, 3 traffic lights, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66a2cb5-64bc6565.jpg: 384x640 8 cars, 1 truck, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66a2cb5-7299f544.jpg: 384x640 11 cars, 1 truck, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66a2cb5-80c469d8.jpg: 384x640 3 cars, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8338/10000 [04:27<00:50, 32.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66c11e4-d8f18588.jpg: 384x640 2 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66c630d-0ffac45a.jpg: 384x640 4 cars, 14.1ms\n",
            "Speed: 2.0ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66c630d-50cda53e.jpg: 384x640 5 cars, 1 bus, 4 trucks, 1 fire hydrant, 19.3ms\n",
            "Speed: 1.9ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66c630d-66c67fe0.jpg: 384x640 4 cars, 2 buss, 2 trucks, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8342/10000 [04:27<00:51, 31.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66c630d-8cc5464a.jpg: 384x640 2 persons, 1 car, 1 truck, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66c630d-a9d179a7.jpg: 384x640 1 person, 1 car, 2 buss, 2 trucks, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66c630d-fd7e3bff.jpg: 384x640 8 persons, 8 cars, 2 traffic lights, 1 handbag, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66c709e-de7a55ed.jpg: 384x640 4 persons, 3 cars, 2 buss, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  83%|████████▎ | 8346/10000 [04:27<00:51, 32.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66cd6fa-73c96046.jpg: 384x640 4 cars, 1 traffic light, 1 fire hydrant, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66cd6fa-979934f5.jpg: 384x640 3 cars, 1 fire hydrant, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66cd6fa-bd40ffc6.jpg: 384x640 4 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66cd6fa-e9647604.jpg: 384x640 4 persons, 4 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▎ | 8350/10000 [04:27<00:49, 33.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66d2237-f9c0a1ef.jpg: 384x640 11 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66db7be-0ca75b1b.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c66f60f8-4a20099b.jpg: 384x640 1 person, 9 cars, 1 fire hydrant, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c67075c0-452a5634.jpg: 384x640 1 car, 1 truck, 1 traffic light, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▎ | 8354/10000 [04:27<00:48, 33.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c67075c0-f1638c70.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6716c49-04844b01.jpg: 384x640 6 persons, 2 cars, 2 stop signs, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6716c49-8a602ea6.jpg: 384x640 7 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6716c49-d48c3543.jpg: 384x640 1 person, 1 bicycle, 5 cars, 2 motorcycles, 1 truck, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▎ | 8358/10000 [04:27<00:48, 34.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c671fa68-14538adf.jpg: 384x640 2 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c671fa68-f2ce610d.jpg: 384x640 16 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6728701-1fccb956.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 1 stop sign, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6728701-5480540c.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▎ | 8362/10000 [04:28<00:47, 34.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6728701-f427d429.jpg: 384x640 6 persons, 3 cars, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6735e95-d11ae6b2.jpg: 384x640 5 cars, 16.1ms\n",
            "Speed: 4.1ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c675081b-c71e159b.jpg: 384x640 5 cars, 1 truck, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c675081b-df5291b4.jpg: 384x640 4 persons, 5 cars, 1 truck, 3 traffic lights, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▎ | 8366/10000 [04:28<00:50, 32.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6758a15-21120f89.jpg: 384x640 1 person, 11 cars, 1 truck, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6758a15-258953c9.jpg: 384x640 1 person, 2 cars, 1 bus, 2 trucks, 4 traffic lights, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6758a15-46130d04.jpg: 384x640 3 cars, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6758a15-8b8246b8.jpg: 384x640 1 person, 5 cars, 1 bus, 2 trucks, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▎ | 8370/10000 [04:28<00:51, 31.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6758a15-9154b963.jpg: 384x640 8 cars, 1 truck, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6758a15-c0202b07.jpg: 384x640 3 persons, 4 cars, 1 fire hydrant, 1 potted plant, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6758a15-d4e2e5ac.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c676514a-1f48a274.jpg: 384x640 2 cars, 13.1ms\n",
            "Speed: 3.1ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▎ | 8374/10000 [04:28<00:51, 31.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c676514a-85a373fc.jpg: 384x640 1 person, 5 cars, 1 traffic light, 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c676514a-8b4d18b7.jpg: 384x640 1 person, 6 cars, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c676514a-c538c5ba.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c676514a-f5d635ae.jpg: 384x640 2 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8378/10000 [04:28<00:52, 31.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6774481-eeba09a9.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c678271e-1cc5809d.jpg: 384x640 (no detections), 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c678271e-55faa3a7.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6785f37-20a97e19.jpg: 384x640 2 persons, 7 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8382/10000 [04:28<00:48, 33.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6785f37-95b28780.jpg: 384x640 1 person, 2 cars, 1 fire hydrant, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c678cb00-1c6211ab.jpg: 384x640 8 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c67c0532-e4a96360.jpg: 384x640 10 cars, 1 truck, 1 traffic light, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c67f1dd2-995c9a8f.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8386/10000 [04:28<00:48, 33.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c680eea3-5a7f9086.jpg: 384x640 7 cars, 4 traffic lights, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c682e776-650bfd20.jpg: 384x640 3 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c682e776-d20a6f25.jpg: 384x640 1 car, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c682e86e-049c847f.jpg: 384x640 4 persons, 9 cars, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8390/10000 [04:28<00:47, 34.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c683d905-119c0ee3.jpg: 384x640 3 cars, 2 traffic lights, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c683d905-eca9ea1a.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c684b9be-e666905f.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c685aea9-1f0ae51d.jpg: 384x640 5 persons, 1 bicycle, 8 cars, 1 motorcycle, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8394/10000 [04:29<00:47, 33.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c685aea9-2f9e84d2.jpg: 384x640 3 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c685aea9-bdeca101.jpg: 384x640 6 persons, 10 cars, 2 trucks, 1 traffic light, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6864b90-0632ce1d.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6864b90-498a3912.jpg: 384x640 1 car, 1 traffic light, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8398/10000 [04:29<00:46, 34.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6866060-6e8de1dd.jpg: 384x640 3 cars, 1 traffic light, 12.5ms\n",
            "Speed: 3.0ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6869d32-cf456c0d.jpg: 384x640 2 persons, 3 cars, 15.6ms\n",
            "Speed: 2.4ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6874e8e-439ea4de.jpg: 384x640 13 cars, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c687f5c9-13db3c6a.jpg: 384x640 2 cars, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8402/10000 [04:29<00:50, 31.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68a02cc-7324141d.jpg: 384x640 1 person, 8 cars, 12.3ms\n",
            "Speed: 6.1ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68b1d0c-06cda4b9.jpg: 384x640 2 cars, 2 traffic lights, 15.0ms\n",
            "Speed: 2.5ms preprocess, 15.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68bb3b7-ae8ce5d9.jpg: 384x640 2 persons, 8 cars, 2 traffic lights, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68d9027-9707e4ed.jpg: 384x640 11 cars, 1 truck, 1 traffic light, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8406/10000 [04:29<00:53, 29.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68dcb6b-c1775bef.jpg: 384x640 1 person, 9 cars, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68dcb6b-c30a5417.jpg: 384x640 (no detections), 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68dcb6b-fe86ae43.jpg: 384x640 2 cars, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68e50e0-1d6a90a8.jpg: 384x640 7 cars, 1 truck, 13.2ms\n",
            "Speed: 5.5ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8410/10000 [04:29<00:54, 28.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68e50e0-65803c55.jpg: 384x640 10 cars, 3 traffic lights, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68e50e0-91685ec0.jpg: 384x640 8 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68f8fd2-61681484.jpg: 384x640 15 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8413/10000 [04:29<00:54, 29.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c68f995b-912c3dbc.jpg: 384x640 1 car, 1 stop sign, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c690ecdd-1dd0cb93.jpg: 384x640 4 persons, 2 cars, 1 truck, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c690ecdd-3bb51114.jpg: 384x640 4 cars, 1 bus, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c690ecdd-4d7973ad.jpg: 384x640 3 persons, 5 cars, 2 buss, 2 trucks, 1 traffic light, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8417/10000 [04:29<00:51, 30.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c690ecdd-50b666c1.jpg: 384x640 4 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c690ecdd-f44a7b4f.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 2.5ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69108fc-10f773dd.jpg: 384x640 11 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6921a51-1735be44.jpg: 384x640 4 persons, 8 cars, 1 bus, 2 trucks, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8421/10000 [04:30<00:51, 30.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6921a51-7d615920.jpg: 384x640 1 car, 1 truck, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6921a51-a36f6af9.jpg: 384x640 7 cars, 2 trucks, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6921a51-c3847215.jpg: 384x640 6 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69227ec-e31502fc.jpg: 384x640 1 person, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8425/10000 [04:30<00:49, 31.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c692ed67-1f8ee968.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6959e96-3e8a0c43.jpg: 384x640 5 cars, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6959e96-6c064011.jpg: 384x640 4 cars, 1 bus, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6959e96-dd05fa7a.jpg: 384x640 7 cars, 11.0ms\n",
            "Speed: 1.7ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8429/10000 [04:30<00:48, 32.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c695fbd3-0a91a52f.jpg: 384x640 3 persons, 13 cars, 1 truck, 1 traffic light, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c696b1c8-4e0accee.jpg: 384x640 7 cars, 1 traffic light, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c696b1c8-b2fba873.jpg: 384x640 7 cars, 1 bus, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c698371e-09aa1092.jpg: 384x640 1 person, 3 cars, 1 bus, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8433/10000 [04:30<00:50, 31.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c698371e-5626f7bb.jpg: 384x640 6 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c698371e-9085357c.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c698371e-9c81ea92.jpg: 384x640 3 cars, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c698371e-a290fa18.jpg: 384x640 1 person, 13 cars, 1 truck, 12.8ms\n",
            "Speed: 7.0ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8437/10000 [04:30<00:52, 29.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c698371e-c1d58557.jpg: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c699a513-c5a722fe.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69b26c7-3fa6979b.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69bb841-f9ad4a40.jpg: 384x640 5 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8441/10000 [04:30<00:49, 31.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69d1519-d0c95d6b.jpg: 384x640 1 car, 1 traffic light, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69d1519-dfb88cdf.jpg: 384x640 5 cars, 16.7ms\n",
            "Speed: 1.8ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69d1519-f8c8bbe8.jpg: 384x640 8 cars, 1 truck, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69e5864-010993d7.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8445/10000 [04:30<00:48, 31.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69e5864-06a7595c.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69e5864-1e46bd03.jpg: 384x640 2 persons, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69e5864-73ad0cfc.jpg: 384x640 1 traffic light, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c69f536a-9d45ee3d.jpg: 384x640 22 cars, 2 traffic lights, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  84%|████████▍ | 8449/10000 [04:30<00:48, 31.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a0e7c1-4171ca59.jpg: 384x640 1 person, 3 buss, 1 train, 9.4ms\n",
            "Speed: 3.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a0e7c1-b9bc987c.jpg: 384x640 3 cars, 2 trucks, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a0f0b4-648cd548.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a2100d-d6e54e21.jpg: 384x640 1 person, 2 bicycles, 2 cars, 3 traffic lights, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8453/10000 [04:31<00:47, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a23a03-fb6ef9c3.jpg: 384x640 1 car, 1 cell phone, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a23c7a-6e9d3e9e.jpg: 384x640 7 cars, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a2eca5-747ac934.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 2.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a2eca5-a06c9e5b.jpg: 384x640 2 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8457/10000 [04:31<00:45, 33.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a365eb-7d11a7c1.jpg: 384x640 7 cars, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a3d2c9-ccd19954.jpg: 384x640 10 cars, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a47cec-c221b550.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a4abc9-1b48b2ab.jpg: 384x640 6 cars, 3 trucks, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8461/10000 [04:31<00:44, 34.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a4abc9-35b69a8f.jpg: 384x640 4 cars, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a4abc9-8897c0c0.jpg: 384x640 8 cars, 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a4abc9-e999da65.jpg: 384x640 7 cars, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a5ec44-26ea8514.jpg: 384x640 15 cars, 1 truck, 16.4ms\n",
            "Speed: 2.6ms preprocess, 16.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8465/10000 [04:31<00:50, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a5ec44-7b0e5542.jpg: 384x640 1 car, 1 truck, 16.6ms\n",
            "Speed: 2.4ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a922ec-c98fe832.jpg: 384x640 1 person, 5 cars, 1 bus, 1 truck, 14.6ms\n",
            "Speed: 3.0ms preprocess, 14.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6a94213-9e85fba1.jpg: 384x640 4 persons, 1 car, 2 buss, 1 truck, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ad7737-578d58ca.jpg: 384x640 1 person, 2 cars, 2 buss, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8469/10000 [04:31<00:51, 29.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ad7737-9c7f7e4e.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ad7737-dfa1f87b.jpg: 384x640 1 person, 7 cars, 1 truck, 1 traffic light, 1 tv, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6adfd20-170409d2.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6adfd20-788e8bba.jpg: 384x640 2 cars, 1 bus, 1 truck, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8473/10000 [04:31<00:48, 31.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6adfd20-c54d2b0f.jpg: 384x640 4 cars, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6adfd20-d22d0b5d.jpg: 384x640 1 person, 5 cars, 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6adfd20-e456ed13.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6adfd20-ef044a06.jpg: 384x640 6 cars, 1 traffic light, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8477/10000 [04:31<00:47, 32.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6af1e13-28b184aa.jpg: 384x640 3 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6af1e13-951da297.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6af6422-517e663a.jpg: 384x640 7 cars, 1 truck, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6af6422-ca528e3b.jpg: 384x640 3 persons, 3 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8481/10000 [04:31<00:45, 33.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b2d249-04498047.jpg: 384x640 4 cars, 5 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b2e302-cdffaf82.jpg: 384x640 5 cars, 1 truck, 3 traffic lights, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b45cee-d74b5791.jpg: 384x640 10 cars, 1 bus, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b45cee-f5551819.jpg: 384x640 3 persons, 10 cars, 1 truck, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8485/10000 [04:32<00:47, 31.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b511a2-d0de577c.jpg: 384x640 9 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b518ec-31800547.jpg: 384x640 2 persons, 5 cars, 3 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b748e6-e281f93f.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b7ebec-b2b3a6c0.jpg: 384x640 4 cars, 2 traffic lights, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8489/10000 [04:32<00:47, 31.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b8dc9c-1d5e230a.jpg: 384x640 8 cars, 1 truck, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6b8f394-6e6a9b99.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bb2e07-3276c201.jpg: 384x640 9 cars, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 2.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bb2e07-5ed95699.jpg: 384x640 1 car, 1 train, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8493/10000 [04:32<00:47, 31.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bb2e07-b043bd9e.jpg: 384x640 6 cars, 3 traffic lights, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bb3f2e-9bfda4df.jpg: 384x640 1 car, 2 traffic lights, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bb7ee7-9fec7fdb.jpg: 384x640 12 cars, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bb8a0c-bdba1c5d.jpg: 384x640 1 car, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▍ | 8497/10000 [04:32<00:48, 31.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bb9629-1727269a.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bc8f3a-29ce4dc7.jpg: 384x640 2 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bc8f3a-719bb999.jpg: 384x640 (no detections), 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bd6f3b-d6ad11b5.jpg: 384x640 2 persons, 3 cars, 1 bus, 1 truck, 1 traffic light, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8501/10000 [04:32<00:47, 31.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bf8d8a-10605e47.jpg: 384x640 5 cars, 16.9ms\n",
            "Speed: 1.8ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bf8d8a-3bfd59ec.jpg: 384x640 4 cars, 1 traffic light, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bf8d8a-8bb7b192.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bf8d8a-b5474262.jpg: 384x640 3 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8505/10000 [04:32<00:48, 31.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6bf8d8a-d624de6b.jpg: 384x640 3 traffic lights, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6c08fb0-7a88ba27.jpg: 384x640 2 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6c08fb0-cb0efab6.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6c1c9ad-c21d153e.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6c642f5-730bd067.jpg: 384x640 2 persons, 9 cars, 1 motorcycle, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8510/10000 [04:32<00:44, 33.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6c75718-c93cfdd7.jpg: 384x640 4 cars, 1 traffic light, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6c8c8a2-cb166bb4.jpg: 384x640 2 cars, 1 traffic light, 22.9ms\n",
            "Speed: 1.9ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ca1dcf-635b762f.jpg: 384x640 3 cars, 1 truck, 1 traffic light, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ca7b50-2ef0a79b.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8514/10000 [04:32<00:46, 32.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ca7b50-4238e038.jpg: 384x640 6 cars, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ca7b50-602f0d02.jpg: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6cd3ccb-b775a5a3.jpg: 384x640 5 cars, 1 truck, 3 traffic lights, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6cde742-b3cceffb.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8518/10000 [04:33<00:44, 33.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6cde742-d52d93a3.jpg: 384x640 3 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6cde7ef-8fc5b688.jpg: 384x640 2 cars, 1 bus, 1 train, 1 truck, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6cf9b39-8831232f.jpg: 384x640 14 cars, 1 truck, 2 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d086e9-0a3f83a3.jpg: 384x640 5 persons, 3 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8522/10000 [04:33<00:44, 33.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d36663-2e8ff6e3.jpg: 384x640 12 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d4654c-0ec10f99.jpg: 384x640 5 cars, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d4654c-a9e415d3.jpg: 384x640 1 traffic light, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d4654c-b09e2a6a.jpg: 384x640 4 cars, 2 traffic lights, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8526/10000 [04:33<00:44, 33.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d4654c-b49944e7.jpg: 384x640 4 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d4654c-caa2d45e.jpg: 384x640 5 cars, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d51f76-d2459db8.jpg: 384x640 1 car, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d586ad-8f0af0ac.jpg: 384x640 1 person, 10 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8530/10000 [04:33<00:44, 32.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d6600c-e4287c96.jpg: 384x640 2 cars, 1 traffic light, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d6c72d-e3bb94af.jpg: 384x640 1 car, 3 traffic lights, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d7400d-8a08045e.jpg: 384x640 10 cars, 1 traffic light, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d77a40-03423c96.jpg: 384x640 2 cars, 1 bus, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8534/10000 [04:33<00:45, 32.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d98de9-cca2e483.jpg: 384x640 1 car, 1 truck, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6d98de9-fcc2713e.jpg: 384x640 4 cars, 2 traffic lights, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6da617f-977c903c.jpg: 384x640 2 persons, 1 bicycle, 10 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6da617f-f5c8afd5.jpg: 384x640 2 persons, 2 cars, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8538/10000 [04:33<00:44, 32.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6da9a5f-4f00039a.jpg: 384x640 3 cars, 2 trucks, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dad47e-47a61b83.jpg: 384x640 1 person, 3 cars, 1 truck, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6db6944-7256efcc.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6db6944-dd240a03.jpg: 384x640 1 person, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6db7763-bd0a64d2.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8543/10000 [04:33<00:41, 35.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dbe91f-4551ad42.jpg: 384x640 (no detections), 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dca574-5a3415b5.jpg: 384x640 8 cars, 1 truck, 4 traffic lights, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dca574-6e641016.jpg: 384x640 2 persons, 9 cars, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dca574-a5f624f4.jpg: 384x640 10 cars, 2 trucks, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  85%|████████▌ | 8547/10000 [04:33<00:41, 34.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dcb37c-ffd8264e.jpg: 384x640 2 persons, 1 car, 1 bus, 1 traffic light, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dcc1a9-0fa80e62.jpg: 384x640 7 cars, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dd289c-693cb0cb.jpg: 384x640 7 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6deff23-56aa65be.jpg: 384x640 2 cars, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8551/10000 [04:34<00:42, 33.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dfb2b8-a74025b0.jpg: 384x640 7 cars, 2 trucks, 1 traffic light, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dfbd67-2c7061bf.jpg: 384x640 11 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dfe6aa-5d33796c.jpg: 384x640 4 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6dfe6aa-d2b95ea8.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8555/10000 [04:34<00:43, 33.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e17725-4e651f0a.jpg: 384x640 10 cars, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e1c974-906461f4.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e2af77-d588bb3e.jpg: 384x640 5 cars, 1 truck, 2 traffic lights, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e2cfc8-cfab245b.jpg: 384x640 1 person, 2 cars, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8559/10000 [04:34<00:43, 32.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e385cd-2cc5c344.jpg: 384x640 4 cars, 16.2ms\n",
            "Speed: 2.6ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e3fc7e-9262d8ed.jpg: 384x640 2 cars, 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e4273a-c3e46891.jpg: 384x640 1 person, 1 car, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e430f3-b658f65a.jpg: 384x640 7 cars, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8563/10000 [04:34<00:46, 31.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e52b8f-d719fd87.jpg: 384x640 6 cars, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e52b8f-eb7a0bd6.jpg: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e6f87c-6b32379a.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6e6f87c-814bdcee.jpg: 384x640 5 cars, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8567/10000 [04:34<00:46, 30.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ea1428-223b4063.jpg: 384x640 10 cars, 1 truck, 4 traffic lights, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ebf831-45affcf4.jpg: 384x640 3 cars, 1 truck, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ec3031-9fa4354c.jpg: 384x640 1 person, 3 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ec3031-cb866ce6.jpg: 384x640 2 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8571/10000 [04:34<00:47, 30.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ed0e98-491efc53.jpg: 384x640 1 car, 1 bus, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ed8102-2bbcbcc2.jpg: 384x640 3 cars, 13.4ms\n",
            "Speed: 6.1ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ed8102-b74b0fad.jpg: 384x640 17 cars, 1 truck, 14.5ms\n",
            "Speed: 3.9ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ed8102-c341da76.jpg: 384x640 14 cars, 1 truck, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8575/10000 [04:34<00:49, 28.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ed86ea-af629103.jpg: 384x640 5 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ef5bc4-1ce53885.jpg: 384x640 5 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ef5bc4-96451c0f.jpg: 384x640 1 person, 2 cars, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ef5bc4-b8cbb710.jpg: 384x640 2 cars, 1 traffic light, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8579/10000 [04:34<00:47, 29.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6f14304-88396ae1.jpg: 384x640 15 cars, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6f14304-e9ad93b9.jpg: 384x640 3 cars, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6f6368c-082957c9.jpg: 384x640 3 persons, 5 cars, 1 bus, 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6f6368c-0e7cbc68.jpg: 384x640 10 cars, 1 bus, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8583/10000 [04:35<00:49, 28.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6f6368c-5890d128.jpg: 384x640 20 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6f9ec52-0bf3e2f7.jpg: 384x640 4 cars, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6fa26d7-056d2a63.jpg: 384x640 6 cars, 1 truck, 1 traffic light, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8586/10000 [04:35<00:48, 28.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6fa5a37-cfd67380.jpg: 384x640 (no detections), 16.3ms\n",
            "Speed: 4.9ms preprocess, 16.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6faa6aa-72bde8a8.jpg: 384x640 5 cars, 18.4ms\n",
            "Speed: 2.4ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6fe2d9d-833142b5.jpg: 384x640 3 persons, 17 cars, 1 traffic light, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8589/10000 [04:35<00:52, 27.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6fea8ac-016040c9.jpg: 384x640 4 cars, 16.6ms\n",
            "Speed: 4.4ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6fea8ac-24b0027a.jpg: 384x640 3 cars, 16.6ms\n",
            "Speed: 2.1ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6fea8ac-31b5f2f4.jpg: 384x640 7 cars, 18.2ms\n",
            "Speed: 2.4ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8592/10000 [04:35<00:52, 26.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6fea8ac-67e16511.jpg: 384x640 3 cars, 1 traffic light, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ffd190-bde22441.jpg: 384x640 3 persons, 2 cars, 16.9ms\n",
            "Speed: 2.7ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ffd190-c9536b0b.jpg: 384x640 1 person, 1 car, 2 traffic lights, 18.7ms\n",
            "Speed: 2.3ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8595/10000 [04:35<00:51, 27.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c6ffd190-dae2fb47.jpg: 384x640 1 car, 15.3ms\n",
            "Speed: 1.8ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c700966a-608d05b4.jpg: 384x640 1 person, 2 cars, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c703904e-4aae94cd.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7049707-934a08d2.jpg: 384x640 8 cars, 1 truck, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8599/10000 [04:35<00:48, 28.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7053a50-d465ffa3.jpg: 384x640 5 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c705bd4a-ae862ae1.jpg: 384x640 2 cars, 1 truck, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c708dc9d-12f425eb.jpg: 384x640 9 cars, 15.7ms\n",
            "Speed: 1.7ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8602/10000 [04:35<00:48, 29.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c709a8e6-502a3b03.jpg: 384x640 2 cars, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c709b82a-a5ff98a2.jpg: 384x640 5 cars, 1 bus, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70a8ace-77774f58.jpg: 384x640 8 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70a8ace-931896fd.jpg: 384x640 3 persons, 1 car, 2 umbrellas, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8606/10000 [04:35<00:44, 31.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70ba359-a4b00815.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70e18ba-0a1b3743.jpg: 384x640 1 person, 6 cars, 1 bus, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70e5493-73848573.jpg: 384x640 2 cars, 2 traffic lights, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70f6d09-37a78b82.jpg: 384x640 5 cars, 18.3ms\n",
            "Speed: 2.1ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8610/10000 [04:36<00:42, 32.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70f6d09-3bcec902.jpg: 384x640 10 cars, 9.7ms\n",
            "Speed: 5.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70f6d09-9850664f.jpg: 384x640 13 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c70f6d09-efd1a01f.jpg: 384x640 4 persons, 1 car, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71090cc-df17811c.jpg: 384x640 2 cars, 2 traffic lights, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8614/10000 [04:36<00:41, 33.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7117810-0f9dda23.jpg: 384x640 4 cars, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7117810-2947b975.jpg: 384x640 11 cars, 1 traffic light, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c711ef96-c4582caa.jpg: 384x640 15 cars, 1 truck, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7123e22-f72e03fb.jpg: 384x640 1 car, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8618/10000 [04:36<00:39, 34.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7134df6-28b042b5.jpg: 384x640 2 persons, 4 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7134df6-ef92e0cd.jpg: 384x640 10 cars, 1 truck, 1 traffic light, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7140eaa-eb9d0128.jpg: 384x640 2 cars, 1 truck, 1 stop sign, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7151d3d-27632b12.jpg: 384x640 1 person, 2 cars, 16.7ms\n",
            "Speed: 2.9ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▌ | 8622/10000 [04:36<00:42, 32.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7151d3d-3db93c62.jpg: 384x640 4 cars, 14.9ms\n",
            "Speed: 3.8ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c715680d-cd283438.jpg: 384x640 4 cars, 3 traffic lights, 14.4ms\n",
            "Speed: 3.5ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71664d9-6ce742a8.jpg: 384x640 2 cars, 1 traffic light, 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71751ee-07587650.jpg: 384x640 1 person, 3 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▋ | 8626/10000 [04:36<00:43, 31.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71751ee-b6f43370.jpg: 384x640 5 cars, 19.0ms\n",
            "Speed: 2.1ms preprocess, 19.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c717fdbd-9b7ef8e2.jpg: 384x640 (no detections), 19.9ms\n",
            "Speed: 2.1ms preprocess, 19.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c718a581-814b4e2d.jpg: 384x640 4 cars, 2 trucks, 1 traffic light, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71936fa-e8370814.jpg: 384x640 2 cars, 3 trucks, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▋ | 8630/10000 [04:36<00:44, 30.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71a5c66-93c9eca0.jpg: 384x640 7 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71de7ef-6343421b.jpg: 384x640 9 cars, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71de7ef-ad5d9110.jpg: 384x640 6 cars, 1 bus, 1 traffic light, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71ef5d9-28743600.jpg: 384x640 8 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▋ | 8634/10000 [04:36<00:45, 30.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c71fcdc8-62a7fa51.jpg: 384x640 3 persons, 3 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c720a13e-ab9c54e7.jpg: 384x640 2 persons, 5 cars, 1 traffic light, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7210a1f-14f8d4ca.jpg: 384x640 2 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c721de81-300f3026.jpg: 384x640 10 cars, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▋ | 8638/10000 [04:36<00:43, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c721de81-d9e0ad96.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72373c0-af574c12.jpg: 384x640 6 cars, 8.2ms\n",
            "Speed: 3.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c723a926-5aaa770c.jpg: 384x640 10 cars, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c723a926-c9bf868b.jpg: 384x640 12 cars, 8.1ms\n",
            "Speed: 7.4ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▋ | 8642/10000 [04:37<00:42, 31.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c723ad21-efed33e5.jpg: 384x640 2 cars, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7265ddc-8f25fc15.jpg: 384x640 2 cars, 1 truck, 15.1ms\n",
            "Speed: 1.8ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72762cc-135927f8.jpg: 384x640 1 car, 11.0ms\n",
            "Speed: 1.7ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7284932-c3a7badf.jpg: 384x640 2 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▋ | 8646/10000 [04:37<00:42, 31.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7284932-f669eff5.jpg: 384x640 2 persons, 3 cars, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7292daf-0761f9c4.jpg: 384x640 4 cars, 3 traffic lights, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7292daf-2ae2a507.jpg: 384x640 8 cars, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72b8356-0bac66a5.jpg: 384x640 1 person, 2 cars, 2 traffic lights, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  86%|████████▋ | 8650/10000 [04:37<00:42, 31.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72c701f-82bf3c37.jpg: 384x640 14 cars, 1 truck, 16.7ms\n",
            "Speed: 2.0ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72d0482-3ae5270e.jpg: 384x640 1 car, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72d0482-c226185a.jpg: 384x640 4 cars, 1 fire hydrant, 16.8ms\n",
            "Speed: 4.0ms preprocess, 16.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72d9780-b7cdea29.jpg: 384x640 7 cars, 20.5ms\n",
            "Speed: 2.0ms preprocess, 20.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8654/10000 [04:37<00:48, 27.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72db42a-c9ea9102.jpg: 384x640 4 cars, 1 truck, 13.3ms\n",
            "Speed: 6.0ms preprocess, 13.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c72e0355-d4ee4973.jpg: 384x640 12 cars, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c730155e-19f0cc5c.jpg: 384x640 1 person, 7 cars, 14.5ms\n",
            "Speed: 2.1ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8657/10000 [04:37<00:51, 25.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c730a403-03ecee1b.jpg: 384x640 4 cars, 2 traffic lights, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c732f53b-304559b2.jpg: 384x640 2 cars, 1 truck, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c732f6d7-2a52f70b.jpg: 384x640 3 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8660/10000 [04:37<00:50, 26.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7331983-36418bf8.jpg: 384x640 1 car, 1 truck, 4 traffic lights, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c733594f-0aa2baf5.jpg: 384x640 1 person, 2 cars, 1 truck, 12.0ms\n",
            "Speed: 3.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c733594f-2568d430.jpg: 384x640 9 cars, 1 traffic light, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8663/10000 [04:37<00:50, 26.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c733594f-86a37630.jpg: 384x640 1 person, 1 car, 1 traffic light, 1 umbrella, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7339013-3979b7a2.jpg: 384x640 4 cars, 2 traffic lights, 11.7ms\n",
            "Speed: 4.9ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7339013-995a01cf.jpg: 384x640 2 cars, 3 traffic lights, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7346130-9d225646.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 4.8ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8667/10000 [04:37<00:46, 28.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c734eb0a-125bba62.jpg: 384x640 5 cars, 11.3ms\n",
            "Speed: 5.1ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c734eb0a-9d6807cb.jpg: 384x640 4 cars, 15.4ms\n",
            "Speed: 1.8ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c737e602-e8793fdc.jpg: 384x640 10 cars, 5 traffic lights, 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8670/10000 [04:38<00:46, 28.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c73abec5-609ede44.jpg: 384x640 2 cars, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c73bced0-43cfc465.jpg: 384x640 3 cars, 9.0ms\n",
            "Speed: 4.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c73bf483-e195b9aa.jpg: 384x640 7 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c73c95f5-2fc1e83d.jpg: 384x640 4 cars, 1 bus, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8674/10000 [04:38<00:44, 29.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c73ca2e7-37f54fa3.jpg: 384x640 5 cars, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c73dee17-6195a64e.jpg: 384x640 1 person, 2 cars, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c73dee17-cf17ae38.jpg: 384x640 (no detections), 17.3ms\n",
            "Speed: 2.6ms preprocess, 17.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c740132e-3c47b4b5.jpg: 384x640 2 cars, 1 traffic light, 20.4ms\n",
            "Speed: 2.9ms preprocess, 20.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8678/10000 [04:38<00:44, 29.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c740132e-4806ffd1.jpg: 384x640 1 car, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c740132e-db258b89.jpg: 384x640 7 cars, 23.1ms\n",
            "Speed: 2.0ms preprocess, 23.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7415d8d-8a2c5150.jpg: 384x640 7 persons, 5 cars, 1 umbrella, 1 handbag, 22.1ms\n",
            "Speed: 1.9ms preprocess, 22.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8681/10000 [04:38<00:48, 27.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7415d8d-cdebab3b.jpg: 384x640 12 persons, 10 cars, 16.8ms\n",
            "Speed: 4.9ms preprocess, 16.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7415d8d-dfb8ef47.jpg: 384x640 11 persons, 4 cars, 1 bus, 1 truck, 5 handbags, 21.7ms\n",
            "Speed: 1.9ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7416644-6723bcd7.jpg: 384x640 4 cars, 1 bus, 1 traffic light, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8684/10000 [04:38<00:51, 25.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7416644-f82aa227.jpg: 384x640 4 cars, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c741a3b6-17ca1b7e.jpg: 384x640 3 cars, 1 boat, 14.8ms\n",
            "Speed: 1.9ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7426098-2eeb9015.jpg: 384x640 7 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7429cad-6e71e583.jpg: 384x640 1 person, 4 cars, 1 traffic light, 11.6ms\n",
            "Speed: 4.9ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8688/10000 [04:38<00:48, 26.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7472294-1eb27561.jpg: 384x640 2 cars, 1 traffic light, 11.9ms\n",
            "Speed: 4.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7472294-e121cc79.jpg: 384x640 2 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c747bbbf-683dbc92.jpg: 384x640 1 car, 2 traffic lights, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c748c1a1-04115595.jpg: 384x640 2 persons, 4 cars, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8692/10000 [04:38<00:44, 29.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c748c1a1-2f810acf.jpg: 384x640 1 person, 13 cars, 1 traffic light, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c748c1a1-55dcbfcd.jpg: 384x640 11 cars, 10.8ms\n",
            "Speed: 4.0ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c748c1a1-58870d4a.jpg: 384x640 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c748c1a1-5fd778ff.jpg: 384x640 1 car, 2 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8696/10000 [04:38<00:43, 29.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c748c1a1-b41ff490.jpg: 384x640 1 person, 4 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c748c1a1-f1338769.jpg: 384x640 1 person, 3 cars, 1 bus, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7491b1e-3eb219fe.jpg: 384x640 1 person, 1 car, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7491b1e-4baa21b7.jpg: 384x640 7 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8700/10000 [04:39<00:40, 32.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7491b1e-c89f51bf.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7491b1e-ee6d3220.jpg: 384x640 12 cars, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74931cf-0970795a.jpg: 384x640 3 cars, 1 traffic light, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7494115-a48473c0.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8704/10000 [04:39<00:38, 34.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7494115-b5251a6b.jpg: 384x640 7 cars, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7495330-a96a2795.jpg: 384x640 4 cars, 1 truck, 8.9ms\n",
            "Speed: 3.7ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74a122c-1494f0b4.jpg: 384x640 5 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74a122c-1586c3f0.jpg: 384x640 18 cars, 1 truck, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8708/10000 [04:39<00:39, 32.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74a122c-24c19251.jpg: 384x640 9 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74a122c-e7005b78.jpg: 384x640 9 cars, 1 truck, 14.6ms\n",
            "Speed: 5.5ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74ac556-60f29765.jpg: 384x640 1 traffic light, 16.6ms\n",
            "Speed: 1.9ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74bbe22-ad68f763.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8712/10000 [04:39<00:41, 31.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74bbfcc-5814e80f.jpg: 384x640 11 cars, 1 truck, 1 traffic light, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74c11fc-1f6d4cb3.jpg: 384x640 3 cars, 17.2ms\n",
            "Speed: 1.8ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74c11fc-3d608bfa.jpg: 384x640 2 cars, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74c11fc-50025b5d.jpg: 384x640 5 cars, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8716/10000 [04:39<00:43, 29.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74c11fc-dd542383.jpg: 384x640 1 car, 1 motorcycle, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74c11fc-f93447f7.jpg: 384x640 5 cars, 17.4ms\n",
            "Speed: 3.0ms preprocess, 17.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74cdf7e-2ab53378.jpg: 384x640 3 cars, 7.9ms\n",
            "Speed: 6.8ms preprocess, 7.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74cfce0-1bccc6d0.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8720/10000 [04:39<00:43, 29.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74ee988-8f4b380d.jpg: 384x640 14 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74f02dd-34e50eab.jpg: 384x640 2 cars, 1 traffic light, 12.4ms\n",
            "Speed: 5.0ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74fff46-459c6503.jpg: 384x640 7 cars, 1 traffic light, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8723/10000 [04:39<00:45, 28.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74fff46-bcbcf958.jpg: 384x640 9 cars, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c74fff46-e992d40c.jpg: 384x640 6 cars, 1 bus, 2 traffic lights, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c750081d-7ff1ef52.jpg: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8726/10000 [04:39<00:44, 28.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7513860-d293b768.jpg: 384x640 8 cars, 1 truck, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c752e922-355b0f70.jpg: 384x640 10 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c752e922-4f7bcda0.jpg: 384x640 15 cars, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8729/10000 [04:40<00:44, 28.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c752e922-918d3afc.jpg: 384x640 6 cars, 14.0ms\n",
            "Speed: 3.3ms preprocess, 14.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c752e922-ae691e9d.jpg: 384x640 4 persons, 1 bicycle, 4 cars, 3 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c752e922-bfcad24f.jpg: 384x640 5 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c752e922-dc304441.jpg: 384x640 8 cars, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8733/10000 [04:40<00:42, 30.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c752e922-ed300ef6.jpg: 384x640 1 person, 4 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c754ce77-a105a975.jpg: 384x640 4 cars, 1 motorcycle, 1 truck, 2 traffic lights, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c755d1f0-4c472aec.jpg: 384x640 2 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c755d1f0-fc14c3a7.jpg: 384x640 6 cars, 2 traffic lights, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8737/10000 [04:40<00:39, 31.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7569602-82b4e54f.jpg: 384x640 (no detections), 17.5ms\n",
            "Speed: 2.6ms preprocess, 17.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7576575-60923084.jpg: 384x640 4 cars, 18.0ms\n",
            "Speed: 1.9ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c759b6f8-e906aa6a.jpg: 384x640 7 cars, 1 truck, 13.8ms\n",
            "Speed: 3.8ms preprocess, 13.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c759b6f8-fd634f2a.jpg: 384x640 5 persons, 9 cars, 1 truck, 6 traffic lights, 1 fire hydrant, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8741/10000 [04:40<00:44, 28.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75a249b-f1341238.jpg: 384x640 9 cars, 2 trucks, 16.2ms\n",
            "Speed: 3.9ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75c7c7c-8e13bb04.jpg: 384x640 7 cars, 14.7ms\n",
            "Speed: 7.1ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75d7961-49f17231.jpg: 384x640 1 person, 3 cars, 8.2ms\n",
            "Speed: 3.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8744/10000 [04:40<00:44, 28.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75dff4f-c91e6880.jpg: 384x640 2 cars, 12.1ms\n",
            "Speed: 6.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75e23fe-086d84a6.jpg: 384x640 4 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75e23fe-1e57a6c4.jpg: 384x640 4 cars, 1 stop sign, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75e23fe-88586adb.jpg: 384x640 1 person, 3 cars, 2 stop signs, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  87%|████████▋ | 8748/10000 [04:40<00:42, 29.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75e23fe-b2deb730.jpg: 384x640 3 cars, 4 traffic lights, 11.7ms\n",
            "Speed: 4.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c75e23fe-fbadb3fa.jpg: 384x640 2 cars, 1 truck, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c760a702-0a5e845b.jpg: 384x640 1 car, 4 traffic lights, 11.7ms\n",
            "Speed: 6.5ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c760a824-730269a3.jpg: 384x640 10 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8752/10000 [04:40<00:42, 29.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c760a824-ae40a6e1.jpg: 384x640 21 cars, 2 trucks, 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c760a824-c688f8a2.jpg: 384x640 2 persons, 7 cars, 2 trucks, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c760a824-ea6ebc28.jpg: 384x640 16 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8755/10000 [04:40<00:42, 29.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76141d9-21508c56.jpg: 384x640 1 person, 3 cars, 1 truck, 1 traffic light, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7640ee1-0cbc6ec0.jpg: 384x640 1 traffic light, 9.7ms\n",
            "Speed: 3.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7640ee1-6c86d60f.jpg: 384x640 1 person, 2 traffic lights, 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7640ee1-8898b36d.jpg: 384x640 (no detections), 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8759/10000 [04:41<00:41, 29.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7648772-2a35b63f.jpg: 384x640 7 cars, 1 traffic light, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7648772-50f60421.jpg: 384x640 2 cars, 16.5ms\n",
            "Speed: 1.8ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7648772-cbd18adf.jpg: 384x640 3 cars, 2 traffic lights, 8.5ms\n",
            "Speed: 5.5ms preprocess, 8.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7648772-e661b276.jpg: 384x640 1 car, 1 train, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8763/10000 [04:41<00:41, 29.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7648772-ed0b23ab.jpg: 384x640 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7648772-fc04b1c3.jpg: 384x640 1 car, 4 traffic lights, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c767ad39-119bf6f3.jpg: 384x640 6 cars, 3 trucks, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c767ad39-1c9a5ce2.jpg: 384x640 1 person, 13 cars, 2 trucks, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8767/10000 [04:41<00:39, 31.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c767ad39-b196c36a.jpg: 384x640 1 person, 3 cars, 1 traffic light, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c768f8a1-4c7b2504.jpg: 384x640 (no detections), 15.1ms\n",
            "Speed: 1.8ms preprocess, 15.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c769da9c-f1ad8284.jpg: 384x640 1 car, 1 truck, 1 traffic light, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76a5f2c-7efa0cc3.jpg: 384x640 1 bicycle, 2 cars, 1 traffic light, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8771/10000 [04:41<00:39, 31.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76adb6d-275e8f71.jpg: 384x640 4 cars, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76b7109-830b56df.jpg: 384x640 13 cars, 3 traffic lights, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76b7109-f2bedded.jpg: 384x640 2 cars, 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76d86ec-f11c0df0.jpg: 384x640 1 car, 7 traffic lights, 21.0ms\n",
            "Speed: 2.9ms preprocess, 21.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8775/10000 [04:41<00:43, 28.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76d90f2-975e81d1.jpg: 384x640 9 cars, 17.8ms\n",
            "Speed: 1.9ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76e42a3-362b5166.jpg: 384x640 1 car, 2 traffic lights, 18.0ms\n",
            "Speed: 5.9ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76e42a3-dac435c3.jpg: 384x640 3 persons, 1 bicycle, 1 bus, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8778/10000 [04:41<00:44, 27.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76e4ccc-86973001.jpg: 384x640 11 cars, 1 traffic light, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76e6e4f-2915de4e.jpg: 384x640 10 cars, 1 bus, 2 trucks, 12.1ms\n",
            "Speed: 5.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76e6e4f-34963f80.jpg: 384x640 13 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8781/10000 [04:41<00:45, 27.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76e8ace-01aa7d5b.jpg: 384x640 1 person, 8 cars, 1 truck, 3 traffic lights, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76fbaa1-0323c784.jpg: 384x640 6 persons, 2 cars, 1 truck, 1 traffic light, 1 fire hydrant, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76fbaa1-07ee965c.jpg: 384x640 2 persons, 4 cars, 1 truck, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8784/10000 [04:41<00:43, 27.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76fbaa1-990ee15a.jpg: 384x640 1 car, 1 bus, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76fbaa1-cd6c2860.jpg: 384x640 1 person, 9 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c76fbaa1-d03af260.jpg: 384x640 4 cars, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c770264c-1ebcf489.jpg: 384x640 1 truck, 10.1ms\n",
            "Speed: 4.1ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8788/10000 [04:42<00:41, 29.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7706d20-5f4987db.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7706d20-daa7bd9c.jpg: 384x640 6 cars, 1 truck, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c771447a-481608db.jpg: 384x640 6 cars, 1 truck, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7729bd7-e38ccf62.jpg: 384x640 9 cars, 1 truck, 2 traffic lights, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8792/10000 [04:42<00:38, 31.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7749319-823a3fd4.jpg: 384x640 9 cars, 2 trucks, 1 traffic light, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c775bec8-4c524651.jpg: 384x640 4 cars, 1 truck, 8.8ms\n",
            "Speed: 3.9ms preprocess, 8.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c775bec8-5f039754.jpg: 384x640 2 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c775de6b-63083e8f.jpg: 384x640 4 cars, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8796/10000 [04:42<00:39, 30.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c775de6b-c8966c9a.jpg: 384x640 3 cars, 1 truck, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c776d10b-06d930cf.jpg: 384x640 1 person, 3 cars, 1 traffic light, 16.7ms\n",
            "Speed: 4.0ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c776d10b-15486206.jpg: 384x640 9 cars, 2 traffic lights, 18.1ms\n",
            "Speed: 1.8ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c776d10b-25177c93.jpg: 384x640 4 cars, 1 bus, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8800/10000 [04:42<00:41, 28.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c776d10b-6732b55c.jpg: 384x640 14 cars, 1 traffic light, 7.6ms\n",
            "Speed: 6.3ms preprocess, 7.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c776d10b-79dd4fee.jpg: 384x640 1 traffic light, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c776d10b-9d6f5ccb.jpg: 384x640 5 cars, 2 traffic lights, 8.3ms\n",
            "Speed: 4.8ms preprocess, 8.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c776d10b-a1314ad4.jpg: 384x640 1 person, 8 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8804/10000 [04:42<00:40, 29.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c776d10b-ea20be3a.jpg: 384x640 4 cars, 8.1ms\n",
            "Speed: 2.6ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7776076-222a8092.jpg: 384x640 4 cars, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7776076-4907b63e.jpg: 384x640 5 cars, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7776076-95aab855.jpg: 384x640 1 car, 1 traffic light, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8808/10000 [04:42<00:38, 30.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7782d73-8f4c444c.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7790bd2-299c163c.jpg: 384x640 7 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7796b42-3936bdf3.jpg: 384x640 1 car, 1 truck, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77bc56d-0c0356ff.jpg: 384x640 4 persons, 3 cars, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8812/10000 [04:42<00:38, 30.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77bc56d-491f85ad.jpg: 384x640 2 cars, 1 stop sign, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77c73fc-1126f4ec.jpg: 384x640 17 cars, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77c73fc-465be2e8.jpg: 384x640 5 cars, 1 traffic light, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77c73fc-eb090c8e.jpg: 384x640 3 cars, 5 traffic lights, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8816/10000 [04:42<00:38, 30.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77ce550-150463e5.jpg: 384x640 3 cars, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77ce550-4cbe3a02.jpg: 384x640 2 cars, 13.5ms\n",
            "Speed: 1.8ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77e41a3-1f322b36.jpg: 384x640 4 persons, 4 cars, 1 traffic light, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c77ed723-8715d065.jpg: 384x640 1 car, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8820/10000 [04:43<00:38, 30.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c784941b-8eb5d07c.jpg: 384x640 1 person, 1 car, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c787a6cc-5bd5e933.jpg: 384x640 1 car, 15.2ms\n",
            "Speed: 1.8ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c787a6cc-7c83adf5.jpg: 384x640 9 cars, 3 traffic lights, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c787a6cc-9b914e7d.jpg: 384x640 3 cars, 2 trucks, 1 traffic light, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8824/10000 [04:43<00:38, 30.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c788983e-01d5b664.jpg: 384x640 5 cars, 1 truck, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7894612-eab9f189.jpg: 384x640 6 cars, 14.2ms\n",
            "Speed: 2.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c789571c-cb26b20b.jpg: 384x640 7 cars, 18.6ms\n",
            "Speed: 2.0ms preprocess, 18.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c789ecd3-819d4445.jpg: 384x640 1 car, 17.0ms\n",
            "Speed: 1.8ms preprocess, 17.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8828/10000 [04:43<00:40, 29.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c78eafc0-f18ef119.jpg: 384x640 1 train, 19.7ms\n",
            "Speed: 1.8ms preprocess, 19.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c78f7d9c-0b57c32f.jpg: 384x640 7 cars, 16.5ms\n",
            "Speed: 1.9ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c78f7d9c-783ee02d.jpg: 384x640 2 cars, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8831/10000 [04:43<00:42, 27.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c78f9fc6-024da644.jpg: 384x640 2 cars, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c78f9fc6-efac7090.jpg: 384x640 1 car, 5 traffic lights, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7911b64-108fc2cd.jpg: 384x640 2 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8834/10000 [04:43<00:41, 28.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7922063-3c0bf396.jpg: 384x640 8 cars, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7922063-76dde2db.jpg: 384x640 8 cars, 15.3ms\n",
            "Speed: 1.8ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7926696-3661975d.jpg: 384x640 1 car, 2 trains, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8837/10000 [04:43<00:43, 26.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7930146-1a9e5399.jpg: 384x640 3 cars, 1 motorcycle, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c793b29d-cdc60db3.jpg: 384x640 2 persons, 13 cars, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c794c86d-e4fadf29.jpg: 384x640 10 cars, 12.2ms\n",
            "Speed: 4.6ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8840/10000 [04:43<00:43, 26.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7955e20-3760bb8a.jpg: 384x640 7 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7955e20-a156a983.jpg: 384x640 7 cars, 1 truck, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7955e20-b48c7a6a.jpg: 384x640 2 persons, 7 cars, 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8843/10000 [04:43<00:43, 26.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79687a5-923d4388.jpg: 384x640 2 cars, 1 bus, 16.0ms\n",
            "Speed: 1.8ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79687a5-a0f3794d.jpg: 384x640 7 cars, 1 traffic light, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79687a5-b610723c.jpg: 384x640 1 person, 3 cars, 1 traffic light, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8846/10000 [04:44<00:42, 27.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79687a5-c8dae3f7.jpg: 384x640 5 persons, 1 car, 1 traffic light, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c796ff16-6fed522b.jpg: 384x640 8 cars, 12.6ms\n",
            "Speed: 5.3ms preprocess, 12.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7987da1-0b8fb6e0.jpg: 384x640 (no detections), 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7987da1-e380f3bb.jpg: 384x640 4 cars, 1 train, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  88%|████████▊ | 8850/10000 [04:44<00:40, 28.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c798a9b7-116a549d.jpg: 384x640 (no detections), 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c798a9b7-fdfaecda.jpg: 384x640 2 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7999be0-41ec7870.jpg: 384x640 8 cars, 1 traffic light, 14.3ms\n",
            "Speed: 1.8ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79be479-405bfb76.jpg: 384x640 1 person, 3 cars, 1 truck, 2 traffic lights, 17.2ms\n",
            "Speed: 1.8ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▊ | 8854/10000 [04:44<00:39, 29.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79be479-4278af09.jpg: 384x640 6 cars, 4 traffic lights, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79be479-ed810331.jpg: 384x640 6 cars, 17.4ms\n",
            "Speed: 1.9ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79be479-f221c1ff.jpg: 384x640 7 cars, 1 truck, 15.5ms\n",
            "Speed: 3.5ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▊ | 8857/10000 [04:44<00:41, 27.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79be479-f3c6c42d.jpg: 384x640 1 person, 4 cars, 1 truck, 1 traffic light, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79de76f-e52908de.jpg: 384x640 10 cars, 1 traffic light, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79e169f-054f74e7.jpg: 384x640 1 car, 2 trucks, 19.4ms\n",
            "Speed: 1.8ms preprocess, 19.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▊ | 8860/10000 [04:44<00:43, 26.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79e3f00-5879235c.jpg: 384x640 2 cars, 5 traffic lights, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79e45ca-9ad90248.jpg: 384x640 7 cars, 3 traffic lights, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c79e8496-5004f68e.jpg: 384x640 3 cars, 1 truck, 14.5ms\n",
            "Speed: 5.8ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▊ | 8863/10000 [04:44<00:44, 25.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7a0fa73-1d4dbbf1.jpg: 384x640 5 cars, 1 bus, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7a1b520-811842d8.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 3.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7a23570-73d2078f.jpg: 384x640 12 cars, 1 bus, 1 traffic light, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▊ | 8866/10000 [04:44<00:42, 26.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7a350a0-cbbae3f7.jpg: 384x640 13 cars, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7a61397-1049116d.jpg: 384x640 1 car, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7a7d604-483d2d58.jpg: 384x640 5 cars, 2 traffic lights, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▊ | 8869/10000 [04:44<00:42, 26.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7a953a8-d284f244.jpg: 384x640 6 persons, 5 cars, 1 truck, 1 tv, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7aa5575-09247466.jpg: 384x640 2 traffic lights, 14.3ms\n",
            "Speed: 1.9ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7aa5575-4706c0d1.jpg: 384x640 1 person, 1 car, 2 traffic lights, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7aa5575-7db02116.jpg: 384x640 4 persons, 5 cars, 2 traffic lights, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▊ | 8873/10000 [04:45<00:40, 27.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ab28a2-a8981141.jpg: 384x640 1 person, 11 cars, 1 bus, 1 truck, 7 traffic lights, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7acf715-2c8a1413.jpg: 384x640 1 person, 6 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ad303b-4957c5f8.jpg: 384x640 3 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8876/10000 [04:45<00:40, 28.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ad303b-6312624f.jpg: 384x640 3 cars, 2 buss, 1 truck, 16.5ms\n",
            "Speed: 1.8ms preprocess, 16.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ad303b-6381dac9.jpg: 384x640 1 person, 8 cars, 2 traffic lights, 1 stop sign, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ad303b-b15cc501.jpg: 384x640 8 cars, 1 truck, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8879/10000 [04:45<00:41, 27.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7b1001c-ee3bf034.jpg: 384x640 1 car, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7b32a0d-71d3cce5.jpg: 384x640 7 cars, 11.2ms\n",
            "Speed: 3.9ms preprocess, 11.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7b32a0d-ffed4ed6.jpg: 384x640 3 cars, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8882/10000 [04:45<00:40, 27.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7b41787-4e83c33d.jpg: 384x640 3 cars, 3 traffic lights, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7b41787-a0d67db5.jpg: 384x640 3 cars, 1 traffic light, 18.5ms\n",
            "Speed: 3.1ms preprocess, 18.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7b49761-5e5c8c62.jpg: 384x640 6 cars, 19.5ms\n",
            "Speed: 3.0ms preprocess, 19.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8885/10000 [04:45<00:40, 27.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7b49761-fc7ed898.jpg: 384x640 1 car, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7b86405-da6e2abc.jpg: 384x640 7 cars, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bb31cc-8bd12af5.jpg: 384x640 1 train, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8888/10000 [04:45<00:39, 27.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bb5f81-1051148c.jpg: 384x640 (no detections), 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bbf4a6-71538fbd.jpg: 384x640 3 cars, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bc09fc-3222b8db.jpg: 384x640 6 cars, 1 bus, 1 truck, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bc28e7-d2556929.jpg: 384x640 3 cars, 2 trucks, 12.7ms\n",
            "Speed: 5.1ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8892/10000 [04:45<00:37, 29.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bc6671-fc3f4552.jpg: 384x640 7 cars, 2 buss, 1 truck, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bc7797-8f8c936a.jpg: 384x640 1 car, 17.4ms\n",
            "Speed: 1.8ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bc7797-e6749988.jpg: 384x640 2 cars, 2 buss, 17.6ms\n",
            "Speed: 1.9ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8895/10000 [04:45<00:37, 29.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bcd5db-6483a43e.jpg: 384x640 14 cars, 20.5ms\n",
            "Speed: 1.8ms preprocess, 20.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bed540-0d2ff5f7.jpg: 384x640 6 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7bed540-cdb47d56.jpg: 384x640 5 cars, 2 traffic lights, 14.5ms\n",
            "Speed: 3.6ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8898/10000 [04:45<00:38, 28.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c03bf5-5188c467.jpg: 384x640 1 car, 1 traffic light, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c03bf5-8450a02e.jpg: 384x640 1 car, 1 traffic light, 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c03bf5-bed03c03.jpg: 384x640 9 cars, 11.4ms\n",
            "Speed: 4.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8901/10000 [04:46<00:38, 28.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c042ec-4986a853.jpg: 384x640 1 car, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c12eb6-2752525d.jpg: 384x640 1 car, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c2a783-260d7aad.jpg: 384x640 7 cars, 1 bus, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c2a783-d98d5909.jpg: 384x640 1 person, 4 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8905/10000 [04:46<00:36, 30.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c39101-5935025f.jpg: 384x640 2 cars, 1 train, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c39101-837064cb.jpg: 384x640 1 car, 1 bus, 1 truck, 3 traffic lights, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c5969b-3d72de47.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 13.9ms\n",
            "Speed: 2.5ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c5969b-4fdfe484.jpg: 384x640 1 person, 6 cars, 4 traffic lights, 17.3ms\n",
            "Speed: 6.3ms preprocess, 17.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8909/10000 [04:46<00:37, 29.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c5969b-c0899dbc.jpg: 384x640 7 cars, 1 traffic light, 19.2ms\n",
            "Speed: 1.8ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c5969b-d4264f7e.jpg: 384x640 2 cars, 2 traffic lights, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c5969b-f1bc3e3a.jpg: 384x640 5 cars, 1 traffic light, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8912/10000 [04:46<00:38, 28.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c5969b-ff18b44d.jpg: 384x640 1 airplane, 13.3ms\n",
            "Speed: 3.5ms preprocess, 13.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c6a4c4-e596d6ca.jpg: 384x640 2 cars, 15.0ms\n",
            "Speed: 3.8ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c86a8e-f29f4e4e.jpg: 384x640 9 cars, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8915/10000 [04:46<00:39, 27.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c97006-1093a6d0.jpg: 384x640 13 cars, 17.7ms\n",
            "Speed: 3.0ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7c9e31d-719f694c.jpg: 384x640 1 person, 7 cars, 3 traffic lights, 15.3ms\n",
            "Speed: 3.4ms preprocess, 15.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7cb4a74-ec912bd8.jpg: 384x640 2 persons, 5 cars, 2 buss, 1 truck, 11.1ms\n",
            "Speed: 5.9ms preprocess, 11.1ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8918/10000 [04:46<00:44, 24.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7cc0645-95e6a224.jpg: 384x640 6 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7cc0f8c-a9cabb69.jpg: 384x640 1 person, 10 cars, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7cece6c-3eccc86a.jpg: 384x640 2 cars, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8921/10000 [04:46<00:42, 25.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7cece6c-805179db.jpg: 384x640 (no detections), 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d0b0a7-7f2306d8.jpg: 384x640 13 cars, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d0b0a7-a0e6b491.jpg: 384x640 2 persons, 6 cars, 3 traffic lights, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d1b792-8a24c40e.jpg: 384x640 2 cars, 2 trucks, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8925/10000 [04:46<00:39, 27.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d1b792-ddcaf626.jpg: 384x640 (no detections), 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d564fe-7c51e3a3.jpg: 384x640 8 cars, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d69f1b-e1ef4bf5.jpg: 384x640 8 cars, 1 truck, 11.5ms\n",
            "Speed: 4.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8928/10000 [04:47<00:38, 27.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d72934-2162b615.jpg: 384x640 12 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d8260d-1c3f0898.jpg: 384x640 2 persons, 7 cars, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d8260d-9d45834e.jpg: 384x640 2 persons, 7 cars, 1 truck, 1 fire hydrant, 14.4ms\n",
            "Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8931/10000 [04:47<00:39, 27.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d8260d-e1f6b3f8.jpg: 384x640 9 cars, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d87387-45ccc76d.jpg: 384x640 1 train, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d8925a-f469385d.jpg: 384x640 1 car, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7d9a24a-bdf745c8.jpg: 384x640 6 cars, 1 bus, 1 truck, 17.9ms\n",
            "Speed: 3.1ms preprocess, 17.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8935/10000 [04:47<00:38, 27.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7dab685-05c2f1df.jpg: 384x640 3 cars, 1 bus, 3 traffic lights, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7dbe674-55c1fda0.jpg: 384x640 3 cars, 15.5ms\n",
            "Speed: 3.9ms preprocess, 15.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7dbfac6-5784ebc9.jpg: 384x640 10 cars, 2 traffic lights, 19.1ms\n",
            "Speed: 3.9ms preprocess, 19.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8938/10000 [04:47<00:41, 25.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7dbfac6-c3921e8b.jpg: 384x640 (no detections), 14.9ms\n",
            "Speed: 3.6ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7dc648e-dd181375.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7dc648e-ea816d21.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7dd6716-f165ff52.jpg: 384x640 7 cars, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8942/10000 [04:47<00:36, 28.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e14afd-15600d7b.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e25b5f-5c098837.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e25b5f-9e6af053.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e61874-56decdeb.jpg: 384x640 6 cars, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e64b14-990b5da5.jpg: 384x640 (no detections), 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  89%|████████▉ | 8947/10000 [04:47<00:32, 32.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e6bfe9-3256d95a.jpg: 384x640 2 persons, 1 car, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e6bfe9-38bc4856.jpg: 384x640 13 cars, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e6d5d1-c8af9fe3.jpg: 384x640 3 persons, 5 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e9dd39-2e5a6648.jpg: 384x640 12 cars, 4 traffic lights, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8951/10000 [04:47<00:32, 32.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e9dd39-997378b3.jpg: 384x640 10 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e9dd39-ae653d55.jpg: 384x640 1 bench, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e9dd39-e54b51ba.jpg: 384x640 (no detections), 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7e9dd39-e640804c.jpg: 384x640 7 cars, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8955/10000 [04:47<00:31, 33.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-1292c919.jpg: 384x640 1 car, 1 traffic light, 20.8ms\n",
            "Speed: 1.8ms preprocess, 20.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-29602d7b.jpg: 384x640 2 cars, 13.5ms\n",
            "Speed: 1.7ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-34e0497b.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-65610875.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8959/10000 [04:47<00:30, 33.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-8737167f.jpg: 384x640 3 traffic lights, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-8cf91286.jpg: 384x640 2 cars, 1 traffic light, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-94d03413.jpg: 384x640 1 car, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-d02c0a19.jpg: 384x640 6 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8963/10000 [04:48<00:30, 34.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eab2ff-fad5c867.jpg: 384x640 (no detections), 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ec3b49-2dea9747.jpg: 384x640 1 person, 7 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7eddd1b-73993ae6.jpg: 384x640 5 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ee01b9-1fb43751.jpg: 384x640 2 persons, 6 cars, 2 trucks, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8967/10000 [04:48<00:29, 34.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ee6626-62a3ed49.jpg: 384x640 6 persons, 5 cars, 1 bus, 2 trucks, 1 traffic light, 15.7ms\n",
            "Speed: 1.9ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f011d1-e88f3d4b.jpg: 384x640 5 cars, 1 truck, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f167f5-edf85801.jpg: 384x640 3 cars, 1 tv, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f18cae-b15c6e09.jpg: 384x640 8 persons, 3 cars, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8971/10000 [04:48<00:33, 30.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f1e810-aa686dab.jpg: 384x640 2 cars, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f24a49-8c5206a6.jpg: 384x640 1 car, 1 bus, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f36d03-c8418294.jpg: 384x640 8 cars, 1 truck, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f68540-18a5e077.jpg: 384x640 1 car, 1 traffic light, 15.5ms\n",
            "Speed: 2.4ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8975/10000 [04:48<00:34, 30.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f7a5bb-41d4551f.jpg: 384x640 10 cars, 14.4ms\n",
            "Speed: 3.0ms preprocess, 14.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f8589f-45c47b58.jpg: 384x640 3 cars, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f8589f-a2c6b9a4.jpg: 384x640 5 cars, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f97365-1c2f54a0.jpg: 384x640 3 cars, 2 traffic lights, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8979/10000 [04:48<00:33, 30.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f97365-5be70930.jpg: 384x640 1 car, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f97365-68b7e100.jpg: 384x640 4 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7f97365-9f629bd2.jpg: 384x640 7 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fa04ea-4cb7df93.jpg: 384x640 1 person, 2 cars, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8983/10000 [04:48<00:31, 32.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fa04ea-9012bec6.jpg: 384x640 2 cars, 1 train, 2 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fa148b-89df90c1.jpg: 384x640 5 cars, 1 bus, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fa8344-959a77c9.jpg: 384x640 2 persons, 4 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fca0c0-c8778e79.jpg: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8987/10000 [04:48<00:29, 33.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fd8df0-429644e7.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fe62b1-831805d0.jpg: 384x640 4 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fe63e7-28d31cda.jpg: 384x640 5 cars, 1 truck, 4 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7fee392-08329b19.jpg: 384x640 1 person, 6 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8991/10000 [04:48<00:28, 34.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c7ff2c12-cf77c29d.jpg: 384x640 2 cars, 2 trucks, 4 traffic lights, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c803615e-07407e4a.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c80451c9-1a7b2854.jpg: 384x640 18 cars, 1 bus, 4 trucks, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8054f9c-3ff3c2b1.jpg: 384x640 6 cars, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8995/10000 [04:49<00:29, 33.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c80565a4-c813cdc0.jpg: 384x640 14 cars, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8062950-28712f80.jpg: 384x640 1 car, 2 traffic lights, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8062950-e7ac08bd.jpg: 384x640 4 cars, 1 traffic light, 15.4ms\n",
            "Speed: 1.9ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c80641a4-d91ca4a9.jpg: 384x640 4 cars, 1 traffic light, 11.7ms\n",
            "Speed: 1.7ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|████████▉ | 8999/10000 [04:49<00:30, 32.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c806608d-592923fd.jpg: 384x640 8 cars, 2 traffic lights, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8069625-0a547aca.jpg: 384x640 1 person, 4 cars, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8069625-f1fe350d.jpg: 384x640 3 cars, 1 bus, 1 train, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8079133-fcaad73c.jpg: 384x640 1 bicycle, 4 cars, 1 bus, 1 truck, 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9003/10000 [04:49<00:30, 32.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c807cb19-7e09cb11.jpg: 384x640 2 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c807d32d-e5383e74.jpg: 384x640 1 person, 1 train, 2 trucks, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c809bd18-bd814eed.jpg: 384x640 5 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c80bb624-37b71a0f.jpg: 384x640 5 cars, 2 traffic lights, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9007/10000 [04:49<00:30, 32.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c80bf9a4-757fadcb.jpg: 384x640 11 cars, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c80cf60a-8bb33a63.jpg: 384x640 3 cars, 2 trucks, 1 traffic light, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c80cf60a-9a7aabc6.jpg: 384x640 1 person, 10 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81079a0-5816ae39.jpg: 384x640 6 cars, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9011/10000 [04:49<00:30, 32.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81079a0-e0ca6df6.jpg: 384x640 2 cars, 1 airplane, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8111dda-1a7dded7.jpg: 384x640 4 cars, 1 bus, 2 trucks, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c811793c-68a3c310.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c811793c-7a592fd4.jpg: 384x640 6 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8152bfa-28181ba4.jpg: 384x640 2 persons, 8 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9016/10000 [04:49<00:28, 34.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8152bfa-d1d0ceac.jpg: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c815ee48-72c1bb07.jpg: 384x640 2 persons, 2 cars, 2 trucks, 9.1ms\n",
            "Speed: 4.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c817d55e-a60cc241.jpg: 384x640 1 person, 18 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81840ad-6dec6be7.jpg: 384x640 17 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9020/10000 [04:49<00:28, 34.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81974c0-1e531dae.jpg: 384x640 8 cars, 1 bus, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81996a2-dcf3e308.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81af731-7a2b15d7.jpg: 384x640 8 cars, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81af731-fe2bd777.jpg: 384x640 7 persons, 6 cars, 1 bus, 2 traffic lights, 1 stop sign, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9024/10000 [04:49<00:28, 34.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81afdad-8b689a37.jpg: 384x640 4 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81afdad-8ceefe85.jpg: 384x640 5 cars, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81c9789-fdf7aae2.jpg: 384x640 2 persons, 9 cars, 1 traffic light, 1 handbag, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81f9adc-855868f5.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9028/10000 [04:50<00:27, 35.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81fac7d-867a6604.jpg: 384x640 4 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81ff2c0-420a8956.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81ff2c0-6243618f.jpg: 384x640 (no detections), 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c81ff2c0-7204c5fe.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9032/10000 [04:50<00:27, 35.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c822956a-316476e0.jpg: 384x640 7 cars, 1 potted plant, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c822956a-7e35a26e.jpg: 384x640 3 persons, 6 cars, 3 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c823aede-898b2c0c.jpg: 384x640 (no detections), 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c824280a-271f2a83.jpg: 384x640 2 cars, 3 traffic lights, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9036/10000 [04:50<00:26, 36.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8257ea8-ea7235f8.jpg: 384x640 5 cars, 1 bus, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8266770-0cc2a4c7.jpg: 384x640 2 cars, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82699fa-76163f60.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8285354-3671f1b2.jpg: 384x640 3 cars, 4 traffic lights, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9040/10000 [04:50<00:28, 34.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82ab19a-024cc3bc.jpg: 384x640 1 person, 1 car, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82ab19a-455ba0d8.jpg: 384x640 11 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82ab19a-4ac23d9f.jpg: 384x640 2 cars, 1 traffic light, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82b6633-15bb4cf5.jpg: 384x640 4 cars, 13.2ms\n",
            "Speed: 3.8ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9044/10000 [04:50<00:28, 33.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82b8f6c-0e90f4f7.jpg: 384x640 2 cars, 15.0ms\n",
            "Speed: 3.8ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82b8f6c-b7c57473.jpg: 384x640 1 traffic light, 1 fire hydrant, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82b8f6c-bb5a30c7.jpg: 384x640 1 car, 15.0ms\n",
            "Speed: 1.9ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82cf5fc-43ee94c6.jpg: 384x640 5 cars, 2 trucks, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  90%|█████████ | 9048/10000 [04:50<00:29, 32.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82cf5fc-e45643c4.jpg: 384x640 6 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82d1b73-4138f567.jpg: 384x640 4 cars, 6 traffic lights, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82d6978-3b12b940.jpg: 384x640 8 cars, 1 fire hydrant, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82d6978-af07c78d.jpg: 384x640 4 persons, 8 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9052/10000 [04:50<00:29, 31.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82e10a6-50b0d417.jpg: 384x640 6 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82e10a6-7be21ed9.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82e10a6-a19ceb0b.jpg: 384x640 2 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82e51e2-c87f5478.jpg: 384x640 3 cars, 1 bus, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9056/10000 [04:50<00:28, 33.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82f8a1c-8c0ee303.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c82f8a1c-dd1020b6.jpg: 384x640 3 persons, 2 cars, 1 bus, 3 trains, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8317cdd-1703e2a7.jpg: 384x640 1 person, 7 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8333fbd-e2650427.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9060/10000 [04:51<00:28, 32.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83351be-a122d44f.jpg: 384x640 5 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c833fb57-b7aef18a.jpg: 384x640 13 cars, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c834d656-8f9f6538.jpg: 384x640 1 car, 1 traffic light, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c834d656-f1688dc3.jpg: 384x640 1 person, 3 cars, 1 traffic light, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9064/10000 [04:51<00:28, 33.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8359900-96959e0f.jpg: 384x640 1 car, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8359900-cda76263.jpg: 384x640 4 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c836d9b9-16a414cd.jpg: 384x640 5 cars, 16.4ms\n",
            "Speed: 2.6ms preprocess, 16.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c836d9b9-215a90eb.jpg: 384x640 6 cars, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9068/10000 [04:51<00:28, 32.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c836f138-19c8ed41.jpg: 384x640 1 person, 3 cars, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c836f138-aa4d7408.jpg: 384x640 3 cars, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c836f138-d9b4f7a1.jpg: 384x640 3 cars, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83718f3-2dfdf688.jpg: 384x640 1 person, 4 cars, 2 traffic lights, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9072/10000 [04:51<00:28, 32.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c837d2ef-25f73789.jpg: 384x640 3 cars, 1 bus, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c837fdf5-0362e336.jpg: 384x640 3 persons, 12 cars, 1 truck, 1 traffic light, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c838510d-e1346288.jpg: 384x640 10 cars, 2 trucks, 17.7ms\n",
            "Speed: 3.2ms preprocess, 17.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c838d26c-769b5f1b.jpg: 384x640 1 person, 2 cars, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9076/10000 [04:51<00:32, 28.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c838d26c-d5612b4e.jpg: 384x640 1 car, 1 truck, 2 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8390b6b-52f1f1b2.jpg: 384x640 1 car, 1 kite, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83a8e22-0454c45c.jpg: 384x640 1 person, 7 cars, 13.4ms\n",
            "Speed: 1.9ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9079/10000 [04:51<00:32, 28.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83b360f-81c019aa.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83b360f-93f970c0.jpg: 384x640 4 cars, 2 trucks, 8.3ms\n",
            "Speed: 2.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83c10de-0d2047c8.jpg: 384x640 3 cars, 1 airplane, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83c10de-85eef163.jpg: 384x640 7 cars, 1 airplane, 1 truck, 1 potted plant, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9083/10000 [04:51<00:29, 30.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83c10de-a413f70e.jpg: 384x640 5 cars, 1 bus, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83c10de-ad9c3fe6.jpg: 384x640 7 cars, 2 buss, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83c10de-e0aee9ee.jpg: 384x640 8 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c83d3fa4-c385cce0.jpg: 384x640 2 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9087/10000 [04:51<00:29, 31.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c840c880-ac5241d0.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8418e1b-5d58f814.jpg: 384x640 3 cars, 1 bus, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8422169-81cbbb30.jpg: 384x640 2 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8438bd1-fdc959eb.jpg: 384x640 3 persons, 6 cars, 1 traffic light, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9091/10000 [04:52<00:27, 32.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84417f6-ca6fd5ac.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84417f6-cd126053.jpg: 384x640 1 person, 4 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8448732-152cd271.jpg: 384x640 4 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c845b617-34b9e98a.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9095/10000 [04:52<00:26, 34.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c845b617-f7e6bd96.jpg: 384x640 8 cars, 4 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c845b699-ce6e759d.jpg: 384x640 1 car, 1 traffic light, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84744c1-4307c1e2.jpg: 384x640 2 persons, 1 car, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8476b52-383b95f4.jpg: 384x640 6 cars, 2 trucks, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9099/10000 [04:52<00:26, 34.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8476b52-3f18494f.jpg: 384x640 1 car, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8476b52-a66aa1c5.jpg: 384x640 1 person, 2 cars, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8478dfd-74b4ed62.jpg: 384x640 9 cars, 2 traffic lights, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8478dfd-872b0509.jpg: 384x640 2 cars, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9103/10000 [04:52<00:27, 32.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c847e107-d70bbfe9.jpg: 384x640 6 cars, 18.9ms\n",
            "Speed: 1.8ms preprocess, 18.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c848093f-09a4c946.jpg: 384x640 2 cars, 19.4ms\n",
            "Speed: 1.8ms preprocess, 19.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84a1922-9f8f21de.jpg: 384x640 1 person, 1 car, 1 bus, 2 trucks, 1 traffic light, 17.7ms\n",
            "Speed: 1.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84a1922-b11418ac.jpg: 384x640 1 person, 16 cars, 1 truck, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9107/10000 [04:52<00:29, 29.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84cf4c9-8667fb28.jpg: 384x640 1 car, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84f848e-2a5e0737.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84f848e-581109ad.jpg: 384x640 7 cars, 1 truck, 9.2ms\n",
            "Speed: 4.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84f848e-7ef75f08.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9111/10000 [04:52<00:27, 32.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84f848e-a703d928.jpg: 384x640 7 cars, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84fc7aa-26a0b1c4.jpg: 384x640 7 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84feccd-a9ee80f0.jpg: 384x640 2 persons, 6 cars, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c84feccd-b5e6cf53.jpg: 384x640 12 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9115/10000 [04:52<00:27, 31.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c85416bd-7dfe1936.jpg: 384x640 (no detections), 9.4ms\n",
            "Speed: 5.1ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c85416bd-b4812a0c.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c85416bd-db975d94.jpg: 384x640 2 cars, 1 truck, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c854d83c-ab3b375a.jpg: 384x640 5 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9119/10000 [04:52<00:27, 32.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8573105-00c1ff3b.jpg: 384x640 1 person, 5 cars, 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8573105-4f2e7c11.jpg: 384x640 4 cars, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8573105-954608fb.jpg: 384x640 10 cars, 15.3ms\n",
            "Speed: 1.8ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8573105-a4addeb6.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████ | 9123/10000 [04:53<00:26, 33.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c85ca3b9-72a968aa.jpg: 384x640 2 persons, 2 cars, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c85d1e8c-8013a9d3.jpg: 384x640 1 person, 1 car, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c85d1e8c-a96baacd.jpg: 384x640 1 car, 1 truck, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c85d3c7e-4501e8b4.jpg: 384x640 14 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████▏| 9127/10000 [04:53<00:26, 33.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c860c2bf-c683410d.jpg: 384x640 8 cars, 1 truck, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8618b44-02824088.jpg: 384x640 1 car, 2 traffic lights, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8618b44-09196f5c.jpg: 384x640 7 cars, 1 traffic light, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8618b44-5b4f8afb.jpg: 384x640 1 car, 1 traffic light, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████▏| 9131/10000 [04:53<00:25, 33.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8618b44-65da0bb3.jpg: 384x640 3 cars, 1 bus, 19.5ms\n",
            "Speed: 1.8ms preprocess, 19.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8618b44-a824d6ae.jpg: 384x640 3 cars, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8618b44-cff1239b.jpg: 384x640 2 persons, 3 cars, 12.5ms\n",
            "Speed: 3.6ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8620a67-55f86ae2.jpg: 384x640 9 cars, 1 truck, 2 traffic lights, 18.2ms\n",
            "Speed: 2.7ms preprocess, 18.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████▏| 9135/10000 [04:53<00:28, 30.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86264ca-bf5ac7a5.jpg: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8628ccd-a4bc1f43.jpg: 384x640 6 cars, 1 truck, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c862e633-4a5ae536.jpg: 384x640 5 cars, 1 bus, 1 truck, 1 traffic light, 16.8ms\n",
            "Speed: 1.8ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8638ebb-151bc1c1.jpg: 384x640 16 cars, 1 truck, 17.0ms\n",
            "Speed: 2.7ms preprocess, 17.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████▏| 9139/10000 [04:53<00:29, 28.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8638ebb-55791b54.jpg: 384x640 5 cars, 1 truck, 13.2ms\n",
            "Speed: 5.2ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8638ebb-5dc7483b.jpg: 384x640 10 cars, 1 bus, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c863c0b3-b53e2a37.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86482ef-b74850ca.jpg: 384x640 8 cars, 1 truck, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████▏| 9143/10000 [04:53<00:28, 29.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8650e15-38bef9dc.jpg: 384x640 3 cars, 2 trucks, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c868e9bf-9dc0f67e.jpg: 384x640 1 person, 7 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86b771a-b1c0561b.jpg: 384x640 4 cars, 1 bus, 3 traffic lights, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86b886b-464a33a5.jpg: 384x640 1 person, 9 cars, 1 bus, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  91%|█████████▏| 9147/10000 [04:53<00:27, 31.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86c1d47-6c425e8f.jpg: 384x640 4 cars, 10.5ms\n",
            "Speed: 3.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86db817-522e17d6.jpg: 384x640 9 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86db817-d6bec56a.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86debcf-e2263028.jpg: 384x640 6 cars, 1 truck, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9151/10000 [04:53<00:26, 31.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86ee6aa-a2ef00fe.jpg: 384x640 3 persons, 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86ee6aa-b5dbd391.jpg: 384x640 4 persons, 2 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86ef161-6b77193e.jpg: 384x640 5 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86f5924-0ec535db.jpg: 384x640 4 cars, 1 bus, 1 train, 1 traffic light, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9155/10000 [04:54<00:26, 32.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86f5924-26a09613.jpg: 384x640 2 cars, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c86f5924-83259ed3.jpg: 384x640 5 cars, 1 truck, 1 traffic light, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c872e1b7-d443b346.jpg: 384x640 1 person, 2 cars, 1 potted plant, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87438f0-d1875e08.jpg: 384x640 1 person, 10 cars, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9159/10000 [04:54<00:24, 33.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c874ddc1-0aee57cf.jpg: 384x640 1 person, 4 cars, 1 bus, 1 truck, 1 traffic light, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c874ddc1-78b9084d.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c874ddc1-d660401e.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c874ddc1-ff4e2b39.jpg: 384x640 2 cars, 1 tv, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9163/10000 [04:54<00:24, 33.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8759ab5-f6a3273f.jpg: 384x640 5 persons, 6 cars, 1 truck, 4 traffic lights, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8759b14-8e37ed36.jpg: 384x640 4 cars, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8766d9e-4289f547.jpg: 384x640 5 cars, 17.7ms\n",
            "Speed: 2.0ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c876a58b-97c4d16e.jpg: 384x640 5 cars, 11.1ms\n",
            "Speed: 6.6ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9167/10000 [04:54<00:27, 29.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c876f8b1-f19a1697.jpg: 384x640 2 cars, 1 train, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8773c4a-092e1a3f.jpg: 384x640 2 cars, 10.3ms\n",
            "Speed: 2.7ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87793e4-f899b0b4.jpg: 384x640 1 car, 1 traffic light, 17.5ms\n",
            "Speed: 1.8ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c877ac5b-56eb96fb.jpg: 384x640 3 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9171/10000 [04:54<00:27, 30.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c877c1e3-107ed45c.jpg: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c877c1e3-775ff079.jpg: 384x640 15 cars, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c877c1e3-b9b26376.jpg: 384x640 6 cars, 1 truck, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c877c1e3-d9eaa422.jpg: 384x640 2 cars, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9175/10000 [04:54<00:26, 30.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c878b7e1-a736922b.jpg: 384x640 5 cars, 3 traffic lights, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8792c3c-a42cb3f6.jpg: 384x640 19 cars, 1 truck, 12.2ms\n",
            "Speed: 5.9ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87a634a-83007615.jpg: 384x640 7 cars, 1 truck, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87a634a-bacc0924.jpg: 384x640 8 cars, 1 truck, 1 stop sign, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9179/10000 [04:54<00:27, 29.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87a634a-d8248e08.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87a6aba-757a0a27.jpg: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87ba6b4-4b91b210.jpg: 384x640 1 car, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87d3555-1b67b671.jpg: 384x640 7 cars, 1 bus, 1 truck, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9183/10000 [04:54<00:26, 31.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87d3555-23765ccd.jpg: 384x640 2 persons, 4 cars, 1 truck, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87d3555-5c159851.jpg: 384x640 6 cars, 2 traffic lights, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87e0427-31e8946b.jpg: 384x640 4 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87ef40a-d9c511a4.jpg: 384x640 1 person, 2 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9187/10000 [04:55<00:24, 32.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c87ef40a-f8631ab2.jpg: 384x640 4 cars, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88144fc-d2606369.jpg: 384x640 (no detections), 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88439db-75bc1603.jpg: 384x640 3 bicycles, 3 cars, 1 truck, 2 traffic lights, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88555fb-a5e194ab.jpg: 384x640 3 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9191/10000 [04:55<00:24, 33.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88555fb-d0df0339.jpg: 384x640 12 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8863aea-d79c8788.jpg: 384x640 9 cars, 1 truck, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c888a3fb-286c1528.jpg: 384x640 12 cars, 1 truck, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-1bafea05.jpg: 384x640 2 cars, 16.5ms\n",
            "Speed: 4.8ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9195/10000 [04:55<00:26, 30.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-53fabe91.jpg: 384x640 1 car, 18.8ms\n",
            "Speed: 2.7ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-6efe6d79.jpg: 384x640 (no detections), 18.3ms\n",
            "Speed: 1.7ms preprocess, 18.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-865ca5b6.jpg: 384x640 1 car, 19.5ms\n",
            "Speed: 3.4ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-8a382793.jpg: 384x640 (no detections), 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9199/10000 [04:55<00:27, 28.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-9604f14d.jpg: 384x640 4 cars, 19.3ms\n",
            "Speed: 1.8ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-9f421d51.jpg: 384x640 3 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-af3a6dd9.jpg: 384x640 (no detections), 16.0ms\n",
            "Speed: 1.8ms preprocess, 16.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9202/10000 [04:55<00:27, 28.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-af58a038.jpg: 384x640 (no detections), 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c889c950-e75d6454.jpg: 384x640 2 cars, 12.3ms\n",
            "Speed: 3.8ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88a29cf-4acca487.jpg: 384x640 5 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88a29cf-a10941c6.jpg: 384x640 3 cars, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9206/10000 [04:55<00:26, 29.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88aac1c-940c43af.jpg: 384x640 1 person, 9 cars, 1 truck, 18.8ms\n",
            "Speed: 1.8ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88b1304-d64dd7b2.jpg: 384x640 9 cars, 1 bus, 1 truck, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88b26c5-0a03ff8e.jpg: 384x640 2 cars, 8.9ms\n",
            "Speed: 6.2ms preprocess, 8.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88c11f9-46b63b1e.jpg: 384x640 1 person, 8 cars, 1 stop sign, 17.0ms\n",
            "Speed: 1.9ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9210/10000 [04:55<00:27, 28.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88f9916-2a874e4d.jpg: 384x640 1 car, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88fa35f-b1639d6e.jpg: 384x640 3 persons, 9 cars, 1 truck, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c88fa35f-e6582069.jpg: 384x640 6 cars, 1 elephant, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c891763b-fea20b04.jpg: 384x640 (no detections), 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9214/10000 [04:55<00:25, 30.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c892a4e4-9bf183c0.jpg: 384x640 13 cars, 1 truck, 2 traffic lights, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c895041f-b2d189ed.jpg: 384x640 2 cars, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c897a9ab-4e006e94.jpg: 384x640 4 cars, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c897cc2b-01aaad95.jpg: 384x640 8 persons, 2 cars, 1 traffic light, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9218/10000 [04:56<00:24, 32.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c897cc2b-2a1bc9f0.jpg: 384x640 2 persons, 4 cars, 1 motorcycle, 1 truck, 14.8ms\n",
            "Speed: 4.2ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c897cc2b-4104fbc7.jpg: 384x640 3 cars, 1 truck, 10.5ms\n",
            "Speed: 5.1ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c897cc2b-6612f914.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c898e070-e490d08e.jpg: 384x640 8 cars, 2 trucks, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9222/10000 [04:56<00:23, 32.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89a1ff4-b538297b.jpg: 384x640 1 truck, 1 traffic light, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89a2698-9dba31c1.jpg: 384x640 9 cars, 1 truck, 2 traffic lights, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89bec33-797b5aca.jpg: 384x640 6 cars, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89ee093-58ed3db1.jpg: 384x640 6 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9226/10000 [04:56<00:23, 32.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89ee093-65ac0019.jpg: 384x640 1 car, 21.0ms\n",
            "Speed: 3.4ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89ee093-6fd1a5bc.jpg: 384x640 10 persons, 1 truck, 14.9ms\n",
            "Speed: 1.8ms preprocess, 14.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89ee093-bf3f50b3.jpg: 384x640 1 bus, 17.4ms\n",
            "Speed: 4.0ms preprocess, 17.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89ee093-f527ef81.jpg: 384x640 2 cars, 4 trucks, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9230/10000 [04:56<00:26, 29.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c89fc3e2-aaab0dfb.jpg: 384x640 9 persons, 6 cars, 1 traffic light, 19.5ms\n",
            "Speed: 1.8ms preprocess, 19.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a13aff-dfec2bff.jpg: 384x640 21 cars, 13.3ms\n",
            "Speed: 4.0ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a3369c-d264119b.jpg: 384x640 6 cars, 1 boat, 13.5ms\n",
            "Speed: 6.9ms preprocess, 13.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9233/10000 [04:56<00:29, 26.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a5a379-cb506f54.jpg: 384x640 15 cars, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a5c2cd-c1d58c72.jpg: 384x640 6 cars, 1 traffic light, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a5ddd2-3dae7adb.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9236/10000 [04:56<00:29, 26.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a5ddd2-9c3962bd.jpg: 384x640 1 person, 2 traffic lights, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a6707c-ce95509d.jpg: 384x640 1 traffic light, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a7a62d-4f48082b.jpg: 384x640 1 person, 5 cars, 1 truck, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a7a62d-5bba0d73.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9240/10000 [04:56<00:25, 29.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a7a62d-8d489d6e.jpg: 384x640 9 cars, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a7a62d-e58e7297.jpg: 384x640 1 person, 5 cars, 1 traffic light, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a830e0-95b22cac.jpg: 384x640 1 person, 2 cars, 1 bus, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a8a0da-10ead00e.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9244/10000 [04:56<00:23, 32.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a8a8b3-8f839ecb.jpg: 384x640 5 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a8a8b3-e36009e8.jpg: 384x640 7 cars, 1 truck, 1 traffic light, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8a9e3c4-ca92fd4a.jpg: 384x640 11 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8aae827-b9b8f6ec.jpg: 384x640 12 cars, 1 traffic light, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  92%|█████████▏| 9248/10000 [04:57<00:22, 32.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8aca1e2-4d35a25a.jpg: 384x640 5 persons, 3 cars, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8af3e03-11a30ece.jpg: 384x640 3 cars, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8af3e03-7468b30d.jpg: 384x640 3 cars, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8af3e03-876c4d1b.jpg: 384x640 1 car, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8af3e03-8966234c.jpg: 384x640 7 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9253/10000 [04:57<00:21, 35.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8af3e03-a4734700.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8afab60-93f92fc5.jpg: 384x640 5 cars, 1 truck, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b0bab6-04d79fe4.jpg: 384x640 (no detections), 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b0bab6-1032cf1e.jpg: 384x640 2 cars, 17.6ms\n",
            "Speed: 1.8ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9257/10000 [04:57<00:21, 34.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b0bab6-2f0f5619.jpg: 384x640 1 car, 2 traffic lights, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b0bab6-60153935.jpg: 384x640 2 cars, 1 traffic light, 17.9ms\n",
            "Speed: 1.8ms preprocess, 17.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b2aaa6-1a53d715.jpg: 384x640 9 cars, 16.9ms\n",
            "Speed: 3.8ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b3b695-3dd9102a.jpg: 384x640 8 cars, 1 bus, 1 truck, 1 traffic light, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9261/10000 [04:57<00:24, 30.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b46126-d3019096.jpg: 384x640 2 persons, 5 cars, 1 truck, 18.7ms\n",
            "Speed: 1.7ms preprocess, 18.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b4e0ea-598432a7.jpg: 384x640 2 persons, 8 cars, 1 traffic light, 1 stop sign, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b4e0ea-9581068d.jpg: 384x640 9 cars, 3 trucks, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b528fd-12a62505.jpg: 384x640 3 cars, 1 bus, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9265/10000 [04:57<00:23, 30.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b528fd-9010dcaf.jpg: 384x640 3 cars, 12.1ms\n",
            "Speed: 1.7ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b528fd-f3a72223.jpg: 384x640 10 cars, 12.9ms\n",
            "Speed: 3.4ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b5bc59-7e4f7285.jpg: 384x640 4 cars, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b5bc59-ad1aa597.jpg: 384x640 2 cars, 1 bus, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9269/10000 [04:57<00:23, 30.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b7195b-738b9147.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b7358d-fc3bd36c.jpg: 384x640 14 cars, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b7358d-fcb96006.jpg: 384x640 4 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8b983aa-59bbf82b.jpg: 384x640 2 cars, 1 bus, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bad943-c78f2df3.jpg: 384x640 1 car, 2 trucks, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9274/10000 [04:57<00:21, 33.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bc1028-89f17211.jpg: 384x640 (no detections), 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bd76fd-04a1c915.jpg: 384x640 6 persons, 6 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bd76fd-1fda46a5.jpg: 384x640 6 persons, 5 cars, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bd76fd-68d847b3.jpg: 384x640 1 car, 8.4ms\n",
            "Speed: 2.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bd76fd-77472fba.jpg: 384x640 11 cars, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9279/10000 [04:57<00:20, 35.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bdf9c7-f5773522.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8beac4c-f1d1d6b5.jpg: 384x640 6 cars, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bf003e-59bda2b9.jpg: 384x640 1 car, 1 traffic light, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bf003e-a663547a.jpg: 384x640 5 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bf003e-abd8611d.jpg: 384x640 4 cars, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9284/10000 [04:58<00:18, 37.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bf003e-c2e23e42.jpg: 384x640 2 cars, 1 traffic light, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bf003e-c4202676.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8bf16f5-dd333834.jpg: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c022ae-aac7455d.jpg: 384x640 2 persons, 14 cars, 1 truck, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9288/10000 [04:58<00:18, 37.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c022ae-b7e1c0b5.jpg: 384x640 5 persons, 4 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c0c00c-39ef4894.jpg: 384x640 7 cars, 1 train, 3 trucks, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c0c00c-5a90317a.jpg: 384x640 7 cars, 1 train, 3 trucks, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c0c00c-f54a95c9.jpg: 384x640 8 cars, 15.4ms\n",
            "Speed: 4.0ms preprocess, 15.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9292/10000 [04:58<00:21, 33.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c21a87-5eb41ad6.jpg: 384x640 13 cars, 14.4ms\n",
            "Speed: 2.0ms preprocess, 14.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c34ebe-07e082be.jpg: 384x640 3 cars, 12.1ms\n",
            "Speed: 5.7ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c34ebe-756f7560.jpg: 384x640 1 car, 1 bus, 1 truck, 19.7ms\n",
            "Speed: 1.9ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c40f8e-20c429b3.jpg: 384x640 6 cars, 20.8ms\n",
            "Speed: 4.2ms preprocess, 20.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9296/10000 [04:58<00:24, 29.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c40f8e-36103452.jpg: 384x640 6 persons, 3 cars, 2 traffic lights, 19.3ms\n",
            "Speed: 2.2ms preprocess, 19.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c40f8e-73bfa1bb.jpg: 384x640 5 cars, 2 traffic lights, 15.3ms\n",
            "Speed: 2.0ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c40f8e-a4f64719.jpg: 384x640 1 person, 4 cars, 1 traffic light, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c4134b-6e17c1d0.jpg: 384x640 8 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9300/10000 [04:58<00:24, 28.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c6e143-981c8f06.jpg: 384x640 3 cars, 1 truck, 1 fire hydrant, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c6e143-d85ae0f6.jpg: 384x640 13 cars, 1 train, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c76d82-9502dce2.jpg: 384x640 1 person, 4 cars, 1 kite, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c87708-09d22f5b.jpg: 384x640 10 cars, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9304/10000 [04:58<00:23, 29.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-0a84ce2b.jpg: 384x640 5 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-35a64c37.jpg: 384x640 1 person, 8 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-657086fb.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-6c607d47.jpg: 384x640 3 persons, 3 cars, 1 bus, 2 traffic lights, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9308/10000 [04:58<00:22, 31.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-75867166.jpg: 384x640 5 cars, 3 traffic lights, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-8f294a3f.jpg: 384x640 3 persons, 7 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-c1e8543d.jpg: 384x640 1 person, 2 cars, 1 bus, 1 truck, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-ddd12fbf.jpg: 384x640 2 persons, 5 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9312/10000 [04:59<00:21, 32.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c97803-f16dd813.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8c9db85-9d8a90c1.jpg: 384x640 3 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8cbb112-9d16c5da.jpg: 384x640 10 cars, 1 bus, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8cbb112-c7c84f4b.jpg: 384x640 2 cars, 1 truck, 3 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9316/10000 [04:59<00:20, 32.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ce53ef-0209f9ea.jpg: 384x640 1 car, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ce53ef-5bbb0ed2.jpg: 384x640 1 car, 1 truck, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ce53ef-62708a1f.jpg: 384x640 (no detections), 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d08ef4-8ed1534f.jpg: 384x640 8 cars, 2 trucks, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9320/10000 [04:59<00:20, 33.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d0d179-15d8ce52.jpg: 384x640 2 cars, 3 traffic lights, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d0d179-7492f586.jpg: 384x640 1 car, 1 train, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d1bc4e-9c43c393.jpg: 384x640 12 cars, 14.2ms\n",
            "Speed: 1.9ms preprocess, 14.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d1bc4e-fa045566.jpg: 384x640 4 cars, 1 truck, 16.5ms\n",
            "Speed: 1.9ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9324/10000 [04:59<00:21, 31.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d2202b-74e688c8.jpg: 384x640 2 persons, 7 cars, 2 traffic lights, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d2ec66-6f31d0dc.jpg: 384x640 3 cars, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d3c68c-da2089e8.jpg: 384x640 10 cars, 2 trucks, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d42255-691c9c96.jpg: 384x640 6 cars, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9328/10000 [04:59<00:21, 31.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d4fbd6-5d396c2e.jpg: 384x640 3 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d7cfb3-0907c433.jpg: 384x640 1 car, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d7cfb3-347e6733.jpg: 384x640 4 cars, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d7cfb3-83ab1da7.jpg: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d7cfb3-cd9f103f.jpg: 384x640 (no detections), 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9333/10000 [04:59<00:19, 34.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d838f3-750f337e.jpg: 384x640 9 cars, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8d92c71-2874cb64.jpg: 384x640 11 cars, 14.7ms\n",
            "Speed: 3.4ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8db7252-6e20c65a.jpg: 384x640 3 persons, 7 cars, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8dd7fb7-453a8242.jpg: 384x640 13 cars, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9337/10000 [04:59<00:20, 31.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ddb7b2-8c453f30.jpg: 384x640 7 cars, 1 bus, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ddd93f-8e314f90.jpg: 384x640 1 car, 3 traffic lights, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8df9893-499c95bc.jpg: 384x640 6 cars, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e01103-8c1b5190.jpg: 384x640 1 person, 5 cars, 1 motorcycle, 2 trucks, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9341/10000 [04:59<00:21, 30.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e01103-9ff8595d.jpg: 384x640 3 cars, 1 truck, 14.8ms\n",
            "Speed: 2.0ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e22fdb-a7148306.jpg: 384x640 12 cars, 1 train, 12.3ms\n",
            "Speed: 3.9ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e59150-52042127.jpg: 384x640 7 cars, 1 traffic light, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e70aac-614de268.jpg: 384x640 5 cars, 1 bus, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9345/10000 [05:00<00:21, 30.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e79c93-00e1d82a.jpg: 384x640 2 cars, 10.0ms\n",
            "Speed: 4.0ms preprocess, 10.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e895be-9bf55449.jpg: 384x640 23 cars, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e8cd4a-2f894188.jpg: 384x640 4 cars, 1 truck, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e8cd4a-3d1efe93.jpg: 384x640 3 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  93%|█████████▎| 9349/10000 [05:00<00:20, 31.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e8cd4a-9dd5daeb.jpg: 384x640 10 cars, 1 truck, 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e8f29f-09ac075a.jpg: 384x640 5 cars, 18.8ms\n",
            "Speed: 4.1ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8e8f29f-aa6b38d9.jpg: 384x640 5 cars, 1 truck, 21.2ms\n",
            "Speed: 4.0ms preprocess, 21.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8eb77ce-567b1fad.jpg: 384x640 1 car, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▎| 9353/10000 [05:00<00:23, 27.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ed2212-b60fa314.jpg: 384x640 2 cars, 4 traffic lights, 15.7ms\n",
            "Speed: 1.9ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ed27d0-7debfc0f.jpg: 384x640 15 cars, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ed3fad-623b1616.jpg: 384x640 1 person, 7 cars, 1 motorcycle, 1 traffic light, 21.3ms\n",
            "Speed: 2.0ms preprocess, 21.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▎| 9356/10000 [05:00<00:24, 26.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ed82f7-fe694d2f.jpg: 384x640 10 cars, 10.6ms\n",
            "Speed: 5.9ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8edf7ac-e984287f.jpg: 384x640 1 person, 9 cars, 1 bus, 1 truck, 9.7ms\n",
            "Speed: 3.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ee7748-be80b2c6.jpg: 384x640 (no detections), 17.8ms\n",
            "Speed: 1.8ms preprocess, 17.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▎| 9359/10000 [05:00<00:24, 26.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8eeb9c9-922af0bb.jpg: 384x640 5 cars, 1 traffic light, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8eeb9c9-cdadaee2.jpg: 384x640 1 person, 3 cars, 1 truck, 15.2ms\n",
            "Speed: 1.9ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8eeb9c9-d3212cfe.jpg: 384x640 2 persons, 1 bicycle, 3 cars, 2 traffic lights, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▎| 9362/10000 [05:00<00:23, 26.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ef1a34-e7c66c0c.jpg: 384x640 3 cars, 1 bus, 1 truck, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ef6556-56df81da.jpg: 384x640 5 cars, 1 truck, 2 traffic lights, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ef6556-627cdf0b.jpg: 384x640 10 cars, 1 bus, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ef6556-8ea04157.jpg: 384x640 1 person, 9 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▎| 9366/10000 [05:00<00:22, 28.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ef6556-c033218f.jpg: 384x640 8 cars, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ef6dea-8a327e57.jpg: 384x640 5 cars, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ef6dea-eea7d4cd.jpg: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8efd5bf-dc61bcfd.jpg: 384x640 5 persons, 5 cars, 1 bus, 1 truck, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▎| 9370/10000 [05:01<00:21, 29.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f0adf0-85eb7754.jpg: 384x640 2 cars, 1 truck, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f1cdd6-9d2a3186.jpg: 384x640 6 cars, 2 stop signs, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f39d22-69f436d4.jpg: 384x640 2 persons, 1 car, 1 truck, 3 traffic lights, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f39d22-9e3f76f8.jpg: 384x640 3 cars, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▎| 9374/10000 [05:01<00:20, 30.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f48328-67aa756a.jpg: 384x640 8 cars, 2 traffic lights, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f48328-7de61e93.jpg: 384x640 1 person, 1 car, 2 traffic lights, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f48328-8b9e4717.jpg: 384x640 7 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f61b8f-81c16429.jpg: 384x640 5 cars, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9378/10000 [05:01<00:20, 30.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f6f631-a1eb5133.jpg: 384x640 1 person, 7 cars, 1 bus, 2 traffic lights, 15.4ms\n",
            "Speed: 4.0ms preprocess, 15.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f90ec2-37aa3a28.jpg: 384x640 1 car, 19.3ms\n",
            "Speed: 6.1ms preprocess, 19.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f90ec2-8b0d49de.jpg: 384x640 4 cars, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f962d8-1925ff9b.jpg: 384x640 5 cars, 1 traffic light, 17.0ms\n",
            "Speed: 3.9ms preprocess, 17.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9382/10000 [05:01<00:22, 27.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8f962d8-e7adb2f9.jpg: 384x640 1 person, 3 cars, 1 stop sign, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8fa732b-fbdaa989.jpg: 384x640 6 cars, 1 bus, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8fc1373-3ce39fc9.jpg: 384x640 25 cars, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9385/10000 [05:01<00:23, 26.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8fd5c4a-16dbf91b.jpg: 384x640 15 cars, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8fddab0-13dbb312.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8fddab0-9ea6d001.jpg: 384x640 1 car, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c8ffbba5-334918b7.jpg: 384x640 2 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9389/10000 [05:01<00:21, 28.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c900eb3c-4b7befc1.jpg: 384x640 5 cars, 1 bus, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9018c4e-976ad16e.jpg: 384x640 4 cars, 1 fire hydrant, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c909551e-fb24caeb.jpg: 384x640 1 person, 3 cars, 1 bus, 1 truck, 1 traffic light, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c909f3df-69d1a96a.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9393/10000 [05:01<00:19, 30.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c909f3df-ac4074ed.jpg: 384x640 3 cars, 1 truck, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c909f3df-d3ce29f1.jpg: 384x640 6 cars, 1 truck, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90a2111-04776fd3.jpg: 384x640 7 cars, 1 stop sign, 12.9ms\n",
            "Speed: 4.0ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90a2111-6d28bf04.jpg: 384x640 7 cars, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9397/10000 [05:01<00:19, 31.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90b5398-63556b1c.jpg: 384x640 18 cars, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90b5398-8706dfbf.jpg: 384x640 1 bus, 12.0ms\n",
            "Speed: 5.7ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90b5398-8d49f2f2.jpg: 384x640 1 person, 7 cars, 2 trucks, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90b5398-d042ec34.jpg: 384x640 15 cars, 1 traffic light, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9401/10000 [05:02<00:20, 29.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90bf06d-4ed5dc9e.jpg: 384x640 1 car, 1 traffic light, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90bf06d-5782a8fb.jpg: 384x640 5 cars, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90bf06d-eda5f238.jpg: 384x640 1 car, 1 traffic light, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9404/10000 [05:02<00:20, 29.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90bf06d-fc30a08e.jpg: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90c8198-92fb12cc.jpg: 384x640 2 cars, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90c8198-f73aed79.jpg: 384x640 1 person, 14 cars, 16.0ms\n",
            "Speed: 1.8ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90e0afb-911ffd59.jpg: 384x640 1 person, 11 cars, 1 truck, 13.8ms\n",
            "Speed: 5.4ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9408/10000 [05:02<00:20, 28.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90ec86b-c3698408.jpg: 384x640 13 cars, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90ecab0-505559be.jpg: 384x640 10 cars, 14.9ms\n",
            "Speed: 3.9ms preprocess, 14.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90ecab0-68dc9839.jpg: 384x640 9 cars, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9411/10000 [05:02<00:21, 27.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c90ff73f-d76cc0c4.jpg: 384x640 2 cars, 1 bus, 1 traffic light, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9106ec8-1df793b7.jpg: 384x640 6 cars, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9106ec8-62580195.jpg: 384x640 11 cars, 14.2ms\n",
            "Speed: 7.0ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9414/10000 [05:02<00:22, 26.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c911f50f-e7958776.jpg: 384x640 9 cars, 1 traffic light, 15.7ms\n",
            "Speed: 1.8ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9123546-b647e40f.jpg: 384x640 3 cars, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9160b61-80e5089a.jpg: 384x640 6 cars, 12.4ms\n",
            "Speed: 5.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9417/10000 [05:02<00:21, 26.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9161830-52503e77.jpg: 384x640 1 car, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c917201f-5bbb8087.jpg: 384x640 3 cars, 1 truck, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9172da6-c3a38f22.jpg: 384x640 1 car, 13.4ms\n",
            "Speed: 1.7ms preprocess, 13.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9178f1b-e33f5de8.jpg: 384x640 7 cars, 1 truck, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9421/10000 [05:02<00:20, 28.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9185b69-e0fda3f0.jpg: 384x640 3 cars, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9195e43-b2fdd978.jpg: 384x640 1 car, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9197398-2fea0795.jpg: 384x640 6 cars, 2 trucks, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91a3cef-888fc664.jpg: 384x640 7 cars, 1 bus, 1 truck, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9425/10000 [05:02<00:19, 29.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91a3cef-e63379c7.jpg: 384x640 6 cars, 2 traffic lights, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91a84db-31862c42.jpg: 384x640 3 cars, 17.8ms\n",
            "Speed: 1.8ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91a84db-3aee7c05.jpg: 384x640 1 bicycle, 5 cars, 1 bus, 1 truck, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9428/10000 [05:03<00:20, 28.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91a84db-a199dd0d.jpg: 384x640 9 persons, 6 cars, 1 truck, 4 traffic lights, 1 fire hydrant, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91a84db-b08249fc.jpg: 384x640 1 person, 6 cars, 9.4ms\n",
            "Speed: 5.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91a84db-cc93d5a1.jpg: 384x640 10 cars, 1 truck, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9431/10000 [05:03<00:20, 27.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91a84db-f40ee6d0.jpg: 384x640 6 cars, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91b89eb-bd95cbff.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91d0862-74c58649.jpg: 384x640 11 persons, 5 cars, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91d0862-eb747701.jpg: 384x640 5 persons, 7 cars, 1 truck, 1 traffic light, 1 umbrella, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9435/10000 [05:03<00:19, 28.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91da210-1252e4c6.jpg: 384x640 1 car, 1 traffic light, 16.7ms\n",
            "Speed: 3.7ms preprocess, 16.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91da210-34d6b472.jpg: 384x640 6 cars, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91da210-37d62a18.jpg: 384x640 23 cars, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9438/10000 [05:03<00:20, 26.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91da210-a2b2bc21.jpg: 384x640 2 persons, 3 cars, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91da210-af3c069e.jpg: 384x640 7 cars, 1 traffic light, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91da210-b1922917.jpg: 384x640 3 cars, 2 traffic lights, 11.4ms\n",
            "Speed: 2.6ms preprocess, 11.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9441/10000 [05:03<00:20, 27.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91da210-bc038b99.jpg: 384x640 (no detections), 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91db2b0-38312b9f.jpg: 384x640 6 cars, 4 traffic lights, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91e8a26-3025d41e.jpg: 384x640 2 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9444/10000 [05:03<00:20, 27.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91eb48f-a7497694.jpg: 384x640 5 persons, 9 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c91eb48f-fa7a6cdc.jpg: 384x640 6 persons, 5 cars, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92005f1-24f38b48.jpg: 384x640 (no detections), 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92005f1-27eb3d9e.jpg: 384x640 (no detections), 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  94%|█████████▍| 9448/10000 [05:03<00:18, 30.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92046a2-2a0b5a9e.jpg: 384x640 1 person, 13 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92046a2-2f8e5345.jpg: 384x640 8 cars, 2 trucks, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92046a2-5264bdd4.jpg: 384x640 3 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9240f77-08db8836.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9452/10000 [05:03<00:17, 31.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9240f77-2c998430.jpg: 384x640 4 cars, 3 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9240f77-37f30fb5.jpg: 384x640 14 cars, 3 trucks, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9240f77-93292ea6.jpg: 384x640 6 cars, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9240f77-988f083f.jpg: 384x640 6 cars, 1 truck, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9456/10000 [05:03<00:17, 31.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c924c4a4-7f9aa43a.jpg: 384x640 8 cars, 3 trucks, 1 traffic light, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c924c4a4-bd2df2dc.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c926408d-2118bffc.jpg: 384x640 5 cars, 1 truck, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c926408d-366b16ee.jpg: 384x640 2 cars, 1 traffic light, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9460/10000 [05:04<00:16, 32.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c926408d-6840aaf6.jpg: 384x640 2 traffic lights, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c926408d-8de795c6.jpg: 384x640 6 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c927d51b-43e6a4e8.jpg: 384x640 (no detections), 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c927d51b-5c078571.jpg: 384x640 6 cars, 1 truck, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9464/10000 [05:04<00:15, 33.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c927d51b-92852659.jpg: 384x640 1 person, 4 cars, 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c927d51b-99c8166b.jpg: 384x640 7 cars, 17.3ms\n",
            "Speed: 1.9ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c927d51b-cb5b7850.jpg: 384x640 9 cars, 1 traffic light, 18.8ms\n",
            "Speed: 3.1ms preprocess, 18.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c927d51b-fa863734.jpg: 384x640 2 cars, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9468/10000 [05:04<00:17, 30.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9283177-1ac311e2.jpg: 384x640 7 persons, 5 cars, 2 trucks, 13.2ms\n",
            "Speed: 3.7ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9283177-33d8db54.jpg: 384x640 1 boat, 11.4ms\n",
            "Speed: 4.0ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9283177-4ac407c3.jpg: 384x640 1 person, 5 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9283177-7531ef01.jpg: 384x640 9 cars, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9472/10000 [05:04<00:17, 29.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c928749e-62bc39dd.jpg: 384x640 4 cars, 1 umbrella, 9.4ms\n",
            "Speed: 3.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c928c559-7cd84c9f.jpg: 384x640 6 persons, 9 cars, 1 truck, 12.5ms\n",
            "Speed: 1.8ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c928c559-b70b74cf.jpg: 384x640 9 cars, 1 traffic light, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92aeef7-3d38133c.jpg: 384x640 1 car, 1 truck, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9476/10000 [05:04<00:17, 29.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92aeef7-9bdd3e46.jpg: 384x640 1 car, 3 traffic lights, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92aeef7-a19d7070.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92aeef7-c8f9fb98.jpg: 384x640 4 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92b8228-b78b5c67.jpg: 384x640 1 car, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9480/10000 [05:04<00:16, 31.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c92db9da-58694b5b.jpg: 384x640 2 persons, 5 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93017ac-e728a438.jpg: 384x640 2 persons, 1 bicycle, 3 cars, 2 motorcycles, 1 truck, 1 traffic light, 14.4ms\n",
            "Speed: 1.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9312bb0-091a6594.jpg: 384x640 5 cars, 15.2ms\n",
            "Speed: 7.2ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9312bb0-7ac780f4.jpg: 384x640 2 cars, 1 traffic light, 14.2ms\n",
            "Speed: 7.3ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9484/10000 [05:04<00:17, 29.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9312bb0-89c7cf4d.jpg: 384x640 7 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9312bb0-95b57597.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9312bb0-f07bcf18.jpg: 384x640 6 cars, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93310c6-1224728c.jpg: 384x640 2 cars, 1 truck, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9488/10000 [05:05<00:16, 30.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93310c6-228c8cce.jpg: 384x640 13 cars, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93310c6-c662ee4b.jpg: 384x640 8 cars, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93364f2-95b285aa.jpg: 384x640 6 cars, 2 buss, 3 traffic lights, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c933ade8-68159c26.jpg: 384x640 4 cars, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9492/10000 [05:05<00:16, 30.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c933ade8-e95faf28.jpg: 384x640 1 person, 5 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c933ade8-f5cb06c8.jpg: 384x640 4 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c933ade8-f63b2db4.jpg: 384x640 2 cars, 3 traffic lights, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c934b18d-b08b04d2.jpg: 384x640 1 person, 6 cars, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▍| 9496/10000 [05:05<00:16, 30.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93557c9-87e615cc.jpg: 384x640 1 person, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c936d348-99cf17b9.jpg: 384x640 6 persons, 8 cars, 1 truck, 2 traffic lights, 16.4ms\n",
            "Speed: 1.9ms preprocess, 16.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9375798-85c143f7.jpg: 384x640 9 cars, 20.0ms\n",
            "Speed: 2.9ms preprocess, 20.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c938658b-62746b31.jpg: 384x640 1 person, 6 cars, 17.4ms\n",
            "Speed: 1.8ms preprocess, 17.4ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9500/10000 [05:05<00:17, 27.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c938658b-7aac4679.jpg: 384x640 8 cars, 1 traffic light, 15.2ms\n",
            "Speed: 2.9ms preprocess, 15.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c938658b-c232988e.jpg: 384x640 7 cars, 1 traffic light, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93a7768-23e29de9.jpg: 384x640 1 person, 7 cars, 1 truck, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9503/10000 [05:05<00:18, 27.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93a7768-f84a9b8f.jpg: 384x640 12 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93a7ee2-e21d6bc5.jpg: 384x640 11 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93b0369-31ac48e7.jpg: 384x640 11 cars, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9506/10000 [05:05<00:17, 27.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93b0369-a0cb051b.jpg: 384x640 12 cars, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93baa24-3b8c5ab3.jpg: 384x640 1 car, 4 traffic lights, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93bd9ce-30b0d752.jpg: 384x640 4 cars, 1 truck, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93bd9ce-d2617cc7.jpg: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9510/10000 [05:05<00:16, 29.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93bd9ce-ea579ed8.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93c1596-372a77b9.jpg: 384x640 2 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93c1596-49d96696.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93c1596-693b041f.jpg: 384x640 3 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9514/10000 [05:05<00:15, 31.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93dc018-9a022605.jpg: 384x640 1 person, 6 cars, 3 traffic lights, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93e76b7-88954e8f.jpg: 384x640 4 cars, 1 bus, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93e76b7-a0e64488.jpg: 384x640 1 person, 1 car, 4 traffic lights, 1 kite, 9.8ms\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93f8df2-9f9687f1.jpg: 384x640 4 persons, 2 cars, 1 bus, 2 trucks, 1 traffic light, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9518/10000 [05:06<00:15, 31.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c93f8df2-d683a18b.jpg: 384x640 3 persons, 2 cars, 1 truck, 2 traffic lights, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9403737-33cab241.jpg: 384x640 7 cars, 13.7ms\n",
            "Speed: 1.9ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9403737-3743ae01.jpg: 384x640 3 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9403737-44485b1f.jpg: 384x640 13 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9522/10000 [05:06<00:14, 31.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9403737-55c6220f.jpg: 384x640 1 car, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9403737-5f34d857.jpg: 384x640 4 cars, 15.4ms\n",
            "Speed: 6.6ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9403737-9675db60.jpg: 384x640 7 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9403737-bf414a95.jpg: 384x640 (no detections), 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9526/10000 [05:06<00:14, 32.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9427dd5-4779940e.jpg: 384x640 1 person, 11 cars, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9427dd5-8dd8e51f.jpg: 384x640 1 person, 9 cars, 2 fire hydrants, 19.2ms\n",
            "Speed: 1.8ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c946b395-eac458c3.jpg: 384x640 10 cars, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c946c532-07177e0a.jpg: 384x640 6 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9530/10000 [05:06<00:14, 31.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9484a09-4a6da4f1.jpg: 384x640 4 cars, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9484cde-1da408d7.jpg: 384x640 1 person, 14 cars, 3 traffic lights, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9484cde-c9b46dc0.jpg: 384x640 2 persons, 11 cars, 1 traffic light, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c948b2b1-1183d2e3.jpg: 384x640 4 cars, 1 truck, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9534/10000 [05:06<00:15, 29.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94958a6-299180ee.jpg: 384x640 2 persons, 7 cars, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94958a6-b66af171.jpg: 384x640 15 cars, 15.3ms\n",
            "Speed: 5.9ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94958a6-beac6097.jpg: 384x640 12 cars, 1 truck, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c949b637-0f47dc98.jpg: 384x640 6 cars, 1 stop sign, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9538/10000 [05:06<00:15, 29.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94a5fb6-446b8726.jpg: 384x640 6 cars, 10.0ms\n",
            "Speed: 4.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94adc37-20233549.jpg: 384x640 2 persons, 4 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94adc37-76e1ff0b.jpg: 384x640 5 cars, 2 traffic lights, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94b896e-40638bf9.jpg: 384x640 8 cars, 3 trucks, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9542/10000 [05:06<00:14, 30.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94c7ebc-dfcf2578.jpg: 384x640 2 persons, 5 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94c8cef-c8c484fc.jpg: 384x640 8 cars, 1 truck, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94c8cef-e3a67ff5.jpg: 384x640 1 car, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94ceb93-5b8608c4.jpg: 384x640 9 cars, 1 truck, 2 traffic lights, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  95%|█████████▌| 9546/10000 [05:06<00:14, 32.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94d8213-1f593522.jpg: 384x640 4 cars, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94d8213-847662eb.jpg: 384x640 1 person, 3 cars, 1 truck, 1 dog, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94d86ee-9835e761.jpg: 384x640 2 persons, 1 car, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c94d86ee-e18fa7ec.jpg: 384x640 5 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9550/10000 [05:07<00:13, 33.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9517ae9-19790405.jpg: 384x640 1 car, 1 train, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9517ae9-b9d3b2f0.jpg: 384x640 1 car, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95241cf-06d29d77.jpg: 384x640 4 cars, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c953eb9b-25d6c90f.jpg: 384x640 9 cars, 1 stop sign, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9554/10000 [05:07<00:12, 34.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9552b40-ae7bc148.jpg: 384x640 15 cars, 1 truck, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9557697-363a490d.jpg: 384x640 1 car, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9557697-64dfbc0f.jpg: 384x640 1 car, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9557697-86314e9b.jpg: 384x640 1 person, 4 cars, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9558/10000 [05:07<00:13, 33.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9557697-8a2ab930.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9557697-a50c7ba4.jpg: 384x640 4 cars, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9557697-e1fc666a.jpg: 384x640 5 cars, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c957b1a8-d327e7fb.jpg: 384x640 1 car, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9562/10000 [05:07<00:13, 32.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95979e7-efb74491.jpg: 384x640 5 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95ad578-8caa410d.jpg: 384x640 4 persons, 1 bicycle, 2 cars, 1 truck, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95c7aac-1ede8bc6.jpg: 384x640 3 cars, 3 traffic lights, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95c7aac-2259b8d6.jpg: 384x640 2 cars, 1 traffic light, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9566/10000 [05:07<00:13, 33.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95c7aac-4af0d339.jpg: 384x640 3 persons, 1 bicycle, 4 cars, 1 motorcycle, 1 bus, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95c7aac-86c314d4.jpg: 384x640 2 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95c7aac-a58cbd30.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95c7aac-ec4ec867.jpg: 384x640 3 cars, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9570/10000 [05:07<00:12, 33.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95f4860-7342216b.jpg: 384x640 6 cars, 1 bus, 1 truck, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95f4860-c29c8118.jpg: 384x640 9 cars, 2 traffic lights, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95f4860-c6c0856d.jpg: 384x640 6 cars, 1 truck, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95f8af6-a4693b4e.jpg: 384x640 1 car, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9574/10000 [05:07<00:12, 34.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95f8af6-f4a9099f.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95f8ca5-0cf1c43c.jpg: 384x640 6 cars, 1 bus, 1 traffic light, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95fecc3-41401a5f.jpg: 384x640 1 car, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95fecc3-4a1dd709.jpg: 384x640 1 person, 10 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9578/10000 [05:07<00:11, 35.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c95fecc3-4e289a4e.jpg: 384x640 1 car, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96109b8-caf84a36.jpg: 384x640 7 cars, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c962949b-dddd40b2.jpg: 384x640 2 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96299f2-8e89da2c.jpg: 384x640 6 cars, 1 truck, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9582/10000 [05:07<00:11, 36.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96299f2-e7dd8431.jpg: 384x640 3 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c962fce0-dcea4e6a.jpg: 384x640 2 cars, 5 traffic lights, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c963d910-fa6c706d.jpg: 384x640 2 cars, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c963fa4b-a46ed02b.jpg: 384x640 9 persons, 2 cars, 1 bus, 3 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9586/10000 [05:08<00:11, 36.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96519fa-2d8cc863.jpg: 384x640 5 cars, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96519fa-d85ac570.jpg: 384x640 5 cars, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9683e6e-68b49262.jpg: 384x640 7 cars, 1 traffic light, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c968f598-3507eb4b.jpg: 384x640 1 traffic light, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9590/10000 [05:08<00:11, 36.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c968f598-7b3b4c6d.jpg: 384x640 6 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96a9fb4-cacac0fc.jpg: 384x640 1 person, 5 cars, 1 truck, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ab7ea-2770185c.jpg: 384x640 6 cars, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ab7ea-3894685f.jpg: 384x640 3 cars, 1 truck, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9594/10000 [05:08<00:10, 37.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ab7ea-6b63e676.jpg: 384x640 5 cars, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ab7ea-761efabd.jpg: 384x640 4 cars, 15.1ms\n",
            "Speed: 6.0ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ab7ea-a10139b9.jpg: 384x640 4 cars, 1 bus, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ab7ea-f0802092.jpg: 384x640 2 cars, 1 traffic light, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9598/10000 [05:08<00:11, 34.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ab7ea-f3e268c8.jpg: 384x640 3 cars, 1 traffic light, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96b5ea4-f4c45a46.jpg: 384x640 4 cars, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96d485d-63a73865.jpg: 384x640 (no detections), 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96d4996-d78b1b88.jpg: 384x640 1 person, 10.5ms\n",
            "Speed: 1.7ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9602/10000 [05:08<00:11, 34.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96e0b6a-0acdb8b5.jpg: 384x640 1 person, 4 cars, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96e0b6a-7d3c5b31.jpg: 384x640 3 persons, 5 buss, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96e0b6a-f3d8aa78.jpg: 384x640 2 persons, 1 motorcycle, 1 stop sign, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96e6559-2b1401da.jpg: 384x640 3 cars, 1 traffic light, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9606/10000 [05:08<00:11, 33.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96fcc84-d7778d41.jpg: 384x640 1 car, 1 truck, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96fcc84-faebc9c9.jpg: 384x640 4 cars, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ffe59-1cf2df11.jpg: 384x640 7 cars, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ffe59-25022c0b.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9610/10000 [05:08<00:11, 34.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ffe59-429ca2a9.jpg: 384x640 7 persons, 2 cars, 3 traffic lights, 1 backpack, 9.0ms\n",
            "Speed: 4.6ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ffe59-868ab1ed.jpg: 384x640 1 car, 1 bus, 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ffe59-d72b7012.jpg: 384x640 5 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c96ffe59-e18bc459.jpg: 384x640 1 car, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9614/10000 [05:08<00:11, 34.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9708ee8-31f4eece.jpg: 384x640 8 cars, 2 trucks, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c970d004-efeb8b97.jpg: 384x640 (no detections), 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c972204c-e7d86629.jpg: 384x640 2 cars, 2 traffic lights, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9736046-5b96af10.jpg: 384x640 2 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9736046-d8b9fd11.jpg: 384x640 (no detections), 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9619/10000 [05:08<00:10, 37.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c975393b-d0309026.jpg: 384x640 3 cars, 4 traffic lights, 1 stop sign, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c975761f-42dd555b.jpg: 384x640 1 person, 2 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9768773-d9cf584c.jpg: 384x640 6 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c976aa56-2902a314.jpg: 384x640 10 cars, 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▌| 9623/10000 [05:09<00:10, 36.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c977423c-43dddd3b.jpg: 384x640 1 car, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c978b30e-673341ec.jpg: 384x640 3 cars, 2 traffic lights, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c978b30e-76bd39af.jpg: 384x640 3 cars, 2 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c978b30e-b7e84613.jpg: 384x640 8 cars, 2 traffic lights, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▋| 9627/10000 [05:09<00:09, 37.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c979b818-481e9da0.jpg: 384x640 16 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97abe9e-ccbca525.jpg: 384x640 5 cars, 1 truck, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97b2568-576a4ba1.jpg: 384x640 2 cars, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97c0d3c-64a7bc09.jpg: 384x640 1 person, 4 cars, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▋| 9631/10000 [05:09<00:09, 37.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97c0d3c-70e91ccf.jpg: 384x640 3 cars, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97c0d3c-b656cd59.jpg: 384x640 1 person, 4 cars, 1 truck, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97c4556-6055e106.jpg: 384x640 10 cars, 1 truck, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97d6560-103e2fc4.jpg: 384x640 3 cars, 3 traffic lights, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▋| 9635/10000 [05:09<00:10, 33.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97deb16-924a514f.jpg: 384x640 1 car, 2 buss, 1 truck, 1 traffic light, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97fc7da-4bca948f.jpg: 384x640 8 cars, 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97fc7da-a19144af.jpg: 384x640 2 cars, 14.8ms\n",
            "Speed: 3.3ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c97fc7da-ed179cad.jpg: 384x640 1 person, 4 cars, 1 traffic light, 15.0ms\n",
            "Speed: 3.0ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▋| 9639/10000 [05:09<00:11, 30.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9815999-611707fe.jpg: 384x640 3 persons, 1 car, 1 bus, 1 truck, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9815999-f1a3d95a.jpg: 384x640 6 persons, 3 cars, 1 bus, 3 trucks, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c981c004-35dc44b9.jpg: 384x640 1 car, 2 buss, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9821da0-2b4ef0c0.jpg: 384x640 1 car, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▋| 9643/10000 [05:09<00:11, 31.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98232a2-4e9128ce.jpg: 384x640 8 cars, 3 traffic lights, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98232a2-66e6e1fb.jpg: 384x640 6 cars, 1 truck, 5 traffic lights, 12.9ms\n",
            "Speed: 6.2ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98258a4-54a47ff2.jpg: 384x640 4 persons, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98258a4-b78aa787.jpg: 384x640 4 cars, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  96%|█████████▋| 9647/10000 [05:09<00:11, 31.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98258a4-e5a366fe.jpg: 384x640 2 persons, 9 cars, 1 bus, 1 traffic light, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c983692b-b3a04393.jpg: 384x640 5 persons, 6 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9854be4-2e4295ce.jpg: 384x640 2 persons, 7 cars, 1 truck, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c985e44f-024d63ab.jpg: 384x640 5 cars, 1 stop sign, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9651/10000 [05:09<00:10, 31.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c986e8a4-81f5a043.jpg: 384x640 6 cars, 1 traffic light, 9.0ms\n",
            "Speed: 2.6ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c988c74a-32132434.jpg: 384x640 1 person, 9 cars, 3 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c988c74a-8d679348.jpg: 384x640 5 persons, 7 cars, 5 traffic lights, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98a01d0-a1e7bb72.jpg: 384x640 6 cars, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9655/10000 [05:10<00:10, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98b35d1-b66b62c2.jpg: 384x640 1 person, 9 cars, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98c1005-1a53d7d2.jpg: 384x640 9 cars, 1 traffic light, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c98c1005-7d014761.jpg: 384x640 3 cars, 1 truck, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c992d89e-45d612c4.jpg: 384x640 5 persons, 4 cars, 2 trucks, 5 traffic lights, 9.5ms\n",
            "Speed: 1.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9659/10000 [05:10<00:10, 32.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c992d89e-63020be4.jpg: 384x640 1 person, 6 cars, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-20359e85.jpg: 384x640 11 cars, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-33101e6b.jpg: 384x640 4 cars, 1 traffic light, 14.3ms\n",
            "Speed: 4.1ms preprocess, 14.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-350c682c.jpg: 384x640 5 cars, 15.1ms\n",
            "Speed: 1.8ms preprocess, 15.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9663/10000 [05:10<00:10, 31.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-613d6034.jpg: 384x640 5 cars, 16.1ms\n",
            "Speed: 3.5ms preprocess, 16.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-665ece03.jpg: 384x640 5 cars, 21.3ms\n",
            "Speed: 2.7ms preprocess, 21.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-768a9187.jpg: 384x640 3 cars, 1 traffic light, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-8cda0568.jpg: 384x640 9 cars, 17.4ms\n",
            "Speed: 2.5ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9667/10000 [05:10<00:11, 29.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-9738b00a.jpg: 384x640 12 cars, 1 bus, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-ab858bd2.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-ae30e2cb.jpg: 384x640 3 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-c333ae32.jpg: 384x640 2 cars, 1 train, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9671/10000 [05:10<00:10, 31.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-c9f6e6aa.jpg: 384x640 2 cars, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c993615f-d2603c39.jpg: 384x640 10 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c994e726-55ae7597.jpg: 384x640 5 cars, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c994e726-d8b6115b.jpg: 384x640 6 cars, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9675/10000 [05:10<00:10, 31.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9957093-21cf5834.jpg: 384x640 1 car, 1 traffic light, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c997006a-1cbe344f.jpg: 384x640 10 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c99927e4-a37dc628.jpg: 384x640 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c99a4baf-83420a6e.jpg: 384x640 7 cars, 1 truck, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9679/10000 [05:10<00:09, 33.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c99a4baf-9b8ca7d9.jpg: 384x640 5 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c99a4baf-a0146015.jpg: 384x640 8 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c99a4baf-daaaed61.jpg: 384x640 5 cars, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a03aa8-301aafe7.jpg: 384x640 2 persons, 6 cars, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9683/10000 [05:10<00:09, 33.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a270fa-dddd15ff.jpg: 384x640 5 cars, 1 truck, 9.6ms\n",
            "Speed: 1.8ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a2a6db-a5b0a35d.jpg: 384x640 9 cars, 1 traffic light, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a2b46c-e2f795a7.jpg: 384x640 5 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a3a466-84e613da.jpg: 384x640 3 persons, 4 cars, 1 truck, 1 traffic light, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9687/10000 [05:11<00:09, 34.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a41ce3-bd04c1ae.jpg: 384x640 3 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a4aaee-24651f2a.jpg: 384x640 5 cars, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a4c2a2-e2ef482c.jpg: 384x640 4 cars, 1 bus, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a5380e-01e2abe2.jpg: 384x640 9 cars, 1 truck, 1 stop sign, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9691/10000 [05:11<00:08, 34.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a653e3-533efdd4.jpg: 384x640 4 cars, 1 truck, 1 traffic light, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a653e3-746daa0d.jpg: 384x640 4 cars, 4 traffic lights, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a80c9b-67f90548.jpg: 384x640 9 cars, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a91df9-fa338ec9.jpg: 384x640 1 person, 3 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9695/10000 [05:11<00:09, 33.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a9290b-86ad51fb.jpg: 384x640 1 person, 3 cars, 1 traffic light, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9a9a2a9-57519e11.jpg: 384x640 1 person, 8 cars, 1 truck, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9aa50be-62caa81b.jpg: 384x640 8 persons, 5 cars, 1 truck, 1 traffic light, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9aa50be-8c87193e.jpg: 384x640 1 person, 6 cars, 1 bus, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9699/10000 [05:11<00:09, 31.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9aa50be-9e8cd399.jpg: 384x640 12 cars, 2 trucks, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b0054d-bded8b46.jpg: 384x640 10 cars, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b0054d-c043599e.jpg: 384x640 2 cars, 1 traffic light, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b099e4-6ab2e4f4.jpg: 384x640 2 cars, 2 trucks, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9703/10000 [05:11<00:09, 31.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b099e4-efc9579f.jpg: 384x640 1 person, 14 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b0aa61-15573161.jpg: 384x640 1 car, 1 train, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b19b83-da526c25.jpg: 384x640 2 persons, 2 cars, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b29647-95da8336.jpg: 384x640 1 car, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9707/10000 [05:11<00:08, 33.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b2aaae-f2ff02a7.jpg: 384x640 7 cars, 1 truck, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b55e48-8c2b4097.jpg: 384x640 3 cars, 1 truck, 5 traffic lights, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b82f4e-454a5878.jpg: 384x640 13 cars, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b82f4e-fd73af29.jpg: 384x640 6 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9711/10000 [05:11<00:08, 33.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b96433-62042524.jpg: 384x640 2 persons, 9 cars, 1 bus, 1 truck, 1 fire hydrant, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b96433-8473dd77.jpg: 384x640 8 cars, 2 traffic lights, 1 fire hydrant, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b9fef4-8aca0267.jpg: 384x640 13 cars, 1 truck, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9b9fef4-a58bf3d5.jpg: 384x640 1 person, 9 cars, 2 buss, 1 truck, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9715/10000 [05:11<00:08, 32.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9bbc56e-b61223fd.jpg: 384x640 3 cars, 4 traffic lights, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9bbc56e-b9f39d14.jpg: 384x640 7 cars, 4 traffic lights, 11.4ms\n",
            "Speed: 1.7ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9bdd74a-9dc0ad2e.jpg: 384x640 8 cars, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c0e486-f197b842.jpg: 384x640 11 cars, 1 traffic light, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9719/10000 [05:12<00:08, 32.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c31e57-3f228293.jpg: 384x640 4 cars, 6 motorcycles, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c31e57-45b42452.jpg: 384x640 9 cars, 1 fire hydrant, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c4d608-4555cd80.jpg: 384x640 4 cars, 2 buss, 2 trucks, 1 traffic light, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c4d608-be7ef06b.jpg: 384x640 5 persons, 6 cars, 2 trucks, 5 traffic lights, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9723/10000 [05:12<00:08, 31.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c4e755-d4a99803.jpg: 384x640 4 traffic lights, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c6949a-14eea22b.jpg: 384x640 1 person, 5 cars, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c6949a-5aeaa8fd.jpg: 384x640 6 cars, 1 traffic light, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c77676-1fa8e0d6.jpg: 384x640 1 person, 3 cars, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9727/10000 [05:12<00:08, 31.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c778b5-772ddc4a.jpg: 384x640 9 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c778b5-83f9cec1.jpg: 384x640 3 cars, 1 truck, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c778b5-86bddb7e.jpg: 384x640 1 person, 9 cars, 2 traffic lights, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-2215a6b7.jpg: 384x640 3 cars, 1 traffic light, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9731/10000 [05:12<00:08, 30.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-27dae64a.jpg: 384x640 2 cars, 2 traffic lights, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-2bf3ae13.jpg: 384x640 3 cars, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-361e5664.jpg: 384x640 2 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-3d954113.jpg: 384x640 2 cars, 1 bus, 1 truck, 1 traffic light, 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9735/10000 [05:12<00:08, 32.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-8c053a4c.jpg: 384x640 10 cars, 1 truck, 2 traffic lights, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-94e65449.jpg: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-c15e8390.jpg: 384x640 6 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-c6c0bdf8.jpg: 384x640 3 cars, 1 traffic light, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9739/10000 [05:12<00:07, 34.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-cc8f42ba.jpg: 384x640 1 car, 1 truck, 20.0ms\n",
            "Speed: 1.8ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9c9235f-d2de2015.jpg: 384x640 1 car, 1 traffic light, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ca4c6c-4c9db372.jpg: 384x640 5 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ca4ffe-8eb6d592.jpg: 384x640 1 person, 1 car, 1 traffic light, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9743/10000 [05:12<00:07, 34.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ca4ffe-c34137ab.jpg: 384x640 3 cars, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cbf127-148245d2.jpg: 384x640 5 cars, 1 truck, 2 traffic lights, 9.3ms\n",
            "Speed: 1.7ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cc3cb0-b0085030.jpg: 384x640 3 cars, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cc53f7-2ac83c8c.jpg: 384x640 1 person, 6 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  97%|█████████▋| 9747/10000 [05:12<00:07, 34.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cd9fa8-30108c57.jpg: 384x640 8 cars, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cd9fa8-6f90442b.jpg: 384x640 2 cars, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cd9fa8-d69dfb4e.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf1065-0f19dbe2.jpg: 384x640 1 car, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9751/10000 [05:13<00:07, 34.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf1065-5578a982.jpg: 384x640 5 cars, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf1065-58a17ed3.jpg: 384x640 4 cars, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf1065-71498367.jpg: 384x640 8 cars, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf1065-8dbf1363.jpg: 384x640 1 car, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf1065-e9fd4f91.jpg: 384x640 2 persons, 1 car, 10.0ms\n",
            "Speed: 4.4ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9756/10000 [05:13<00:06, 35.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf1065-f841eddc.jpg: 384x640 6 cars, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf1065-fd69ddbf.jpg: 384x640 2 cars, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9cf175a-131d4aae.jpg: 384x640 3 cars, 1 traffic light, 16.4ms\n",
            "Speed: 2.4ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d61a6d-92609e9c.jpg: 384x640 7 cars, 2 traffic lights, 17.5ms\n",
            "Speed: 1.9ms preprocess, 17.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9760/10000 [05:13<00:07, 32.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d61a6d-986df2e9.jpg: 384x640 9 cars, 1 traffic light, 17.9ms\n",
            "Speed: 3.9ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d6a839-f66aaace.jpg: 384x640 6 persons, 17 cars, 19.2ms\n",
            "Speed: 2.9ms preprocess, 19.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d6dbc7-5580002c.jpg: 384x640 1 truck, 15.3ms\n",
            "Speed: 2.0ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d6dbc7-edc72471.jpg: 384x640 14 cars, 13.6ms\n",
            "Speed: 5.5ms preprocess, 13.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9764/10000 [05:13<00:08, 28.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d7b898-27eba05f.jpg: 384x640 2 cars, 17.8ms\n",
            "Speed: 1.9ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d7eba9-57de0925.jpg: 384x640 2 persons, 5 cars, 14.5ms\n",
            "Speed: 3.0ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d89485-18576ffb.jpg: 384x640 1 person, 1 bicycle, 3 cars, 1 train, 10.1ms\n",
            "Speed: 6.3ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9767/10000 [05:13<00:08, 27.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d9a47f-951c00bd.jpg: 384x640 4 persons, 3 cars, 1 traffic light, 16.6ms\n",
            "Speed: 3.2ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9d9cbf9-e86cf1ef.jpg: 384x640 8 cars, 1 traffic light, 17.4ms\n",
            "Speed: 1.8ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9dc0649-b5aa2483.jpg: 384x640 1 car, 3 traffic lights, 15.8ms\n",
            "Speed: 3.9ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9770/10000 [05:13<00:08, 25.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9dc96aa-01dec7af.jpg: 384x640 3 cars, 15.1ms\n",
            "Speed: 3.2ms preprocess, 15.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9de245d-d0bf2816.jpg: 384x640 3 cars, 1 bus, 14.2ms\n",
            "Speed: 3.7ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9dedfc8-b23ac57e.jpg: 384x640 2 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df3b7e-0bf4fa31.jpg: 384x640 2 persons, 4 cars, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9774/10000 [05:13<00:08, 27.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df3b7e-2b54cd7f.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df3b7e-4701c0f2.jpg: 384x640 3 cars, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df3b7e-bb72e430.jpg: 384x640 5 cars, 14.9ms\n",
            "Speed: 1.9ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df3b7e-bfcabe04.jpg: 384x640 3 cars, 1 traffic light, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9778/10000 [05:13<00:07, 29.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df3b7e-ef94efe9.jpg: 384x640 1 person, 4 cars, 1 truck, 1 traffic light, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df836e-5955e515.jpg: 384x640 1 person, 1 car, 1 traffic light, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df836e-80c5caa3.jpg: 384x640 5 cars, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9df836e-b8fcc9d7.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9782/10000 [05:14<00:07, 30.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9dfbc72-db954e64.jpg: 384x640 (no detections), 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9dfbdd0-1d00a047.jpg: 384x640 4 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9e4a2e8-2ac2fabd.jpg: 384x640 2 cars, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9e4a2e8-e29e53ec.jpg: 384x640 3 cars, 1 truck, 8.3ms\n",
            "Speed: 3.9ms preprocess, 8.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9e77458-658d5966.jpg: 384x640 (no detections), 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9787/10000 [05:14<00:06, 33.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9e7c9d4-18d31194.jpg: 384x640 6 cars, 1 bus, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ead9ee-4ebeef77.jpg: 384x640 1 car, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9eb9a86-523e6e0f.jpg: 384x640 7 cars, 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9eb9a86-c9dd6104.jpg: 384x640 3 cars, 16.9ms\n",
            "Speed: 3.3ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9791/10000 [05:14<00:06, 31.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ece337-21d7e75e.jpg: 384x640 7 cars, 1 bus, 8.8ms\n",
            "Speed: 4.2ms preprocess, 8.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ece337-ff38bdec.jpg: 384x640 6 cars, 1 bus, 4 trucks, 2 traffic lights, 16.6ms\n",
            "Speed: 3.1ms preprocess, 16.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ee0f8e-286c0acb.jpg: 384x640 1 person, 12 cars, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ee0f8e-3308c0e4.jpg: 384x640 5 cars, 1 truck, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9795/10000 [05:14<00:06, 29.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ef0aa9-41d939af.jpg: 384x640 1 person, 7 cars, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ef51b7-9dc86de1.jpg: 384x640 11 cars, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9effc42-0eb861b2.jpg: 384x640 13 cars, 10.3ms\n",
            "Speed: 3.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9effc42-a75644ee.jpg: 384x640 4 cars, 3 buss, 8.6ms\n",
            "Speed: 2.0ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9799/10000 [05:14<00:06, 30.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f5283d-1b02cbcc.jpg: 384x640 2 cars, 1 traffic light, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f5283d-30641e3e.jpg: 384x640 6 cars, 1 truck, 2 traffic lights, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f5283d-36783b15.jpg: 384x640 12 cars, 1 truck, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f5283d-5ef0a1b2.jpg: 384x640 11 cars, 1 bus, 1 truck, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9803/10000 [05:14<00:06, 30.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f5283d-71e7d62c.jpg: 384x640 1 car, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f5283d-7b81eb6b.jpg: 384x640 1 person, 2 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f5283d-8e8344c6.jpg: 384x640 5 cars, 3 traffic lights, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f6b520-19d9d3ad.jpg: 384x640 2 cars, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f6b520-523674ac.jpg: 384x640 7 cars, 13.3ms\n",
            "Speed: 1.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9808/10000 [05:14<00:05, 32.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f9c6ac-b3270e58.jpg: 384x640 3 cars, 1 traffic light, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f9c6ac-ba013d70.jpg: 384x640 4 cars, 1 bus, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9f9c6ac-e412ca03.jpg: 384x640 4 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9fa0253-3a8bc597.jpg: 384x640 8 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9812/10000 [05:15<00:05, 34.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9fb03a5-9a1788d9.jpg: 384x640 6 cars, 1 traffic light, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9fb1a4c-0bd0ea9d.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9fc208f-16aa9283.jpg: 384x640 6 cars, 3 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9fc208f-4cf24bbd.jpg: 384x640 8 cars, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9816/10000 [05:15<00:05, 34.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9fc208f-75876b0b.jpg: 384x640 1 person, 9 cars, 1 traffic light, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9fcc762-bf7c7c67.jpg: 384x640 (no detections), 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9fea009-ee6a4d2a.jpg: 384x640 10 cars, 1 truck, 8.7ms\n",
            "Speed: 6.3ms preprocess, 8.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/c9ffe9d7-7558d38d.jpg: 384x640 5 cars, 1 truck, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9820/10000 [05:15<00:05, 34.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca00540c-261a3e99.jpg: 384x640 3 cars, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca009e13-883fafc6.jpg: 384x640 11 cars, 2 umbrellas, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca009e13-fdb666f6.jpg: 384x640 1 person, 12 cars, 1 traffic light, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca049e30-02338b16.jpg: 384x640 5 cars, 16.5ms\n",
            "Speed: 2.1ms preprocess, 16.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9824/10000 [05:15<00:05, 32.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca049e30-1b2337e2.jpg: 384x640 4 cars, 11.7ms\n",
            "Speed: 3.9ms preprocess, 11.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca049e30-382d661d.jpg: 384x640 12 cars, 13.8ms\n",
            "Speed: 4.3ms preprocess, 13.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca049e30-4e81f5ee.jpg: 384x640 4 cars, 1 train, 18.2ms\n",
            "Speed: 1.8ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca049e30-5d1864a5.jpg: 384x640 4 cars, 2 traffic lights, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9828/10000 [05:15<00:05, 30.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca049e30-cb9982a6.jpg: 384x640 2 cars, 1 traffic light, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca049e30-f0a8ccd4.jpg: 384x640 1 car, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca04d99f-c1282bb7.jpg: 384x640 1 person, 2 cars, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca057c8b-e42f0882.jpg: 384x640 8 cars, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9832/10000 [05:15<00:05, 32.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0619a2-ccd6a93c.jpg: 384x640 6 cars, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca068cb6-1418f2fb.jpg: 384x640 11 cars, 11.4ms\n",
            "Speed: 1.7ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca068cb6-59709029.jpg: 384x640 9 cars, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca068cb6-e29842f7.jpg: 384x640 1 car, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9836/10000 [05:15<00:05, 32.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca074e75-7d525ad9.jpg: 384x640 8 cars, 2 traffic lights, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca077fe9-b7f766fd.jpg: 384x640 5 cars, 3 trucks, 11.3ms\n",
            "Speed: 4.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca077fe9-d2cf4446.jpg: 384x640 3 cars, 9.5ms\n",
            "Speed: 2.0ms preprocess, 9.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca08d93c-c406e9aa.jpg: 384x640 1 car, 1 traffic light, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9840/10000 [05:15<00:05, 31.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca095e13-3477eff3.jpg: 384x640 3 persons, 8 cars, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca095e13-ac7f314a.jpg: 384x640 3 cars, 2 trucks, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca098890-0947e76a.jpg: 384x640 2 persons, 3 cars, 1 bus, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca098890-6ef745ed.jpg: 384x640 9 cars, 1 truck, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9844/10000 [05:16<00:04, 32.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0b4ef4-3917ead1.jpg: 384x640 3 persons, 11 cars, 1 bus, 1 truck, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0b4ef4-effd52f4.jpg: 384x640 1 person, 9 cars, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0de85e-53bdd171.jpg: 384x640 7 cars, 1 traffic light, 11.4ms\n",
            "Speed: 5.8ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0e9da5-d7dece6c.jpg: 384x640 7 cars, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  98%|█████████▊| 9848/10000 [05:16<00:04, 31.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0e9da5-f5507d00.jpg: 384x640 1 person, 5 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0eb18c-165a3cc9.jpg: 384x640 3 cars, 1 truck, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0eb18c-772780e0.jpg: 384x640 1 car, 2 traffic lights, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0eb18c-907cd101.jpg: 384x640 5 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▊| 9852/10000 [05:16<00:04, 32.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0eb18c-b0e6fe6c.jpg: 384x640 2 cars, 1 traffic light, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0f0248-0350c116.jpg: 384x640 1 car, 14.5ms\n",
            "Speed: 4.0ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0f0248-0d55e8dd.jpg: 384x640 1 truck, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0fd2c4-30e68102.jpg: 384x640 5 cars, 1 bus, 1 truck, 21.4ms\n",
            "Speed: 5.0ms preprocess, 21.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▊| 9856/10000 [05:16<00:04, 30.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca0fd2c4-82195ac4.jpg: 384x640 3 cars, 4 trucks, 21.0ms\n",
            "Speed: 5.3ms preprocess, 21.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca130ab2-7f5598b7.jpg: 384x640 7 cars, 18.1ms\n",
            "Speed: 1.9ms preprocess, 18.1ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca146661-7f70d0c4.jpg: 384x640 5 cars, 14.7ms\n",
            "Speed: 2.0ms preprocess, 14.7ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1543ec-4ef9d107.jpg: 384x640 9 cars, 12.9ms\n",
            "Speed: 6.0ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▊| 9860/10000 [05:16<00:05, 26.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1543ec-6ad48f6e.jpg: 384x640 7 persons, 12 cars, 1 traffic light, 15.0ms\n",
            "Speed: 2.1ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca15f699-e51c14c0.jpg: 384x640 1 car, 22.0ms\n",
            "Speed: 2.0ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca177f63-6cb08f25.jpg: 384x640 1 person, 10 cars, 1 bus, 2 traffic lights, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▊| 9863/10000 [05:16<00:05, 24.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca17cd93-f9c06b09.jpg: 384x640 6 cars, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca189794-fa2c18e9.jpg: 384x640 (no detections), 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca18c314-eec8974d.jpg: 384x640 4 cars, 16.1ms\n",
            "Speed: 1.9ms preprocess, 16.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca194104-1aa2aa9a.jpg: 384x640 6 cars, 13.1ms\n",
            "Speed: 4.9ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▊| 9867/10000 [05:16<00:04, 26.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1a41b3-38240d1e.jpg: 384x640 1 person, 4 cars, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1a87ef-4f83ae99.jpg: 384x640 3 cars, 3 traffic lights, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1a87ef-5b03345d.jpg: 384x640 8 cars, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1a87ef-783b4ceb.jpg: 384x640 1 car, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▊| 9871/10000 [05:16<00:04, 28.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1a92b5-4677f24c.jpg: 384x640 6 cars, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1b1f3e-64dd9b2a.jpg: 384x640 5 persons, 2 cars, 1 bus, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1b5c7f-2ef9c22a.jpg: 384x640 1 person, 4 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1c6003-aad4464c.jpg: 384x640 4 cars, 1 bus, 2 trucks, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca1d52b5-84e8dfa0.jpg: 384x640 2 cars, 1 traffic light, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9876/10000 [05:17<00:03, 31.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca21055c-2050513f.jpg: 384x640 3 cars, 1 bus, 2 trucks, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca21055c-8a012812.jpg: 384x640 5 cars, 2 traffic lights, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca21055c-a1a80ec4.jpg: 384x640 7 cars, 3 traffic lights, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca222491-8d710efa.jpg: 384x640 3 cars, 1 bus, 1 truck, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9880/10000 [05:17<00:03, 33.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2260e9-51ebcdc6.jpg: 384x640 2 cars, 5 traffic lights, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca23fea0-97c90df7.jpg: 384x640 5 persons, 6 cars, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca24a6cf-59fe35d2.jpg: 384x640 1 person, 6 cars, 1 truck, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca25cf74-7cb42159.jpg: 384x640 2 persons, 3 cars, 1 bus, 1 truck, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9884/10000 [05:17<00:03, 32.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca284215-73cade97.jpg: 384x640 9 cars, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca284215-d643be76.jpg: 384x640 2 persons, 6 cars, 1 traffic light, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca28f275-03f8cef5.jpg: 384x640 2 cars, 5 traffic lights, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca28f275-08807c93.jpg: 384x640 2 cars, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9888/10000 [05:17<00:03, 32.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca28f275-24384f38.jpg: 384x640 5 cars, 1 bench, 15.6ms\n",
            "Speed: 2.1ms preprocess, 15.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca28f275-95fc6836.jpg: 384x640 3 cars, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca28f275-ca28f770.jpg: 384x640 1 car, 17.4ms\n",
            "Speed: 2.8ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca28f275-cac4f254.jpg: 384x640 2 persons, 3 cars, 1 traffic light, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9892/10000 [05:17<00:03, 30.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca28f275-df2e6ad2.jpg: 384x640 9 cars, 21.3ms\n",
            "Speed: 3.4ms preprocess, 21.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca297f76-c2ce18f5.jpg: 384x640 9 cars, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca29b7bd-0820fffb.jpg: 384x640 5 cars, 2 traffic lights, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2b7ab0-bfdc0fec.jpg: 384x640 (no detections), 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9896/10000 [05:17<00:03, 30.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2ba838-fdddb1fb.jpg: 384x640 8 persons, 5 cars, 3 suitcases, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2bcf0e-69e964d2.jpg: 384x640 4 cars, 1 truck, 15.8ms\n",
            "Speed: 1.9ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2c7c84-39bf84ee.jpg: 384x640 1 person, 6 cars, 1 train, 1 truck, 17.1ms\n",
            "Speed: 1.8ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2c7c84-5495c318.jpg: 384x640 4 cars, 11.2ms\n",
            "Speed: 4.1ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9900/10000 [05:17<00:03, 29.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2c7c84-5902ee09.jpg: 384x640 3 persons, 7 cars, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2c7c84-ba7685fc.jpg: 384x640 1 person, 10 cars, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2d1df6-54538d1a.jpg: 384x640 3 cars, 2 traffic lights, 14.2ms\n",
            "Speed: 4.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9903/10000 [05:18<00:03, 27.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2d1df6-76d59c0c.jpg: 384x640 8 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2d32b3-5e8835ac.jpg: 384x640 11 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca2fb80b-9d22e350.jpg: 384x640 11 cars, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3045ee-a27490fa.jpg: 384x640 2 cars, 12.4ms\n",
            "Speed: 1.9ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9907/10000 [05:18<00:03, 28.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3045ee-b8ab4712.jpg: 384x640 1 car, 12.1ms\n",
            "Speed: 1.8ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3045ee-ec76b7c9.jpg: 384x640 9 cars, 2 traffic lights, 13.8ms\n",
            "Speed: 1.9ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca309fd3-10ac1488.jpg: 384x640 8 cars, 15.2ms\n",
            "Speed: 2.0ms preprocess, 15.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9910/10000 [05:18<00:03, 28.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca309fd3-4a6f706c.jpg: 384x640 10 cars, 2 trucks, 12.2ms\n",
            "Speed: 6.5ms preprocess, 12.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca309fd3-c485c1eb.jpg: 384x640 13 cars, 16.9ms\n",
            "Speed: 4.7ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca309fd3-f767659b.jpg: 384x640 9 cars, 1 truck, 2 traffic lights, 17.6ms\n",
            "Speed: 3.6ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9913/10000 [05:18<00:03, 26.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3165e0-175d6f79.jpg: 384x640 1 person, 3 cars, 1 motorcycle, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3165e0-3a330c98.jpg: 384x640 7 cars, 11.4ms\n",
            "Speed: 4.5ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3165e0-949dbfc8.jpg: 384x640 10 cars, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9916/10000 [05:18<00:03, 27.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3165e0-a8c1ce7a.jpg: 384x640 1 bus, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3165e0-c1c82c8f.jpg: 384x640 2 cars, 1 truck, 1 traffic light, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca319f4c-b34af0f1.jpg: 384x640 (no detections), 11.7ms\n",
            "Speed: 1.8ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca326312-b648ccab.jpg: 384x640 6 cars, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9920/10000 [05:18<00:02, 29.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca35c192-7f0eadba.jpg: 384x640 6 cars, 1 bus, 13.4ms\n",
            "Speed: 7.8ms preprocess, 13.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3736db-3471ce50.jpg: 384x640 5 cars, 1 bus, 1 truck, 10.0ms\n",
            "Speed: 4.9ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3736db-ab6db00c.jpg: 384x640 9 cars, 1 truck, 3 traffic lights, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3736db-cc8e1fb7.jpg: 384x640 6 cars, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9924/10000 [05:18<00:02, 28.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3736db-cd087585.jpg: 384x640 11 cars, 1 traffic light, 1 stop sign, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3736db-cf9e0cd4.jpg: 384x640 12 cars, 1 bus, 1 truck, 4 traffic lights, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3bbb0a-115a055f.jpg: 384x640 1 car, 2 traffic lights, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9927/10000 [05:18<00:02, 27.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3bbb0a-255bb069.jpg: 384x640 (no detections), 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3bbb0a-b711f4e3.jpg: 384x640 2 cars, 1 truck, 4 traffic lights, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3bbb0a-cd13da9e.jpg: 384x640 9 cars, 2 trucks, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3bf9b0-55d6ae41.jpg: 384x640 (no detections), 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9931/10000 [05:19<00:02, 29.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3bf9b0-ab1201eb.jpg: 384x640 1 car, 1 traffic light, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3e6e3d-cc5275dd.jpg: 384x640 5 cars, 1 traffic light, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3e6e3d-f66373c8.jpg: 384x640 (no detections), 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3f4c16-add215c4.jpg: 384x640 3 persons, 4 cars, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9935/10000 [05:19<00:02, 30.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca3f4c16-b33f3a0b.jpg: 384x640 8 cars, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca4071a6-6fa1a1c8.jpg: 384x640 8 cars, 1 truck, 3 traffic lights, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca40ddd3-102f3b02.jpg: 384x640 3 persons, 4 cars, 2 traffic lights, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca40ddd3-f81f28e9.jpg: 384x640 2 persons, 1 bicycle, 4 cars, 18.7ms\n",
            "Speed: 1.9ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9939/10000 [05:19<00:02, 30.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca4269e1-0f1e4f92.jpg: 384x640 1 person, 3 cars, 11.7ms\n",
            "Speed: 6.0ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca4269e1-80c4e87b.jpg: 384x640 3 persons, 7 cars, 1 truck, 20.4ms\n",
            "Speed: 2.1ms preprocess, 20.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca4269e1-914f1061.jpg: 384x640 4 cars, 2 traffic lights, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca4269e1-a3a6e21a.jpg: 384x640 5 cars, 16.5ms\n",
            "Speed: 6.9ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9943/10000 [05:19<00:02, 27.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca4269e1-db6d731e.jpg: 384x640 3 cars, 18.6ms\n",
            "Speed: 1.8ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca430005-edb0085d.jpg: 384x640 2 persons, 1 car, 1 motorcycle, 1 traffic light, 15.8ms\n",
            "Speed: 1.8ms preprocess, 15.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca430d8c-0b371423.jpg: 384x640 13 cars, 2 traffic lights, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9946/10000 [05:19<00:02, 26.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca455727-92566d05.jpg: 384x640 2 cars, 2 trucks, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca479701-2ab57f9a.jpg: 384x640 4 cars, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca4bdfab-34ec6a3a.jpg: 384x640 2 cars, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:  99%|█████████▉| 9949/10000 [05:19<00:01, 26.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca509e4e-a3166aa9.jpg: 384x640 2 cars, 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca513280-e4ec496c.jpg: 384x640 1 person, 3 cars, 1 bus, 2 trucks, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca52e79f-eca3eeec.jpg: 384x640 6 cars, 1 traffic light, 13.1ms\n",
            "Speed: 1.9ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9952/10000 [05:19<00:01, 26.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca546e6d-852f3913.jpg: 384x640 12 cars, 1 truck, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca551156-5999d6d4.jpg: 384x640 3 persons, 4 cars, 3 traffic lights, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca551156-fb7d1680.jpg: 384x640 4 cars, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca55fb23-6aec0f71.jpg: 384x640 3 persons, 8 cars, 1 motorcycle, 2 traffic lights, 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9956/10000 [05:19<00:01, 28.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca55fb23-83a86167.jpg: 384x640 3 cars, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca55fb23-f91ca9ad.jpg: 384x640 2 persons, 4 cars, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca561e94-8f719a63.jpg: 384x640 4 cars, 2 buss, 1 truck, 1 traffic light, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca561e94-d40cddf8.jpg: 384x640 1 person, 3 cars, 2 trucks, 9.1ms\n",
            "Speed: 1.8ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9960/10000 [05:20<00:01, 30.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca56690a-05ed80e9.jpg: 384x640 2 cars, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca56898d-f6400cb3.jpg: 384x640 1 car, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca587a24-113bd37a.jpg: 384x640 2 cars, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca5925b8-ca06566b.jpg: 384x640 4 cars, 2 trucks, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9964/10000 [05:20<00:01, 31.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca59adc8-62801139.jpg: 384x640 14 cars, 1 traffic light, 11.3ms\n",
            "Speed: 1.8ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca59adc8-9001648c.jpg: 384x640 5 cars, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca59adc8-d7551f95.jpg: 384x640 8 cars, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca5e947c-c2f1d14b.jpg: 384x640 3 cars, 14.0ms\n",
            "Speed: 4.8ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9968/10000 [05:20<00:01, 31.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca5e947c-c6ac10fd.jpg: 384x640 8 cars, 1 traffic light, 15.8ms\n",
            "Speed: 4.2ms preprocess, 15.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca5f8e49-0df2e0a1.jpg: 384x640 2 cars, 1 traffic light, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca5fba82-4e60d94e.jpg: 384x640 8 cars, 17.4ms\n",
            "Speed: 1.9ms preprocess, 17.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca6142b4-ef037b5b.jpg: 384x640 1 car, 2 traffic lights, 12.8ms\n",
            "Speed: 1.9ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9972/10000 [05:20<00:00, 29.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca6170df-1893979a.jpg: 384x640 6 cars, 14.9ms\n",
            "Speed: 3.9ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca6170df-a566823d.jpg: 384x640 1 traffic light, 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca6170df-c1a75664.jpg: 384x640 5 cars, 17.1ms\n",
            "Speed: 1.9ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9975/10000 [05:20<00:00, 28.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca6412a2-3db85e24.jpg: 384x640 4 cars, 14.0ms\n",
            "Speed: 4.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca656c47-876ad414.jpg: 384x640 1 person, 10 cars, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca656c47-e483f464.jpg: 384x640 2 persons, 7 cars, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9978/10000 [05:20<00:00, 27.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca679a1e-a680fd14.jpg: 384x640 14 cars, 14.9ms\n",
            "Speed: 4.8ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca679a1e-b92f424d.jpg: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca679a1e-cee7f0bc.jpg: 384x640 2 cars, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca68e8b3-3ecd270a.jpg: 384x640 1 car, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9982/10000 [05:20<00:00, 29.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/ca6927ab-497d6b29.jpg: 384x640 1 car, 3 traffic lights, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe189115-9981a740.jpg: 384x640 1 person, 1 car, 2 traffic lights, 11.3ms\n",
            "Speed: 2.7ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe189115-9cc4a501.jpg: 384x640 13 cars, 1 truck, 1 traffic light, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe189115-adbd209a.jpg: 384x640 4 cars, 1 truck, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9986/10000 [05:20<00:00, 29.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe189115-c31cac5a.jpg: 384x640 3 cars, 1 traffic light, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe189115-cfad8fcf.jpg: 384x640 3 persons, 7 cars, 1 bus, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe194677-e2d2ac8c.jpg: 384x640 7 cars, 2 trucks, 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9989/10000 [05:21<00:00, 28.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1b3799-a7863feb.jpg: 384x640 2 persons, 6 cars, 1 bus, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1b92a1-faaaa1eb.jpg: 384x640 1 car, 14.6ms\n",
            "Speed: 1.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1cc363-a3f36598.jpg: 384x640 9 cars, 1 bus, 2 trucks, 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9992/10000 [05:21<00:00, 28.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1d74f0-5cdc4057.jpg: 384x640 2 persons, 2 cars, 2 traffic lights, 21.0ms\n",
            "Speed: 1.9ms preprocess, 21.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1d74f0-6969bdb5.jpg: 384x640 1 car, 1 bus, 1 truck, 1 traffic light, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1d9184-cd999efe.jpg: 384x640 6 cars, 4 traffic lights, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9995/10000 [05:21<00:00, 27.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1d9184-d144106a.jpg: 384x640 13 cars, 2 trucks, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1d9184-dec09b65.jpg: 384x640 1 person, 1 car, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1f2409-5b415eb7.jpg: 384x640 (no detections), 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1f2409-c16ea1ed.jpg: 384x640 3 persons, 5 cars, 1 truck, 2 traffic lights, 18.5ms\n",
            "Speed: 2.1ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|█████████▉| 9999/10000 [05:21<00:00, 28.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/data/val_images/bdd100k/images/100k/val/fe1f55fa-19ba3600.jpg: 384x640 1 bus, 1 truck, 18.4ms\n",
            "Speed: 1.9ms preprocess, 18.4ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating: 100%|██████████| 10000/10000 [05:21<00:00, 31.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth Categories: {'bicycle', 'rider', 'trailer', 'other person', 'traffic light', 'truck', 'bus', 'other vehicle', 'car', 'train', 'motorcycle', 'pedestrian', 'traffic sign'}\n",
            "\n",
            "Class-wise Results:\n",
            "Category: bicycle\n",
            "  Precision: 0.72\n",
            "  Recall: 0.11\n",
            "  F1-score: 0.20\n",
            "  TP: 115, FP: 45, FN: 892\n",
            "Category: rider\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  TP: 0, FP: 0, FN: 654\n",
            "Category: trailer\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  TP: 0, FP: 0, FN: 1\n",
            "Category: other person\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  TP: 0, FP: 0, FN: 1\n",
            "Category: traffic light\n",
            "  Precision: 0.50\n",
            "  Recall: 0.09\n",
            "  F1-score: 0.15\n",
            "  TP: 2428, FP: 2415, FN: 24693\n",
            "Category: truck\n",
            "  Precision: 0.70\n",
            "  Recall: 0.46\n",
            "  F1-score: 0.55\n",
            "  TP: 2112, FP: 924, FN: 2495\n",
            "Category: bus\n",
            "  Precision: 0.72\n",
            "  Recall: 0.46\n",
            "  F1-score: 0.56\n",
            "  TP: 776, FP: 309, FN: 909\n",
            "Category: other vehicle\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  TP: 0, FP: 0, FN: 64\n",
            "Category: car\n",
            "  Precision: 0.79\n",
            "  Recall: 0.39\n",
            "  F1-score: 0.52\n",
            "  TP: 39760, FP: 10870, FN: 62773\n",
            "Category: train\n",
            "  Precision: 0.14\n",
            "  Recall: 0.63\n",
            "  F1-score: 0.23\n",
            "  TP: 24, FP: 148, FN: 14\n",
            "Category: motorcycle\n",
            "  Precision: 0.74\n",
            "  Recall: 0.18\n",
            "  F1-score: 0.29\n",
            "  TP: 83, FP: 29, FN: 380\n",
            "Category: pedestrian\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  TP: 0, FP: 0, FN: 13405\n",
            "Category: traffic sign\n",
            "  Precision: 0.00\n",
            "  Recall: 0.00\n",
            "  F1-score: 0.00\n",
            "  TP: 0, FP: 0, FN: 34454\n",
            "\n",
            "Overall Results:\n",
            "  TP: 45298, FP: 14740, FN: 140735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "# Step 1: Define paths\n",
        "train_image_path = \"/content/data/train_images/bdd100k/images/100k/train\"\n",
        "train_label_path = \"/content/data/labels/bdd100k/labels/det_20/det_train.json\"\n",
        "output_dataset_path = \"/content/yolo_dataset\"  # YOLO 형식으로 변환된 데이터 저장 위치\n",
        "\n",
        "# Step 2: Clear and recreate YOLO dataset directories\n",
        "if os.path.exists(output_dataset_path):\n",
        "    shutil.rmtree(output_dataset_path)  # Recursively delete the folder\n",
        "\n",
        "os.makedirs(f\"{output_dataset_path}/images/train\", exist_ok=True)\n",
        "os.makedirs(f\"{output_dataset_path}/labels/train\", exist_ok=True)\n",
        "\n",
        "print(\"Existing dataset directory cleared and reset.\")\n",
        "\n",
        "# Step 3: Load JSON annotations\n",
        "with open(train_label_path, 'r') as f:\n",
        "    train_annotations = json.load(f)\n",
        "\n",
        "# Step 4: Define a function to convert bounding box to YOLO format\n",
        "def convert_bbox_to_yolo_format(img_width, img_height, box):\n",
        "    \"\"\"Convert bounding box from absolute coordinates to YOLO format.\"\"\"\n",
        "    x_center = (box['x1'] + box['x2']) / 2 / img_width\n",
        "    y_center = (box['y1'] + box['y2']) / 2 / img_height\n",
        "    width = (box['x2'] - box['x1']) / img_width\n",
        "    height = (box['y2'] - box['y1']) / img_height\n",
        "    return x_center, y_center, width, height\n",
        "\n",
        "# Step 5: Process annotations and prepare YOLO format data\n",
        "for annotation in tqdm(train_annotations, desc=\"Processing annotations\"):\n",
        "    image_name = annotation['name']\n",
        "    image_path = os.path.join(train_image_path, image_name)\n",
        "    label_path = f\"{output_dataset_path}/labels/train/{os.path.splitext(image_name)[0]}.txt\"\n",
        "\n",
        "    # Check if 'labels' key exists and is not empty\n",
        "    if 'labels' not in annotation or not annotation['labels']:\n",
        "        # If no labels, skip and delete the corresponding image if exists\n",
        "        if os.path.exists(image_path):\n",
        "            os.remove(image_path)  # Remove the image file\n",
        "        continue\n",
        "\n",
        "    # Check if image exists\n",
        "    if not os.path.exists(image_path):\n",
        "        continue\n",
        "\n",
        "    # Copy the image to the YOLO dataset directory (no resizing)\n",
        "    destination_path = f\"{output_dataset_path}/images/train/{image_name}\"\n",
        "    if not os.path.exists(destination_path):\n",
        "        os.link(image_path, destination_path)\n",
        "\n",
        "    # Write YOLO format labels\n",
        "    with open(label_path, 'w') as label_file:\n",
        "        img_width, img_height = 1280, 720  # Assuming default image size (adjust if different)\n",
        "        for label in annotation['labels']:\n",
        "            category = label['category']\n",
        "            if category not in ground_truth_categories:\n",
        "                continue  # Skip if category is not in ground truth categories\n",
        "\n",
        "            # Convert bounding box to YOLO format\n",
        "            box = label['box2d']\n",
        "            yolo_bbox = convert_bbox_to_yolo_format(img_width, img_height, box)\n",
        "            category_id = list(ground_truth_categories).index(category)  # Convert category to class index\n",
        "            label_file.write(f\"{category_id} {' '.join(map(str, yolo_bbox))}\\n\")\n",
        "\n",
        "print(\"Data preparation complete!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvtdcL-6RIkB",
        "outputId": "5dfda282-0b26-43e4-edb3-b977550bcad7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing dataset directory cleared and reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing annotations: 100%|██████████| 69863/69863 [00:24<00:00, 2887.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preparation complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "# Step 1: Define paths\n",
        "val_image_path = \"/content/data/val_images/bdd100k/images/100k/val\"\n",
        "val_label_path = \"/content/data/labels/bdd100k/labels/det_20/det_val.json\"\n",
        "output_val_dataset_path = \"/content/yolo_dataset\"  # YOLO 형식으로 변환된 데이터 저장 위치\n",
        "\n",
        "# Step 2: Clear and recreate YOLO dataset directories for validation\n",
        "os.makedirs(f\"{output_val_dataset_path}/images/val\", exist_ok=True)\n",
        "os.makedirs(f\"{output_val_dataset_path}/labels/val\", exist_ok=True)\n",
        "\n",
        "print(\"Validation dataset directory cleared and reset.\")\n",
        "\n",
        "# Step 3: Load JSON annotations\n",
        "with open(val_label_path, 'r') as f:\n",
        "    val_annotations = json.load(f)\n",
        "\n",
        "# Step 4: Define a function to convert bounding box to YOLO format\n",
        "def convert_bbox_to_yolo_format(img_width, img_height, box):\n",
        "    \"\"\"Convert bounding box from absolute coordinates to YOLO format.\"\"\"\n",
        "    x_center = (box['x1'] + box['x2']) / 2 / img_width\n",
        "    y_center = (box['y1'] + box['y2']) / 2 / img_height\n",
        "    width = (box['x2'] - box['x1']) / img_width\n",
        "    height = (box['y2'] - box['y1']) / img_height\n",
        "    return x_center, y_center, width, height\n",
        "\n",
        "# Step 5: Process annotations and prepare YOLO format validation data\n",
        "for annotation in tqdm(val_annotations, desc=\"Processing validation annotations\"):\n",
        "    image_name = annotation['name']\n",
        "    image_path = os.path.join(val_image_path, image_name)\n",
        "    label_path = f\"{output_val_dataset_path}/labels/val/{os.path.splitext(image_name)[0]}.txt\"\n",
        "\n",
        "    # Check if 'labels' key exists and is not empty\n",
        "    if 'labels' not in annotation or not annotation['labels']:\n",
        "        # If no labels, skip and delete the corresponding image if exists\n",
        "        if os.path.exists(image_path):\n",
        "            os.remove(image_path)  # Remove the image file\n",
        "        continue\n",
        "\n",
        "    # Check if image exists\n",
        "    if not os.path.exists(image_path):\n",
        "        continue\n",
        "\n",
        "    # Copy the image to the YOLO dataset validation directory\n",
        "    destination_path = f\"{output_val_dataset_path}/images/val/{image_name}\"\n",
        "    if not os.path.exists(destination_path):\n",
        "        os.link(image_path, destination_path)\n",
        "\n",
        "    # Write YOLO format labels\n",
        "    with open(label_path, 'w') as label_file:\n",
        "        img_width, img_height = 1280, 720  # Assuming default image size (adjust if different)\n",
        "        for label in annotation['labels']:\n",
        "            category = label['category']\n",
        "            if category not in ground_truth_categories:\n",
        "                continue  # Skip if category is not in ground truth categories\n",
        "\n",
        "            # Convert bounding box to YOLO format\n",
        "            box = label['box2d']\n",
        "            yolo_bbox = convert_bbox_to_yolo_format(img_width, img_height, box)\n",
        "            category_id = list(ground_truth_categories).index(category)  # Convert category to class index\n",
        "            label_file.write(f\"{category_id} {' '.join(map(str, yolo_bbox))}\\n\")\n",
        "\n",
        "print(\"Validation data preparation complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx7UjmZOVR1x",
        "outputId": "81fb8516-5f60-4ed5-ccc9-0212817c8ab2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation dataset directory cleared and reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing validation annotations: 100%|██████████| 10000/10000 [00:02<00:00, 3421.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation data preparation complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Step 1: Create data.yaml file\n",
        "# Assuming ground_truth_categories is already defined\n",
        "data_yaml = {\n",
        "    \"train\": \"/content/yolo_dataset/images/train\",  # Path to train images\n",
        "    \"val\": \"/content/yolo_dataset/images/val\",      # Path to validation images\n",
        "    \"nc\": len(ground_truth_categories),            # Number of classes\n",
        "    \"names\": list(ground_truth_categories)         # Class names\n",
        "}\n",
        "\n",
        "# Save the data.yaml file\n",
        "with open(\"/content/data.yaml\", \"w\") as f:\n",
        "    yaml.dump(data_yaml, f)\n",
        "\n",
        "print(\"data.yaml created successfully!\")\n",
        "\n",
        "# Step 2: Load YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")  # Use YOLOv8 Nano model for faster training\n",
        "\n",
        "# Step 3: Train the model\n",
        "model.train(\n",
        "    data=\"/content/data.yaml\",           # Path to dataset configuration\n",
        "    epochs=10,                           # Train for 10 epochs\n",
        "    imgsz=320,                           # Image size set to 320x320\n",
        "    batch=16,                            # Batch size\n",
        "    name=\"bdd100k_finetune_with_val\",    # Name of the experiment\n",
        "    fraction=0.1,                        # Use only 10% of train dataset\n",
        "    workers=2                            # Number of workers for data loading\n",
        ")\n",
        "\n",
        "print(\"Fine-tuning complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LOVKnFoWfBX",
        "outputId": "6ca9d467-9eeb-4468-efd4-147c75cf2aa6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml created successfully!\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=2, project=None, name=bdd100k_finetune_with_val, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=0.1, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/bdd100k_finetune_with_val\n",
            "Overriding model.yaml nc=80 with nc=13\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753847  ultralytics.nn.modules.head.Detect           [13, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3,013,383 parameters, 3,013,367 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/bdd100k_finetune_with_val', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_dataset/labels/train.cache... 6985 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6985/6985 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels/val... 10000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10000/10000 [00:15<00:00, 661.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_dataset/labels/val.cache\n",
            "Plotting labels to runs/detect/bdd100k_finetune_with_val/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000588, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/bdd100k_finetune_with_val\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.837G      1.789      2.025      1.056        168        320: 100%|██████████| 437/437 [01:30<00:00,  4.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:24<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.523      0.075     0.0628     0.0339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      0.86G      1.666      1.267      1.025        169        320: 100%|██████████| 437/437 [01:28<00:00,  4.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:19<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.452     0.0876     0.0717     0.0382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.952G      1.625      1.179      1.013        175        320: 100%|██████████| 437/437 [01:25<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:17<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.463     0.0906     0.0753       0.04\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.879G      1.589      1.117      1.005        147        320: 100%|██████████| 437/437 [01:24<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:16<00:00,  4.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.323     0.0965     0.0827     0.0438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.879G      1.559      1.063     0.9934        137        320: 100%|██████████| 437/437 [01:23<00:00,  5.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:17<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.362      0.101     0.0934     0.0502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.858G      1.525      1.026     0.9825        165        320: 100%|██████████| 437/437 [01:25<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:17<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.284      0.118        0.1     0.0534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.854G      1.495     0.9926      0.975        202        320: 100%|██████████| 437/437 [01:23<00:00,  5.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:17<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.269       0.12      0.103     0.0562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      0.91G      1.474     0.9645     0.9665        147        320: 100%|██████████| 437/437 [01:25<00:00,  5.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:18<00:00,  3.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033       0.28      0.125      0.107     0.0578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      0.87G      1.445      0.942     0.9595        135        320: 100%|██████████| 437/437 [01:24<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:18<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.362      0.131      0.111      0.061\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.841G      1.432     0.9213     0.9569        194        320: 100%|██████████| 437/437 [01:25<00:00,  5.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:18<00:00,  3.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.291      0.132      0.114     0.0625\n",
            "\n",
            "10 epochs completed in 0.471 hours.\n",
            "Optimizer stripped from runs/detect/bdd100k_finetune_with_val/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/bdd100k_finetune_with_val/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/bdd100k_finetune_with_val/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,008,183 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 313/313 [01:33<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033      0.289      0.132      0.114     0.0625\n",
            "               bicycle        592       1039      0.193     0.0905     0.0582     0.0209\n",
            "                 rider        527        658      0.181      0.079     0.0466     0.0185\n",
            "               trailer          2          2          0          0          0          0\n",
            "          other person          1          1          0          0          0          0\n",
            "         traffic light       5651      26884      0.339      0.119     0.0919      0.026\n",
            "                 truck       2733       4243      0.355      0.279       0.24      0.161\n",
            "                   bus       1299       1660      0.285      0.273      0.221      0.166\n",
            "         other vehicle         70         85          1          0     0.0035    0.00226\n",
            "                   car       9882     102837      0.476      0.477      0.467      0.276\n",
            "                 train         14         15          0          0          0          0\n",
            "            motorcycle        346        460      0.192     0.0348     0.0316     0.0121\n",
            "            pedestrian       3261      13425      0.336      0.214      0.179     0.0672\n",
            "          traffic sign       8211      34724      0.398      0.147      0.138     0.0616\n",
            "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/bdd100k_finetune_with_val\u001b[0m\n",
            "Fine-tuning complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Path to the YOLO runs directory\n",
        "runs_dir = \"/content/runs/detect\"\n",
        "\n",
        "# Check if the runs directory exists\n",
        "if os.path.exists(runs_dir):\n",
        "    print(f\"Contents of {runs_dir}:\")\n",
        "    for root, dirs, files in os.walk(runs_dir):\n",
        "        level = root.replace(runs_dir, \"\").count(os.sep)\n",
        "        indent = \" \" * 4 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        sub_indent = \" \" * 4 * (level + 1)\n",
        "        for file in files:\n",
        "            print(f\"{sub_indent}{file}\")\n",
        "else:\n",
        "    print(f\"{runs_dir} does not exist. Please check your training process or file paths.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGZ-Or-weKR_",
        "outputId": "c5812890-b26d-44a2-c8b6-f6fcad912bb2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/runs/detect:\n",
            "detect/\n",
            "    bdd100k_finetune_with_val/\n",
            "        train_batch2.jpg\n",
            "        events.out.tfevents.1733159429.193f363204a9.937.1\n",
            "        val_batch2_labels.jpg\n",
            "        labels.jpg\n",
            "        val_batch0_pred.jpg\n",
            "        train_batch0.jpg\n",
            "        R_curve.png\n",
            "        P_curve.png\n",
            "        PR_curve.png\n",
            "        val_batch1_labels.jpg\n",
            "        results.png\n",
            "        val_batch0_labels.jpg\n",
            "        labels_correlogram.jpg\n",
            "        confusion_matrix_normalized.png\n",
            "        results.csv\n",
            "        val_batch2_pred.jpg\n",
            "        F1_curve.png\n",
            "        confusion_matrix.png\n",
            "        args.yaml\n",
            "        val_batch1_pred.jpg\n",
            "        train_batch1.jpg\n",
            "        weights/\n",
            "            best.pt\n",
            "            last.pt\n",
            "    bdd100k_finetune_fraction/\n",
            "        events.out.tfevents.1733159110.193f363204a9.937.0\n",
            "        args.yaml\n",
            "        weights/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to results.csv\n",
        "results_csv_path = \"/content/runs/detect/bdd100k_finetune_with_val/results.csv\"\n",
        "\n",
        "if os.path.exists(results_csv_path):\n",
        "    results = pd.read_csv(results_csv_path)\n",
        "    print(\"Validation Results (First 5 rows):\")\n",
        "    print(results.head())  # Display the first few rows of the results\n",
        "else:\n",
        "    print(\"results.csv not found. Check the training process or file paths.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhBUdBI5gH5E",
        "outputId": "cdb4300d-2766-41df-a833-4e11fc7c83e5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results (First 5 rows):\n",
            "   epoch     time  train/box_loss  train/cls_loss  train/dfl_loss  \\\n",
            "0      1  185.096         1.78852         2.02533         1.05610   \n",
            "1      2  358.277         1.66585         1.26679         1.02452   \n",
            "2      3  525.967         1.62539         1.17917         1.01299   \n",
            "3      4  692.396         1.58916         1.11721         1.00457   \n",
            "4      5  858.068         1.55864         1.06273         0.99340   \n",
            "\n",
            "   metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
            "0               0.52320            0.07504           0.06281   \n",
            "1               0.45238            0.08762           0.07166   \n",
            "2               0.46332            0.09065           0.07526   \n",
            "3               0.32287            0.09654           0.08274   \n",
            "4               0.36236            0.10120           0.09336   \n",
            "\n",
            "   metrics/mAP50-95(B)  val/box_loss  val/cls_loss  val/dfl_loss    lr/pg0  \\\n",
            "0              0.03394       1.62950       1.18216       1.00946  0.000196   \n",
            "1              0.03821       1.58956       1.11597       1.00116  0.000353   \n",
            "2              0.03997       1.57292       1.08228       1.00469  0.000471   \n",
            "3              0.04383       1.53923       1.04251       0.99124  0.000413   \n",
            "4              0.05019       1.53473       1.01593       0.98450  0.000355   \n",
            "\n",
            "     lr/pg1    lr/pg2  \n",
            "0  0.000196  0.000196  \n",
            "1  0.000353  0.000353  \n",
            "2  0.000471  0.000471  \n",
            "3  0.000413  0.000413  \n",
            "4  0.000355  0.000355  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to results.csv\n",
        "results_csv_path = \"/content/runs/detect/bdd100k_finetune_with_val/results.csv\"\n",
        "\n",
        "# Load the results.csv file\n",
        "results = pd.read_csv(results_csv_path)\n",
        "\n",
        "# Extract relevant metrics (from the last epoch)\n",
        "last_epoch = results.iloc[-1]\n",
        "\n",
        "# Overall Results\n",
        "overall_results = {\n",
        "    \"Precision\": last_epoch[\"metrics/precision(B)\"],\n",
        "    \"Recall\": last_epoch[\"metrics/recall(B)\"],\n",
        "    \"mAP@50\": last_epoch[\"metrics/mAP50(B)\"],\n",
        "    \"mAP@50-95\": last_epoch[\"metrics/mAP50-95(B)\"],\n",
        "}\n",
        "\n",
        "# Print Overall Results\n",
        "print(\"\\nOverall Validation Results:\")\n",
        "for metric, value in overall_results.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Placeholder for Class-wise Results (requires YOLO's log or another source for per-class metrics)\n",
        "# In this dataset, we can only compute overall metrics from `results.csv`.\n",
        "print(\"\\nClass-wise Results (not available from results.csv):\")\n",
        "print(\"  YOLO doesn't provide class-wise metrics directly in results.csv.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSSkngPfgTkt",
        "outputId": "be14d0ac-ebb5-41f9-e043-4e5a5183ed38"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Validation Results:\n",
            "  Precision: 0.2906\n",
            "  Recall: 0.1316\n",
            "  mAP@50: 0.1136\n",
            "  mAP@50-95: 0.0625\n",
            "\n",
            "Class-wise Results (not available from results.csv):\n",
            "  YOLO doesn't provide class-wise metrics directly in results.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretrained 모델 결과\n",
        "overall_results = {\n",
        "    \"TP\": 45298,\n",
        "    \"FP\": 14740,\n",
        "    \"FN\": 140735\n",
        "}\n",
        "\n",
        "# Precision\n",
        "precision = overall_results[\"TP\"] / (overall_results[\"TP\"] + overall_results[\"FP\"])\n",
        "# Recall\n",
        "recall = overall_results[\"TP\"] / (overall_results[\"TP\"] + overall_results[\"FN\"])\n",
        "# F1-score\n",
        "f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "# Print Overall Results\n",
        "print(\"Overall Results for Pretrained Model:\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall: {recall:.4f}\")\n",
        "print(f\"  F1-Score: {f1_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jbt_LXJg01F",
        "outputId": "5b89b78d-14c8-434f-b2f7-f80c562de0c4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Results for Pretrained Model:\n",
            "  Precision: 0.7545\n",
            "  Recall: 0.2435\n",
            "  F1-Score: 0.3682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Step 1: Load YOLOv8 model (Pretrained)\n",
        "model = YOLO(\"yolov8n.pt\")  # Path to the pretrained model\n",
        "\n",
        "# Step 2: Ensure data.yaml matches training settings\n",
        "data_yaml_path = \"/content/data.yaml\"  # The same file used during training\n",
        "\n",
        "# Step 3: Perform Validation\n",
        "results = model.val(\n",
        "    data=data_yaml_path,  # Path to data.yaml\n",
        "    imgsz=320,            # Image size (same as training)\n",
        "    batch=16,             # Batch size (same as training)\n",
        "    conf=0.25,            # Confidence threshold (default)\n",
        "    workers=2,            # Number of workers (same as training)\n",
        "    device=0              # Use GPU if available\n",
        ")\n",
        "\n",
        "# Step 4: Display Results\n",
        "print(\"Validation Complete!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YimIkjvXiMgf",
        "outputId": "04a022bf-78e6-4399-c5ff-42f0f07ad0aa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_dataset/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10000/10000 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 625/625 [01:35<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      10000     186033     0.0827     0.0124      0.042     0.0288\n",
            "                person        592       1039     0.0226     0.0414     0.0122     0.0024\n",
            "               bicycle        527        658     0.0323    0.00152     0.0162    0.00162\n",
            "                   car          2          2          0          0          0          0\n",
            "            motorcycle          1          1          0          0          0          0\n",
            "              airplane       5651      26884          0          0          0          0\n",
            "                   bus       2733       4243      0.184     0.0394     0.0955     0.0785\n",
            "                 train       1299       1660      0.209    0.00843      0.106     0.0882\n",
            "                 truck         70         85    0.00272     0.0706    0.00162    0.00112\n",
            "                  boat       9882     102837      0.625   0.000194      0.314      0.203\n",
            "         traffic light         14         15          0          0          0          0\n",
            "          fire hydrant        346        460          0          0          0          0\n",
            "             stop sign       3261      13425          0          0          0          0\n",
            "         parking meter       8211      34724          0          0          0          0\n",
            "Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "Validation Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src_path = \"/content/runs\"\n",
        "dst_path = \"/content/drive/MyDrive/runs\"\n",
        "\n",
        "# Google Drive로 폴더 복사\n",
        "shutil.copytree(src_path, dst_path)\n",
        "\n",
        "print(\"Runs folder successfully copied to Google Drive!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y39E5gY6loZD",
        "outputId": "4660272e-dfc9-4fe8-90a3-5be070c3a402"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runs folder successfully copied to Google Drive!\n"
          ]
        }
      ]
    }
  ]
}