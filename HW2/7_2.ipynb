{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4052a6b3-8136-4286-883a-16f9d594705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a8922e-e2bb-4892-906f-e8f746f84a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X,K):\n",
    "    h,w=K.shape\n",
    "    Y = torch.zeros((X.shape[0]-h+1, X.shape[1]-w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572cee80-9d09-42a4-ac1b-934d6ea2ea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0,1.0,2.0],[3.0,4.0,5.0],[6.0,7.0,8.0]])\n",
    "K = torch.tensor([[0.0,1.0],[2.0,3.0]])\n",
    "corr2d(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e39e53a-3b3e-4515-814b-267af460c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7368f648-175e-4d44-b250-80ae23420f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f40adb-4705-4593-8f98-73bf1b5c4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de47d2a6-5b71-4cf0-8278-75844871a3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f008f22e-6ece-4bf5-a7ad-f979cfa37898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(), K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862e4039-2505-4154-8a04-f2df12598e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 9.297\n",
      "epoch 4, loss 3.076\n",
      "epoch 6, loss 1.137\n",
      "epoch 8, loss 0.445\n",
      "epoch 10, loss 0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2 \n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c73ab2e5-bb7f-4b11-b7ee-f29e3c4ef571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9476, -1.0343]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d5b30-ef9b-4d62-b56f-0fddf3478b7b",
   "metadata": {},
   "source": [
    "Discussion: 이번 단원에서는 CNN에서 사용하는 연산인 Cross-correlation Operation, 교차 상관 연산을 배웠다. 입력 텐서와 커널 텐서를 통해 출력 텐서를 생성하는 연산이다. 이때, 커널이라 함은 이미지의 특정 부분에 대한 연산을 수행하여 해당 부분에서 중요한 정보를 추출하는 것을 뜻한다. 합성곱에서는 커널을 뒤집어서 연산을 수행하지만, 이러한 커널은 학습 과정에서 데이터를 통해 자동으로 학습되기 때문에 CNN에서는 이 cross-correlation과 합성곱 연산의 결과가 크게 달라지지 않고 그렇기 때문에 이 분야에서는 거의 비슷한 말로 쓰인다고 한다. 이런 방식으로 이미지 데이터의 특징을 활용해서 다른 방법의 학습을 한다는 것이 인상적이었다.\n",
    "\n",
    "Excercise: Construct an image X with diagonal edges. <- X를 단순화해서 대각행렬로 생각해보자.\n",
    "\n",
    "What happens if you apply the kernel K in this section to it?\n",
    "\n",
    "어떤 K를 말하는지 살짝 헷갈리지만, 수정한 K = [1 -1]을 기준으로 하면, 이 커널은 가로로 인접한 두 픽셀의 차이를 계산하기 때문에, 어느 정도 이미지 경계를 파악 가능하지만 가로+세로를 포함한 대각선의 특성상 완전한 탐지는 힘들 것 같다.\n",
    "\n",
    "What happens if you transpose X?\n",
    "\n",
    "X를 행렬로 표현하면, 대각 행렬이고, 대각 행렬에서 X^T = X 이므로 동일할 것이다.\n",
    "\n",
    "What happens if you transpose K?\n",
    "\n",
    "K를 전치하면, 세로의 변화를 잘 감지할 것 같다. K^T를 해보면.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
