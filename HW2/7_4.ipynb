{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307f4aa7-f3e5-4e8e-96b1-390e1f031726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab783ba-9c4c-4d2d-b2b5-eb82962716a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3313c8-dd75-4330-b043-c38bbb7a8b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd763a1-142e-4dfd-818c-5ab1ae9ee6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f4ea4b-719b-4666-b913-45be2ba8aa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb344738-4be1-4f1c-b5a0-d39599f96f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b348bd5-275e-4e80-89f0-db67167103c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c1d7b1f-5837-48e2-9fe8-4f0aa2b8cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5353017-ffee-49c8-b6d1-a196441b5d3f",
   "metadata": {},
   "source": [
    "Discussion: 이번 단원에서는, CNN 중 다중 입력 채널 및 다중 출력 채널을 처리하는 방식에 대해서 배웠다. 이번 단원 전까지는 단일 입력 채널에 대해서 다루었지만, 실제로 이미지에서는 여러 입력 채널이 있기 때문에 이를 처리하여야 한다. 합성곱 연산을 할 때에도 마찬가지로, 입력 데이터의 채널의 수 n에 따라 각 채널마다 별도의 n차원 커널이 필요하다는 것이 중요한 내용이라고 생각했다. 이러한 입력 채널과 마찬가지로, 출력 채널 역시 다중 출력 채널이 필요한데, 이미지에는 한 가지 특징이 있는 것이 아니라 많은 특징을 가지고 있기 때문에 다중 출력 채널을 사용하여 여러 가지 특징을 동시에 학습할 수 있도록 해준다. (예를 들어, edge를 감지하는 채널과 shape를 감지하는 채널) 이렇게 출력 채널을 여러 개로 만들기 위해서는, 각 출력 채널마다 별도의 합성곱 커널이 필요하기 때문에 커널의 수가 많아지는 특징이 있다.\n",
    "추가적으로, 1x1 convolution이라는 개념도 나왔는데, 이는 각 픽셀에서 channel간의 상호작용을 학습하는 데 사용하여. 각 픽셀의 다양한 특징을 통합하는 기능을 한다고 한다. 각 픽셀의 값을 linear combination하여 새로운 값을 계산하는 방식이라고 한다. 다른 기초 전공들 (자구, 알고)에서 많이 다루었던 개념이기도 한 연산의 cost는 O(input size x output size)라고 한다.\n",
    "\n",
    "Exercise Assume that we have two convolution kernels of size k1 and k2, respectively (with no nonlinearity in between).\n",
    "\n",
    "Prove that the result of the operation can be expressed by a single convolution.\n",
    "합성곱 연산은 결합법칙이 성립하기 때문에, 차례로 입력하는 상황인 (X * k1) * k2와 , 한번에 적용하는 상황인 X * (k1 * k2)가 같을 수 밖에 없다.\n",
    "What is the dimensionality of the equivalent single convolution?\n",
    "(k1 +  k2 - 1)^2 (k1의 차원이 k1^2이고, k2의 차원이 k2^2라고 가정)\n",
    "Is the converse true, i.e., can you always decompose a convolution into two smaller ones?\n",
    "이것은 잘 몰라서 인터넷을 검색해 봤는데, 특정한 경우를 제외하고는 불가능하다고 한다. 왜냐하면 큰 커널의 학습 과정에서 얻어진 복잡한 필터링은 더 작은 커널로 나누었을 때 동일한 필터링 결과를 보장할 수 없기 때문이라고 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
